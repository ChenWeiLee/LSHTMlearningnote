# (PART) 廣義線性迴歸模型 {-}

# 重要概念複習

## 概率論學派統計推斷要點複習

下面我們一起用二項分佈的概念 ($n$ 個對象中 $K$ 個“事件”)，來複習概率論學派的統計推斷要點。

1. 模型，the Model。一個統計模型，描述的不僅僅是我們研究的人羣的一些特徵，而且通常一個模型還可提供如何從人羣中收集該樣本的信息。<br> 用二項分佈的概念來解釋，人羣是衆多個體的集合，他們中的一部分佔比 $\pi$ 的人身上發生了某個事件。從這個人羣的集合中，我們隨機抽取 $n$ 個對象作爲**研究樣本**，該樣本中有 $K$ 個人身上發生了事件。此時，我們說 $K$ 服從人羣比例爲 $\pi$ 的二項分佈：$K \sim \text{Bin}(n,\pi)$。
2. 參數，parameters。模型中的參數反映了人羣的某些特徵。在實際應用中，從來沒有“人類”能知道人羣參數的真實值，渺小的我們從人羣中抽取樣本，用於推斷 “上帝才知道的” 這些代表了人羣特徵的參數。<br> 在二項分佈的情境下，有且只有一個人羣參數，人羣中事件的比例 $\pi$。
3. 參數估計量，parameter estimators。估計量是樣本的統計量，被用來估計未知的總體參數。估計量 estimator，是一個隨機變量，是我們計算估計值的一般形式。估計值 estimate，是每個樣本通過統計模型計算獲得的估計量的真實值，每採樣一次，計算獲得的估計值理論上會略有不同。<br> 二項分佈的上下文中，人羣事件比例 -- 這一參數 $\pi$ 的天然估計量是 $\hat\pi = \frac{K}{n}$，當一個樣本中發現 $K = k$，該樣本給出的估計值是 $\frac{k}{n}$。
4. 研究假設，hypotheses。研究假設是實驗前我們提出的要被檢驗的一些關於人羣某些特徵參數的 “陳述 statement”。可以是猜想參數等於某個特定值，或者多個參數大小相同。<br> 二項分佈的數據裏，只有一個人羣參數，$\pi$。可能提出的零假設和替代假設有很多，$\pi = 0.5 \text{ v.s. } \pi \neq 0.5$ 是其中之一的複合型假設。

## 似然

如果一個模型只有一個參數 $\theta$，樣本數據已知的話，該參數的似然爲：

$$\text{L}(\theta | \text{data}) = \text{Pr}(\text{data}|\theta)$$

其中，$\text{Pr}(\text{data}|\theta)$ 對於離散型變量，是概率方程 probability function；對於連續型變量，則是概率密度方程 probability density function (PDF)。

對數似然，就是上面的似然方程取自然底數的對數方程：

$$\ell(\theta | \text{data}) = \text{ln}\{ \text{L}(\theta | \text{data}) \}$$


## 極大似然估計

當數據收集完畢，從獲得的數據中計算獲得的能夠使似然方程/或對數似然方程取得極大值的 $\theta$ 的大小，被叫做極大似然估計 $\text{(MLE)}$，且通常數學標記會在參數上加一頂帽子： $\hat\theta$。收集不同的樣本，在相同的似然方程或對數似然方程下，極大似然估計不同。

1. 許多問題，我們獲得極大似然估計的方法是先定義好模型的似然方程，然後求該方程的一階導數之後計算使之等於零的參數值大小就是 $\text{MLE } \hat\theta$。此時，你還要記得再求一次二階導數，看是否小於零，以確保前一步計算獲得的值給出的似然方程是極大值。
2. 更多的時候我們用對數似然方程以簡化計算過程：

$$
\begin{aligned}
\left.\frac{\text{d}}{\text{d } \theta}\ell (\theta | \text{data})\right\vert_{\theta=\hat{\theta}}  &= \ell^\prime(\hat\theta) = 0 \\
\left.\frac{\text{d}^2}{\text{d } \theta^2}\ell (\theta | \text{data})\right\vert_{\theta=\hat{\theta}}  &= \ell^{\prime\prime}(\hat\theta) < 0
\end{aligned}
$$

3. 我們只關心似然方程的形狀，所以方程中不包含參數的部分可全部忽略掉。
4. $\text{MLE}$ 的一些關鍵性質：
    1. 漸進無偏 asymptotically unbiased：當 $n\rightarrow \infty$ 時，$E(\hat\theta) \rightarrow \theta$；
    2. 一致性 consistency：隨着樣本量的增加，$\hat\theta$ 收斂於 (converges) 總體參數 $\theta$；
    3. 漸進正態分佈 asymptotically normality：隨着樣本量增加，$\hat\theta$ 的樣本分佈收斂於 (converges) 正態分佈，方差爲  $$E[-\ell^{\prime\prime}(\theta)]^{-1}=[-\ell^{\prime\prime}(\hat\theta)]^{-1}$$
    4. 恆定性 invariance：如果 $\hat\theta$ 是 $\text{MLE}$，那麼 $\theta$ 被數學轉換以後 $g(\theta)$ 的方程的 $\text{MLE}$ 是 $g(\hat\theta)$
5. 似然理論可以直接拓展到多個參數的情況。一般地，如果一個模型有 $p$ 個參數 $\mathbf{\theta} = (\theta_1, \theta_2, \cdots, \theta_p)^T$，這些參數在給定數據的條件下的似然方程爲：$$\text{L}(\mathbf{\theta} | \text{data}) = \text{Pr}(\text{data} | \mathbf{\theta})$$ 其中，概率 (密度) 方程在多個參數時變成聯合 (joint) 概率 (密度) 方程。似然，也是各個參數的聯合似然方程。此時，參數向量 $\mathbf{\theta} = (\theta_1, \theta_2, \cdots, \theta_p)^T$ 的方差協方差矩陣的估計量爲

$$
\hat{\text{Var}}(\mathbf{\hat\theta}) = - \left(
\begin{array}{c}
\frac{\partial^2\ell}{\partial\theta^2_1} & \frac{\partial^2\ell}{\partial\theta_2\partial\theta_1} & \cdots & \frac{\partial^2\ell}{\partial\theta_k\partial\theta_1}  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_2} & \frac{\partial^2\ell}{\partial\theta^2_2} & \cdots & \frac{\partial^2\ell}{\partial\theta_k\partial\theta_2}  \\
\vdots & \vdots & \ddots & \vdots  \\
\frac{\partial^2\ell}{\partial\theta_1\partial\theta_k} & \frac{\partial^2\ell}{\partial\theta_2\partial\theta_k} & \cdots & \frac{\partial^2\ell}{\partial\theta^2_k}  \\
\end{array}
\right)^{-1}_{\theta=\hat\theta}
$$


# 廣義線性迴歸入門

# 二項分佈的廣義線性迴歸模型

# 模型比較和擬合優度

# 計數型因變量

# 率的廣義線性迴歸

# 混雜，調整，交互作用

# 邏輯迴歸

# 分析策略

# 模型檢查

# Assessing model performance

# Matched studies

# 條件邏輯迴歸


# Multinomial Logistic Regression

# Ordinal Logistic Regression
