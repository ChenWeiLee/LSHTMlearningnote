# (PART) 統計分析方法 Analytical Techniques {-}

# 探索數據和簡單描述

##  數據分析的流程



```{r echo=FALSE, fig.asp=.7, fig.width=4, fig.cap='Population, sample and statistical inference', fig.align='center', out.width='70%'}
knitr::include_graphics("img/AT1.png")
```

統計推斷的目的，是通過從人群中取樣本，經過對樣本特徵的 (描述) 統計分析 (summary statistic)，去推斷人群的相應特徵。

所以，無論什麼數據，到手以後我們一定要做的第一件事情，就是對其進行總結和描述，其過程又要盡可能地簡單明了。

在絕大多數的科學研究中數據分析都很重要，然而現實是，它多數情況下只出現在研究的第三部分：

1. 研究設計
2. 實施研究，收集數據
3. **數據分析**
4. 結果報告

### 研究設計和實施

正確的統計推斷需要獲得具有代表性可以值得分析的數據，這必須建立在實驗研究設計良好，實施過程縝密的基礎上。設計糟糕，執行效率低下或者漏洞百出的實驗，給出的實驗數據必然是不可靠的，分析它也沒有意義。但是，不是說設計和實施階段就不需要統計學家的參與了。相反地，統計學家必須在研究實施過程中盡可能早的階段 (實驗設計) 參與進來。因為理解了實驗的目的，統計學家才能真正決定這個實驗要收集怎樣的數據，多大的樣本量，實施怎樣的分析方法。這些決定，注定了一項實驗研究的成敗。

### 數據分析

然而現實很殘酷，多數情況下實驗設計階段好像沒有統計學家什麼事，等到了數據分析階段，某些人才拍腦袋想讓統計學家來拯救他們收集的垃圾數據。通常都太晚了 (too late!)。

假設理想狀態下，我們收集到了想要分析的數據，可是接下來的工作流程的第一步，又常常被太多人忽略。許多 “科學家” 興奮地把數據輸入軟件，立刻就開始著手建立數學模型，進行假設檢驗，卻對數據的特徵一無所知！要知道，建立怎樣的模型，做怎樣的推斷，選用什麼樣的分析手段，都必須建立在你對數據內容完全熟悉的前提下，才能正確地實施。

數據分析第一步：**數據清理, data cleaning**。

這一步的目的很簡單，把收集來的粗糙的，充滿了缺失值和數據類型註解等等無法直接分析的數據，整理打扮成可以建模的數據庫。這個過程中，你可能需要對某些變量進行分類，可能兩三個實驗的結果需要被合併協調，可能在這個過程中你會發現數據錄入出現了一些錯誤導致數據庫裡有一些異常值，甚至是重複錄入。所以，各位小伙伴當你拿到一個數據準備分析的第一步，你必須要先了解你的數據。常用的手段包括簡單作圖，對感興趣的變量做概括分析 (summary your data!)。除此之外，由於沒有人能保證實驗中能收集到所有對象的完整數據，我們還需要分析缺失數據的特徵，思考他們為什麼會變成缺失數據。

## 數據類型

不同類型的數據，使用的初步描述手段各不相同。因此區分定性數據和定量數據，連續型數據，離散型數據，分類型數據顯得十分必要。

1. 連續型變量，continuous data  <br>連續型數據多來自實驗中對某些特徵的測量，例如身高，體重等，它們本質上是一組連續型的數據。現實生活中接觸到的許多數據也都是連續型的，例如：時間，距離，骨骼密度，藥物濃度等等。所謂連續型變量是由於它理論上可以取某段數值區間內的任何值。當然我們還會被測量尺度的精確度所局限。
2. 離散型變量，discrete data  <br>許多數據，是通過計數來收集的。離散型變量的本質上也是屬於數值型數據 (numeric)，特徵是這種數值型數據總是**取正整數**或者零。例如，醫院中發生感染的次數，一個家庭中兄弟姐妹的人數，術後患者存活天數等等。
3. 分類型變量，categorical data <br>分類型變量的數據，其每一個觀察值都歸類於一種類別 (或者屬性)。分類型數據和離散型數據最大的不同是，它從本質上說就不屬於數值型數據。例如，頭髮的顏色 (紅色，黃色，黑色)，職業類型 (裝修工人，教師，總統)。儘管分類型數據本質上不是數值，分析過程中我們常常會給它們賦予一定的數值以便於計算。
    1. 二分類型數據，binary：十分常見，例如，生存/死亡，有效/無效，成功/失敗；
    2. 名義型數據，nominal：數據本身沒有高低順序之分，例如，種族，血型等；
    3. 排序型數據，ordinal：每個分類是包函了順序含義的數據，例如，回答某些問卷問題時用的 “十分同意，同意，不同意，十分不同意”，某些癌症使用的分級診斷 “一級，二級，三級，終級”，對一些結果的評價時使用的 “優，良，中，差”。

其實，對於連續型變量我們還常常會將它們轉化成分類型變量，使用一些特定的或者事先定義好的閾值 (cutoff values) 把連續型數據分組，分級，分層等等。最常見的例子就是體重指數 (BMI)，它本身是一個連續型的變量，但是又可以根據定義好的閾值把它分類成低體重 ($< 18.5 \; kg/m^2$)，正常體重 ($18.5 - 24.9 \; kg/m^2$)，超重 ($25-29.9 \; kg/m^2$)，肥胖 ($\geqslant 30 \; kg/m^2$)。另一個例子是血紅蛋白 (haemoglobin, $g/l$)，它本身是一個連續型變量，但是我們利用它的閾值 (女性，$<120 \; g/l$；男性，$< 130 \; g/l$)，作為診斷是否患有貧血症的依據。

把連續型變量進行分類處理的代價是信息的丟失。如果一個人的體重指數是 $25$，他/她的數據被和體重指數為 $29.9$ 的人當作相同數值來對待是否合理是我們需要考慮的問題。而且許多情況下閾值的定義並不能達成共識，即使達成共識的閾值又是十分人為且恣意的，它可能導致一些相關關係被“強化”，或者反過來被“弱化”。所以，如果要對連續型數值進行分組，現在的要求是，在實驗設計階段就必須明確分組的閾值之定義，而不能在看到數據以後進行人為地劃分。**更加不推薦的是直接使用四分位或者五分位來對數據分組。**

##  如何總結並展示數據

光觀察原始數據很難真正明白數據的分佈特徵和形式，所以使用表格，或者用散點圖，柱狀圖等形式來描述數據就成為了常用的手段。前一節所描述的數據類型，決定了一組數據該如何被描述。

###  離散型分類型數據的描述 - 頻數分佈表 frequency table

下面的表格就是使用頻數分佈表來描述 `cars` 這個數據包中不同車速 (mph) 的分佈。汽車車速本身應該是一個連續型變量，但是這是1920年的數據當時的記錄只精確到整數，因此人為地造成了一組離散型變量的情況。下面的第二個表格使用的是繪圖瑞士軍刀包 `ggplot2` 裡自帶的鑽石數據。其中 `cut` 是對於鑽石切割水平的評價，所以是一個帶有排序性質的分組型變量。

```{r, message=FALSE}
data("cars")
epiDisplay::tab1(cars$speed, graph = FALSE)
library(ggplot2); data("diamonds")
epiDisplay::tab1(diamonds$cut, graph = FALSE)
```
離散型變量和分類型變量的描述還可以使用柱狀圖的形式來展示如下：

```{r car-speed, echo=FALSE, fig.asp=.7, fig.width=4, fig.cap='Bar chart displaying the speed of cars', fig.align='center', out.width='80%'}
library(ggthemes)
ggplot(cars, aes(x=speed)) + geom_bar() +
   theme_stata()+labs(x = "Speed (mph)", y = "Frequency")
```

```{r diamonds-cut, echo=FALSE, fig.asp=.7, fig.width=4, fig.cap='Bar chart displaying distribution of evaluation of diamonds cut', fig.align='center', out.width='80%'}
ggplot(diamonds, aes(x=cut)) + geom_bar() +
   theme_stata()+labs(x = "Quality of the cut", y = "Frequency")
```

上面這兩圖的 y 軸都用的是頻率，當然還可以使用百分比。不同組間分類型變量的分佈比較的話更常使用百分比作為 y 軸。如下面的表格及百分比條形圖所示。

```{r message=FALSE}

library(Epi)

diamonds$clarity2g <- "Good"
diamonds$clarity2g[(diamonds$clarity=="I1")|
                    (diamonds$clarity=="SI2")|
                     (diamonds$clarity=="SI1")|
                     (diamonds$clarity=="VS2")] <- "Poor"
tab <- stat.table(index=list(Cut=cut,Clarity=clarity2g),
                   contents=list(count(),percent(cut)), data=diamonds, margins=T)
print(tab, digits = 2)

```

```{r diamonds-cut-clarity, echo=FALSE, fig.asp=.7, fig.width=7, fig.cap='Bar chart displaying distribution of evaluation of diamonds cut by clarity', fig.align='center', out.width='80%'}
library(plyr)
library(ggsci)
T1 <-  table(diamonds$clarity2g, diamonds$cut)
Prop1 <-  T1/rowSums(T1)
Prop1 <- as.data.frame(Prop1)
names(Prop1) <- c("Clarity", "Cut",  "Percent")
ggplot(Prop1, aes(x=Clarity, y=Percent, fill=Cut)) + geom_bar(stat = "identity", width = 0.5)+ theme_bw() +
  coord_flip() + scale_fill_jama() +
  theme(legend.position = "bottom", legend.direction = "horizontal",
         panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(colour = "black"))
```

### 連續型變量

連續型變量如果做頻數分佈表一般提供的信息量就較小。常用來描述連續型變量的手段是柱狀圖，histogram，和箱形圖，boxplot。柱狀圖應該不必過多解釋。箱形圖，展示的是連續型變量的中位數，四分位，範圍值，以及異常值。一個典型的箱形圖，中間的方形區域包括了該數據的四分位距，interquartile range (即中間 50% 的數據, IQR)。

```{r diamond-carat-box, echo=FALSE, fig.asp=.7, fig.width=6, fig.cap='Boxplot of the diamond carat data', fig.align='center', out.width='80%'}
boxplot(diamonds$carat[diamonds$carat < 2.1])
```


R作出的箱形圖如 \@ref(fig:diamond-carat-box) 所示，箱子以上的橫線，意為最高值為75%分位值加上1.5倍的IQR；箱子以下橫線，意為最低值為25%分位值減去1.5倍的IQR。其他的觀察值如果不在這個上下限範圍之內的，會用黑點標記出來。這些值被認為是異常值 (outliers)。

## 數據總結方案：位置，分散，偏度，和峰度

### 位置

描述一組連續型變量的位置，location，此處的位置指的是數據分佈的**中心**位置，常用的數值是眾數 (mode)，中位數 (median)，均值 (mean)。
    - 眾數 mode，的定義是，一組數據中出現最多次的數值大小；
    - 中位數 median，的定義是，一組數據中從小到大/或者從大到小排序後50%位置的數值大小，如果觀察值有偶數個，中位數的定義是中間兩個數值的平均值大小；
    - 算術平均值 arithmetic mean 的**大小受異常值影響較大**，通常簡略為均值，其定義可以用下面的表達式：$$\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i$$
    - 幾何平均值 geometrix mean，常用在正偏態分佈數據 (positively skewed data)，其定義為： $$\sqrt[n]{\prod_{i=1}^n X_i}=exp[\frac{1}{n}\sum_{i=1}^n log_e(X_i)]$$
    - 調和平均值 harmonic mean，是所有觀察值的倒數和的倒數，定義為：$$\frac{1}{\frac{1}{n}\sum_{i=1}^n\frac{1}{X_i}}$$



### 分散

數據的分散程度，dispersion，也就是數據的波動大小 variation。同樣均值的數據，他們的分散可能差別很大：

```{r diff-dispersion, echo=FALSE, fig.align='center', fig.cap='Distributions with similar central location but different dispersion', fig.height=8, fig.width=6, out.width='80%'}
par(mfrow=c(2,1))
set.seed(1234)
a <- rnorm(10000,50, 5)
b <- rnorm(10000, 50, 10)
hist(a, xlim=c(0,100), breaks = 25,  col='lightblue',
     xlab = "Mean=50, SD=5", freq = TRUE, main = "")

hist(b, xlim=c(0,100), breaks = 30,  col='lightblue',
     xlab = "Mean=50, SD=10", freq = TRUE, main = "")
```

分散程度的描述方法花樣不少，我們這裡先考慮範圍 (range)，四分位差 (interquartile range)，方差 (variance)，標準差 (standard deviation)。

#### 範圍 range

- 定義：最大值和最小值的差。

- 缺點：受樣本量大小，以及異常值影響較大。

- 在表格，論文中需要同時報告最大值和最小值。

#### 四分位差 interquartile range (IQR)

- 定義：四分位差是包含了數據中間 50% 數值的範圍。即，75%分位數-25%分位數的差值。

- 當觀察值數量為奇數個時，計算方法為：去掉中位數，計算大於中位數和小於兩個部分數值的中位數，求其差，例如：$5,10,12,14,16,19,22$ 這組數字，25%分位數為10，75%分位數為19，所以IQR等於9。

- 當觀察值數量為偶數個時，計算方法為：計算較小的50%數值的中位數，和較大50%數值的中位數，求其差，例如：$5,10,12,14,16,19,22,38$ 這組數字，上下兩半部分的中位數分別是 $Q_L=\frac{10+12}{2}=11;\;Q_U=\frac{19+22}{2}=20.5$，所以，其IQR等於9.5.

- 在表格，論文中需要同時報告25%，75%分位數兩個數值，例：[11,20.5]。

#### 方差和標準差 variance and standard deviation

- 先定義每一個觀察值和均值之間的差為 $D_i = X_i - \bar{X}$。

- 根據定義，$\frac{1}{n}\sum_{i=1}^n D_i=0$。

- 樣本方差 Variance 被定義為 $\frac{1}{n-1}\sum_{i=1}^n D_i^2$。

- 樣本方差的平方根，被定義為標準差 standard deviation，$\text{SD}=\sqrt{\frac{1}{n-1}\sum_{i=1}^n D_i^2}$

- 更常見的表達式為：

$$
\begin{aligned}
\text{Var} &= \frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2 \\
           &= \frac{1}{n-1}[(\sum_{i=1}^nX_i^2)-n\bar{X}^2]
\end{aligned}
$$

此處分母為 $n-1$ 而不是 $n$ 的原因，需要參考推斷部分的解釋 (Section \@ref(samplevarbias))。

- 方差標準差受異常值影響較大。例如，下面的數據：

$$
5, 9, 12, 14, 14, 15, 16, 19, 22\;\;\; \text{Var}=25.5\\
5, 9, 12, 14, 14, 15, 16, 19, 58\;\; \text{Var}=241.5
$$

### 偏度 skewness

使用柱狀圖來描述數據時，如果柱狀圖左右基本對稱 (中位數和均值基本一致)，偏度為零，正態分佈數據都是左右對稱的。如果柱狀圖右側的尾巴較長，偏度為正；如果左側的尾巴較長，偏度為負。偏度計算公式為：

$$
\frac{\frac{1}{n}\sum_{i=1}^n D_i^3}{(\frac{1}{n}\sum_{i=1}^n D_i^2)^{\frac{3}{2}}}
$$

```{r skewness, echo=FALSE, fig.align='center', fig.cap='Relationship between skew and measures of location', fig.height=10, fig.width=7, out.width='80%'}
set.seed(1234)
par(mfrow=c(3,1))
# normal distribution
 N <- 10000
a <- rnorm(N, 0, 1)
hist(a, breaks = 30,
     xlim=c(min(a), max(a)), probability = T,
   col='lightblue', xlab='Skew = 0 \n mean=median', ylab=' ', axes=F,
   main='Normal \n symmetric',cex.lab=1.5)

# positively skewed

x <- rbeta(N,2,80)
 hist(x, breaks = 30,
 xlim=c(min(x),max(x)), probability=T,
   col='lightblue', xlab='Skew > 0 \n Mean > median', ylab=' ', axes=F,
   main='Positively Skewed \n assymmetric',cex.lab=1.5)

# negatively skewed

x <- rbeta(N,80,2)
hist(x, breaks = 30,
     xlim=c(min(x),max(x)), probability=T,
     col='lightblue', xlab='Skew < 0 \n Mean < median', ylab=' ', axes=F,
     main='Negatively Skewed \n assymmetric',cex.lab=1.5)

```



### 峯度 kurtosis

峯度是描述數據分佈的最後一個指標。峯度衡量的是一組數據分佈的尾部的厚度。一個正態分佈數據，大約 5% 的數據分佈在左右兩邊的尾部 (2.5% 低於 $\mu-2\sigma$，2.5% 高於 $\mu +2\sigma$)。峯度測量的是一組數據尾部數據的分佈和正態分佈兩側尾部數據之間的差距。

峯度的計算公式爲：
$$
\frac{\frac{1}{n}\sum_{i=1}^nD_i^4}{(\frac{1}{n}\sum_{i=1}^nD_i^2)^2}
$$
一個正態分佈數據，峯度值爲 3。當左右兩段的數值佔比低於正態分佈預期時，峯度值小於 3。反之，峯度大於 3。尾部較厚 (峯度較大) 的典型分佈之一是 $t$ 分佈 (圖 \@ref(fig:kurtosis))


```{r kurtosis, echo=FALSE, fig.align='center', fig.cap='t distributions with 5 and 10 degrees of freedom compared with a standard normal distribution', fig.height=4, fig.width=6, out.width='80%'}
set.seed(1234)
#hist(x, breaks = 30, probability = T)
curve(dt(x, 10), xlim = c(-5,5), frame=F, type = "l", lty=2, lwd = 2, xlab = "", ylab = "Density")
curve(dt(x, 5), xlim = c(-5,5), add = T, col="red", type = "l", lty=3, lwd=2)
curve(dnorm(x), xlim = c(-5,5), add = T, col="blue")
legend("topright", legend=c("Normal", "t with 10 df", "t with 5 df"), col=c("blue", "black", "red"), lty = c(1, 2, 3), lwd = c(1, 2, 2) ,bty="n")
```

# 信賴區間 confidence intervals

## 定義

信賴區間的定義，曾經在統計推斷中介紹過 (Section \@ref(CI-for-sample-mean))。信賴區間 (CI)，提供了一種對參數估計精確度的度量。CI，也是一種統計量，有自己的樣本分佈，它總是成對成對地出現的。L，表示下限，U，表示上限。顯著性水平 (confidence level) 下的下限和上限之間的間距大小，是由信賴區間本身的樣本分佈決定的。

一般地，對於一個總體參數 $\mu$，它的 $100(1-\alpha)\text{CI}$  信賴區間的含義爲：

$$
\begin{equation}
\text{Prob}\{\mu\in (\text{L}, \text{U}) | \mu\} = (1-\alpha)
\end{equation}
(\#eq:confi)
$$

所以，一個總體參數 $\mu$，的 $95\%\text{CI}$ 信賴區間爲：

$$
\begin{equation}
\text{Prob}\{ \mu \in (\text{L, U}) | \mu\} =0.95
\end{equation}
(\#eq:confinv)
$$

用公式 \@ref(eq:confinv) 來解釋就是，區間 $\text{(L, U)}$ 內包含了總體參數 $\mu$ 的概率爲 $95\%$。本文以下部分從公式中省略 $|\mu$ 部分。但是必須要記住，概率論環境下的信賴區間 (或者其他統計學參數估計) 都是總體參數的條件概率。在概率論語境下，信賴區間一般是左右對稱的。所以 $100(1-\alpha)\%\text{CI}$ 的含義可以解讀爲：

$$
\begin{equation}
\text{Prob} \{ \mu \leqslant \text{L} \} = \text{Prob} \{ \mu \geqslant \text{U} \} = \frac{\alpha}{2}
\end{equation}
(\#eq:confinvmean)
$$


```{r CIdefin, echo=FALSE, fig.asp=.7, fig.width=4, fig.align='center', out.width='80%', fig.cap="General definition of a CI for a 95% CI"}
knitr::include_graphics("img/Selection_100.png")
```


## 利用總體參數的樣本分佈求信賴區間

總體參數的樣本分佈是求其信賴區間的關鍵。假設 $\hat\mu$ 是總體參數 $\mu$ 的估計量。且已知存在兩個單調遞增函數 $A(\mu), B(\mu)$ 來描述該總體參數 $\mu$ ：


$$
\begin{equation}
\text{Prob} \{ \hat\mu \leqslant A(\mu) \} = \text{Prob} \{ \hat\mu \geqslant B(\mu) \} = \frac{\alpha}{2}
\end{equation}
(\#eq:AT4)
$$


所以，


$$
\begin{equation}
\text{Prob} \{ A^{-1} (\hat\mu) \leqslant \mu \} = \text{Prob} \{ B^{-1}(\hat\mu) \geqslant \mu \} = \frac{\alpha}{2}
\end{equation}
(\#eq:AT5)
$$




因此，$A^{-1}(\hat\mu), B^{-1}(\hat\mu)$  就是我們想要找的公式 (\@ref(eq:confinvmean)) 參數的估計信賴區間的下限 $\text{L}$，和上限  $\text{U}$。所以，關鍵的任務就在於，每一次尋找計算參數樣本分佈的方程 $A, B$ 。

## 情況1：已知方差的正態分佈數據均值的信賴區間

從已知**正態分佈且方差**爲 $\sigma^2$ 的人羣中抽取樣本量爲 $n$ 的相互獨立觀察數據 $Y_i (i=1,2,\cdots,n)$。該樣本均值的估計量 $\hat\mu=\bar{Y}$，也服從方差已知的 $(\frac{\sigma^2}{n})$ 正態分佈：


$$
\begin{equation}
\bar{Y}\sim N(\mu, \frac{\sigma^2}{n}) \Leftrightarrow Z=\frac{\bar{Y}-\mu}{\sqrt{\frac{\sigma^2}{n}}} \sim N(0,1)
\end{equation}
(\#eq:AT6)
$$


所以利用標準正態分佈，往公式 \@ref(eq:confinvmean) 儘可能靠：$\text{Prob}\{ Z \leqslant z_{\alpha/2}\} = \text{Prob}\{ Z \geqslant z_{1-\alpha/2}\} = \frac{\alpha}{2}$ 。

把式子 \@ref(eq:AT6) 代入以後：


$$
\begin{equation}
\text{Prob}\{ \bar{Y} \leqslant \mu+z_{\alpha/2}\frac{\alpha}{\sqrt{n}} \} = \text{Prob}\{ \bar{Y} \geqslant \mu+z_{1-\alpha/2}\frac{\alpha}{\sqrt{n}} \} = \frac{\alpha}{2}
\end{equation}
(\#eq:AT7)
$$


至此，我們找到了描述總體均值的單調函數：


$$
\begin{aligned}
A(\mu) &= \mu + z_{\alpha/2}\frac{\sigma}{\sqrt{n}} \\
B(\mu) &= \mu + z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}
\end{aligned}
$$


由於標準正態分佈左右對稱，所以 $z_{\alpha/2}=-z_{1-\alpha/2}$ ，因而，$A(\mu) = \mu - z_{1-\alpha/2}\frac{\sigma}{n}$。

此時，求信賴區間上限和下限的方法應該已經一目瞭然：


$$
\begin{equation}
\text{U} =A^{-1}(\bar{Y})=\bar{Y} + z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}} \\
\text{L} = B^{-1}(\bar{Y})=\bar{Y} - z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}
\end{equation}
(\#eq:AT2-8)
$$


我們也常將它簡寫成爲：$\text{CI} = \bar{Y} \pm z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$。

它的意義是：


$$
\begin{equation}
\text{Prob} \{ \bar{Y} - z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}} < \mu < \bar{Y} + z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}} \} = 1-\alpha
\end{equation}
(\#eq:AT2-9)
$$


所以區間 $(\bar{Y} - z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}, \bar{Y} + z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}})$ 包含了總體參數均值 $(\mu)$ 的概率是 $1-\alpha$。我們把這個區間叫做總體均值 $\mu$ 的 $100(1-\alpha)\%$ 信賴區間。常說的 $95\%$ 信賴區間我們使用的 $z_{0.975} = 1.96$。其他置信水平的 $z$ 值舉例如下：


$$
\begin{array}{lr}
z_{0.90} = 1.28 &  \text{for } 80\% \text{ level} \\
z_{0.95} = 1.645 &  \text{for } 90\% \text{ level} \\
z_{0.995} = 2.58 &  \text{for } 99\% \text{ level} \\
z_{0.9995} = 3.29 &  \text{for } 99.9\% \text{ level} \\
\end{array}
$$


所以，根據上面羅列的不同置信水平下 $z$ 值的大小，我們不難判斷 $\text{CI} = \bar{Y} - z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$ 範圍隨着標準差增大而變寬 (不精確)，隨着樣本量增加而變窄 (精確)。

這裏補充另一個容易混淆的概念，參數估計的信賴區間公式 $\text{CI} = \bar{Y} \pm z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}$ ，和參考值範圍 (reference range) 是不同的概念。後者的公式爲 $\bar{Y}\pm z_{1-\alpha/2} \sigma$。參考值範圍的意義是， $95\%$ 的樣本數據包含在這個區間內。信賴區間，給出的是這個樣本對總體均值的估計的**精確度**。

## 信賴區間的意義 {#CImean}

當 $\alpha = 0.05$ 時，我們說$(\bar{Y} - z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}, \bar{Y} + z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}})$ 包含了總體參數均值 $(\mu)$ 的概率是 $95\%$。但是要記住，千萬不能說：總體參數 $\mu$ 有 $95\%$ 的概率落在這個信賴區間內。因爲**總體參數不是隨機變量**，它不會隨我們的樣本變化而變化，它是恆定不變的。我們每一次實驗，每一次採樣，獲得的樣本數據，計算出一個新的信賴區間，這樣的區間都是在估計這個未知位置的總體參數。所以，**從長遠來說，相同的實驗，重複20次，其中19次計算獲得的信賴區間，會包含真實的總體參數。**

## 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間

多數情況下，總體的方差我們無從知曉。它也必須通過實驗數據來估計 $\hat\sigma^2$。那麼，下面的公式計算的統計量 $T$ 服從自由度爲 $n-1$ 的 $t$ 分佈：

$$
T=\frac{\bar{Y}-\mu}{\sqrt{\hat\sigma^2/n}} \sim t_{n-1}
$$

用跟前面類似的辦法，用統計量 $T$ 取代 $Z$，我們可以求未知方差時正態分佈數據均值的信賴區間 (類比 \@ref(eq:AT2-8))：


$$
\begin{aligned}
&\text{U} = \bar{Y} + t_{n-1, 1-\alpha/2}\frac{\sigma}{\sqrt{n}} \\
&\text{L} = \bar{Y} - z_{n-1, 1-\alpha/2}\frac{\sigma}{\sqrt{n}} \\
&\text{Or, equivalently :} \\
&\text{CI } = \bar{Y} \pm t_{n-1, 1-\alpha/2}\frac{\sigma}{\sqrt{n}}
\end{aligned}
(\#eq:AT2-10)
$$

## 情況3：服從正態分佈的隨機變量方差的信賴區間

用 $Y_i (i=1,2,\cdots,n)$ 標記樣本量爲 $n$ 的獨立觀察數據。已知該數據來自的人羣服從正態分佈，但是方差未知。那麼從統計推斷第二章 (Section \@ref(samplevar)) 推導過的內容，我們知道：

$$
\begin{aligned}
&\text{Sample variance is defined as: } \\
&\hat\sigma^2 = \frac{\sum_{i=1}^n(Y_i-\bar{Y})^2}{n-1} \\
&\text{and } \\
&\frac{(n-1)\hat\sigma^2}{\sigma^2} \sim \chi^2_{n-1} \\
&\text{It follows that we want } \\
&\text{Prob}\{ \hat\sigma^2 \leqslant \frac{\sigma^2}{n-1}\chi^2_{n-1, \alpha/2} \} = \text{Prob}\{ \hat\sigma^2 \geqslant \frac{\sigma^2}{n-1}\chi^2_{n-1, 1-\alpha/2} \} = \frac{\alpha}{2} \\
& \Rightarrow \text{U} = \frac{(n-1)\hat\sigma^2}{\chi^2_{n-1, \alpha/2}} \; \text{L} = \frac{(n-1)\hat\sigma^2}{\chi^2_{n-1, 1-\alpha/2}} \\
\end{aligned}
$$


## 當樣本量足夠大時

根據中心極限定理，當樣本量足夠大時，**樣本均數**服從正態分佈，即使**樣本數據**並不服從正態分佈。這就意味着，樣本足夠大，章節 \@ref(CImean) 中用到的均值信賴區間公式，也可適用於樣本數據不服從正態分佈的情況下。我們常使用這個定理，和章節 \@ref(CImean) 中的公式去計算許多總體均數以外的參數的 $95\%$ 信賴區間，通過正態分佈近似法計算獲得的信賴區間，被叫做近似信賴區間。

## 情況4：求人羣百分比的信賴區間

### 一般原則

用 $R$ 表示 $n$ 次實驗中成功的次數。如果滿足實驗相互獨立的條件，那麼 $R\sim \text{Binomial}(n,\pi)$。那麼樣本比例 $P=\frac{R}{n}$ 是人羣比例 $\pi$ 的無偏估計。如果想要求 $\pi$ 的 $95\%$ 信賴區間 $(\pi_L, \pi_U)$，我們可能自然而讓想到用成功次數 $R$ 來計算。然而，由於 $R$ 本身是離散型變量 (只能取大於等於零的整數)，恰好加起來概率等於 $95\%$ 的 $\pi$ 的區間是幾乎不可能計算的。我們處理比例的信賴區間的問題時，要計算的兩個下限值和上限值要滿足的條件：

1. 尋找最小的 $\pi_L$ 滿足 $\text{Prob}(\pi_L>\pi) \leqslant 0.025$
2. 尋找最大的 $\pi_U$ 滿足 $\text{Prob}(\pi_U<\pi) \leqslant 0.025$

有兩種方案可供選擇：

1. 利用樣本分佈服從二項分佈 $R \sim \text{Binomial}(n, \pi)$ 的原則來“精確”計算；
2. 正態近似法計算。

第一種方法被叫做精確法，並不是因爲它能夠精確計算恰好概率和等於 $95\%$ 的所有的 $\pi$，而是因爲它利用的是樣本分佈的二項分佈屬性進行計算。然而隨着樣本量的增加，兩種方法計算的信賴區間結果越來越接近概率和 $95\%$。

### 二項分佈的“精確法”計算信賴區間 {#exactprop}

例：樣本量 $n=20$, 成功次數 $r=5$ 時，你可以用查水錶的辦法，也可以利用 R 進行精確計算


```{r}
binom.test(5, 20, conf.level = 0.95)
```

下面兩個圖分別展示了當 $\pi$ 等於精確法計算的下限和上限時的概率分佈。可以看出 $\pi=0.0866$ 時，$\text{Prob}\{R \geqslant 5\} \leqslant 0.025$。同時，當 $\pi = 0.4910$ 時， $\text{Prob}\{ R\leqslant 5 \} \leqslant 0.025$

```{r ATfig2-1, echo=FALSE, fig.asp=.7, fig.width=7, fig.cap='Sampling distribution of number of successes out of 20 (R) conditional on the probability of success being 0.0866', fig.align='center', out.width='70%'}
source("graphbinom.R")
graph.binom(20, 0.0866)
```


```{r ATfig2-2, echo=FALSE, fig.asp=.7, fig.width=7, fig.cap='Sampling distribution of number of successes out of 20 (R) conditional on the probability of success being 0.4910', fig.align='center', out.width='70%'}
source("graphbinom.R")
graph.binom(20, 0.4910)
```

### 二項分佈的近似法計算信賴區間

當 $n$ 較大時，百分比 $P$ 分佈 可以用正態分佈來近似：

$$
P\sim N(\pi, \sigma^2) \text{ where } \sigma^2 = \frac{\pi(1-\pi)}{n}
$$

總體均值用樣本百分比 $p$ 替代，方差用樣本方差 $\hat\sigma^2 = \frac{p(1-p)}{n}$，因此，當樣本量較大時二項分佈的近似正態分佈特徵可以描述爲：

$$
P \sim N(p, \hat\sigma^2) \text{ where } \hat\sigma^2 = \frac{p(1-p)}{n}
$$

接下去對與百分比的信賴區間的計算就可以套用章節 \@ref(CImean) 中用到的均值信賴區間公式：

$$
\begin{aligned}
& P\pm z_{1-\alpha/2}\sqrt{\frac{P(1-P)}{n}}  \\
& \text{ where } z_{1-\alpha/2} = 1.96 \text{ for } 95\% \text{CI}
\end{aligned}
(\#eq:AT2-16)
$$

正態近似法的好處是簡單，但是代價就是樣本量小時不準確。

例如：

1. $n=10, r=4, p=0.4$ 時
    - 精確法 $95\%$ 信賴區間：`r binom.test(4,10, 0.4)$conf.int[1:2]`
    - 正態近似法 $95\%$ 信賴區間：$0.4\pm1.96\sqrt{\frac{0.4\times0.6}{10}} =$ `r 0.4-1.96*sqrt((0.4*0.6)/10)`, `r 0.4+1.96*sqrt((0.4*0.6)/10)`

2. $n=50, r=20, p=0.4$ 時
    - 精確法 $95\%$ 信賴區間：`r binom.test(20, 50, 0.4)$conf.int[1:2]`
    - 正態近似法 $95\%$ 信賴區間： $0.4\pm1.96\sqrt{\frac{0.4\times0.6}{50}} =$ `r 0.4-1.96*sqrt((0.4*0.6)/50)`, `r 0.4+1.96*sqrt((0.4*0.6)/50)`

2. $n=1000, r=400, p=0.4$ 時
    - 精確法 $95\%$ 信賴區間：`r binom.test(400, 1000, 0.4)$conf.int[1:2]`
    - 正態近似法 $95\%$ 信賴區間： $0.4\pm1.96\sqrt{\frac{0.4\times0.6}{1000}} =$ `r 0.4-1.96*sqrt((0.4*0.6)/1000)`, `r 0.4+1.96*sqrt((0.4*0.6)/1000)`

可以明顯看到隨着樣本量增加，信賴區間本身的範圍在不斷變小 (精確)。且正態近似法計算的信賴區間也越來越接近“精確法”。“Statistical Methods in Medical Research” [@Armitage2008] 書中建議，滿足 $n\pi \geqslant 10 \text{ or } n(1-\pi) \geqslant 10$ 時，正態近似法可以給出較爲滿意的百分比的信賴區間估計。

## 率的信賴區間

### 利用泊松分佈精確計算

假設在一段時間 $t$ 內某事件發生的次數記爲 $Y$。如果每個相同事件的發生相互獨立那麼 $Y \sim \text{Poisson}(\mu t)$。樣本率 $R=\frac{Y}{t}$，是人羣事件發生概率 $\mu$ 的無偏估計。

$$
\text{The probability that } Y=y \text{ is given by } \frac{(\mu t)^y e^{-\mu t}}{y!} \text{ for } y= 0,1,2,\cdots,\infty
$$

與前一節百分比的精確計算信賴區間相類似 (Section \@ref(exactprop))，我們可以使用泊松分佈的性質進行計算：


1. 尋找最小的 $\mu_L$ 滿足 $\text{Prob}(\mu_L>\mu) \leqslant 0.025$
2. 尋找最大的 $\mu_U$ 滿足 $\text{Prob}(\mu_U<\mu) \leqslant 0.025$

例：某核電站附近的村莊從1968年起的10年內，發生了 6 人死於白血病。平均死亡率爲 0.6/年。計算死亡率的95%信賴區間。

可以利用 R 的精確計算發病率的代碼 `poission.test` 來獲得精確法率的信賴區間：

```{r}
poisson.test(6, 10)
```

### 利用正態近似法計算

當樣本量較大時，發生事件次數 $Y$ 近似服從正態分佈，其均值和方差均等於 $\mu t$ (參考 Section \@ref(poisson) 推導)：

$$
Y \sim N(\mu t, \sigma^2) \text{ where } \sigma^2=\mu t
$$

所以事件發生率 $\mu$ 的信賴區間公式爲 $\frac{Y\pm 1.96\sqrt{Y}}{t}$。

# 假設檢驗

## 拋硬幣的例子

對數據進行假設檢驗是統計分析最重要的部分。一般進行實驗或者調查時我們會先設定一個零假設。假如實驗或者調查中獲得的一系列數據可以認爲是相互獨立且隨機地從人羣中抽取的樣本，那麼根據零假設爲真的條件，樣本數據提供的參數估計和零假設條件下的參數應該是差距不大 (一致) 的。因爲概率論環境下，我們用樣本數據來作假設檢驗，如果樣本提供的數值比起零假設條件下的參數大很多或者小很多，我們就有理由，有證據拒絕零假設。

下面用投硬幣作爲例子說明。硬幣如果是公平的，那麼拋硬幣後正反面出現的概率應該一樣，都是 $50\%$ (零假設：$p=0.5$)。假如有一枚硬幣，拋了 $10$ 次只有一次是反面朝上的，我們可能就會懷疑，這枚資本主義硬幣一定是被做了手腳 (變得不再公平了)，這就是通過實驗質疑和挑戰零假設的思想。如此粗糙的想法卻是統計學假設檢驗的理論起源。只是在統計學裏面，需要制定一些規則來規定，實驗數據跟零假設 (設想) 差異達到多大時 (檢驗)，認爲證據足夠達到相信零假設“非真” (挑戰權威)。

檢驗的過程，就是計算我們朝思暮想的 $p$ 值。$p$ 值的定義是，當零假設爲真時，我們**觀察到的實驗結果以及比這個結果更加極端 (雙側) 的情況**在所有可能的情況中出現的概率。繼續使用拋硬幣的例子來說的話，跟 “$10$ 次拋硬幣出現一次反面朝上” 一樣極端或者更加極端的事件有：

- "一次反面朝上"，
- “零次反面朝上”，
- “九次反面朝上 (或者說一次正面朝上)”，
- “十次反面朝上 (或者說零次正面朝上)”。

相反地，沒有觀察事件 “$10$ 次拋硬幣出現一次反面朝上” 那麼極端的事件就包括了：

- “兩次反面朝上”，
- “三次反面朝上”，
- “四次反面朝上”，
- “五次反面朝上”，
- “六次反面朝上”，
- “七次反面朝上”，
- “八次反面朝上”。

檢驗的過程我們會定義一個被檢驗的統計量，一般就是我們感興趣的參數的估計 (estimator of a parameter of interest)。在上面拋硬幣的例子中，這個檢驗統計量就是 “硬幣反面朝上的次數”。觀察到的反面朝上次數除以拋硬幣次數 ($10$ 次) 就是獲得硬幣反面朝上的概率 (參數) 的估計。用 $R$ 表示十次拋硬幣中觀察到反面朝上的次數，那麼此時 $R$ 就是一個服從二項分佈的隨機變量，其服從的二項分佈成功 (反面朝上事件發生) 的概率 (參數) 是$\pi$。所以某一次實驗中 (拋十次硬幣算一次實驗)，$R=r$，那麼這次試驗的參數估計的 $p$ 值被定義爲：

$$
\begin{equation}
\text{Prob}\{ R \text{ as or more extreme than } r | \pi=0.5 \}
\end{equation}
(\#eq:AT3-1)
$$

零假設：反面朝上出現的概率是 $\pi=0.5$；替代假設： $\pi\neq 0.5$。當零假設爲真時，$R\sim \text{Bin}(10, 0.5)$，它的零假設分佈如下圖 \@ref(fig:ATfig3-1)：

```{r ATfig3-1, echo=FALSE, fig.asp=.7, fig.width=7, fig.cap='Binomial distribution n=10, \U03C0 = 0.5', fig.align='center', out.width='80%'}
 x <- (dbinom(0:10, size = 10, prob = 0.5))
  barplot(x, yaxt="n",
          col = "lightblue",
          ylim = c(0, 0.3),
          names.arg = 0:10, ylab = "Probability", xlab = "R (Number of tails)",
          main = 'Binomial Distribution (10,0.5)')
  axis(2, at=seq(0, 0.3, 0.1), las=2)
```

本節拋硬幣的例子我們觀察到十次拋硬幣只有一次反面朝上，$r=1$。其發生的概率等於上面列舉的四種與之同等極端或者更加極端的情況發生概率之和：

$$
\begin{aligned}
&\text{Prob} \{R=0|\pi=0.5\} + \text{Prob} \{R=1|\pi=0.5\} + \text{Prob} \{R=9|\pi=0.5\} + \text{Prob} \{R=10|\pi=0.5\} \\
& = (\binom{10}{0} + \binom{10}{1} + \binom{10}{9} + \binom{10}{10})\times(0.5)^{10} = 0.021
\end{aligned}
$$

### 單側和雙側檢驗

在上面的例子中其實我們已經用到了雙側檢驗的概念。例如，我們把 “九次反面朝上” 事件發生的概率當作和 “一次反面朝上” 事件發生的概率具有同等 “極端”概率事件，但是其實在圖 \@ref(fig:ATfig3-1) 中也能看出兩種事件發生的方向是在概率分佈的左右兩側，這就是典型的雙側檢驗思想。一個“單側”檢驗則不考慮另一個方向發生的極端事件。

還是用本節的例子，如果要計算單側檢驗 $p$ 值：

$$
\begin{aligned}
&\text{Prob}\{R\leqslant r| \pi=0.5\}\\
&\text{In the example } r=1 \\
&\Rightarrow \text{Prob}\{R=0 | \pi = 0.5\} + \text{Prob}\{ R=1 | \pi = 0.5 \} = 0.011
\end{aligned}
$$

此時零假設爲 $\pi=0.5$，替代假設爲 $\pi < 0.5$

# 相關

# 比較

# 假定前提和數據轉換
