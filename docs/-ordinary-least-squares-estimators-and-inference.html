<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>醫學統計學</title>
  <meta name="description" content="在LSHTM的學習筆記">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="醫學統計學" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/cover.jpg" />
  <meta property="og:description" content="在LSHTM的學習筆記" />
  <meta name="github-repo" content="winterwang/LSHTMlearningnote" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="醫學統計學" />
  
  <meta name="twitter:description" content="在LSHTM的學習筆記" />
  <meta name="twitter:image" content="img/cover.jpg" />

<meta name="author" content="王 超辰 Chaochen Wang">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="-simple-linear-regression.html">
<link rel="next" href="-introduction-to-analysis-of-variance.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">在LSHTM的學習筆記</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i>我是誰</a></li>
<li class="part"><span><b>I 概率論 Probability</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> 概率論入門：定義與公理</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#section-1.1"><i class="fa fa-check"></i><b>1.1</b> 三個概率公理：</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#-conditional-probability"><i class="fa fa-check"></i><b>1.2</b> 條件概率 Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#-independence-"><i class="fa fa-check"></i><b>1.3</b> 獨立 (independence) 的定義</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#section-1.4"><i class="fa fa-check"></i><b>1.4</b> 賭博問題</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#section-1.5"><i class="fa fa-check"></i><b>1.5</b> 賭博問題的答案</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Bayes-Definition.html"><a href="Bayes-Definition.html"><i class="fa fa-check"></i><b>2</b> Bayes 貝葉斯理論的概念</a></li>
<li class="chapter" data-level="3" data-path="-expectation-or-mean-variance.html"><a href="-expectation-or-mean-variance.html"><i class="fa fa-check"></i><b>3</b> 期望 Expectation (或均值 or mean) 和 方差 Variance</a><ul>
<li class="chapter" data-level="3.1" data-path="-expectation-or-mean-variance.html"><a href="-expectation-or-mean-variance.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 方差的性質：</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="-bernoulli-distribution.html"><a href="-bernoulli-distribution.html"><i class="fa fa-check"></i><b>4</b> 伯努利分佈 Bernoulli distribution</a></li>
<li class="chapter" data-level="5" data-path="-binomial-distribution.html"><a href="-binomial-distribution.html"><i class="fa fa-check"></i><b>5</b> 二項分佈的概念 Binomial distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="-binomial-distribution.html"><a href="-binomial-distribution.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 二項分佈的期望和方差</a></li>
<li class="chapter" data-level="5.2" data-path="-binomial-distribution.html"><a href="-binomial-distribution.html#-hypergeometric-distribution"><i class="fa fa-check"></i><b>5.2</b> 超幾何分佈 hypergeometric distribution</a></li>
<li class="chapter" data-level="5.3" data-path="-binomial-distribution.html"><a href="-binomial-distribution.html#section-5.3"><i class="fa fa-check"></i><b>5.3</b> 樂透中獎概率問題：</a><ul>
<li class="chapter" data-level="5.3.1" data-path="-binomial-distribution.html"><a href="-binomial-distribution.html#-3-"><i class="fa fa-check"></i><b>5.3.1</b> 如果我只想中其中的 <span class="math inline">\(3\)</span> 個號碼，概率有多大？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="poisson.html"><a href="poisson.html"><i class="fa fa-check"></i><b>6</b> 泊松分佈 Poisson Distribution</a></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 正態分佈</a><ul>
<li class="chapter" data-level="7.1" data-path="section-7.html"><a href="section-7.html#-probability-density-function-pdf"><i class="fa fa-check"></i><b>7.1</b> 概率密度曲線 probability density function， PDF</a></li>
<li class="chapter" data-level="7.2" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>7.2</b> 正態分佈</a></li>
<li class="chapter" data-level="7.3" data-path="section-7.html"><a href="section-7.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 標準正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="CLT.html"><a href="CLT.html"><i class="fa fa-check"></i><b>8</b> 中心極限定理 the Central Limit Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path="CLT.html"><a href="CLT.html#-covariance"><i class="fa fa-check"></i><b>8.1</b> 協方差 Covariance</a></li>
<li class="chapter" data-level="8.2" data-path="CLT.html"><a href="CLT.html#-correlation"><i class="fa fa-check"></i><b>8.2</b> 相關 Correlation</a></li>
<li class="chapter" data-level="8.3" data-path="CLT.html"><a href="CLT.html#-the-central-limit-theorem"><i class="fa fa-check"></i><b>8.3</b> 中心極限定理 the Central Limit Theorem</a></li>
<li class="chapter" data-level="8.4" data-path="CLT.html"><a href="CLT.html#binomial-normal-approx"><i class="fa fa-check"></i><b>8.4</b> 二項分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.5" data-path="CLT.html"><a href="CLT.html#section-8.5"><i class="fa fa-check"></i><b>8.5</b> 泊松分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.6" data-path="CLT.html"><a href="CLT.html#continuity-correction"><i class="fa fa-check"></i><b>8.6</b> 正態分佈模擬的校正：continuity corrections</a><ul>
<li class="chapter" data-level="8.6.1" data-path="CLT.html"><a href="CLT.html#section-8.6.1"><i class="fa fa-check"></i><b>8.6.1</b> 例題</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="CLT.html"><a href="CLT.html#section-8.7"><i class="fa fa-check"></i><b>8.7</b> 兩個連續隨機變量</a></li>
<li class="chapter" data-level="8.8" data-path="CLT.html"><a href="CLT.html#-"><i class="fa fa-check"></i><b>8.8</b> 兩個連續隨機變量 例子：</a></li>
<li class="chapter" data-level="8.9" data-path="CLT.html"><a href="CLT.html#section-8.9"><i class="fa fa-check"></i><b>8.9</b> 條件分佈和邊緣分佈的概念</a></li>
<li class="chapter" data-level="8.10" data-path="CLT.html"><a href="CLT.html#section-8.10"><i class="fa fa-check"></i><b>8.10</b> 條件分佈和邊緣分佈的例子</a><ul>
<li class="chapter" data-level="8.10.1" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>8.10.1</b> 例題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 統計推斷 Inference</b></span></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> 統計推斷的概念</a><ul>
<li class="chapter" data-level="9.1" data-path="section-9.html"><a href="section-9.html#-population-and-sample"><i class="fa fa-check"></i><b>9.1</b> 人羣與樣本 (population and sample)</a></li>
<li class="chapter" data-level="9.2" data-path="section-9.html"><a href="section-9.html#-sample-and-statistic"><i class="fa fa-check"></i><b>9.2</b> 樣本和統計量 (sample and statistic)</a></li>
<li class="chapter" data-level="9.3" data-path="section-9.html"><a href="section-9.html#-estimation"><i class="fa fa-check"></i><b>9.3</b> 估計 Estimation</a></li>
<li class="chapter" data-level="9.4" data-path="section-9.html"><a href="section-9.html#-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> 信賴區間 confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html"><i class="fa fa-check"></i><b>10</b> 估計和精確度 Estimation and Precision</a><ul>
<li class="chapter" data-level="10.1" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#CI-for-sample-mean"><i class="fa fa-check"></i><b>10.1</b> 估計量和他們的樣本分佈</a></li>
<li class="chapter" data-level="10.2" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#section-10.2"><i class="fa fa-check"></i><b>10.2</b> 估計量的特質</a><ul>
<li class="chapter" data-level="10.2.1" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#section-10.2.1"><i class="fa fa-check"></i><b>10.2.1</b> 偏倚</a></li>
<li class="chapter" data-level="10.2.2" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#-efficiency"><i class="fa fa-check"></i><b>10.2.2</b> 估計量的效能 Efficiency</a></li>
<li class="chapter" data-level="10.2.3" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#section-10.2.3"><i class="fa fa-check"></i><b>10.2.3</b> 均值和中位數的相對效能</a></li>
<li class="chapter" data-level="10.2.4" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#-mean-square-error-mse"><i class="fa fa-check"></i><b>10.2.4</b> 均方差 mean square error (MSE)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#samplevarbias"><i class="fa fa-check"></i><b>10.3</b> 總體方差的估計，自由度</a></li>
<li class="chapter" data-level="10.4" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#samplevar"><i class="fa fa-check"></i><b>10.4</b> 樣本方差的樣本分佈</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html"><i class="fa fa-check"></i><b>11</b> 卡方分佈 Chi-square distribution</a><ul>
<li class="chapter" data-level="11.1" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#section-11.1"><i class="fa fa-check"></i><b>11.1</b> 卡方分佈的期望和方差的證明</a></li>
<li class="chapter" data-level="11.2" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#section-11.2"><i class="fa fa-check"></i><b>11.2</b> 卡方分佈的期望</a></li>
<li class="chapter" data-level="11.3" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#section-11.3"><i class="fa fa-check"></i><b>11.3</b> 卡方分佈的方差</a><ul>
<li class="chapter" data-level="11.3.1" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#-ex_14"><i class="fa fa-check"></i><b>11.3.1</b> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#section-11.4"><i class="fa fa-check"></i><b>11.4</b> 把上面的推導擴展</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="likelihood-definition.html"><a href="likelihood-definition.html"><i class="fa fa-check"></i><b>12</b> 似然 Likelihood</a><ul>
<li class="chapter" data-level="12.1" data-path="likelihood-definition.html"><a href="likelihood-definition.html#-vs.-probability-vs.inference"><i class="fa fa-check"></i><b>12.1</b> 概率 vs. 推斷 Probability vs. Inference</a></li>
<li class="chapter" data-level="12.2" data-path="likelihood-definition.html"><a href="likelihood-definition.html#-likelihood-and-maximum-likelihood-estimators"><i class="fa fa-check"></i><b>12.2</b> 似然和極大似然估計 Likelihood and maximum likelihood estimators</a></li>
<li class="chapter" data-level="12.3" data-path="likelihood-definition.html"><a href="likelihood-definition.html#section-12.3"><i class="fa fa-check"></i><b>12.3</b> 似然方程的一般化定義</a></li>
<li class="chapter" data-level="12.4" data-path="likelihood-definition.html"><a href="likelihood-definition.html#-log-likelihood"><i class="fa fa-check"></i><b>12.4</b> 對數似然方程 log-likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="likelihood-definition.html"><a href="likelihood-definition.html#-maximum-likelihood-estimator-mle-"><i class="fa fa-check"></i><b>12.5</b> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</a></li>
<li class="chapter" data-level="12.6" data-path="likelihood-definition.html"><a href="likelihood-definition.html#likelihood-poi"><i class="fa fa-check"></i><b>12.6</b> 率的似然估計 Likelihood for a rate</a></li>
<li class="chapter" data-level="12.7" data-path="likelihood-definition.html"><a href="likelihood-definition.html#-n-"><i class="fa fa-check"></i><b>12.7</b> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="llr.html"><a href="llr.html"><i class="fa fa-check"></i><b>13</b> 對數似然比 Log-likelihood ratio</a><ul>
<li class="chapter" data-level="13.1" data-path="llr.html"><a href="llr.html#section-13.1"><i class="fa fa-check"></i><b>13.1</b> 正態分佈數據的極大似然和對數似然比</a></li>
<li class="chapter" data-level="13.2" data-path="llr.html"><a href="llr.html#llr-chi1"><i class="fa fa-check"></i><b>13.2</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</a></li>
<li class="chapter" data-level="13.3" data-path="llr.html"><a href="llr.html#llr-chi"><i class="fa fa-check"></i><b>13.3</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</a></li>
<li class="chapter" data-level="13.4" data-path="llr.html"><a href="llr.html#section-13.4"><i class="fa fa-check"></i><b>13.4</b> 似然比信賴區間</a><ul>
<li class="chapter" data-level="13.4.1" data-path="llr.html"><a href="llr.html#binomial-ex"><i class="fa fa-check"></i><b>13.4.1</b> 以二項分佈數據爲例</a></li>
<li class="chapter" data-level="13.4.2" data-path="llr.html"><a href="llr.html#normal-ex"><i class="fa fa-check"></i><b>13.4.2</b> 以正態分佈數據爲例</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="llr.html"><a href="llr.html#section-13.5"><i class="fa fa-check"></i><b>13.5</b> 練習題</a><ul>
<li class="chapter" data-level="13.5.1" data-path="llr.html"><a href="llr.html#q1"><i class="fa fa-check"></i><b>13.5.1</b> Q1</a></li>
<li class="chapter" data-level="13.5.2" data-path="llr.html"><a href="llr.html#q2"><i class="fa fa-check"></i><b>13.5.2</b> Q2</a></li>
<li class="chapter" data-level="13.5.3" data-path="llr.html"><a href="llr.html#q3"><i class="fa fa-check"></i><b>13.5.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="quadratic-llr.html"><a href="quadratic-llr.html"><i class="fa fa-check"></i><b>14</b> 二次方程近似法求對數似然比 approximate log-likelihood ratios</a><ul>
<li class="chapter" data-level="14.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#quadratic-llr2"><i class="fa fa-check"></i><b>14.1</b> 正態近似法求對數似然 Normal approximation to the log-likelihood</a><ul>
<li class="chapter" data-level="14.1.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#section-14.1.1"><i class="fa fa-check"></i><b>14.1.1</b> 近似法估算對數似然比的信賴區間</a></li>
<li class="chapter" data-level="14.1.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#section-14.1.2"><i class="fa fa-check"></i><b>14.1.2</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.1.3" data-path="quadratic-llr.html"><a href="quadratic-llr.html#quadratic-binomial-approx"><i class="fa fa-check"></i><b>14.1.3</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#para-trans"><i class="fa fa-check"></i><b>14.2</b> 參數转换 parameter transformations</a><ul>
<li class="chapter" data-level="14.2.1" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>14.2.1</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.2.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#section-14.2.2"><i class="fa fa-check"></i><b>14.2.2</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>14.3</b> 練習題</a><ul>
<li class="chapter" data-level="14.3.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#q1-1"><i class="fa fa-check"></i><b>14.3.1</b> Q1</a></li>
<li class="chapter" data-level="14.3.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#q2-1"><i class="fa fa-check"></i><b>14.3.2</b> Q2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html"><i class="fa fa-check"></i><b>15</b> 假設檢驗的構建 Construction of a hypothesis test</a><ul>
<li class="chapter" data-level="15.1" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#null-and-alter"><i class="fa fa-check"></i><b>15.1</b> 什麼是假設檢驗 Hypothesis testing</a></li>
<li class="chapter" data-level="15.2" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#-error-probabilities-and-the-power-function"><i class="fa fa-check"></i><b>15.2</b> 錯誤概率和效能方程 error probabilities and the power function</a><ul>
<li class="chapter" data-level="15.2.1" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>15.2.1</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#Neyman-Pearson"><i class="fa fa-check"></i><b>15.3</b> 如何選擇要檢驗的統計量</a><ul>
<li class="chapter" data-level="15.3.1" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#section-15.3.1"><i class="fa fa-check"></i><b>15.3.1</b> 以已知方差的正態分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#-composite-hypotheses"><i class="fa fa-check"></i><b>15.4</b> 複合假設 composite hypotheses</a><ul>
<li class="chapter" data-level="15.4.1" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#section-15.4.1"><i class="fa fa-check"></i><b>15.4.1</b> 單側替代假設</a></li>
<li class="chapter" data-level="15.4.2" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#section-15.4.2"><i class="fa fa-check"></i><b>15.4.2</b> 雙側替代假設</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#-h_0-"><i class="fa fa-check"></i><b>15.5</b> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</a><ul>
<li class="chapter" data-level="15.5.1" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#normal-mean-compare"><i class="fa fa-check"></i><b>15.5.1</b> 回到正態分佈的均值比較問題上來(單側替代假設)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#-p-"><i class="fa fa-check"></i><b>15.6</b> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</a></li>
<li class="chapter" data-level="15.7" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#test-summary"><i class="fa fa-check"></i><b>15.7</b> 假設檢驗構建之總結</a></li>
<li class="chapter" data-level="15.8" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#-2"><i class="fa fa-check"></i><b>15.8</b> 練習題</a><ul>
<li class="chapter" data-level="15.8.1" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#q1-2"><i class="fa fa-check"></i><b>15.8.1</b> Q1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="section-16.html"><a href="section-16.html"><i class="fa fa-check"></i><b>16</b> 假設檢驗的近似方法</a><ul>
<li class="chapter" data-level="16.1" data-path="section-16.html"><a href="section-16.html#-approximate-and-exact-tests"><i class="fa fa-check"></i><b>16.1</b> 近似和精確檢驗 approximate and exact tests</a></li>
<li class="chapter" data-level="16.2" data-path="section-16.html"><a href="section-16.html#--likelihood-ratio-test"><i class="fa fa-check"></i><b>16.2</b> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</a></li>
<li class="chapter" data-level="16.3" data-path="section-16.html"><a href="section-16.html#-3"><i class="fa fa-check"></i><b>16.3</b> 練習題</a></li>
<li class="chapter" data-level="16.4" data-path="section-16.html"><a href="section-16.html#Wald"><i class="fa fa-check"></i><b>16.4</b> 近似檢驗法之 – Wald 檢驗</a><ul>
<li class="chapter" data-level="16.4.1" data-path="section-16.html"><a href="section-16.html#section-16.4.1"><i class="fa fa-check"></i><b>16.4.1</b> 再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="section-16.html"><a href="section-16.html#-score-"><i class="fa fa-check"></i><b>16.5</b> 近似檢驗法之 – Score 检验</a><ul>
<li class="chapter" data-level="16.5.1" data-path="section-16.html"><a href="section-16.html#section-16.5.1"><i class="fa fa-check"></i><b>16.5.1</b> 再再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="section-16.html"><a href="section-16.html#lrt-wald-score-"><i class="fa fa-check"></i><b>16.6</b> LRT, Wald, Score 檢驗三者的比較</a></li>
<li class="chapter" data-level="16.7" data-path="section-16.html"><a href="section-16.html#-4"><i class="fa fa-check"></i><b>16.7</b> 練習題</a><ul>
<li class="chapter" data-level="16.7.1" data-path="section-16.html"><a href="section-16.html#q1-3"><i class="fa fa-check"></i><b>16.7.1</b> Q1</a></li>
<li class="chapter" data-level="16.7.2" data-path="section-16.html"><a href="section-16.html#q2-2"><i class="fa fa-check"></i><b>16.7.2</b> Q2</a></li>
<li class="chapter" data-level="16.7.3" data-path="section-16.html"><a href="section-16.html#q3-1"><i class="fa fa-check"></i><b>16.7.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="-normal-error.html"><a href="-normal-error.html"><i class="fa fa-check"></i><b>17</b> 誤差模型 Normal error</a></li>
<li class="part"><span><b>III 統計分析方法 Analytical Techniques</b></span></li>
<li class="chapter" data-level="18" data-path="section-18.html"><a href="section-18.html"><i class="fa fa-check"></i><b>18</b> 探索數據和簡單描述</a><ul>
<li class="chapter" data-level="18.1" data-path="section-18.html"><a href="section-18.html#section-18.1"><i class="fa fa-check"></i><b>18.1</b> 數據分析的流程</a><ul>
<li class="chapter" data-level="18.1.1" data-path="section-18.html"><a href="section-18.html#section-18.1.1"><i class="fa fa-check"></i><b>18.1.1</b> 研究設計和實施</a></li>
<li class="chapter" data-level="18.1.2" data-path="section-18.html"><a href="section-18.html#section-18.1.2"><i class="fa fa-check"></i><b>18.1.2</b> 數據分析</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="section-18.html"><a href="section-18.html#section-18.2"><i class="fa fa-check"></i><b>18.2</b> 數據類型</a></li>
<li class="chapter" data-level="18.3" data-path="section-18.html"><a href="section-18.html#section-18.3"><i class="fa fa-check"></i><b>18.3</b> 如何總結並展示數據</a><ul>
<li class="chapter" data-level="18.3.1" data-path="section-18.html"><a href="section-18.html#----frequency-table"><i class="fa fa-check"></i><b>18.3.1</b> 離散型分類型數據的描述 - 頻數分佈表 frequency table</a></li>
<li class="chapter" data-level="18.3.2" data-path="section-18.html"><a href="section-18.html#section-18.3.2"><i class="fa fa-check"></i><b>18.3.2</b> 連續型變量</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="section-18.html"><a href="section-18.html#section-18.4"><i class="fa fa-check"></i><b>18.4</b> 數據總結方案：位置，分散，偏度，和峰度</a><ul>
<li class="chapter" data-level="18.4.1" data-path="section-18.html"><a href="section-18.html#section-18.4.1"><i class="fa fa-check"></i><b>18.4.1</b> 位置</a></li>
<li class="chapter" data-level="18.4.2" data-path="section-18.html"><a href="section-18.html#section-18.4.2"><i class="fa fa-check"></i><b>18.4.2</b> 分散</a></li>
<li class="chapter" data-level="18.4.3" data-path="section-18.html"><a href="section-18.html#-skewness"><i class="fa fa-check"></i><b>18.4.3</b> 偏度 skewness</a></li>
<li class="chapter" data-level="18.4.4" data-path="section-18.html"><a href="section-18.html#-kurtosis"><i class="fa fa-check"></i><b>18.4.4</b> 峯度 kurtosis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html"><i class="fa fa-check"></i><b>19</b> 信賴區間 confidence intervals</a><ul>
<li class="chapter" data-level="19.1" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#section-19.1"><i class="fa fa-check"></i><b>19.1</b> 定義</a></li>
<li class="chapter" data-level="19.2" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#section-19.2"><i class="fa fa-check"></i><b>19.2</b> 利用總體參數的樣本分佈求信賴區間</a></li>
<li class="chapter" data-level="19.3" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#1"><i class="fa fa-check"></i><b>19.3</b> 情況1：已知方差的正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="19.4" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#CImean"><i class="fa fa-check"></i><b>19.4</b> 信賴區間的意義</a></li>
<li class="chapter" data-level="19.5" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#2"><i class="fa fa-check"></i><b>19.5</b> 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="19.6" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#3"><i class="fa fa-check"></i><b>19.6</b> 情況3：服從正態分佈的隨機變量方差的信賴區間</a></li>
<li class="chapter" data-level="19.7" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#section-19.7"><i class="fa fa-check"></i><b>19.7</b> 當樣本量足夠大時</a></li>
<li class="chapter" data-level="19.8" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#4"><i class="fa fa-check"></i><b>19.8</b> 情況4：求人羣百分比的信賴區間</a><ul>
<li class="chapter" data-level="19.8.1" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#section-19.8.1"><i class="fa fa-check"></i><b>19.8.1</b> 一般原則</a></li>
<li class="chapter" data-level="19.8.2" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#exactprop"><i class="fa fa-check"></i><b>19.8.2</b> 二項分佈的“精確法”計算信賴區間</a></li>
<li class="chapter" data-level="19.8.3" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#section-19.8.3"><i class="fa fa-check"></i><b>19.8.3</b> 二項分佈的近似法計算信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="19.9" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#section-19.9"><i class="fa fa-check"></i><b>19.9</b> 率的信賴區間</a><ul>
<li class="chapter" data-level="19.9.1" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#section-19.9.1"><i class="fa fa-check"></i><b>19.9.1</b> 利用泊松分佈精確計算</a></li>
<li class="chapter" data-level="19.9.2" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#section-19.9.2"><i class="fa fa-check"></i><b>19.9.2</b> 利用正態近似法計算</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="section-20.html"><a href="section-20.html"><i class="fa fa-check"></i><b>20</b> 假設檢驗</a></li>
<li class="chapter" data-level="21" data-path="section-21.html"><a href="section-21.html"><i class="fa fa-check"></i><b>21</b> 相關</a></li>
<li class="chapter" data-level="22" data-path="section-22.html"><a href="section-22.html"><i class="fa fa-check"></i><b>22</b> 比較</a></li>
<li class="chapter" data-level="23" data-path="section-23.html"><a href="section-23.html"><i class="fa fa-check"></i><b>23</b> 假定前提和數據轉換</a></li>
<li class="part"><span><b>IV 線性迴歸 Linear Regression</b></span></li>
<li class="chapter" data-level="24" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html"><i class="fa fa-check"></i><b>24</b> 簡單線性迴歸 Simple Linear Regression</a><ul>
<li class="chapter" data-level="24.1" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#section-24.1"><i class="fa fa-check"></i><b>24.1</b> 一些背景和術語</a></li>
<li class="chapter" data-level="24.2" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-simple-linear-regression-model"><i class="fa fa-check"></i><b>24.2</b> 簡單線性迴歸模型 simple linear regression model</a><ul>
<li class="chapter" data-level="24.2.1" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#1"><i class="fa fa-check"></i><b>24.2.1</b> 例1</a></li>
<li class="chapter" data-level="24.2.2" data-path="-confidence-intervals-1.html"><a href="-confidence-intervals-1.html#2"><i class="fa fa-check"></i><b>24.2.2</b> 例2</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#section-24.3"><i class="fa fa-check"></i><b>24.3</b> 區分因變量和預測變量</a><ul>
<li class="chapter" data-level="24.3.1" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#meanfunction"><i class="fa fa-check"></i><b>24.3.1</b> 均值 (期待值) 公式</a></li>
<li class="chapter" data-level="24.3.2" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-the-conditional-distribution-and-the-variance-function"><i class="fa fa-check"></i><b>24.3.2</b> 條件分佈和方差 the conditional distribution and the variance function</a></li>
<li class="chapter" data-level="24.3.3" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#section-24.3.3"><i class="fa fa-check"></i><b>24.3.3</b> 定義簡單線性迴歸模型</a></li>
<li class="chapter" data-level="24.3.4" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-residuals"><i class="fa fa-check"></i><b>24.3.4</b> 殘差 residuals</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-estimation-of-parameters"><i class="fa fa-check"></i><b>24.4</b> 參數的估計 estimation of parameters</a><ul>
<li class="chapter" data-level="24.4.1" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-alpha-beta"><i class="fa fa-check"></i><b>24.4.1</b> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="24.5" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-estimation-of-the-residual-variance-sigma2"><i class="fa fa-check"></i><b>24.5</b> 殘差方差的估計 Estimation of the residual variance <span class="math inline">\((\sigma^2)\)</span></a></li>
<li class="chapter" data-level="24.6" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#r---1--reffigage-wt-"><i class="fa fa-check"></i><b>24.6</b> R 演示 例 1： 圖 @ref(fig:age-wt) 數據</a></li>
<li class="chapter" data-level="24.7" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#binarylms"><i class="fa fa-check"></i><b>24.7</b> R 演示 例 2： 表@ref(tab:walk) 數據</a></li>
<li class="chapter" data-level="24.8" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#exeChol"><i class="fa fa-check"></i><b>24.8</b> 練習</a><ul>
<li class="chapter" data-level="24.8.1" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-c_1-c_2-c_2alphabeta-c_2-varepsilon"><i class="fa fa-check"></i><b>24.8.1</b> 兩次測量的膽固醇水平分別用 <span class="math inline">\(C_1, C_2\)</span> 來標記的話，考慮這樣的簡單線性迴歸模型：<span class="math inline">\(C_2=\alpha+\beta C_2 + \varepsilon\)</span>。我們進行這樣迴歸的前提假設有哪些？</a></li>
<li class="chapter" data-level="24.8.2" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-ols--hatalpha-hatbeta"><i class="fa fa-check"></i><b>24.8.2</b> 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 <span class="math inline">\(\hat\alpha, \hat\beta\)</span></a></li>
<li class="chapter" data-level="24.8.3" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#section-24.8.3"><i class="fa fa-check"></i><b>24.8.3</b> 和迴歸模型計算的結果作比較，解釋這些估計值的含義</a></li>
<li class="chapter" data-level="24.8.4" data-path="CLT.html"><a href="CLT.html#-"><i class="fa fa-check"></i><b>24.8.4</b> 加上計算的估計值直線 (即迴歸直線)</a></li>
<li class="chapter" data-level="24.8.5" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#section-24.8.5"><i class="fa fa-check"></i><b>24.8.5</b> 下面的代碼用於模型的假設診斷</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html"><i class="fa fa-check"></i><b>25</b> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</a><ul>
<li class="chapter" data-level="25.1" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#ols-"><i class="fa fa-check"></i><b>25.1</b> OLS 估計量的性質</a></li>
<li class="chapter" data-level="25.2" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#hatbeta-"><i class="fa fa-check"></i><b>25.2</b> <span class="math inline">\(\hat\beta\)</span> 的性質</a><ul>
<li class="chapter" data-level="25.2.1" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#randbeta"><i class="fa fa-check"></i><b>25.2.1</b> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</a></li>
<li class="chapter" data-level="25.2.2" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#-1--reffigage-wt-"><i class="fa fa-check"></i><b>25.2.2</b> 例 1： 還是圖 @ref(fig:age-wt) 數據</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#section-25.3"><i class="fa fa-check"></i><b>25.3</b> 截距和迴歸係數的方差，協方差</a><ul>
<li class="chapter" data-level="25.3.1" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#-centring"><i class="fa fa-check"></i><b>25.3.1</b> 中心化 centring</a></li>
</ul></li>
<li class="chapter" data-level="25.4" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#alpha-beta-"><i class="fa fa-check"></i><b>25.4</b> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</a><ul>
<li class="chapter" data-level="25.4.1" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#section-25.4.1"><i class="fa fa-check"></i><b>25.4.1</b> 對迴歸係數進行假設檢驗</a></li>
<li class="chapter" data-level="25.4.2" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#section-25.4.2"><i class="fa fa-check"></i><b>25.4.2</b> 迴歸係數，截距的信賴區間</a></li>
<li class="chapter" data-level="25.4.3" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#----"><i class="fa fa-check"></i><b>25.4.3</b> 預測值的信賴區間 (置信带) - 测量回归曲线本身的不确定性</a></li>
<li class="chapter" data-level="25.4.4" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#-reference-range----95-"><i class="fa fa-check"></i><b>25.4.4</b> 预测带 Reference range - 包含了 95% 观察值的区间</a></li>
</ul></li>
<li class="chapter" data-level="25.5" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#rsquare"><i class="fa fa-check"></i><b>25.5</b> 線性迴歸模型和 Pearson 相關係數</a><ul>
<li class="chapter" data-level="25.5.1" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#r2-"><i class="fa fa-check"></i><b>25.5.1</b> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</a></li>
</ul></li>
<li class="chapter" data-level="25.6" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#t-r2-F"><i class="fa fa-check"></i><b>25.6</b> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</a></li>
<li class="chapter" data-level="25.7" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html#section-25.7"><i class="fa fa-check"></i><b>25.7</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html"><i class="fa fa-check"></i><b>26</b> 方差分析 Introduction to Analysis of Variance</a><ul>
<li class="chapter" data-level="26.1" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#section-26.1"><i class="fa fa-check"></i><b>26.1</b> 背景</a></li>
<li class="chapter" data-level="26.2" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#section-26.2"><i class="fa fa-check"></i><b>26.2</b> 簡單線性迴歸模型的方差分析</a><ul>
<li class="chapter" data-level="26.2.1" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#section-26.2.1"><i class="fa fa-check"></i><b>26.2.1</b> 兩個模型的參數估計</a></li>
<li class="chapter" data-level="26.2.2" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#section-26.2.2"><i class="fa fa-check"></i><b>26.2.2</b> 分割零假設模型的殘差平方和</a></li>
<li class="chapter" data-level="26.2.3" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#Rsquare"><i class="fa fa-check"></i><b>26.2.3</b> <span class="math inline">\(R^2\)</span> – 我的名字叫<strong>決定係數</strong> coefficient of determination</a></li>
<li class="chapter" data-level="26.2.4" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#-the-anova-table"><i class="fa fa-check"></i><b>26.2.4</b> 方差分析表格 the ANOVA table</a></li>
<li class="chapter" data-level="26.2.5" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#-anova-"><i class="fa fa-check"></i><b>26.2.5</b> 用 ANOVA 進行假設檢驗</a></li>
<li class="chapter" data-level="26.2.6" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#-f-"><i class="fa fa-check"></i><b>26.2.6</b> 簡單線性迴歸時的 <span class="math inline">\(F\)</span> 檢驗</a></li>
<li class="chapter" data-level="26.2.7" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#F-t-same"><i class="fa fa-check"></i><b>26.2.7</b> 簡單線性迴歸時 <span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗的一致性</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#-anova"><i class="fa fa-check"></i><b>26.3</b> 分類變量用作預測變量時的 ANOVA</a><ul>
<li class="chapter" data-level="26.3.1" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#section-26.3.1"><i class="fa fa-check"></i><b>26.3.1</b> 一個二分類預測變量</a></li>
<li class="chapter" data-level="26.3.2" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#section-26.3.2"><i class="fa fa-check"></i><b>26.3.2</b> 一個模型，兩種表述</a></li>
<li class="chapter" data-level="26.3.3" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#section-26.3.3"><i class="fa fa-check"></i><b>26.3.3</b> 分組變量的平方和</a></li>
<li class="chapter" data-level="26.3.4" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html#section-26.3.4"><i class="fa fa-check"></i><b>26.3.4</b> 簡單模型的分組變量大於兩組的情況</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="-multivariable-models.html"><a href="-multivariable-models.html"><i class="fa fa-check"></i><b>27</b> 多元模型分析 Multivariable Models</a><ul>
<li class="chapter" data-level="27.1" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>27.1</b> 背景</a></li>
<li class="chapter" data-level="27.2" data-path="-multivariable-models.html"><a href="-multivariable-models.html#section-27.2"><i class="fa fa-check"></i><b>27.2</b> 兩個預測變量的線性迴歸模型</a><ul>
<li class="chapter" data-level="27.2.1" data-path="-multivariable-models.html"><a href="-multivariable-models.html#section-27.2.1"><i class="fa fa-check"></i><b>27.2.1</b> 數學標記法和解釋</a></li>
<li class="chapter" data-level="27.2.2" data-path="-multivariable-models.html"><a href="-multivariable-models.html#-least-squares-estimation"><i class="fa fa-check"></i><b>27.2.2</b> 最小平方和估計 Least Squares Estimation</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="-multivariable-models.html"><a href="-multivariable-models.html#section-27.3"><i class="fa fa-check"></i><b>27.3</b> 線性回歸模型中使用分組變量</a></li>
<li class="chapter" data-level="27.4" data-path="-multivariable-models.html"><a href="-multivariable-models.html#-the-analysis-of-covariance-ancova-model"><i class="fa fa-check"></i><b>27.4</b> 協方差分析模型 the Analysis of Covariance (ANCOVA) Model</a></li>
<li class="chapter" data-level="27.5" data-path="-multivariable-models.html"><a href="-multivariable-models.html#section-27.5"><i class="fa fa-check"></i><b>27.5</b> 偏回歸係數的變化</a><ul>
<li class="chapter" data-level="27.5.1" data-path="-multivariable-models.html"><a href="-multivariable-models.html#1-beta_1-beta_1"><i class="fa fa-check"></i><b>27.5.1</b> 情況1： <span class="math inline">\(\beta_1 &gt; \beta_1^*\)</span></a></li>
<li class="chapter" data-level="27.5.2" data-path="-multivariable-models.html"><a href="-multivariable-models.html#2beta_1beta_1"><i class="fa fa-check"></i><b>27.5.2</b> 情況2：<span class="math inline">\(\beta_1&lt;\beta_1^*\)</span></a></li>
<li class="chapter" data-level="27.5.3" data-path="-multivariable-models.html"><a href="-multivariable-models.html#3-beta_1-beta_1"><i class="fa fa-check"></i><b>27.5.3</b> 情況3： <span class="math inline">\(\beta_1 = \beta_1^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="27.6" data-path="-multivariable-models.html"><a href="-multivariable-models.html#-confounding"><i class="fa fa-check"></i><b>27.6</b> 混雜 confounding</a><ul>
<li class="chapter" data-level="27.6.1" data-path="-multivariable-models.html"><a href="-multivariable-models.html#-mediation-effect"><i class="fa fa-check"></i><b>27.6.1</b> 作為媒介 mediation effect</a></li>
<li class="chapter" data-level="27.6.2" data-path="-multivariable-models.html"><a href="-multivariable-models.html#section-27.6.2"><i class="fa fa-check"></i><b>27.6.2</b> 兩個預測變量之間的關係</a></li>
<li class="chapter" data-level="27.6.3" data-path="-multivariable-models.html"><a href="-multivariable-models.html#rct"><i class="fa fa-check"></i><b>27.6.3</b> RCT臨床實驗是個特例</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="section-28.html"><a href="section-28.html"><i class="fa fa-check"></i><b>28</b> 多元模型分析：矩陣標記與其意義</a><ul>
<li class="chapter" data-level="28.1" data-path="section-28.html"><a href="section-28.html#section-28.1"><i class="fa fa-check"></i><b>28.1</b> 背景介紹</a></li>
<li class="chapter" data-level="28.2" data-path="section-28.html"><a href="section-28.html#section-28.2"><i class="fa fa-check"></i><b>28.2</b> 線性回歸模型的矩陣/非矩陣標記法</a><ul>
<li class="chapter" data-level="28.2.1" data-path="section-28.html"><a href="section-28.html#section-28.2.1"><i class="fa fa-check"></i><b>28.2.1</b> 模型標記：</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="section-28.html"><a href="section-28.html#-interpretation-of-the-parameters"><i class="fa fa-check"></i><b>28.3</b> 解讀參數 interpretation of the parameters</a><ul>
<li class="chapter" data-level="28.3.1" data-path="-multivariable-models.html"><a href="-multivariable-models.html#-least-squares-estimation"><i class="fa fa-check"></i><b>28.3.1</b> 最小二乘估計 least squares estimation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V 臨床實驗 Clinical Trials</b></span></li>
<li class="chapter" data-level="29" data-path="sample-size.html"><a href="sample-size.html"><i class="fa fa-check"></i><b>29</b> 樣本量計算問題</a><ul>
<li class="chapter" data-level="29.1" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#-2"><i class="fa fa-check"></i><b>29.1</b> 背景</a></li>
<li class="chapter" data-level="29.2" data-path="sample-size.html"><a href="sample-size.html#section-29.2"><i class="fa fa-check"></i><b>29.2</b> 決定所需樣本量大小的統計學因素</a></li>
<li class="chapter" data-level="29.3" data-path="sample-size.html"><a href="sample-size.html#-type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>29.3</b> 第一類和第二類錯誤 Type I and type II errors</a></li>
<li class="chapter" data-level="29.4" data-path="sample-size.html"><a href="sample-size.html#-percentages-or-proportions"><i class="fa fa-check"></i><b>29.4</b> 比較兩組之間的百分比 (percentages or proportions)</a><ul>
<li class="chapter" data-level="29.4.1" data-path="sample-size.html"><a href="sample-size.html#--5--90"><i class="fa fa-check"></i><b>29.4.1</b> 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)</a></li>
<li class="chapter" data-level="29.4.2" data-path="CLT.html"><a href="CLT.html#-"><i class="fa fa-check"></i><b>29.4.2</b> 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)</a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="sample-size.html"><a href="sample-size.html#section-29.5"><i class="fa fa-check"></i><b>29.5</b> 比較兩組之間的均值</a><ul>
<li class="chapter" data-level="29.5.1" data-path="sample-size.html"><a href="sample-size.html#section-29.5.1"><i class="fa fa-check"></i><b>29.5.1</b> 樣本量計算公式</a></li>
</ul></li>
<li class="chapter" data-level="29.6" data-path="sample-size.html"><a href="sample-size.html#section-29.6"><i class="fa fa-check"></i><b>29.6</b> 樣本量計算的調整</a></li>
</ul></li>
<li class="part"><span><b>VI 穩健統計方法 Robust Statistic Methods</b></span></li>
<li class="chapter" data-level="30" data-path="section-30.html"><a href="section-30.html"><i class="fa fa-check"></i><b>30</b> 穩健統計方法入門</a></li>
<li class="chapter" data-level="31" data-path="section-31.html"><a href="section-31.html"><i class="fa fa-check"></i><b>31</b> 基於秩次的非參數檢驗</a><ul>
<li class="chapter" data-level="31.1" data-path="section-31.html"><a href="section-31.html#-the-sign-test"><i class="fa fa-check"></i><b>31.1</b> 符號檢驗 the Sign test</a><ul>
<li class="chapter" data-level="31.1.1" data-path="section-31.html"><a href="section-31.html#section-31.1.1"><i class="fa fa-check"></i><b>31.1.1</b> 符號檢驗的特點</a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="section-31.html"><a href="section-31.html#wilcoxon-the-wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>31.2</b> Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="31.3" data-path="section-31.html"><a href="section-31.html#wilcoxon-mann-whitney-wmw-"><i class="fa fa-check"></i><b>31.3</b> Wilcoxon-Mann-Whitney (WMW) 檢驗</a></li>
<li class="chapter" data-level="31.4" data-path="section-31.html"><a href="section-31.html#spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>31.4</b> 秩相關，Spearman’s Rank Correlation Coefficient</a></li>
<li class="chapter" data-level="31.5" data-path="section-31.html"><a href="section-31.html#section-31.5"><i class="fa fa-check"></i><b>31.5</b> 基於秩次的非參數檢驗的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="-permutation-procedures.html"><a href="-permutation-procedures.html"><i class="fa fa-check"></i><b>32</b> 排列置換法 Permutation procedures</a><ul>
<li class="chapter" data-level="32.1" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>32.1</b> 背景介紹</a></li>
<li class="chapter" data-level="32.2" data-path="-permutation-procedures.html"><a href="-permutation-procedures.html#section-32.2"><i class="fa fa-check"></i><b>32.2</b> 直接上實例</a></li>
<li class="chapter" data-level="32.3" data-path="-permutation-procedures.html"><a href="-permutation-procedures.html#section-32.3"><i class="fa fa-check"></i><b>32.3</b> 排列置換法三板斧</a><ul>
<li class="chapter" data-level="32.3.1" data-path="-permutation-procedures.html"><a href="-permutation-procedures.html#-t"><i class="fa fa-check"></i><b>32.3.1</b> 該如何選用合適的檢驗統計量 <span class="math inline">\(T\)</span>？</a></li>
<li class="chapter" data-level="32.3.2" data-path="-permutation-procedures.html"><a href="-permutation-procedures.html#-adjustment-"><i class="fa fa-check"></i><b>32.3.2</b> 可以在排列置換法中對其他變量進行統計學調整 (adjustment) 嗎？</a></li>
<li class="chapter" data-level="32.3.3" data-path="-permutation-procedures.html"><a href="-permutation-procedures.html#section-32.3.3"><i class="fa fa-check"></i><b>32.3.3</b> 排列置換法，基於秩次的非參數檢驗之間的關係</a></li>
<li class="chapter" data-level="32.3.4" data-path="-permutation-procedures.html"><a href="-permutation-procedures.html#section-32.3.4"><i class="fa fa-check"></i><b>32.3.4</b> 排列置換檢驗法，是一種精確檢驗</a></li>
</ul></li>
<li class="chapter" data-level="32.4" data-path="-permutation-procedures.html"><a href="-permutation-procedures.html#section-32.4"><i class="fa fa-check"></i><b>32.4</b> 基於排序置換檢驗法計算信賴區間</a></li>
<li class="chapter" data-level="32.5" data-path="-permutation-procedures.html"><a href="-permutation-procedures.html#section-32.5"><i class="fa fa-check"></i><b>32.5</b> 排序置換法的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="-the-bootstrap.html"><a href="-the-bootstrap.html"><i class="fa fa-check"></i><b>33</b> 自助重抽法 The bootstrap</a><ul>
<li class="chapter" data-level="33.1" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>33.1</b> 定義</a></li>
</ul></li>
<li class="part"><span><b>VII 貝葉斯統計</b></span></li>
<li class="chapter" data-level="34" data-path="section-34.html"><a href="section-34.html"><i class="fa fa-check"></i><b>34</b> 貝葉斯統計入門</a><ul>
<li class="chapter" data-level="34.1" data-path="section-34.html"><a href="section-34.html#section-34.1"><i class="fa fa-check"></i><b>34.1</b> 概率論推斷的複習</a></li>
<li class="chapter" data-level="34.2" data-path="section-34.html"><a href="section-34.html#-bayesian-reasoninginverse-probability"><i class="fa fa-check"></i><b>34.2</b> 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability</a><ul>
<li class="chapter" data-level="34.2.1" data-path="section-34.html"><a href="section-34.html#-deductive-reasoning---weak-syllogisms"><i class="fa fa-check"></i><b>34.2.1</b> 演繹推理 deductive reasoning 和 三段論 weak syllogisms</a></li>
<li class="chapter" data-level="34.2.2" data-path="section-34.html"><a href="section-34.html#-quantifying-plausibility"><i class="fa fa-check"></i><b>34.2.2</b> 如何給可能性定量 Quantifying plausibility</a></li>
</ul></li>
<li class="chapter" data-level="34.3" data-path="section-34.html"><a href="section-34.html#section-34.3"><i class="fa fa-check"></i><b>34.3</b> 貝葉斯推理的統計學實現</a><ul>
<li class="chapter" data-level="34.3.1" data-path="section-34.html"><a href="section-34.html#-diagnostic-testing"><i class="fa fa-check"></i><b>34.3.1</b> 醫學診斷測試 diagnostic testing</a></li>
<li class="chapter" data-level="34.3.2" data-path="section-34.html"><a href="section-34.html#hiv-"><i class="fa fa-check"></i><b>34.3.2</b> HIV 檢查時的應用</a></li>
<li class="chapter" data-level="34.3.3" data-path="section-34.html"><a href="section-34.html#section-34.3.3"><i class="fa fa-check"></i><b>34.3.3</b> 說點小歷史</a></li>
</ul></li>
<li class="chapter" data-level="34.4" data-path="section-34.html"><a href="section-34.html#-5"><i class="fa fa-check"></i><b>34.4</b> 練習題</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="section-35.html"><a href="section-35.html"><i class="fa fa-check"></i><b>35</b> 貝葉斯定理的應用：單一參數模型</a><ul>
<li class="chapter" data-level="35.1" data-path="section-35.html"><a href="section-35.html#-notation-for-probability-density-functions"><i class="fa fa-check"></i><b>35.1</b> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions</a></li>
<li class="chapter" data-level="35.2" data-path="section-35.html"><a href="section-35.html#theta-"><i class="fa fa-check"></i><b>35.2</b> <span class="math inline">\(\theta\)</span> 的先驗概率</a><ul>
<li class="chapter" data-level="35.2.1" data-path="section-35.html"><a href="section-35.html#beta--the-beta-distribution"><i class="fa fa-check"></i><b>35.2.1</b> beta 分佈 the beta distribution</a></li>
<li class="chapter" data-level="35.2.2" data-path="section-35.html"><a href="section-35.html#conjugate"><i class="fa fa-check"></i><b>35.2.2</b> 二項分佈數據事後概率分佈的一般化：共軛性</a></li>
</ul></li>
<li class="chapter" data-level="35.3" data-path="section-35.html"><a href="section-35.html#-6"><i class="fa fa-check"></i><b>35.3</b> 練習題</a><ul>
<li class="chapter" data-level="35.3.1" data-path="section-35.html"><a href="section-35.html#q1-4"><i class="fa fa-check"></i><b>35.3.1</b> Q1</a></li>
<li class="chapter" data-level="35.3.2" data-path="section-35.html"><a href="section-35.html#q2-3"><i class="fa fa-check"></i><b>35.3.2</b> Q2</a></li>
<li class="chapter" data-level="35.3.3" data-path="section-35.html"><a href="section-35.html#q3-2"><i class="fa fa-check"></i><b>35.3.3</b> Q3</a></li>
<li class="chapter" data-level="35.3.4" data-path="section-35.html"><a href="section-35.html#q4"><i class="fa fa-check"></i><b>35.3.4</b> Q4</a></li>
<li class="chapter" data-level="35.3.5" data-path="section-35.html"><a href="section-35.html#q5"><i class="fa fa-check"></i><b>35.3.5</b> Q5</a></li>
<li class="chapter" data-level="35.3.6" data-path="section-35.html"><a href="section-35.html#q6"><i class="fa fa-check"></i><b>35.3.6</b> Q6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>参考文献</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">本书由 bookdown 强力驱动</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">醫學統計學</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="-ordinary-least-squares-estimators-and-inference" class="section level1">
<h1><span class="header-section-number">第 25 章</span> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</h1>
<p>前一章介紹了簡單線性迴歸模型中對總體參數 <span class="math inline">\(\alpha, \beta, \sigma^2\)</span> 的估計公式，分別是 <a href="-simple-linear-regression.html#eq:hatalpha">(24.5)</a> <a href="-simple-linear-regression.html#eq:hatbeta">(24.6)</a> <a href="-simple-linear-regression.html#eq:sigma2right">(24.9)</a>。本章繼續介紹他們的統計學性質。下面的標記和統計量也會被用到：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\bar{y}=\frac{\sum_{i=1}^n y_i}{n}\)</span>，因變量 <span class="math inline">\(y\)</span> 的樣本均值；</li>
<li><span class="math inline">\(\bar{x}=\frac{\sum_{i=1}^n x_i}{n}\)</span>，預測變量 <span class="math inline">\(x\)</span> 的樣本均值；</li>
<li><span class="math inline">\(SS_{yy}=\sum_{i=1}^n(y_i-\bar{y})^2\)</span>，因變量 <span class="math inline">\(y\)</span> 的校正平方和；</li>
<li><span class="math inline">\(SS_{xx}=\sum_{i=1}^n(x_i-\bar{x})^2\)</span>，預測變量 <span class="math inline">\(x\)</span> 的校正平方和；</li>
<li><span class="math inline">\(SD_y^2=\frac{\sum_{i=1}(y_i-\bar{y})^2}{n-1}=\frac{SS_{yy}}{n-1}\)</span>，因變量 <span class="math inline">\(y\)</span> 的樣本方差；</li>
<li><span class="math inline">\(SD_x^2=\frac{\sum_{i=1}(x_i-\bar{x})^2}{n-1}=\frac{SS_{xx}}{n-1}\)</span>，因變量 <span class="math inline">\(y\)</span> 的樣本方差；</li>
<li><span class="math inline">\(S_{xy}=\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})\)</span>，<span class="math inline">\(x,y\)</span> 的交叉乘積；</li>
<li><span class="math inline">\(CV_{xy}=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{n-1}=\frac{S_{xy}}{n-1}\)</span>，樣本協方差；</li>
<li><span class="math inline">\(r_{xy}=\frac{CV_{xy}}{SD_xSD_y}\)</span>，<span class="math inline">\(x,y\)</span> 的樣本相關係數；</li>
<li><span class="math inline">\(SS_{RES}=\sum_{i=1}^n\hat\varepsilon^2=\sum_{i=1}^n(y_i-\hat\alpha-\hat\beta x_i)^2\)</span>，殘差的估計平方和。</li>
</ol>
<div id="ols-" class="section level2">
<h2><span class="header-section-number">25.1</span> OLS 估計量的性質</h2>
<ol style="list-style-type: decimal">
<li>樣本估計的迴歸直線必定穿過數據的中心 <span class="math inline">\((\bar{x},\bar{y})\)</span>。</li>
</ol>
<p><strong>證明</strong></p>
<p>由於樣本估計的截距和斜率公式 <a href="-simple-linear-regression.html#eq:hatalpha">(24.5)</a> <a href="-simple-linear-regression.html#eq:hatbeta">(24.6)</a> 可知：</p>
<p><span class="math display" id="eq:lmcenter">\[
\begin{aligned}
\hat\alpha &amp;= \bar{y} - \hat\beta\bar{x} \\
 \hat y_i  &amp;= \hat\alpha + \hat\beta x_i \\
 \Rightarrow \hat y_i &amp;= \bar{y}+\hat\beta(x_i-\bar{x})
\end{aligned}
\tag{25.1}
\]</span></p>
<p>所以，當 <span class="math inline">\(\hat x_i=\bar{x}\)</span> 時 <span class="math inline">\(\hat y_i=\bar{y}\)</span>。即迴歸直線必然穿過中心點。</p>
<ol start="2" style="list-style-type: decimal">
<li>如果擬合模型是正確無誤的， <span class="math inline">\(\hat\alpha,\hat\beta,\hat\sigma^2\)</span> 分別是各自的無偏估計。</li>
<li><span class="math inline">\(\hat\alpha, \hat\beta\)</span> 是極大似然估計， <span class="math inline">\(\hat\sigma^2\)</span> 不是MLE。</li>
<li><span class="math inline">\(\hat\alpha, \hat\beta\)</span> 是 <span class="math inline">\(\alpha, \beta\)</span> 最有效的估計量。</li>
</ol>
</div>
<div id="hatbeta-" class="section level2">
<h2><span class="header-section-number">25.2</span> <span class="math inline">\(\hat\beta\)</span> 的性質</h2>
<p><span class="math display" id="eq:hatbetaalt">\[
\begin{equation}
\hat\beta=\frac{S_{xy}}{SS_{xx}}=\frac{CV_{xy}}{SD_x^2}
\end{equation}
\tag{25.2}
\]</span></p>
<div id="randbeta" class="section level3">
<h3><span class="header-section-number">25.2.1</span> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</h3>
<p>如果我們使用 <span class="math inline">\(\hat\beta_{y|x}\)</span> 表示預測變量 <span class="math inline">\(x\)</span>，因變量 <span class="math inline">\(y\)</span> 的簡單線性迴歸係數，那麼我們就有：</p>
<p><span class="math display" id="eq:r2">\[
\begin{equation}
\hat\beta_{y|x} = \frac{CV_{xy}}{SD_x^2}  \text{ and } \hat\beta_{x|y} = \frac{CV_{xy}}{SD_y^2} \\
\text{Hence, } \hat\beta_{y|x}\hat\beta_{x|y} = r^2_{xy}
\end{equation}
\tag{25.3}
\]</span></p>
<p>公式 <a href="-ordinary-least-squares-estimators-and-inference.html#eq:r2">(25.3)</a> 也證明了：如果兩個變量相關係數爲 <span class="math inline">\(1\)</span> (100% 相關)， <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸的迴歸係數，是 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸的迴歸係數的倒數。</p>
</div>
<div id="-1--reffigage-wt-" class="section level3">
<h3><span class="header-section-number">25.2.2</span> 例 1： 還是圖 <a href="-simple-linear-regression.html#fig:age-wt">24.1</a> 數據</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(haven)
growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)

<span class="co"># regress wt on age</span>
<span class="kw">summary</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age, data = growgam1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.924 -0.785  0.007  0.797  4.068 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   6.8376     0.2101    32.5   &lt;2e-16 ***
## age           0.1653     0.0111    14.9   &lt;2e-16 ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.27 on 188 degrees of freedom
## Multiple R-squared:  0.541,  Adjusted R-squared:  0.538 
## F-statistic:  221 on 1 and 188 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">anova</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)), <span class="dt">digits =</span> <span class="dv">8</span>)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: wt
##            Df    Sum Sq   Mean Sq   F value     Pr(&gt;F)
## age         1 359.06320 359.06320 221.39203 &lt; 2.22e-16
## Residuals 188 304.90655   1.62184                     
##              
## age       ***
## Residuals    
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># regress age on wt</span>
<span class="kw">summary</span>(<span class="kw">lm</span>(age<span class="op">~</span>wt, <span class="dt">data=</span>growgam1))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = age ~ wt, data = growgam1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -16.010  -4.239   0.083   3.130  21.111 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   -14.57       2.16   -6.75  1.8e-10 ***
## wt              3.27       0.22   14.88  &lt; 2e-16 ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.66 on 188 degrees of freedom
## Multiple R-squared:  0.541,  Adjusted R-squared:  0.538 
## F-statistic:  221 on 1 and 188 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">anova</span>(<span class="kw">lm</span>(age<span class="op">~</span>wt, <span class="dt">data=</span>growgam1)), <span class="dt">digits =</span> <span class="dv">8</span>)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: age
##            Df    Sum Sq   Mean Sq   F value     Pr(&gt;F)
## wt          1 7103.6730 7103.6730 221.39203 &lt; 2.22e-16
## Residuals 188 6032.2428   32.0864                     
##              
## wt        ***
## Residuals    
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>可以看到二者的輸出結果中統計檢驗量一樣，但是一個是將體重針對年齡迴歸，另一個則是反過來，所以迴歸係數和截距都不同。迴歸方程的含義也就發生了變化。如果把兩條迴歸曲線同時作圖可以更加直觀：</p>
<div class="figure" style="text-align: center"><span id="fig:age-wt-lm1"></span>
<img src="bookdown_files/figure-html/age-wt-lm1-1.png" alt="Simple linear regression model line relating weight to age" width="80%" />
<p class="caption">
图 25.1: Simple linear regression model line relating weight to age
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:wt-age-lm"></span>
<img src="bookdown_files/figure-html/wt-age-lm-1.png" alt="Simple linear regression model line relating age to weight" width="80%" />
<p class="caption">
图 25.2: Simple linear regression model line relating age to weight
</p>
</div>
</div>
</div>
<div id="section-25.3" class="section level2">
<h2><span class="header-section-number">25.3</span> 截距和迴歸係數的方差，協方差</h2>
<p>假如簡單線性迴歸模型是正確的，那麼截距 <span class="math inline">\(\hat\alpha\)</span> 和迴歸係數 <span class="math inline">\(\hat\beta\)</span> 的方差分別是：</p>
<p><span class="math display" id="eq:varhatalpha">\[
\begin{equation}
V(\hat\alpha) = \sigma^2(\frac{1}{n}+\frac{\bar{x}^2}{SS_{xx}}) = \frac{\sigma^2}{(n-1)} (1-\frac{1}{n}+\frac{\bar{x}^2}{SD_x^2})
\end{equation}
\tag{25.4}
\]</span></p>
<p><span class="math display" id="eq:varhatbeta">\[
\begin{equation}
V(\hat\beta) = \frac{\sigma^2}{SS_{xx}}=\frac{\sigma^2}{(n-1)SD_x^2}
\end{equation}
\tag{25.5}
\]</span></p>
<p>從公式 <a href="-ordinary-least-squares-estimators-and-inference.html#eq:varhatalpha">(25.4)</a> 和 <a href="-ordinary-least-squares-estimators-and-inference.html#eq:varhatbeta">(25.5)</a> 也可以看出，兩個估計量的方差隨着殘差方差的增加而增加 (估計不精確)，隨着樣本兩的增加而減少 (估計更精確)。截距 <span class="math inline">\(\hat\alpha\)</span> 的方差會隨着樣本均值的增加而增加。</p>
<p>通常來說，截距和迴歸係數二者之間並非相互獨立。他們的協方差爲：</p>
<p><span class="math display" id="eq:covaralphabeta">\[
\begin{equation}
Cov(\hat\alpha,\hat\beta) = -\frac{\sigma^2\bar{x}}{SS_{xx}}
\end{equation}
\tag{25.6}
\]</span></p>
<p>上面的公式 <a href="-ordinary-least-squares-estimators-and-inference.html#eq:varhatalpha">(25.4)</a> <a href="-ordinary-least-squares-estimators-and-inference.html#eq:varhatbeta">(25.5)</a> <a href="-ordinary-least-squares-estimators-and-inference.html#eq:covaralphabeta">(25.6)</a> 都包含了真實的殘差方差 <span class="math inline">\(\sigma^2\)</span>。這個量對於我們“人類”來說是未知的。</p>
<div id="-centring" class="section level3">
<h3><span class="header-section-number">25.3.1</span> 中心化 centring</h3>
<p>簡單線性迴歸模型常用的一個技巧是將預測變量中心化。即，求預測變量的均值，然後將每個觀測值減去均值之後再用這個新的預測變量擬合簡單線性迴歸模型。這樣做其實完全不影響回顧係數，卻會影響截距的大小。此時新的迴歸直線的截距，就等於因變量 (體重) 的均值。</p>
<p>用圖 <a href="-simple-linear-regression.html#fig:age-wt">24.1</a> 數據來解釋：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># mean value of age</span>
<span class="kw">mean</span>(growgam1<span class="op">$</span>age)</code></pre></div>
<pre><code>## [1] 16.98</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">growgam1<span class="op">$</span>age_cen &lt;-<span class="st"> </span>growgam1<span class="op">$</span>age<span class="op">-</span><span class="kw">mean</span>(growgam1<span class="op">$</span>age)
<span class="co"># regress wt on age</span>
<span class="kw">print</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)), <span class="dt">digit=</span><span class="dv">5</span>)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.92418 -0.78489  0.00710  0.79747  4.06781 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 6.837584   0.210070  32.549 &lt; 2.2e-16 ***
## age         0.165331   0.011112  14.879 &lt; 2.2e-16 ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.274 on 188 degrees of freedom
## Multiple R-squared:  0.54078,    Adjusted R-squared:  0.53834 
## F-statistic: 221.39 on 1 and 188 DF,  p-value: &lt; 2.22e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age_cen, <span class="dt">data=</span>growgam1)), <span class="dt">digit=</span><span class="dv">5</span>)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wt ~ age_cen, data = growgam1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.92418 -0.78489  0.00710  0.79747  4.06781 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 9.644737   0.092391 104.391 &lt; 2.2e-16 ***
## age_cen     0.165331   0.011112  14.879 &lt; 2.2e-16 ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.274 on 188 degrees of freedom
## Multiple R-squared:  0.54078,    Adjusted R-squared:  0.53834 
## F-statistic: 221.39 on 1 and 188 DF,  p-value: &lt; 2.22e-16</code></pre>
<p>很明顯，結果顯示中心化不會改變迴歸係數，也不會改變它的方差。但是“新”的截距，其實就等於因變量 (體重) 的均值。而且很多數據都集中在這個均值附近，因而，截距的方差比沒有中心化的迴歸方程要小。</p>
</div>
</div>
<div id="alpha-beta-" class="section level2">
<h2><span class="header-section-number">25.4</span> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</h2>
<p><span class="math inline">\(\hat\alpha, \hat\beta\)</span> 都可以被改寫成關於因變量 <span class="math inline">\(Y\)</span> 的方程，因此同時也是隨機誤差的方程式：</p>
<p><span class="math display">\[
\begin{aligned}
\hat\beta &amp;= \sum_{i=1}^n[\frac{(x_i-\bar{x})}{SS_{xx}}(y_i-\bar{y})] \\
\text{Substituting } &amp;(y_i-\bar{y}) = \beta(x_i-\bar{x})+(\varepsilon_i-\bar{\varepsilon}) \\
          &amp;= \beta + \sum_{i=1}^n[\frac{x_i-\bar{x}}{SS_{xx}}(\varepsilon_i-\bar{\varepsilon})]
\end{aligned}
\]</span></p>
<p>又因爲，<span class="math inline">\(\varepsilon_i \sim NID(0,\sigma^2)\)</span>，估計量 <span class="math inline">\(\hat\alpha, \hat\beta\)</span> 均爲 <span class="math inline">\(\varepsilon_i\)</span> 的線性轉換，所以他們也都是服從正態分佈的。</p>
<div id="section-25.4.1" class="section level3">
<h3><span class="header-section-number">25.4.1</span> 對迴歸係數進行假設檢驗</h3>
<p>對於迴歸係數 <span class="math inline">\(\beta\)</span>，我們可以使用 Wald statistic (Section <a href="section-16.html#Wald">16.4</a>) 進行零假設爲 <span class="math inline">\(\text{H}_0: \beta=0\)</span> 的假設檢驗。此時，替代假設爲 <span class="math inline">\(\text{H}_1: \beta\neq0\)</span>。最佳檢驗統計量爲：</p>
<p><span class="math display" id="eq:betattest">\[
\begin{equation}
t = \frac{\hat\beta-0}{SE(\hat\beta)} \\
\end{equation}
\tag{25.7}
\]</span></p>
<p>根據公式 <a href="-ordinary-least-squares-estimators-and-inference.html#eq:varhatbeta">(25.5)</a> <span class="math inline">\(SE(\hat\beta) = \sqrt{V(\hat\beta)} = \frac{\hat\sigma}{\sqrt{SS_{xx}}}\)</span>。用 <span class="math inline">\(\hat\sigma^2\)</span> 替換掉公式 <a href="-ordinary-least-squares-estimators-and-inference.html#eq:varhatbeta">(25.5)</a> 中的 <span class="math inline">\(\sigma^2\)</span>，意味着迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 服從自由度爲 <span class="math inline">\(n-2\)</span> 的 <span class="math inline">\(t\)</span> 分佈。之後就可以根據 <span class="math inline">\(t\)</span> 分佈的性質求相應的 <span class="math inline">\(p\)</span> 值了，對相關係數是否爲 <span class="math inline">\(0\)</span> 進行檢驗。之所以我們可以在這裏使用 Wald 檢驗，是因爲前提條件：隨機誤差服從正態分佈，於是 <span class="math inline">\(\beta\)</span> 的對數似然比也是左右對稱的，當對數似然比的圖形左右對稱時，就可以使用二次方程來近似 (Wald 檢驗的實質)。</p>
</div>
<div id="section-25.4.2" class="section level3">
<h3><span class="header-section-number">25.4.2</span> 迴歸係數，截距的信賴區間</h3>
<p>估計量 <span class="math inline">\(\beta\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間的計算公式如下：</p>
<p><span class="math display" id="eq:CIbeta">\[
\begin{equation}
\hat\beta \pm t_{n-2,0.975}SE(\hat\beta)
\end{equation}
\tag{25.8}
\]</span></p>
<p>其中，<span class="math inline">\(t_{n-2, 0.975}\)</span> 表示自由度爲 <span class="math inline">\(n-2\)</span> 的 <span class="math inline">\(t\)</span> 分佈的 <span class="math inline">\(97.5\%\)</span> 位點的值。繼續使用之前的實例，圖 <a href="-simple-linear-regression.html#fig:age-wt">24.1</a> 中的數據。體重對年齡進行簡單線性迴歸之後，年齡的估計回顧係數 <span class="math inline">\(\hat\beta=0.165, SE(\hat\beta)=0.0111\)</span>, 此例中 <span class="math inline">\(n=190\)</span>，所以 <span class="math inline">\(t_{188, 0.975}=1.973\)</span>。所以迴歸係數的 <span class="math inline">\(95\%\)</span> 信賴區間可以如此計算：<span class="math inline">\(0.165\pm1.973\times0.0111=(0.143, 0.187)\)</span>。</p>
<p>類似的，估計截距 <span class="math inline">\(\hat\alpha\)</span> 的 <span class="math inline">\(95\%\)</span> 信賴區間的計算式便是： <span class="math inline">\(\hat\alpha \pm t_{n-2, 0.975}SE(\hat\alpha)\)</span>。同樣的例子裏，<span class="math inline">\(\hat\alpha=6.838, SE(\hat\beta) = 0.210, t_{188, 0.975}=1.973\)</span>。所以截距的 <span class="math inline">\(95\%\)</span> 信賴區間的計算方法就是： <span class="math inline">\(6.838\pm1.973\times0.210=(6.42, 7.25)\)</span></p>
<p>跟下面 R 計算的完全一樣：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(<span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1))</code></pre></div>
<pre><code>##              2.5 % 97.5 %
## (Intercept) 6.4232 7.2520
## age         0.1434 0.1873</code></pre>
</div>
<div id="----" class="section level3">
<h3><span class="header-section-number">25.4.3</span> 預測值的信賴區間 (置信带) - 测量回归曲线本身的不确定性</h3>
<p>這裏所謂的“預測值”其實並沒有拿來預測什麼新的數值，而是說我們希望通過線性迴歸找到因變量真實值的存在區間 (信賴區間)。所以這個預測值的真實含義其實應該是在預測變量取 <span class="math inline">\(X=x\)</span> 時，因變量的期待值，<span class="math inline">\(E(Y|X=x)\)</span>。</p>
<p>這個預測值的方差公式如下：</p>
<p><span class="math display" id="eq:predictvar">\[
\begin{equation}
V(\hat y_{x}) = \sigma^2[\frac{1}{n}+\frac{(x_i-\bar{x})^2}{SS_{xx}}]
\end{equation}
\tag{25.9}
\]</span></p>
<p>於是可以計算它的 <span class="math inline">\(95\%\)</span> 信賴區間公式是：</p>
<p><span class="math display" id="eq:predictCI">\[
\begin{equation}
\hat y_x \pm t_{n-2, 0.975} \hat\sigma \sqrt{[\frac{1}{n}+\frac{(x-\bar{x})^2}{SS_{xx}}]}
\end{equation}
\tag{25.10}
\]</span></p>
<p>其實在之前的圖 (圖 <a href="-simple-linear-regression.html#fig:age-wt-lm">24.2</a>) 我們也已經展示過這個信賴區間的範圍。</p>
</div>
<div id="-reference-range----95-" class="section level3">
<h3><span class="header-section-number">25.4.4</span> 预测带 Reference range - 包含了 95% 观察值的区间</h3>
<p>此處的 <span class="math inline">\(95\%\)</span> 預測帶，其實是包含了 <span class="math inline">\(95\%\)</span> 觀察數據的區間。所以預測帶要比置信帶更寬。它的方差計算公式爲：</p>
<p><span class="math display" id="eq:refrangevar">\[
\begin{equation}
V(\hat y_x)+\sigma^2 = \sigma^2[1+\frac{1}{n}+\frac{(x-\bar{x})^2}{SS_{xx}}]
\end{equation}
\tag{25.11}
\]</span></p>
<p>區間計算公式爲：</p>
<p><span class="math display" id="eq:refrangeCI">\[
\begin{equation}
\hat{y}_x \pm t_{n-2, 0.975} \sqrt{1+\frac{1}{n}+\frac{(x-\bar{x})^2}{SS_{xx}}}
\end{equation}
\tag{25.12}
\]</span></p>
<p>將置信帶和預測帶同時展現則如下圖：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(haven)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(ggthemes)
growgam1 &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/growgam1.dta&quot;</span>)


Model &lt;-<span class="st"> </span><span class="kw">lm</span>(wt<span class="op">~</span>age, <span class="dt">data=</span>growgam1)
temp_var &lt;-<span class="st"> </span><span class="kw">predict</span>(Model, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)

new_df &lt;-<span class="st"> </span><span class="kw">cbind</span>(growgam1, temp_var)


<span class="kw">ggplot</span>(new_df, <span class="kw">aes</span>(<span class="dt">x=</span>age, <span class="dt">y=</span>wt)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">shape=</span><span class="dv">20</span>, <span class="dt">colour=</span><span class="st">&quot;grey40&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> lm, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">size =</span> <span class="fl">0.3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>lwr), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>upr), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">38</span>, <span class="dv">4</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">36.5</span>))<span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dv">5</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">20.5</span>)) <span class="op">+</span>
<span class="st">   </span><span class="kw">theme_stata</span>() <span class="op">+</span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Age (Months)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Weight (kg)&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:age-wt-lm-pred"></span>
<img src="bookdown_files/figure-html/age-wt-lm-pred-1.png" alt="Simple linear regression for age and weight of children in a cross-sectional survey with 95% CI of predicted values and 95% reference range" width="80%" />
<p class="caption">
图 25.3: Simple linear regression for age and weight of children in a cross-sectional survey with 95% CI of predicted values and 95% reference range
</p>
</div>
</div>
</div>
<div id="rsquare" class="section level2">
<h2><span class="header-section-number">25.5</span> 線性迴歸模型和 Pearson 相關係數</h2>
<p>前面也推導過線性迴歸係數和 Pearson 相關係數之間的關係 (Section <a href="-ordinary-least-squares-estimators-and-inference.html#randbeta">25.2.1</a>)，這裏詳細再展開討論它們之間關係的另外兩個重要結論。</p>
<div id="r2-" class="section level3">
<h3><span class="header-section-number">25.5.1</span> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</h3>
<p>Pearson 相關係數，因變量的平方和，模型的殘差平方和之間有如下的關係：</p>
<p><span class="math display" id="eq:rSSyySSres">\[
\begin{equation}
r^2 = \frac{SS_{yy}-SS_{RES}}{SS_{yy}} = 1-\frac{SS_{RES}}{SS_{yy}}
\end{equation}
\tag{25.13}
\]</span></p>
<p><strong>證明</strong></p>
<p><span class="math display">\[
\frac{SS_{RES}}{SS_{yy}} = \frac{\sum_{i=1}^n(y_i-\hat\alpha-\hat\beta x_i)^2}{\sum_{i=1}^n(y_i-\bar{y})^2}
\]</span></p>
<p>因爲 <a href="-simple-linear-regression.html#eq:hatalpha">(24.5)</a> : <span class="math inline">\(\hat\alpha=\bar{y}-\hat{\beta}\bar{x}\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{SS_{RES}}{SS_{yy}} &amp;= \frac{\sum_{i=1}^n[(y_i-\bar{y})-\hat\beta(x_i-\bar{x})]^2}{\sum_{i=1}^n(y_i-\bar{y})^2} \\
                  &amp;=\frac{\sum_{i=1}^n(y_i-\bar{y})^2}{\sum_{i=1}^n(y_i-\bar{y})^2}-\frac{2\hat\beta\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(y_i-\bar{y})^2}+\frac{\hat\beta^2\sum_{i=1}^n(x_i-\bar{x})^2}{\sum_{i=1}^n(y_i-\bar{y})^2}\\
                  &amp;=1-\frac{2\hat\beta SS_{xy}}{SS_{yy}} + \frac{\hat\beta^2SS_{xx}}{SS_{yy}}
\end{aligned}
\]</span></p>
<p>又因爲 <span class="math inline">\(\hat\beta=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}=\frac{S_{xy}}{SS_{xx}}, r^2=\frac{S_{xy}^2}{SS_{xx}SS_{yy}}\)</span>。</p>
<p><span class="math display">\[
\begin{aligned}
\frac{SS_{RES}}{SS_{yy}} &amp;= 1-\frac{2S_{xy}^2}{SS_{yy}SS_{xx}}+\frac{S_{xy}^2}{SS_{xx}SS_{yy}}\\
&amp;=1-2r^2+r^2\\
&amp;=1-r^2\\
\Rightarrow r^2&amp;=1-\frac{SS_{RES}}{SS_{yy}}
\end{aligned}
\]</span></p>
<p>因此，這裏就引出了非常重要的一個結論，<strong>Pearson 相關係數的平方 <span class="math inline">\(r^2\)</span> 的統計學含義是，因變量的平方和 <span class="math inline">\(SS_{yy}\)</span> 中，模型的預測變量能夠解釋的部分 <span class="math inline">\(1-SS_{RES}\)</span> 的百分比。</strong> 統計學結果的報告中，爲了和一般相關係數的意義區分，會用大寫的 <span class="math inline">\(R^2\)</span> 來表示這個模型解釋了因變量的百分比。(Section <a href="-introduction-to-analysis-of-variance.html#Rsquare">26.2.3</a>)</p>
</div>
</div>
<div id="t-r2-F" class="section level2">
<h2><span class="header-section-number">25.6</span> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</h2>
<p><span class="math display" id="eq:t-r2">\[
\begin{equation}
t=r\sqrt{\frac{n-2}{1-r^2}}
\end{equation}
\tag{25.14}
\]</span></p>
<p><strong>證明</strong></p>
<p>由於前面推導的 <span class="math inline">\(r^2\)</span> 公式 <a href="-ordinary-least-squares-estimators-and-inference.html#eq:rSSyySSres">(25.13)</a>，而且 <span class="math inline">\(r^2=\frac{S_{xy}^2}{SS_{xx}SS_{yy}}\)</span>：</p>
<p><span class="math display">\[
\begin{aligned}
\frac{r^2}{1-r^2} &amp; = \frac{\frac{S_{xy}^2}{SS_{xx}SS_{yy}}}{\frac{SS_{RES}}{SS_{yy}}} \\
                  &amp; = \frac{S_{xy}^2}{SS_{xx}SS_{RES}} \\
                  &amp; = \frac{S_{xy}^2}{SS_{xx}(n-2)\hat\sigma^2}
\end{aligned}
\]</span></p>
<p>由於公式 <a href="-ordinary-least-squares-estimators-and-inference.html#eq:varhatbeta">(25.5)</a>，所以 <span class="math inline">\(\hat\sigma^2=V(\hat\beta)SS_{xx}\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{r^2}{1-r^2} &amp; = \frac{S_{xy}^2}{SS^2_{xx}(n-2)V(\hat\beta)} \\
                  &amp; = \frac{\hat\beta^2}{(n-2)V(\hat\beta)} \\
\Rightarrow t=r\sqrt{\frac{n-2}{1-r^2}}
\end{aligned}
\]</span></p>
<p>這個結論也被用於相關係數的假設檢驗。而且也正如 Section <a href="-ordinary-least-squares-estimators-and-inference.html#randbeta">25.2.1</a> 證明過的那樣，在簡單線性迴歸裏因變量和預測變量的位置對調以後，對於回顧係數是否爲零的檢驗統計量不受影響。</p>
</div>
<div id="section-25.7" class="section level2">
<h2><span class="header-section-number">25.7</span> 練習</h2>
<p>數據同前一章練習部分數據相同 <a href="-simple-linear-regression.html#exeChol">24.8</a>：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 數據讀入</span>
<span class="kw">library</span>(haven)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(ggthemes)
Chol &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;backupfiles/chol.dta&quot;</span>)
Model &lt;-<span class="st"> </span><span class="kw">lm</span>(chol2<span class="op">~</span>chol1, <span class="dt">data=</span>Chol)
<span class="kw">print</span>(<span class="kw">summary</span>(Model), <span class="dt">digit=</span><span class="dv">6</span>)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = chol2 ~ chol1, data = Chol)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -56.87654 -22.06181   1.84937  16.63107  84.11839 
## 
## Coefficients:
##                Estimate  Std. Error t value   Pr(&gt;|t|)
## (Intercept) 110.4246582  20.0113279 5.51811 2.8499e-07
## chol1         0.5786806   0.0747598 7.74053 9.5114e-12
##                
## (Intercept) ***
## chol1       ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 30.16 on 97 degrees of freedom
## Multiple R-squared:  0.381834,   Adjusted R-squared:  0.375462 
## F-statistic: 59.9159 on 1 and 97 DF,  p-value: 9.51139e-12</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">anova</span>(Model), <span class="dt">digit=</span><span class="dv">6</span>)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: chol2
##           Df  Sum Sq Mean Sq F value     Pr(&gt;F)    
## chol1      1 54511.7 54511.7 59.9159 9.5114e-12 ***
## Residuals 97 88250.9   909.8                       
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 計算截距和迴歸係數的 P 值 HAND CALCULATIONS twosided p-value in R can be obtained by pt(t, df) function</span>

## p value for intercept:

<span class="fl">110.42466</span><span class="op">/</span><span class="fl">20.01133</span> <span class="co">#=5.518107</span></code></pre></div>
<pre><code>## [1] 5.518</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span><span class="op">*</span><span class="kw">pt</span>(<span class="fl">5.518107</span>, <span class="dv">97</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## [1] 2.85e-07</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## p value for beta:

<span class="fl">0.57868</span><span class="op">/</span><span class="fl">0.07476</span> <span class="co">#= 7.740503</span></code></pre></div>
<pre><code>## [1] 7.741</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span><span class="op">*</span><span class="kw">pt</span>(<span class="fl">7.740503</span>, <span class="dv">97</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## [1] 9.513e-12</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># add fitted regression lines 95% CIs and reference range</span>
temp_var &lt;-<span class="st"> </span><span class="kw">predict</span>(Model, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)

new_df &lt;-<span class="st"> </span><span class="kw">cbind</span>(Chol, temp_var)

<span class="kw">ggplot</span>(new_df, <span class="kw">aes</span>(<span class="dt">x=</span>chol1, <span class="dt">y=</span>chol2)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">shape=</span><span class="dv">20</span>, <span class="dt">colour=</span><span class="st">&quot;grey40&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> lm, <span class="dt">se=</span><span class="ot">TRUE</span>, <span class="dt">size=</span><span class="fl">0.5</span>)  <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>lwr), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>upr), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span>
<span class="st">   </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>))<span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">150</span>, <span class="dv">400</span>, <span class="dv">50</span>),<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">355</span>)) <span class="op">+</span>
<span class="st">   </span><span class="kw">theme_stata</span>() <span class="op">+</span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Cholesterol at visit 1 (mg/100ml)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Cholesterol at visit 2 (mg/100ml)&quot;</span>)</code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-44-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>圖中可見，95% 置信帶變化顯著，距離均值越遠的地方，置信帶越寬。然而預測帶基本是平行的沒有變化。因爲預測帶的涵義是，95%的觀察數據都在這個區間範圍內。</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="-simple-linear-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="-introduction-to-analysis-of-variance.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/winterwang/LSHTMlearningnote/edit/master/04-Linear-Regression.Rmd",
"text": "编辑"
},
"download": ["bookdown.pdf", "bookdown.epub"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
