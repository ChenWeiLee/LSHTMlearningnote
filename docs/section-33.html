<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>醫學統計學</title>
  <meta name="description" content="在LSHTM的學習筆記">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="醫學統計學" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/cover.jpg" />
  <meta property="og:description" content="在LSHTM的學習筆記" />
  <meta name="github-repo" content="winterwang/LSHTMlearningnote" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="醫學統計學" />
  
  <meta name="twitter:description" content="在LSHTM的學習筆記" />
  <meta name="twitter:image" content="img/cover.jpg" />

<meta name="author" content="王 超辰 Chaochen Wang">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="section-32.html">
<link rel="next" href="references.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">在LSHTM的學習筆記</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i>我是誰</a></li>
<li class="part"><span><b>I 概率論 Probability</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> 概率論入門：定義與公理</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#section-1.1"><i class="fa fa-check"></i><b>1.1</b> 三個概率公理：</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#-conditional-probability"><i class="fa fa-check"></i><b>1.2</b> 條件概率 Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#-independence-"><i class="fa fa-check"></i><b>1.3</b> 獨立 (independence) 的定義</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#section-1.4"><i class="fa fa-check"></i><b>1.4</b> 賭博問題</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#section-1.5"><i class="fa fa-check"></i><b>1.5</b> 賭博問題的答案</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Bayes-Definition.html"><a href="Bayes-Definition.html"><i class="fa fa-check"></i><b>2</b> Bayes 貝葉斯理論的概念</a></li>
<li class="chapter" data-level="3" data-path="-expectation-or-mean-variance.html"><a href="-expectation-or-mean-variance.html"><i class="fa fa-check"></i><b>3</b> 期望 Expectation (或均值 or mean) 和 方差 Variance</a><ul>
<li class="chapter" data-level="3.1" data-path="-expectation-or-mean-variance.html"><a href="-expectation-or-mean-variance.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 方差的性質：</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="-bernoulli-distribution.html"><a href="-bernoulli-distribution.html"><i class="fa fa-check"></i><b>4</b> 伯努利分佈 Bernoulli distribution</a></li>
<li class="chapter" data-level="5" data-path="-binomial-distribution.html"><a href="-binomial-distribution.html"><i class="fa fa-check"></i><b>5</b> 二項分佈的概念 Binomial distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="-binomial-distribution.html"><a href="-binomial-distribution.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 二項分佈的期望和方差</a></li>
<li class="chapter" data-level="5.2" data-path="-binomial-distribution.html"><a href="-binomial-distribution.html#-hypergeometric-distribution"><i class="fa fa-check"></i><b>5.2</b> 超幾何分佈 hypergeometric distribution</a></li>
<li class="chapter" data-level="5.3" data-path="-binomial-distribution.html"><a href="-binomial-distribution.html#section-5.3"><i class="fa fa-check"></i><b>5.3</b> 樂透中獎概率問題：</a><ul>
<li class="chapter" data-level="5.3.1" data-path="-binomial-distribution.html"><a href="-binomial-distribution.html#-3-"><i class="fa fa-check"></i><b>5.3.1</b> 如果我只想中其中的 <span class="math inline">\(3\)</span> 個號碼，概率有多大？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="-poisson-distribution.html"><a href="-poisson-distribution.html"><i class="fa fa-check"></i><b>6</b> 泊松分佈 Poisson Distribution</a></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 正態分佈</a><ul>
<li class="chapter" data-level="7.1" data-path="section-7.html"><a href="section-7.html#-probability-density-function-pdf"><i class="fa fa-check"></i><b>7.1</b> 概率密度曲線 probability density function， PDF</a></li>
<li class="chapter" data-level="7.2" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>7.2</b> 正態分佈</a></li>
<li class="chapter" data-level="7.3" data-path="section-7.html"><a href="section-7.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 標準正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="CLT.html"><a href="CLT.html"><i class="fa fa-check"></i><b>8</b> 中心極限定理 the Central Limit Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path="CLT.html"><a href="CLT.html#-covariance"><i class="fa fa-check"></i><b>8.1</b> 協方差 Covariance</a></li>
<li class="chapter" data-level="8.2" data-path="CLT.html"><a href="CLT.html#-correlation"><i class="fa fa-check"></i><b>8.2</b> 相關 Correlation</a></li>
<li class="chapter" data-level="8.3" data-path="CLT.html"><a href="CLT.html#-the-central-limit-theorem"><i class="fa fa-check"></i><b>8.3</b> 中心極限定理 the Central Limit Theorem</a></li>
<li class="chapter" data-level="8.4" data-path="CLT.html"><a href="CLT.html#binomial-normal-approx"><i class="fa fa-check"></i><b>8.4</b> 二項分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.5" data-path="CLT.html"><a href="CLT.html#section-8.5"><i class="fa fa-check"></i><b>8.5</b> 泊松分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.6" data-path="CLT.html"><a href="CLT.html#continuity-correction"><i class="fa fa-check"></i><b>8.6</b> 正態分佈模擬的校正：continuity corrections</a><ul>
<li class="chapter" data-level="8.6.1" data-path="CLT.html"><a href="CLT.html#section-8.6.1"><i class="fa fa-check"></i><b>8.6.1</b> 例題</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="CLT.html"><a href="CLT.html#section-8.7"><i class="fa fa-check"></i><b>8.7</b> 兩個連續隨機變量</a></li>
<li class="chapter" data-level="8.8" data-path="CLT.html"><a href="CLT.html#-"><i class="fa fa-check"></i><b>8.8</b> 兩個連續隨機變量 例子：</a></li>
<li class="chapter" data-level="8.9" data-path="CLT.html"><a href="CLT.html#section-8.9"><i class="fa fa-check"></i><b>8.9</b> 條件分佈和邊緣分佈的概念</a></li>
<li class="chapter" data-level="8.10" data-path="CLT.html"><a href="CLT.html#section-8.10"><i class="fa fa-check"></i><b>8.10</b> 條件分佈和邊緣分佈的例子</a><ul>
<li class="chapter" data-level="8.10.1" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>8.10.1</b> 例題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 統計推斷 Inference</b></span></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> 統計推斷的概念</a><ul>
<li class="chapter" data-level="9.1" data-path="section-9.html"><a href="section-9.html#-population-and-sample"><i class="fa fa-check"></i><b>9.1</b> 人羣與樣本 (population and sample)</a></li>
<li class="chapter" data-level="9.2" data-path="section-9.html"><a href="section-9.html#-sample-and-statistic"><i class="fa fa-check"></i><b>9.2</b> 樣本和統計量 (sample and statistic)</a></li>
<li class="chapter" data-level="9.3" data-path="section-9.html"><a href="section-9.html#-estimation"><i class="fa fa-check"></i><b>9.3</b> 估計 Estimation</a></li>
<li class="chapter" data-level="9.4" data-path="section-9.html"><a href="section-9.html#-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> 信賴區間 confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html"><i class="fa fa-check"></i><b>10</b> 估計和精確度 Estimation and Precision</a><ul>
<li class="chapter" data-level="10.1" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#CI-for-sample-mean"><i class="fa fa-check"></i><b>10.1</b> 估計量和他們的樣本分佈</a></li>
<li class="chapter" data-level="10.2" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#section-10.2"><i class="fa fa-check"></i><b>10.2</b> 估計量的特質</a><ul>
<li class="chapter" data-level="10.2.1" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#section-10.2.1"><i class="fa fa-check"></i><b>10.2.1</b> 偏倚</a></li>
<li class="chapter" data-level="10.2.2" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#-efficiency"><i class="fa fa-check"></i><b>10.2.2</b> 估計量的效能 Efficiency</a></li>
<li class="chapter" data-level="10.2.3" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#section-10.2.3"><i class="fa fa-check"></i><b>10.2.3</b> 均值和中位數的相對效能</a></li>
<li class="chapter" data-level="10.2.4" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#-mean-square-error-mse"><i class="fa fa-check"></i><b>10.2.4</b> 均方差 mean square error (MSE)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#section-10.3"><i class="fa fa-check"></i><b>10.3</b> 總體方差的估計，自由度</a></li>
<li class="chapter" data-level="10.4" data-path="-estimation-and-precision.html"><a href="-estimation-and-precision.html#section-10.4"><i class="fa fa-check"></i><b>10.4</b> 樣本方差的樣本分佈</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html"><i class="fa fa-check"></i><b>11</b> 卡方分佈 Chi-square distribution</a><ul>
<li class="chapter" data-level="11.1" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#section-11.1"><i class="fa fa-check"></i><b>11.1</b> 卡方分佈的期望和方差的證明</a></li>
<li class="chapter" data-level="11.2" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#section-11.2"><i class="fa fa-check"></i><b>11.2</b> 卡方分佈的期望</a></li>
<li class="chapter" data-level="11.3" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#section-11.3"><i class="fa fa-check"></i><b>11.3</b> 卡方分佈的方差</a><ul>
<li class="chapter" data-level="11.3.1" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#-ex_14"><i class="fa fa-check"></i><b>11.3.1</b> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#section-11.4"><i class="fa fa-check"></i><b>11.4</b> 把上面的推導擴展</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="likelihood-definition.html"><a href="likelihood-definition.html"><i class="fa fa-check"></i><b>12</b> 似然 Likelihood</a><ul>
<li class="chapter" data-level="12.1" data-path="likelihood-definition.html"><a href="likelihood-definition.html#-vs.-probability-vs.inference"><i class="fa fa-check"></i><b>12.1</b> 概率 vs. 推斷 Probability vs. Inference</a></li>
<li class="chapter" data-level="12.2" data-path="likelihood-definition.html"><a href="likelihood-definition.html#-likelihood-and-maximum-likelihood-estimators"><i class="fa fa-check"></i><b>12.2</b> 似然和極大似然估計 Likelihood and maximum likelihood estimators</a></li>
<li class="chapter" data-level="12.3" data-path="likelihood-definition.html"><a href="likelihood-definition.html#section-12.3"><i class="fa fa-check"></i><b>12.3</b> 似然方程的一般化定義</a></li>
<li class="chapter" data-level="12.4" data-path="likelihood-definition.html"><a href="likelihood-definition.html#-log-likelihood"><i class="fa fa-check"></i><b>12.4</b> 對數似然方程 log-likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="likelihood-definition.html"><a href="likelihood-definition.html#-maximum-likelihood-estimator-mle-"><i class="fa fa-check"></i><b>12.5</b> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</a></li>
<li class="chapter" data-level="12.6" data-path="likelihood-definition.html"><a href="likelihood-definition.html#likelihood-poi"><i class="fa fa-check"></i><b>12.6</b> 率的似然估計 Likelihood for a rate</a></li>
<li class="chapter" data-level="12.7" data-path="likelihood-definition.html"><a href="likelihood-definition.html#-n-"><i class="fa fa-check"></i><b>12.7</b> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="llr.html"><a href="llr.html"><i class="fa fa-check"></i><b>13</b> 對數似然比 Log-likelihood ratio</a><ul>
<li class="chapter" data-level="13.1" data-path="llr.html"><a href="llr.html#section-13.1"><i class="fa fa-check"></i><b>13.1</b> 正態分佈數據的極大似然和對數似然比</a></li>
<li class="chapter" data-level="13.2" data-path="llr.html"><a href="llr.html#llr-chi1"><i class="fa fa-check"></i><b>13.2</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</a></li>
<li class="chapter" data-level="13.3" data-path="llr.html"><a href="llr.html#llr-chi"><i class="fa fa-check"></i><b>13.3</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</a></li>
<li class="chapter" data-level="13.4" data-path="llr.html"><a href="llr.html#section-13.4"><i class="fa fa-check"></i><b>13.4</b> 似然比信賴區間</a><ul>
<li class="chapter" data-level="13.4.1" data-path="llr.html"><a href="llr.html#binomial-ex"><i class="fa fa-check"></i><b>13.4.1</b> 以二項分佈數據爲例</a></li>
<li class="chapter" data-level="13.4.2" data-path="llr.html"><a href="llr.html#normal-ex"><i class="fa fa-check"></i><b>13.4.2</b> 以正態分佈數據爲例</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="llr.html"><a href="llr.html#section-13.5"><i class="fa fa-check"></i><b>13.5</b> 練習題</a><ul>
<li class="chapter" data-level="13.5.1" data-path="llr.html"><a href="llr.html#q1"><i class="fa fa-check"></i><b>13.5.1</b> Q1</a></li>
<li class="chapter" data-level="13.5.2" data-path="llr.html"><a href="llr.html#q2"><i class="fa fa-check"></i><b>13.5.2</b> Q2</a></li>
<li class="chapter" data-level="13.5.3" data-path="llr.html"><a href="llr.html#q3"><i class="fa fa-check"></i><b>13.5.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="quadratic-llr.html"><a href="quadratic-llr.html"><i class="fa fa-check"></i><b>14</b> 二次方程近似法求對數似然比 approximate log-likelihood ratios</a><ul>
<li class="chapter" data-level="14.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#quadratic-llr2"><i class="fa fa-check"></i><b>14.1</b> 正態近似法求對數似然 Normal approximation to the log-likelihood</a><ul>
<li class="chapter" data-level="14.1.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#section-14.1.1"><i class="fa fa-check"></i><b>14.1.1</b> 近似法估算對數似然比的信賴區間</a></li>
<li class="chapter" data-level="14.1.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#section-14.1.2"><i class="fa fa-check"></i><b>14.1.2</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.1.3" data-path="quadratic-llr.html"><a href="quadratic-llr.html#quadratic-binomial-approx"><i class="fa fa-check"></i><b>14.1.3</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#para-trans"><i class="fa fa-check"></i><b>14.2</b> 參數转换 parameter transformations</a><ul>
<li class="chapter" data-level="14.2.1" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>14.2.1</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.2.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#section-14.2.2"><i class="fa fa-check"></i><b>14.2.2</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>14.3</b> 練習題</a><ul>
<li class="chapter" data-level="14.3.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#q1-1"><i class="fa fa-check"></i><b>14.3.1</b> Q1</a></li>
<li class="chapter" data-level="14.3.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#q2-1"><i class="fa fa-check"></i><b>14.3.2</b> Q2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html"><i class="fa fa-check"></i><b>15</b> 假設檢驗的構建 Construction of a hypothesis test</a><ul>
<li class="chapter" data-level="15.1" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#null-and-alter"><i class="fa fa-check"></i><b>15.1</b> 什麼是假設檢驗 Hypothesis testing</a></li>
<li class="chapter" data-level="15.2" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#-error-probabilities-and-the-power-function"><i class="fa fa-check"></i><b>15.2</b> 錯誤概率和效能方程 error probabilities and the power function</a><ul>
<li class="chapter" data-level="15.2.1" data-path="section-7.html"><a href="section-7.html#-1"><i class="fa fa-check"></i><b>15.2.1</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#Neyman-Pearson"><i class="fa fa-check"></i><b>15.3</b> 如何選擇要檢驗的統計量</a><ul>
<li class="chapter" data-level="15.3.1" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#section-15.3.1"><i class="fa fa-check"></i><b>15.3.1</b> 以已知方差的正態分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#-composite-hypotheses"><i class="fa fa-check"></i><b>15.4</b> 複合假設 composite hypotheses</a><ul>
<li class="chapter" data-level="15.4.1" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#section-15.4.1"><i class="fa fa-check"></i><b>15.4.1</b> 單側替代假設</a></li>
<li class="chapter" data-level="15.4.2" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#section-15.4.2"><i class="fa fa-check"></i><b>15.4.2</b> 雙側替代假設</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#-h_0-"><i class="fa fa-check"></i><b>15.5</b> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</a><ul>
<li class="chapter" data-level="15.5.1" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#normal-mean-compare"><i class="fa fa-check"></i><b>15.5.1</b> 回到正態分佈的均值比較問題上來(單側替代假設)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#-p-"><i class="fa fa-check"></i><b>15.6</b> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</a></li>
<li class="chapter" data-level="15.7" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#test-summary"><i class="fa fa-check"></i><b>15.7</b> 假設檢驗構建之總結</a></li>
<li class="chapter" data-level="15.8" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#-2"><i class="fa fa-check"></i><b>15.8</b> 練習題</a><ul>
<li class="chapter" data-level="15.8.1" data-path="-construction-of-a-hypothesis-test.html"><a href="-construction-of-a-hypothesis-test.html#q1-2"><i class="fa fa-check"></i><b>15.8.1</b> Q1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="section-16.html"><a href="section-16.html"><i class="fa fa-check"></i><b>16</b> 假設檢驗的近似方法</a><ul>
<li class="chapter" data-level="16.1" data-path="section-16.html"><a href="section-16.html#-approximate-and-exact-tests"><i class="fa fa-check"></i><b>16.1</b> 近似和精確檢驗 approximate and exact tests</a></li>
<li class="chapter" data-level="16.2" data-path="section-16.html"><a href="section-16.html#--likelihood-ratio-test"><i class="fa fa-check"></i><b>16.2</b> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</a></li>
<li class="chapter" data-level="16.3" data-path="section-16.html"><a href="section-16.html#-3"><i class="fa fa-check"></i><b>16.3</b> 練習題</a></li>
<li class="chapter" data-level="16.4" data-path="section-16.html"><a href="section-16.html#-wald-"><i class="fa fa-check"></i><b>16.4</b> 近似檢驗法之 – Wald 檢驗</a><ul>
<li class="chapter" data-level="16.4.1" data-path="section-16.html"><a href="section-16.html#section-16.4.1"><i class="fa fa-check"></i><b>16.4.1</b> 再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="section-16.html"><a href="section-16.html#-score-"><i class="fa fa-check"></i><b>16.5</b> 近似檢驗法之 – Score 检验</a><ul>
<li class="chapter" data-level="16.5.1" data-path="section-16.html"><a href="section-16.html#section-16.5.1"><i class="fa fa-check"></i><b>16.5.1</b> 再再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="section-16.html"><a href="section-16.html#lrt-wald-score-"><i class="fa fa-check"></i><b>16.6</b> LRT, Wald, Score 檢驗三者的比較</a></li>
<li class="chapter" data-level="16.7" data-path="section-16.html"><a href="section-16.html#-4"><i class="fa fa-check"></i><b>16.7</b> 練習題</a><ul>
<li class="chapter" data-level="16.7.1" data-path="section-16.html"><a href="section-16.html#q1-3"><i class="fa fa-check"></i><b>16.7.1</b> Q1</a></li>
<li class="chapter" data-level="16.7.2" data-path="section-16.html"><a href="section-16.html#q2-2"><i class="fa fa-check"></i><b>16.7.2</b> Q2</a></li>
<li class="chapter" data-level="16.7.3" data-path="section-16.html"><a href="section-16.html#q3-1"><i class="fa fa-check"></i><b>16.7.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="-normal-error.html"><a href="-normal-error.html"><i class="fa fa-check"></i><b>17</b> 誤差模型 Normal error</a></li>
<li class="part"><span><b>III 統計分析方法 Analytical Techniques</b></span></li>
<li class="chapter" data-level="18" data-path="section-18.html"><a href="section-18.html"><i class="fa fa-check"></i><b>18</b> 探索數據和簡單描述</a></li>
<li class="chapter" data-level="19" data-path="section-19.html"><a href="section-19.html"><i class="fa fa-check"></i><b>19</b> 信賴區間</a></li>
<li class="chapter" data-level="20" data-path="section-20.html"><a href="section-20.html"><i class="fa fa-check"></i><b>20</b> 假設檢驗</a></li>
<li class="chapter" data-level="21" data-path="section-21.html"><a href="section-21.html"><i class="fa fa-check"></i><b>21</b> 相關</a></li>
<li class="chapter" data-level="22" data-path="section-22.html"><a href="section-22.html"><i class="fa fa-check"></i><b>22</b> 比較</a></li>
<li class="chapter" data-level="23" data-path="section-23.html"><a href="section-23.html"><i class="fa fa-check"></i><b>23</b> 假定前提和數據轉換</a></li>
<li class="part"><span><b>IV 線性迴歸 Linear Regression</b></span></li>
<li class="chapter" data-level="24" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html"><i class="fa fa-check"></i><b>24</b> 簡單線性迴歸 Simple Linear Regression</a><ul>
<li class="chapter" data-level="24.1" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#section-24.1"><i class="fa fa-check"></i><b>24.1</b> 一些背景和術語</a></li>
<li class="chapter" data-level="24.2" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-simple-linear-regression-model"><i class="fa fa-check"></i><b>24.2</b> 簡單線性迴歸模型 simple linear regression model</a><ul>
<li class="chapter" data-level="24.2.1" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#1"><i class="fa fa-check"></i><b>24.2.1</b> 例1</a></li>
<li class="chapter" data-level="24.2.2" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#2"><i class="fa fa-check"></i><b>24.2.2</b> 例2</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#section-24.3"><i class="fa fa-check"></i><b>24.3</b> 區分因變量和預測變量</a><ul>
<li class="chapter" data-level="24.3.1" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#--"><i class="fa fa-check"></i><b>24.3.1</b> 均值 (期待值) 公式</a></li>
<li class="chapter" data-level="24.3.2" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-the-conditional-distribution-and-the-variance-function"><i class="fa fa-check"></i><b>24.3.2</b> 條件分佈和方差 the conditional distribution and the variance function</a></li>
<li class="chapter" data-level="24.3.3" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#section-24.3.3"><i class="fa fa-check"></i><b>24.3.3</b> 定義簡單線性迴歸模型</a></li>
<li class="chapter" data-level="24.3.4" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-residuals"><i class="fa fa-check"></i><b>24.3.4</b> 殘差 residuals</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-estimation-of-parameters"><i class="fa fa-check"></i><b>24.4</b> 參數的估計 estimation of parameters</a><ul>
<li class="chapter" data-level="24.4.1" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#-alpha-beta"><i class="fa fa-check"></i><b>24.4.1</b> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="24.5" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#r---1--reffigage-wt"><i class="fa fa-check"></i><b>24.5</b> R 演示 例 1： 圖 @ref(fig:age-wt)</a></li>
<li class="chapter" data-level="24.6" data-path="-simple-linear-regression.html"><a href="-simple-linear-regression.html#r---2-reftabwalk"><i class="fa fa-check"></i><b>24.6</b> R 演示 例 2： @ref(tab:walk)</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="-ordinary-least-squares-estimators-and-inference.html"><a href="-ordinary-least-squares-estimators-and-inference.html"><i class="fa fa-check"></i><b>25</b> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</a></li>
<li class="chapter" data-level="26" data-path="-introduction-to-analysis-of-variance.html"><a href="-introduction-to-analysis-of-variance.html"><i class="fa fa-check"></i><b>26</b> 方差分析 Introduction to Analysis of Variance</a></li>
<li class="chapter" data-level="27" data-path="-multivariable-models.html"><a href="-multivariable-models.html"><i class="fa fa-check"></i><b>27</b> 多元模型分析 Multivariable Models</a></li>
<li class="chapter" data-level="28" data-path="section-28.html"><a href="section-28.html"><i class="fa fa-check"></i><b>28</b> 多元模型分析的解釋</a></li>
<li class="part"><span><b>V 臨床實驗 Clinical Trials</b></span></li>
<li class="chapter" data-level="29" data-path="sample-size.html"><a href="sample-size.html"><i class="fa fa-check"></i><b>29</b> 樣本量計算問題</a><ul>
<li class="chapter" data-level="29.1" data-path="sample-size.html"><a href="sample-size.html#section-29.1"><i class="fa fa-check"></i><b>29.1</b> 背景</a></li>
<li class="chapter" data-level="29.2" data-path="sample-size.html"><a href="sample-size.html#section-29.2"><i class="fa fa-check"></i><b>29.2</b> 決定所需樣本量大小的統計學因素</a></li>
<li class="chapter" data-level="29.3" data-path="sample-size.html"><a href="sample-size.html#-type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>29.3</b> 第一類和第二類錯誤 Type I and type II errors</a></li>
<li class="chapter" data-level="29.4" data-path="sample-size.html"><a href="sample-size.html#-percentages-or-proportions"><i class="fa fa-check"></i><b>29.4</b> 比較兩組之間的百分比 (percentages or proportions)</a><ul>
<li class="chapter" data-level="29.4.1" data-path="sample-size.html"><a href="sample-size.html#--5--90"><i class="fa fa-check"></i><b>29.4.1</b> 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)</a></li>
<li class="chapter" data-level="29.4.2" data-path="CLT.html"><a href="CLT.html#-"><i class="fa fa-check"></i><b>29.4.2</b> 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)</a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="sample-size.html"><a href="sample-size.html#section-29.5"><i class="fa fa-check"></i><b>29.5</b> 比較兩組之間的均值</a><ul>
<li class="chapter" data-level="29.5.1" data-path="sample-size.html"><a href="sample-size.html#section-29.5.1"><i class="fa fa-check"></i><b>29.5.1</b> 樣本量計算公式</a></li>
</ul></li>
<li class="chapter" data-level="29.6" data-path="sample-size.html"><a href="sample-size.html#section-29.6"><i class="fa fa-check"></i><b>29.6</b> 樣本量計算的調整</a></li>
</ul></li>
<li class="part"><span><b>VI 穩健統計方法 Robust Statistic Methods</b></span></li>
<li class="chapter" data-level="30" data-path="section-30.html"><a href="section-30.html"><i class="fa fa-check"></i><b>30</b> 穩健統計方法入門</a></li>
<li class="chapter" data-level="31" data-path="section-31.html"><a href="section-31.html"><i class="fa fa-check"></i><b>31</b> 基於秩次的非參數檢驗</a><ul>
<li class="chapter" data-level="31.1" data-path="section-31.html"><a href="section-31.html#-the-sign-test"><i class="fa fa-check"></i><b>31.1</b> 符號檢驗 the Sign test</a><ul>
<li class="chapter" data-level="31.1.1" data-path="section-31.html"><a href="section-31.html#section-31.1.1"><i class="fa fa-check"></i><b>31.1.1</b> 符號檢驗的特點</a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="section-31.html"><a href="section-31.html#wilcoxon-the-wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>31.2</b> Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="31.3" data-path="section-31.html"><a href="section-31.html#wilcoxon-mann-whitney-wmw-"><i class="fa fa-check"></i><b>31.3</b> Wilcoxon-Mann-Whitney (WMW) 檢驗</a></li>
<li class="chapter" data-level="31.4" data-path="section-31.html"><a href="section-31.html#spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>31.4</b> 秩相關，Spearman’s Rank Correlation Coefficient</a></li>
<li class="chapter" data-level="31.5" data-path="section-31.html"><a href="section-31.html#section-31.5"><i class="fa fa-check"></i><b>31.5</b> 基於秩次的非參數檢驗的優缺點</a></li>
</ul></li>
<li class="part"><span><b>VII 貝葉斯統計</b></span></li>
<li class="chapter" data-level="32" data-path="section-32.html"><a href="section-32.html"><i class="fa fa-check"></i><b>32</b> 貝葉斯統計入門</a><ul>
<li class="chapter" data-level="32.1" data-path="section-32.html"><a href="section-32.html#section-32.1"><i class="fa fa-check"></i><b>32.1</b> 概率論推斷的複習</a></li>
<li class="chapter" data-level="32.2" data-path="section-32.html"><a href="section-32.html#-bayesian-reasoninginverse-probability"><i class="fa fa-check"></i><b>32.2</b> 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability</a><ul>
<li class="chapter" data-level="32.2.1" data-path="section-32.html"><a href="section-32.html#-deductive-reasoning---weak-syllogisms"><i class="fa fa-check"></i><b>32.2.1</b> 演繹推理 deductive reasoning 和 三段論 weak syllogisms</a></li>
<li class="chapter" data-level="32.2.2" data-path="section-32.html"><a href="section-32.html#-quantifying-plausibility"><i class="fa fa-check"></i><b>32.2.2</b> 如何給可能性定量 Quantifying plausibility</a></li>
</ul></li>
<li class="chapter" data-level="32.3" data-path="section-32.html"><a href="section-32.html#section-32.3"><i class="fa fa-check"></i><b>32.3</b> 貝葉斯推理的統計學實現</a><ul>
<li class="chapter" data-level="32.3.1" data-path="section-32.html"><a href="section-32.html#-diagnostic-testing"><i class="fa fa-check"></i><b>32.3.1</b> 醫學診斷測試 diagnostic testing</a></li>
<li class="chapter" data-level="32.3.2" data-path="section-32.html"><a href="section-32.html#hiv-"><i class="fa fa-check"></i><b>32.3.2</b> HIV 檢查時的應用</a></li>
<li class="chapter" data-level="32.3.3" data-path="section-32.html"><a href="section-32.html#section-32.3.3"><i class="fa fa-check"></i><b>32.3.3</b> 說點小歷史</a></li>
</ul></li>
<li class="chapter" data-level="32.4" data-path="section-32.html"><a href="section-32.html#-5"><i class="fa fa-check"></i><b>32.4</b> 練習題</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="section-33.html"><a href="section-33.html"><i class="fa fa-check"></i><b>33</b> 貝葉斯定理的應用：單一參數模型</a><ul>
<li class="chapter" data-level="33.1" data-path="section-33.html"><a href="section-33.html#-notation-for-probability-density-functions"><i class="fa fa-check"></i><b>33.1</b> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions</a></li>
<li class="chapter" data-level="33.2" data-path="section-33.html"><a href="section-33.html#theta-"><i class="fa fa-check"></i><b>33.2</b> <span class="math inline">\(\theta\)</span> 的先驗概率</a><ul>
<li class="chapter" data-level="33.2.1" data-path="section-33.html"><a href="section-33.html#beta--the-beta-distribution"><i class="fa fa-check"></i><b>33.2.1</b> beta 分佈 the beta distribution</a></li>
<li class="chapter" data-level="33.2.2" data-path="section-33.html"><a href="section-33.html#conjugate"><i class="fa fa-check"></i><b>33.2.2</b> 二項分佈數據事後概率分佈的一般化：共軛性</a></li>
</ul></li>
<li class="chapter" data-level="33.3" data-path="section-33.html"><a href="section-33.html#-6"><i class="fa fa-check"></i><b>33.3</b> 練習題</a><ul>
<li class="chapter" data-level="33.3.1" data-path="section-33.html"><a href="section-33.html#q1-4"><i class="fa fa-check"></i><b>33.3.1</b> Q1</a></li>
<li class="chapter" data-level="33.3.2" data-path="section-33.html"><a href="section-33.html#q2-3"><i class="fa fa-check"></i><b>33.3.2</b> Q2</a></li>
<li class="chapter" data-level="33.3.3" data-path="section-33.html"><a href="section-33.html#q3-2"><i class="fa fa-check"></i><b>33.3.3</b> Q3</a></li>
<li class="chapter" data-level="33.3.4" data-path="section-33.html"><a href="section-33.html#q4"><i class="fa fa-check"></i><b>33.3.4</b> Q4</a></li>
<li class="chapter" data-level="33.3.5" data-path="section-33.html"><a href="section-33.html#q5"><i class="fa fa-check"></i><b>33.3.5</b> Q5</a></li>
<li class="chapter" data-level="33.3.6" data-path="section-33.html"><a href="section-33.html#q6"><i class="fa fa-check"></i><b>33.3.6</b> Q6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>参考文献</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">本书由 bookdown 强力驱动</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">醫學統計學</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-33" class="section level1">
<h1><span class="header-section-number">第 33 章</span> 貝葉斯定理的應用：單一參數模型</h1>
<p>從前一章節我們可以深切體會到，貝葉斯統計是如何讓我們的先驗概率，在觀察到數據之後，更新信息，獲得事後概率 (這是一個通過數據自我學習，進化的過程)。(How a prior belief about an event can be updated, given data, to a posterior belief.)</p>
<p>所以說，在貝葉斯模型中，我們期待使用觀察數據來學習，以增加現有的對相關參數的知識和信息。本章我們把重點放在二項分佈，用二項分佈作爲單一參數模型來瞭解怎樣推導事後分佈。</p>
<div id="-notation-for-probability-density-functions" class="section level2">
<h2><span class="header-section-number">33.1</span> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions</h2>
<ul>
<li><span class="math inline">\(R\)</span> 用來表示服從一個二項分佈的隨機變量， <span class="math inline">\(R\sim Bin(n, \theta)\)</span>。</li>
<li><span class="math inline">\(r\)</span> 表示觀察到 <span class="math inline">\(r\)</span> 次成功實驗，實驗次數爲 <span class="math inline">\(n\)</span>。</li>
<li>先驗概率分佈： <span class="math inline">\(\pi_\Theta(\theta)\)</span></li>
<li>應用貝葉斯定理：</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\pi_{\Theta|R}(\theta|r) &amp;= \frac{f_R(r|\theta)\pi_\Theta(\theta)}{\int_0^1f_R(r|\theta)\pi_\Theta(\theta)\text{ d}\theta}\\
&amp;= \frac{f_R(r|\theta)\pi_\Theta(\theta)}{f_R(r)}
\end{aligned}
\]</span></p>
<p>如果我們的先驗概率分佈：</p>
<p><span class="math display">\[\begin{equation}
\pi_\Theta(\theta)=\begin{cases}
1 \text{ if } \theta=0.2\\
0 \text{ otherwise}
\end{cases}
\end{equation}\]</span></p>
<p>意思就是，我們 100% 相信 <span class="math inline">\(\theta\)</span> 絕對就等於 0.2，不相信 <span class="math inline">\(\theta\)</span> 竟然還能取任何其他值（霸道自大又狂妄的我們）。</p>
<p>如果先驗概率分佈：</p>
<p><span class="math display">\[\begin{equation}
\pi_\Theta(\theta)=\begin{cases}
0.4 \text{ if } \theta=0.2\\
0.6 \text{ if } \theta=0.7
\end{cases}
\end{equation}\]</span></p>
<p>意思就是，我們有 60% 的把握相信 <span class="math inline">\(\theta=0.7\)</span>，有 40% 的把握相信 <span class="math inline">\(\theta=0.2\)</span>，稍微傾向於 <span class="math inline">\(\theta=0.7\)</span>。</p>
<p>假設進行10次實驗，觀察到3次成功。當 <span class="math inline">\(\theta=0.2\)</span> 時，觀察數據的似然 (likelihood) 爲：</p>
<p><span class="math display">\[f_R(3|\theta=0.2)=\binom{10}{3}0.2^3(1-0.2)^7\]</span></p>
<p>當 <span class="math inline">\(\theta=0.7\)</span> 時，觀察數據的似然爲：</p>
<p><span class="math display">\[f_R(3|\theta=0.7)=\binom{10}{3}0.7^3(1-0.7)^7\]</span></p>
<p>應用貝葉斯定理計算事後概率分佈：</p>
<p><span class="math display">\[\begin{equation}
\pi_{\Theta|R}(\theta|3)=\begin{cases}
\frac{\binom{10}{3}0.2^3(1-0.2)^7\times0.4}{\binom{10}{3}0.2^3(1-0.2)^7\times0.4+\binom{10}{3}0.7^3(1-0.7)^7\times0.6}=0.937 \text{ if } \theta=0.2\\
\frac{\binom{10}{3}0.7^3(1-0.7)^7\times0.6}{\binom{10}{3}0.7^3(1-0.7)^7\times0.6+\binom{10}{3}0.2^3(1-0.2)^7\times0.4}=0.063 \text{ if }\theta=0.7
\end{cases}
\end{equation}\]</span></p>
<p>所以，我們從一開始認爲只有40%的把握相信 <span class="math inline">\(\theta=0.2\)</span>，觀察數據告訴我們 10 次實驗，3次獲得了成功。所以我們現在有 93.7% 的把握相信 <span class="math inline">\(\theta=0.2\)</span>。也就是說，觀察數據讓我們對參數 <span class="math inline">\(\theta\)</span> 的取值可能性發生了質的變化，從原先的傾向於 <span class="math inline">\(\theta=0.7\)</span> 到現在幾乎接近 100% 的認爲 <span class="math inline">\(\theta=0.2\)</span>。也就是，觀察數據獲得的信息改變了我們的立場。</p>
<p>上面的例子很直觀，但是有下面幾個問題：</p>
<ol style="list-style-type: decimal">
<li>如果我們無法對參數 <span class="math inline">\(\theta\)</span> 賦予先驗概率的點估計時，該怎麼辦？</li>
<li>如果事後概率不是一個離散的分佈時，該如何才能表達事後概率？</li>
</ol>
</div>
<div id="theta-" class="section level2">
<h2><span class="header-section-number">33.2</span> <span class="math inline">\(\theta\)</span> 的先驗概率</h2>
<p>一種選擇是，我們用均一分佈 (uniform distribution)，即我們對數據一無所知，認爲所有的 <span class="math inline">\(\theta\)</span> 的可能性都一樣，概率密度方程爲 <span class="math inline">\(1\)</span>。在這一情況下，先驗概率爲 1： <span class="math inline">\(\pi_\Theta(\theta)=1\)</span>，其事後概率分佈爲：</p>
<p><span class="math display" id="eq:uniformBayes">\[
\begin{equation}
\pi_{\Theta|R}(\theta|r)=\frac{\binom{n}{r}\theta^r(1-\theta)^{n-r}}{\int_0^1\binom{n}{r}\theta^r(1-\theta)^{n-r} \text{ d}\theta}
\tag{33.1}
\end{equation}
\]</span></p>
<p>看到即使在如此簡單的先驗概率下，我們還是要使用複雜的微積分進行計算。幸運的是，像 <a href="section-33.html#eq:uniformBayes">(33.1)</a> 的分母這樣的積分公式其實是有跡可循的。這就是 beta (<span class="math inline">\(\beta\)</span>) 分佈。</p>
<div id="beta--the-beta-distribution" class="section level3">
<h3><span class="header-section-number">33.2.1</span> beta 分佈 the beta distribution</h3>
<div class="figure" style="text-align: center"><span id="fig:beta-distr"></span>
<img src="bookdown_files/figure-html/beta-distr-1.png" alt="Beta distribution functions for various values of a, b" width="90%" />
<p class="caption">
图 33.1: Beta distribution functions for various values of a, b
</p>
</div>
<p>我們定義 <span class="math inline">\(a&gt;0\)</span> 時<a href="https://zh.wikipedia.org/wiki/%CE%93%E5%87%BD%E6%95%B0">伽馬方程</a>爲</p>
<p><span class="math display">\[\Gamma(a)=\int_0^\infty x^{a-1}e^{-ax}\text{ d}x\]</span></p>
<p>當 <span class="math inline">\(a\)</span> 取正整數時， <span class="math inline">\(\Gamma(a)\)</span> 是 <span class="math inline">\((a-1)!\)</span>。例如，當 <span class="math inline">\(a=4, \Gamma(a)=3\times2\times1=6\)</span>。</p>
<p>對於 <span class="math inline">\(\theta\in[0,1]\)</span> 時，beta 方程 <span class="math inline">\(Beta(a,b)\)</span> 被定義爲：</p>
<p><span class="math display">\[
\begin{aligned}
\pi\Theta(\theta|a,b) &amp;= \theta^{a-1}(1-\theta)^{b-1}\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\\
&amp;= \frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)}
\end{aligned}
\]</span></p>
<p>其中 <span class="math display">\[B(a,b)=\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\]</span></p>
<p><strong>莫要混淆 B 方程和 Beta 方程。</strong></p>
<p>利用 Beta 方程作爲前概率顯得十分便捷且靈活。圖 <a href="section-33.html#fig:beta-distr">33.1</a> 展示的是 6 種不同的 <span class="math inline">\((a,b)\)</span> 取值下的先驗概率分佈示意圖。其實我們可以看到，包括均一分佈在內的各種可能性都可以通過 Beta 分佈實現。其中 <span class="math inline">\((a,b)\)</span> 被叫做超參數 (hyperparameter)。<span class="math inline">\((a,b)\)</span> 取值越大，先驗概率分佈的方差越小。</p>
<p>關於 Beta 分佈的幾個性質：</p>
<ol style="list-style-type: decimal">
<li>均值：<span class="math inline">\(\text{mean}=\frac{a}{a+b}\)</span>；</li>
<li>衆數：<span class="math inline">\(\text{mode}=\frac{a-1}{a+b-2}\)</span>；</li>
<li>方差：<span class="math inline">\(\text{variance}=\frac{ab}{(a+b)^2(a+b+1)}\)</span>。</li>
</ol>
<p>回到均一分佈的簡單例子 <a href="section-33.html#eq:uniformBayes">(33.1)</a> 上：</p>
<p><span class="math inline">\(\pi_\Theta(\theta)=Beta(1,1)\)</span> 是 <span class="math inline">\(\theta\in[0,1]\)</span> 上的均一分佈。所以事後概率 posterior 和下面的式子成正比：</p>
<p><span class="math display">\[\theta^r(1-\theta)^{n-r}\]</span></p>
<p>換句話說，事後概率分佈服從 <span class="math inline">\(Beta(r+1,n-r+1)\)</span>，均值爲 <span class="math inline">\(\frac{r+1}{n+2}\)</span>，方差爲 <span class="math inline">\(\frac{(1+r)(n-r+1)}{(n+2)^2(n+3)}\)</span>。</p>
<p>由此可見，在貝葉斯統計思維下，先驗概率爲均一分佈的二項分佈數據，其事後概率分佈的均值和方差，和經典概率論下的極大似然估計 <span class="math inline">\(r/n\)</span> 不同，和它的漸進樣本方差 <span class="math inline">\(r(n-r)/n^3\)</span> 也不同。但是，當 <span class="math inline">\(n\)</span> 越來越大，獲得的觀察數據越多提供的信息越來越多以後，我們會發現事後概率分佈的均值和方差也會越來越趨近於經典概率論下的極大似然估計和它的方差。</p>
<p>於是這裏可以總結以下兩點：</p>
<ol style="list-style-type: decimal">
<li>即使先驗概率對參數毫無用處（不能提供有效信息，或者我們對所觀察的數據一無所知），也可能會對事後概率分佈結果提供一些意外的信息。</li>
<li>當樣本量增加，似然就主導了整個貝葉斯方程，在數學計算上，經典概率論和貝葉斯推理的估計結果將會十分接近。當然，其各自的意義還是截然不同的。</li>
</ol>
</div>
<div id="conjugate" class="section level3">
<h3><span class="header-section-number">33.2.2</span> 二項分佈數據事後概率分佈的一般化：共軛性</h3>
<p>當 <span class="math inline">\(r\sim \text{Binomial}(n,\theta)\)</span> 時，如果先驗概率 <span class="math inline">\(\pi_\Theta(\theta)=\text{Beta}(a,b)\)</span>。那麼參數 <span class="math inline">\(\theta\)</span> 的事後概率分佈的密度方程滿足：</p>
<p><span class="math display">\[\pi_{\Theta|r}(\theta|r)=\text{Beta}(a+r, b+n-r)\]</span></p>
<p>它的事後概率分佈均值爲：</p>
<p><span class="math display">\[E[\theta|r]=\frac{a+r}{a+b+n}\]</span></p>
<p>事後概率分佈的衆數爲：</p>
<p><span class="math display">\[\text{Mode}[\theta|r]=\frac{a+r-1}{n+a+b-2}\]</span></p>
<p>事後概率分佈方差爲：</p>
<p><span class="math display">\[\text{Var}[\theta|r]=\frac{(a+r)(b+n-r)}{(a+b+n)^2(a+b+n+1)}\]</span></p>
<p>因此，我們看到先驗概率服從 <span class="math inline">\(\text{Beta}(a,b)\)</span> 分佈，觀察數據爲二項分佈時，事後概率分佈還是服從 <span class="math inline">\(\text{Beta}\)</span> 分佈，僅僅只是超參數發生了轉變（更新）。這就是<strong>共軛分佈</strong>的實例。<span class="math inline">\(\text{Beta}\)</span> 分佈是二項分佈的共軛先驗概率分佈 (the <span class="math inline">\(\text{Beta}(a,b)\)</span> is the conjugate prior for the binomial likelihood)。</p>
<p>在經典概率論的框架下，參數 <span class="math inline">\(\theta\)</span> 的估計就是極大似然估計 (MLE)。在二項分佈的例子中， <span class="math inline">\(\text{MLE}=\hat\theta=r/n\)</span>，當樣本量 <span class="math inline">\(n\rightarrow\infty\)</span> 時，事後概率分佈均值：</p>
<p><span class="math display">\[E[\theta|r]=\frac{a+r}{a+b+n}=\frac{\frac{r}{n}+\frac{a}{n}}{1+\frac{a+b}{n}}\approx\frac{r}{n}=\text{MLE}\]</span></p>
<p>事後概率分佈的衆數爲：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Mode}[\theta|r] &amp;=\frac{a+r-1}{n+a+b-2} \\
&amp;= \frac{\frac{r}{n}+\frac{a-1}{n}}{1+\frac{a+b-2}{n}}\\
&amp;\approx \frac{r}{n}
\end{aligned}
\]</span></p>
<p>事後概率分佈的方差爲：</p>
<p><span class="math display">\[\frac{(a+r)(b+n+r)}{(a+b+n)^2(a+b+n+1)}\approx0\]</span></p>
<p>當 <span class="math inline">\(n\)</span>，樣本越來越大時，我們獲得更多的來自數據的信息，所以來自數據的信息逐漸主導 (dominate) 了整個貝葉斯推斷的過程，事後均值等衆多統計結果都越來越趨近於概率論統計思想下的極大似然估計等結論。</p>
<p>我們也可以注意到，當 <span class="math inline">\(a\rightarrow0, b\rightarrow0\)</span> 時，事後概率分佈的均值 <span class="math inline">\(E[\theta|r] = \frac{a+r}{a+b+n} \rightarrow \frac{r}{n}\)</span>，方差也趨向於樣本漸進方差 (asymptotic sample variance)。但是當 <span class="math inline">\(a\rightarrow 0, b\rightarrow0\)</span> 時，先驗概率是沒有被定義的，可是此例下事後概率卻可以正常被定義。所以當先驗概率分佈無法被定義，或者被定義的不恰當時，事後概率分佈依然不受太大影響。所以特別是對於均值（或迴歸係數，regression coefficients）等參數，我們常常會使用均一分佈這樣的無信息先驗概率。</p>
</div>
</div>
<div id="-6" class="section level2">
<h2><span class="header-section-number">33.3</span> 練習題</h2>
<div id="q1-4" class="section level3">
<h3><span class="header-section-number">33.3.1</span> Q1</h3>
<p>當先驗概率分佈服從 <span class="math inline">\(\text{Beta}(0.5,0.5)\)</span>，觀察數據記錄到 <span class="math inline">\(5\)</span> 個患者中 <span class="math inline">\(3\)</span> 人死亡的事件。 試求： 死亡發生概率 <span class="math inline">\(\theta\)</span> 的 95% 可信區間 (credible intervals)。</p>
<p><strong>解</strong></p>
<p>根據 Section <a href="section-33.html#conjugate">33.2.2</a> 的公式，當先驗概率爲 <span class="math inline">\(\pi_{\Theta|r}(\theta|r)=\text{Beta}(a=0.5,b=0.5)\)</span> ，數據 <span class="math inline">\(n=5, r=3\)</span>。參數 <span class="math inline">\(\theta\)</span> 的事後概率分佈 <span class="math inline">\(\pi_{\Theta|r}(\theta|r)=\text{Beta}(a+r,b+n-r)=\text{Beta}(3.5,2.5)\)</span>。</p>
<p>在 <a href="https://www.r-project.org/">R</a> 裏進行貝葉斯計算十分簡便：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 95% Credible Intervals</span>
L &lt;-<span class="st"> </span><span class="kw">qbeta</span>(<span class="fl">0.025</span>, <span class="fl">3.5</span>, <span class="fl">2.5</span>)
U &lt;-<span class="st"> </span><span class="kw">qbeta</span>(<span class="fl">0.975</span>, <span class="fl">3.5</span>, <span class="fl">2.5</span>)

<span class="kw">print</span>(<span class="kw">c</span>(L,U))</code></pre></div>
<pre><code>## [1] 0.20941666 0.90560967</code></pre>
<p>事後分佈 <span class="math inline">\(\pi_{\Theta|r}(\theta|r)=\text{Beta}(3.5,2.5)\)</span> 的分佈圖形如下：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">post &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(theta) <span class="kw">dbeta</span>(theta, <span class="fl">3.5</span>, <span class="fl">2.5</span>))

<span class="co"># Illustration</span>
x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">length=</span><span class="dv">10000</span>)
y &lt;-<span class="st"> </span><span class="kw">post</span>(x)
<span class="kw">plot</span>(x,y, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">xlab=</span><span class="op">~</span>theta, <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>)

<span class="kw">polygon</span>(<span class="kw">c</span>(L, x[x<span class="op">&gt;=</span>L <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&lt;=</span><span class="st"> </span>U], U), <span class="kw">c</span>(<span class="dv">0</span>, y[x<span class="op">&gt;=</span>L <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&lt;=</span>U], <span class="dv">0</span>), <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-56"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-56-1.png" alt="Posterior distribution of Beta(3.5,2.5)" width="80%" />
<p class="caption">
图 33.2: Posterior distribution of Beta(3.5,2.5)
</p>
</div>
<p>我們可以自己寫一個求可信區間的公式來計算：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Credible Interval function:</span>
<span class="co"># a, b : shape / super parameters</span>
<span class="co"># level: probability level (0,1)</span>

cred.int &lt;-<span class="st"> </span><span class="cf">function</span>(a,b,level){
  L &lt;-<span class="st"> </span><span class="kw">qbeta</span>((<span class="dv">1</span><span class="op">-</span>level)<span class="op">/</span><span class="dv">2</span>, a, b) <span class="co"># Lower limit</span>
  U &lt;-<span class="st"> </span><span class="kw">qbeta</span>((<span class="dv">1</span><span class="op">+</span>level)<span class="op">/</span><span class="dv">2</span>, a, b) <span class="co"># Upper limit</span>
  <span class="kw">return</span>(<span class="kw">c</span>(L,U))
}

<span class="kw">cred.int</span>(<span class="fl">3.5</span>,<span class="fl">2.5</span>,<span class="fl">0.95</span>)</code></pre></div>
<pre><code>## [1] 0.20941666 0.90560967</code></pre>
<p>95%可信區間 <span class="math inline">\((0.2094, 0.9056)\)</span> 告訴我們，參數 <span class="math inline">\(\theta\in(0.2094, 0.9056)\)</span> 的概率是 <span class="math inline">\(0.95\)</span>。</p>
<p>下面我們嘗試寫 Beta 分佈的其他統計量：均值，衆數，方差等。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># a, b: shape / super parameters</span>
MeanBeta &lt;-<span class="st"> </span><span class="cf">function</span>(a,b) a<span class="op">/</span>(a<span class="op">+</span>b)
ModeBeta &lt;-<span class="st"> </span><span class="cf">function</span>(a,b) {
  m &lt;-<span class="st"> </span><span class="kw">ifelse</span>(a<span class="op">&gt;</span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>b<span class="op">&gt;</span><span class="dv">1</span>, (a<span class="op">-</span><span class="dv">1</span>)<span class="op">/</span>(a<span class="op">+</span>b<span class="op">-</span><span class="dv">2</span>), <span class="ot">NA</span>)
  <span class="kw">return</span>(m)
}
VarianceBeta &lt;-<span class="st"> </span><span class="cf">function</span>(a,b) (a<span class="op">*</span>b)<span class="op">/</span>((a<span class="op">+</span>b)<span class="op">^</span><span class="dv">2</span><span class="op">*</span>(a<span class="op">+</span>b<span class="op">+</span><span class="dv">1</span>))

<span class="co"># mean</span>
<span class="kw">MeanBeta</span>(<span class="fl">3.5</span>,<span class="fl">2.5</span>)</code></pre></div>
<pre><code>## [1] 0.58333333</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># mode</span>
<span class="kw">ModeBeta</span>(<span class="fl">3.5</span>,<span class="fl">2.5</span>)</code></pre></div>
<pre><code>## [1] 0.625</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Variance</span>
<span class="kw">VarianceBeta</span>(<span class="fl">3.5</span>, <span class="fl">2.5</span>)</code></pre></div>
<pre><code>## [1] 0.034722222</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># SD</span>
<span class="kw">sqrt</span>(<span class="kw">VarianceBeta</span>(<span class="fl">3.5</span>, <span class="fl">2.5</span>))</code></pre></div>
<pre><code>## [1] 0.186339</code></pre>
</div>
<div id="q2-3" class="section level3">
<h3><span class="header-section-number">33.3.2</span> Q2</h3>
<p>假如數據還是 Q1 的數據，然而先驗概率讓我們認爲可能在 5 名受試對象中觀察到 1 次事件。</p>
<ol style="list-style-type: decimal">
<li>試求超參數 <span class="math inline">\((a,b)\)</span> 滿足先驗概率的 Beta 分佈。(不止一組)</li>
</ol>
<p><strong>解</strong></p>
<p>我們認爲最有可能發生 “5 名受試對象中觀察到 1 次事件” 的情況，所以先驗概率的均值爲 <span class="math inline">\(\frac{a}{a+b}=0.2\)</span>。所以，在實數中有無數組超參數都可以用來模擬先驗概率分佈。例如 <span class="math inline">\(a=1, b=4; a=10, b=40; a=100, b=400; a=0.317, b=1.268, \cdots\)</span>。</p>
<ol start="2" style="list-style-type: decimal">
<li>假如觀察數據是 <span class="math inline">\(n=5, r=1\)</span>，計算事後概率分佈及其均值，標準差。</li>
</ol>
<p><strong>解</strong></p>
<p>先來嘗試寫一個計算貝葉斯二項分佈的方程：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># binbayes function in R</span>
<span class="co">#------------------------------</span>
<span class="co"># a, b: shape / super parameters</span>
<span class="co"># r   : number of successes</span>
<span class="co"># n   : number of trials</span>

binbayes &lt;-<span class="st"> </span><span class="cf">function</span>(a, b, r, n) {
  prior &lt;-<span class="st"> </span><span class="kw">c</span>(a, b, <span class="ot">NA</span>, <span class="kw">MeanBeta</span>(a,b), <span class="kw">sqrt</span>(<span class="kw">VarianceBeta</span>(a, b)), <span class="kw">qbeta</span>(<span class="fl">0.025</span>, a, b), <span class="kw">qbeta</span>(<span class="fl">0.5</span>, a, b), <span class="kw">qbeta</span>(<span class="fl">0.975</span>, a, b))
  posterior &lt;-<span class="st"> </span><span class="kw">c</span>(a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r, r<span class="op">/</span>n, <span class="kw">MeanBeta</span>(a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r), <span class="kw">sqrt</span>(<span class="kw">VarianceBeta</span>(a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r)), <span class="kw">qbeta</span>(<span class="fl">0.025</span>, a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r), <span class="kw">qbeta</span>(<span class="fl">0.5</span>, a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r), <span class="kw">qbeta</span>(<span class="fl">0.975</span>, a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r))
  out &lt;-<span class="st"> </span><span class="kw">rbind</span>(prior, posterior)
  out &lt;-<span class="st"> </span><span class="kw">round</span>(out, <span class="dv">4</span>)
  <span class="kw">colnames</span>(out) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;a&quot;</span>,<span class="st">&quot;b&quot;</span>,<span class="st">&quot;r/n&quot;</span>,<span class="st">&quot;Mean&quot;</span>, <span class="st">&quot;SD&quot;</span>, <span class="st">&quot;2.5%&quot;</span>, <span class="st">&quot;50%&quot;</span>, <span class="st">&quot;97.5%&quot;</span>)
  <span class="kw">return</span>(out)
}

<span class="co"># a=1, b=4, r=1, n=5</span>
<span class="kw">binbayes</span>(<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">5</span>)</code></pre></div>
<pre><code>##           a b r/n Mean     SD   2.5%    50%  97.5%
## prior     1 4  NA  0.2 0.1633 0.0063 0.1591 0.6024
## posterior 2 8 0.2  0.2 0.1206 0.0281 0.1796 0.4825</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># a=10, b=40, r=1, n=5</span>
<span class="kw">binbayes</span>(<span class="dv">10</span>,<span class="dv">40</span>,<span class="dv">1</span>,<span class="dv">5</span>)</code></pre></div>
<pre><code>##            a  b r/n Mean     SD   2.5%    50%  97.5%
## prior     10 40  NA  0.2 0.0560 0.1024 0.1960 0.3202
## posterior 11 44 0.2  0.2 0.0535 0.1063 0.1963 0.3143</code></pre>
<p>通過繪製先驗概率分佈圖和事後概率分佈圖來比較二者的變化：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Prior vs posterior graphs</span>
<span class="co"># a,b : shape / super parameters</span>
<span class="co"># r   : number of successes</span>
<span class="co"># n   : number of trials</span>
graph.binbayes &lt;-<span class="st"> </span><span class="cf">function</span>(a,b,r,n) {
  prior &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(theta) <span class="kw">dbeta</span>(theta, a,b))
  posterior &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(theta) <span class="kw">dbeta</span>(theta, a<span class="op">+</span>r, b<span class="op">+</span>n<span class="op">-</span>r))
  YL &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">prior</span>(<span class="kw">seq</span>(<span class="fl">0.001</span>,<span class="fl">0.999</span>,<span class="dt">by=</span><span class="fl">0.001</span>)),<span class="kw">posterior</span>(<span class="kw">seq</span>(<span class="fl">0.001</span>,<span class="fl">0.999</span>,<span class="dt">by=</span><span class="fl">0.001</span>)))
  <span class="kw">curve</span>(prior, <span class="dt">xlab=</span><span class="op">~</span>theta, <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">lty=</span><span class="dv">2</span>,<span class="dt">n=</span><span class="dv">10000</span>,<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,YL), <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>)
  <span class="kw">curve</span>(posterior, <span class="dt">xlab=</span><span class="op">~</span>theta,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">add=</span>T,<span class="dt">n=</span><span class="dv">10000</span>)
}

<span class="kw">graph.binbayes</span>(<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">5</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-60"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-60-1.png" alt="Prior (dashed) Beta(1,4) vs. Posterior (cont.) Beta(2,8)" width="80%" />
<p class="caption">
图 33.3: Prior (dashed) Beta(1,4) vs. Posterior (cont.) Beta(2,8)
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">graph.binbayes</span>(<span class="dv">10</span>,<span class="dv">40</span>,<span class="dv">1</span>,<span class="dv">5</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-61"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-61-1.png" alt="Prior (dashed) Beta(10,40) vs. Posterior (cont.) Beta(11, 44)" width="80%" />
<p class="caption">
图 33.4: Prior (dashed) Beta(10,40) vs. Posterior (cont.) Beta(11, 44)
</p>
</div>
<p>我們可以很清楚的看見，先驗概率相同時，<span class="math inline">\(\text{Beta} (a,b)\)</span> 的超參數如果越大，先驗概率的分佈就越趨近與對稱圖形，且極大值也就越出現在均值的地方 (本例中是 <span class="math inline">\(0.2\)</span>)。而且也會使事後概率的 HPD (highest posterior density) 的區間更狹窄 (意爲對事後概率的預測越準確)，同時事後概率分佈也更加接近左右對稱。</p>
</div>
<div id="q3-2" class="section level3">
<h3><span class="header-section-number">33.3.3</span> Q3</h3>
<p>我們事先估計某個事件在 <span class="math inline">\(n=20\)</span> 名患者中發生的概率爲 <span class="math inline">\(15\%\)</span>。當實際觀察數據爲 <span class="math inline">\(n=15,r=3\)</span> 時，計算相應的事後概率。</p>
<p><strong>解</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># because 15% events happened in 20 subjects, assuming prior Beta(a=3, b=17)</span>
<span class="co"># observed n=15, r=3</span>
<span class="kw">binbayes</span>(<span class="dv">3</span>,<span class="dv">17</span>,<span class="dv">3</span>,<span class="dv">15</span>)</code></pre></div>
<pre><code>##           a  b r/n   Mean     SD   2.5%    50%  97.5%
## prior     3 17  NA 0.1500 0.0779 0.0338 0.1383 0.3314
## posterior 6 29 0.2 0.1714 0.0628 0.0676 0.1651 0.3106</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">graph.binbayes</span>(<span class="dv">3</span>,<span class="dv">17</span>,<span class="dv">3</span>,<span class="dv">15</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-63"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-63-1.png" alt="Prior (dashed) Beta(3,17) vs. Posterior (cont.) Beta(6,29)" width="80%" />
<p class="caption">
图 33.5: Prior (dashed) Beta(3,17) vs. Posterior (cont.) Beta(6,29)
</p>
</div>
<p>試着繪製先驗概率服從 <span class="math inline">\(\text{Beta} (1,1)\)</span>，回憶之前本章開頭的圖 <a href="section-33.html#fig:beta-distr">33.1</a>，這個先驗概率的含義就是我們沒有任何背景知識，對數據完全陌生的情況：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">graph.binbayes</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">15</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-64"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-64-1.png" alt="Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(4,13)" width="80%" />
<p class="caption">
图 33.6: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(4,13)
</p>
</div>
</div>
<div id="q4" class="section level3">
<h3><span class="header-section-number">33.3.4</span> Q4</h3>
<p>試給出上面各題中參數 <span class="math inline">\(\theta\)</span> 落在 <span class="math inline">\((0.1,0.25)\)</span> 之間的概率。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># function to calculate probabilities in a interval</span>
<span class="co"># a, b: super parameters</span>
<span class="co"># r   : number of successes</span>
<span class="co"># n   : number of trials</span>
<span class="co"># L   : Lower limit of the probability interval</span>
<span class="co"># U   : Upper limit of the probability interval</span>

prob.int &lt;-<span class="st"> </span><span class="cf">function</span>(a,b,r,n,L,U){
prior0 &lt;-<span class="st"> </span><span class="kw">pbeta</span>(U,a,b) <span class="op">-</span><span class="st"> </span><span class="kw">pbeta</span>(L,a,b)
posterior0 &lt;-<span class="st"> </span><span class="kw">pbeta</span>(U,a<span class="op">+</span>r,n<span class="op">-</span>r<span class="op">+</span>b) <span class="op">-</span><span class="st"> </span><span class="kw">pbeta</span>(L,a<span class="op">+</span>r,n<span class="op">-</span>r<span class="op">+</span>b)
prob &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">c</span>(prior0, posterior0))
prob &lt;-<span class="st"> </span><span class="kw">round</span>(prob,<span class="dv">4</span>)
<span class="kw">colnames</span>(prob) &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;Probability of theta lies between the Interval&quot;</span>, L, U)
<span class="kw">rownames</span>(prob) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Prior&quot;</span>,<span class="st">&quot;Posterior&quot;</span>)
  <span class="kw">return</span>(prob)
}

<span class="co"># Prior Beta(0.317,1.286) n = 5, r=1</span>
<span class="kw">binbayes</span>(<span class="fl">0.317</span>, <span class="fl">1.286</span>, <span class="dv">1</span>, <span class="dv">5</span>)</code></pre></div>
<pre><code>##               a     b r/n   Mean     SD  2.5%    50%
## prior     0.317 1.286  NA 0.1978 0.2469 0.000 0.0823
## posterior 1.317 5.286 0.2 0.1995 0.1449 0.013 0.1684
##            97.5%
## prior     0.8516
## posterior 0.5493</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prob.int</span>(<span class="fl">0.317</span>, <span class="fl">1.286</span>, <span class="dv">1</span>, <span class="dv">5</span>,<span class="fl">0.1</span>,<span class="fl">0.25</span>)</code></pre></div>
<pre><code>##           Probability of theta lies between the Interval 0.1 0.25
## Prior                                                      0.1711
## Posterior                                                  0.3911</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">graph.binbayes</span>(<span class="fl">0.317</span>, <span class="fl">1.286</span>, <span class="dv">1</span>, <span class="dv">5</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-66"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-66-1.png" alt="Prior (dashed) Beta(0.317,1.286) vs. Posterior (cont.) Beta(1.317, 5.286)" width="80%" />
<p class="caption">
图 33.7: Prior (dashed) Beta(0.317,1.286) vs. Posterior (cont.) Beta(1.317, 5.286)
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Prior Beta(10,40) n = 5, r=1</span>
<span class="kw">binbayes</span>(<span class="dv">10</span>, <span class="dv">40</span>, <span class="dv">1</span>, <span class="dv">5</span>)</code></pre></div>
<pre><code>##            a  b r/n Mean     SD   2.5%    50%  97.5%
## prior     10 40  NA  0.2 0.0560 0.1024 0.1960 0.3202
## posterior 11 44 0.2  0.2 0.0535 0.1063 0.1963 0.3143</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prob.int</span>(<span class="dv">10</span>, <span class="dv">40</span>, <span class="dv">1</span>, <span class="dv">5</span>,<span class="fl">0.1</span>,<span class="fl">0.25</span>)</code></pre></div>
<pre><code>##           Probability of theta lies between the Interval 0.1 0.25
## Prior                                                      0.7951
## Posterior                                                  0.8099</code></pre>
<p>所以在範圍固定的時候，事後概率分佈總是能夠比先驗概率分佈給出更高的累計概率。</p>
</div>
<div id="q5" class="section level3">
<h3><span class="header-section-number">33.3.5</span> Q5</h3>
<p>一個臨牀試驗要進行兩個階段 (two phases)，第一階段我們觀察到 <span class="math inline">\(10\)</span> 個患者中 <span class="math inline">\(1\)</span> 個事件。第二階段，觀察到 <span class="math inline">\(n=50, r=5\)</span>。</p>
<ol style="list-style-type: decimal">
<li>兩個階段都使用 <span class="math inline">\(\text{Beta}(1,1)\)</span> 作先驗概率。求兩個實驗階段參數 <span class="math inline">\(\theta&lt;0.1\)</span> 的概率。</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Phase I</span>
<span class="kw">binbayes</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">10</span>)</code></pre></div>
<pre><code>##           a  b r/n   Mean     SD   2.5%   50%  97.5%
## prior     1  1  NA 0.5000 0.2887 0.0250 0.500 0.9750
## posterior 2 10 0.1 0.1667 0.1034 0.0228 0.148 0.4128</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prob.int</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">10</span>,<span class="dv">0</span>,<span class="fl">0.1</span>)</code></pre></div>
<pre><code>##           Probability of theta lies between the Interval 0 0.1
## Prior                                                   0.1000
## Posterior                                               0.3026</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">graph.binbayes</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">10</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-69"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-69-1.png" alt="Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(2, 10)" width="80%" />
<p class="caption">
图 33.8: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(2, 10)
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Phase II</span>
<span class="kw">binbayes</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">50</span>)</code></pre></div>
<pre><code>##           a  b r/n   Mean     SD   2.5%    50%  97.5%
## prior     1  1  NA 0.5000 0.2887 0.0250 0.5000 0.9750
## posterior 6 46 0.1 0.1154 0.0439 0.0444 0.1105 0.2141</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prob.int</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">50</span>,<span class="dv">0</span>,<span class="fl">0.1</span>)</code></pre></div>
<pre><code>##           Probability of theta lies between the Interval 0 0.1
## Prior                                                   0.1000
## Posterior                                               0.4024</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">graph.binbayes</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">50</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-71"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-71-1.png" alt="Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(6, 46)" width="80%" />
<p class="caption">
图 33.9: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(6, 46)
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>繼續使用先驗概率分佈 <span class="math inline">\(\text{Beta}(1,1)\)</span>，合併兩個實驗階段，求此時的事後概率分佈，以及參數 <span class="math inline">\(\theta&lt;0.1\)</span> 的概率。</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Combining both phases</span>
<span class="kw">binbayes</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">60</span>)</code></pre></div>
<pre><code>##           a  b r/n   Mean     SD   2.5%    50%  97.5%
## prior     1  1  NA 0.5000 0.2887 0.0250 0.5000 0.9750
## posterior 7 55 0.1 0.1129 0.0399 0.0474 0.1087 0.2019</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prob.int</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">6</span>,<span class="dv">60</span>,<span class="dv">0</span>,<span class="fl">0.1</span>)</code></pre></div>
<pre><code>##           Probability of theta lies between the Interval 0 0.1
## Prior                                                   0.1000
## Posterior                                               0.4105</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">graph.binbayes</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">60</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-73"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-73-1.png" alt="Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(7, 55)" width="80%" />
<p class="caption">
图 33.10: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(7, 55)
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li>用第一階段的實驗結果做第二階段實驗的先驗概率分佈，再計算事後概率分佈，以及 <span class="math inline">\(\theta&lt;0.1\)</span> 的概率。</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Using Phase I results as a prior for Phase II</span>
<span class="kw">binbayes</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">50</span>)</code></pre></div>
<pre><code>##           a  b r/n   Mean     SD   2.5%    50%  97.5%
## prior     2 10  NA 0.1667 0.1034 0.0228 0.1480 0.4128
## posterior 7 55 0.1 0.1129 0.0399 0.0474 0.1087 0.2019</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prob.int</span>(<span class="dv">2</span>,<span class="dv">10</span>,<span class="dv">5</span>,<span class="dv">50</span>,<span class="dv">0</span>,<span class="fl">0.1</span>)</code></pre></div>
<pre><code>##           Probability of theta lies between the Interval 0 0.1
## Prior                                                   0.3026
## Posterior                                               0.4105</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">graph.binbayes</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">50</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-75"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-75-1.png" alt="Prior (dashed) Beta(2,10) vs. Posterior (cont.) Beta(7, 55)" width="80%" />
<p class="caption">
图 33.11: Prior (dashed) Beta(2,10) vs. Posterior (cont.) Beta(7, 55)
</p>
</div>
<p>第2，3兩個小問題提示我們，無論是將第一階段實驗結果作爲第二階段實驗的先驗假設還是將兩次實驗合併，最終的結果是不會改變的。Both approaches are equivalent.</p>
</div>
<div id="q6" class="section level3">
<h3><span class="header-section-number">33.3.6</span> Q6</h3>
<p>藥物 A 和藥物 B 都被批准用於治療某種疾病。在 5000 例病例中使用藥物 A，發現有 3 人發生了不良副作用。在另外 7000 例病例中使用藥物 B，發現只有 1 例發生了副作用。</p>
<ol style="list-style-type: decimal">
<li>先使用單一分佈作爲先驗概率 (uniform prior: <span class="math inline">\(\text{Beta}(1,1)\)</span>)。求藥物 A 和藥物 B 各自發生不良反應的事後概率。</li>
</ol>
<p><strong>藥物 A</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Drug A</span>
<span class="kw">binbayes</span>(<span class="dv">1</span>,<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5000</span>)</code></pre></div>
<pre><code>##           a    b    r/n   Mean     SD   2.5%    50%
## prior     1    1     NA 0.5000 0.2887 0.0250 0.5000
## posterior 4 4998 0.0006 0.0008 0.0004 0.0002 0.0007
##            97.5%
## prior     0.9750
## posterior 0.0018</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-77"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-77-1.png" alt="Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(4, 4998)" width="80%" />
<p class="caption">
图 33.12: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(4, 4998)
</p>
</div>
<p><strong>藥物 B</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Drug B</span>
<span class="kw">binbayes</span>(<span class="dv">1</span>,<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">7000</span>)</code></pre></div>
<pre><code>##           a    b    r/n   Mean     SD  2.5%    50%
## prior     1    1     NA 0.5000 0.2887 0.025 0.5000
## posterior 2 7000 0.0001 0.0003 0.0002 0.000 0.0002
##            97.5%
## prior     0.9750
## posterior 0.0008</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-79"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-79-1.png" alt="Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(2, 7000)" width="80%" />
<p class="caption">
图 33.13: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(2, 7000)
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>使用 <span class="math inline">\(\text{Beta}(0.00001,0.00001)\)</span> 作爲先驗概率，重複上面的計算</li>
</ol>
<p><strong>藥物 A</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Drug A</span>
<span class="kw">binbayes</span>(<span class="fl">0.00001</span>, <span class="fl">0.00001</span>, <span class="dv">3</span>, <span class="dv">5000</span>)</code></pre></div>
<pre><code>##           a    b    r/n   Mean     SD   2.5%    50%
## prior     0    0     NA 0.5000 0.5000 0.0000 0.5000
## posterior 3 4997 0.0006 0.0006 0.0003 0.0001 0.0005
##            97.5%
## prior     1.0000
## posterior 0.0014</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-81"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-81-1.png" alt="Prior (dashed) Beta(0.00001,0.00001) vs. Posterior (cont.) Beta(3, 4997)" width="80%" />
<p class="caption">
图 33.14: Prior (dashed) Beta(0.00001,0.00001) vs. Posterior (cont.) Beta(3, 4997)
</p>
</div>
<p><strong>藥物 B</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Drug B</span>
<span class="kw">binbayes</span>(<span class="fl">0.00001</span>, <span class="fl">0.00001</span>, <span class="dv">1</span>, <span class="dv">7000</span>)</code></pre></div>
<pre><code>##           a    b    r/n   Mean     SD 2.5%    50%
## prior     0    0     NA 0.5000 0.5000    0 0.5000
## posterior 1 6999 0.0001 0.0001 0.0001    0 0.0001
##            97.5%
## prior     1.0000
## posterior 0.0005</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-83"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-83-1.png" alt="Prior (dashed) Beta(0.00001,0.00001) vs. Posterior (cont.) Beta(1, 6999)" width="80%" />
<p class="caption">
图 33.15: Prior (dashed) Beta(0.00001,0.00001) vs. Posterior (cont.) Beta(1, 6999)
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li>現在使用概率論的計算信賴區間 (confidence intervals) 的方法，求上面數據的精確二項分佈 95% 信賴區間。之前兩問中使用的哪個先驗概率更加接近概率論算法？</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#------------------------------------------------</span>
<span class="co"># Binomial confidence intervals</span>
<span class="co">#------------------------------------------------</span>
<span class="co"># r    : number of successes</span>
<span class="co"># n    : number of trials</span>
<span class="co"># level: confidence level</span>
binom.confint &lt;-<span class="st"> </span><span class="cf">function</span>(r,n,level){
 p &lt;-<span class="st"> </span>r<span class="op">/</span>n
conf &lt;-<span class="st">  </span><span class="kw">as.vector</span>(<span class="kw">binom.test</span>(r,n,<span class="dt">conf.level =</span> <span class="fl">0.95</span>)<span class="op">$</span>conf.int)
out &lt;-<span class="st"> </span><span class="kw">c</span>(p,conf)
out &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">t</span>(<span class="kw">round</span>(out,<span class="dv">8</span>)))
<span class="kw">colnames</span>(out) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;MLE&quot;</span>, <span class="st">&quot;L&quot;</span>, <span class="st">&quot;U&quot;</span>)
<span class="kw">return</span>(out)
}

<span class="co"># Drug A</span>
<span class="kw">binom.confint</span>(<span class="dv">3</span>,<span class="dv">5000</span>,<span class="fl">0.95</span>)</code></pre></div>
<pre><code>##         MLE          L          U
## [1,] 0.0006 0.00012375 0.00175244</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Drug B</span>
<span class="kw">binom.confint</span>(<span class="dv">1</span>,<span class="dv">7000</span>,<span class="fl">0.95</span>)</code></pre></div>
<pre><code>##             MLE        L          U
## [1,] 0.00014286 3.62e-06 0.00079569</code></pre>
<p>明顯可以看到，先驗概率使用 <span class="math inline">\(\text{Beta}(0.00001,0.00001)\)</span> 時，事後概率的均值和可信區間的下限值更接近概率論算法。使用先驗概率 <span class="math inline">\(\text{Beta}(1,1)\)</span> 時，事後概率的可信區間的上限值更接近概率論算法。</p>
<ol start="4" style="list-style-type: decimal">
<li>如果需要你來下結論說，藥物 B 和藥物 A 哪個更加安全？ 求 <span class="math inline">\(\text{Pr}(\theta_B &lt; \theta_A|data)\)</span>。</li>
</ol>
<p><strong>解</strong></p>
<p><strong>貝葉斯</strong></p>
<p>在計算機的輔助下，這是一個十分簡單的計算。我們從各自的事後分佈中採集大量隨機樣本，然後求 <span class="math inline">\(\theta_B-\theta_A\)</span> 然後看有多少比例這個數值是小於零的就可以得出結論：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Simulating from each posterior</span>
<span class="kw">set.seed</span>(<span class="dv">1001</span>)
post.thetaA &lt;-<span class="st"> </span><span class="kw">rbeta</span>(<span class="dv">1000000</span>, <span class="dv">3</span>, <span class="dv">4997</span>)
post.thetaB &lt;-<span class="st"> </span><span class="kw">rbeta</span>(<span class="dv">1000000</span>, <span class="dv">1</span>, <span class="dv">6999</span>)

<span class="co"># Taking the differences</span>
theta.diff0 &lt;-<span class="st"> </span>post.thetaB <span class="op">-</span><span class="st"> </span>post.thetaA</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Histogram of the differences</span>
<span class="kw">hist</span>(theta.diff0,<span class="dt">probability =</span> <span class="ot">TRUE</span>, <span class="dt">breaks =</span> <span class="dv">50</span>, <span class="dt">xlab=</span><span class="kw">expression</span>(theta[B] <span class="op">-</span><span class="st"> </span>theta[A]),<span class="dt">main =</span> <span class="st">&quot;&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">box</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-86"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-86-1.png" alt="Histogram of  Drug B - Drug A" width="80%" />
<p class="caption">
图 33.16: Histogram of Drug B - Drug A
</p>
</div>
<p>也可以不採用直方圖而是使用連續曲線：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Continuous version</span>
<span class="kw">plot</span>(<span class="kw">density</span>(theta.diff0), <span class="dt">xlab=</span><span class="kw">expression</span>(theta[B] <span class="op">-</span><span class="st"> </span>theta[A]), <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">frame=</span><span class="ot">FALSE</span>)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">box</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-87"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-87-1.png" alt="Density of Drug B - Drug A" width="80%" />
<p class="caption">
图 33.17: Density of Drug B - Drug A
</p>
</div>
<p>計算 <span class="math inline">\(\text{Pr}(\theta_B &lt; \theta_A|data)\)</span> 和可信區間：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># P(theta[B] &lt; theta[A] | Data)</span>
<span class="kw">mean</span>(theta.diff0 <span class="op">&lt;</span><span class="dv">0</span>)</code></pre></div>
<pre><code>## [1] 0.927829</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Credible interval for theta[B] - theta[A]</span>
<span class="kw">quantile</span>(theta.diff0, <span class="kw">c</span>(<span class="fl">0.05</span>,<span class="fl">0.95</span>))</code></pre></div>
<pre><code>##              5%             95% 
## -0.001142862872  0.000052484912</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">quantile</span>(theta.diff0, <span class="kw">c</span>(<span class="fl">0.10</span>,<span class="fl">0.90</span>))</code></pre></div>
<pre><code>##            10%            90% 
## -0.00094605885 -0.00004674857</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Simulating from each posterior</span>
<span class="kw">set.seed</span>(<span class="dv">1001</span>)
post.thetaA &lt;-<span class="st"> </span><span class="kw">rbeta</span>(<span class="dv">1000000</span>, <span class="dv">4</span>, <span class="dv">4998</span>)
post.thetaB &lt;-<span class="st"> </span><span class="kw">rbeta</span>(<span class="dv">1000000</span>, <span class="dv">2</span>, <span class="dv">7000</span>)

<span class="co"># Taking the differences</span>
theta.diff1 &lt;-<span class="st"> </span>post.thetaB <span class="op">-</span><span class="st"> </span>post.thetaA</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(theta.diff1,<span class="dt">probability =</span> <span class="ot">TRUE</span>, <span class="dt">breaks =</span> <span class="dv">50</span>, <span class="dt">xlab=</span><span class="kw">expression</span>(theta[B] <span class="op">-</span><span class="st"> </span>theta[A]),<span class="dt">main =</span> <span class="st">&quot;&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">box</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-90"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-90-1.png" alt="Histogram of  Drug B - Drug A" width="80%" />
<p class="caption">
图 33.18: Histogram of Drug B - Drug A
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Continuous version</span>
<span class="kw">plot</span>(<span class="kw">density</span>(theta.diff1), <span class="dt">xlab=</span><span class="kw">expression</span>(theta[B] <span class="op">-</span><span class="st"> </span>theta[A]), <span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">main =</span> <span class="st">&quot;&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">box</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-91"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-91-1.png" alt="Density of  Drug B - Drug A" width="80%" />
<p class="caption">
图 33.19: Density of Drug B - Drug A
</p>
</div>
<p>計算 <span class="math inline">\(\text{Pr}(\theta_B &lt; \theta_A|data)\)</span> 和可信區間：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># P(theta[B] &lt; theta[A] | Data)</span>

<span class="kw">mean</span>(theta.diff1 <span class="op">&lt;</span><span class="dv">0</span>)</code></pre></div>
<pre><code>## [1] 0.899677</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Credible interval for theta[B] - theta[A]</span>
<span class="kw">quantile</span>(theta.diff1, <span class="kw">c</span>(<span class="fl">0.05</span>,<span class="fl">0.95</span>))</code></pre></div>
<pre><code>##             5%            95% 
## -0.00131289334  0.00013423126</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">quantile</span>(theta.diff1, <span class="kw">c</span>(<span class="fl">0.10</span>,<span class="fl">0.90</span>))</code></pre></div>
<pre><code>##            10%            90% 
## -1.0955252e-03  6.5146438e-07</code></pre>
<p><strong>概率論算法</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Normal Approximation</span>
diff_mle &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">7000</span>)<span class="op">-</span>(<span class="dv">3</span><span class="op">/</span><span class="dv">5000</span>)
diff_se &lt;-<span class="st"> </span><span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">*</span><span class="dv">6999</span><span class="op">/</span><span class="dv">7000</span><span class="op">^</span><span class="dv">3</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span><span class="op">*</span><span class="dv">4997</span><span class="op">/</span><span class="dv">5000</span><span class="op">^</span><span class="dv">3</span> )
U &lt;-<span class="st"> </span>diff_mle <span class="op">+</span><span class="st"> </span><span class="fl">1.28</span><span class="op">*</span>diff_se
L &lt;-<span class="st"> </span>diff_mle <span class="op">-</span><span class="st"> </span><span class="fl">1.28</span><span class="op">*</span>diff_se
<span class="kw">print</span>(<span class="kw">c</span>(U,L))</code></pre></div>
<pre><code>## [1]  0.000022358961 -0.000936644675</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">norm.app &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(x) <span class="kw">dnorm</span>(x,diff_mle,diff_se))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Comparison</span>
<span class="kw">plot</span>(<span class="kw">density</span>(theta.diff0), <span class="dt">xlab=</span><span class="kw">expression</span>(theta[B] <span class="op">-</span><span class="st"> </span>theta[A]), <span class="dt">xlim=</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.002</span>,<span class="fl">0.001</span>), <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">main =</span> <span class="st">&quot;&quot;</span>)
<span class="kw">points</span>(<span class="kw">density</span>(theta.diff1), <span class="dt">xlab=</span><span class="kw">expression</span>(theta[B] <span class="op">-</span><span class="st"> </span>theta[A]), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">curve</span>(norm.app,<span class="op">-</span><span class="fl">0.0045</span>,<span class="fl">0.002</span>,<span class="dt">add=</span>T,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">n=</span><span class="dv">10000</span>)
<span class="kw">legend</span>(<span class="op">-</span><span class="fl">0.0021</span>, <span class="dv">1300</span>, <span class="kw">c</span>(<span class="st">&quot;Posterior with B(0,0)&quot;</span>,<span class="st">&quot;Posterior with B(1,1)&quot;</span>,<span class="st">&quot;Frequentist Normal App&quot;</span>), <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;red&quot;</span>,<span class="st">&quot;blue&quot;</span>,<span class="st">&quot;black&quot;</span>),
       <span class="dt">text.col =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">lwd =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>),
       <span class="dt">merge =</span> <span class="ot">TRUE</span>, <span class="dt">bg =</span> <span class="st">&quot;gray90&quot;</span>,<span class="dt">cex=</span><span class="fl">0.8</span>)
<span class="kw">box</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-94"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-94-1.png" alt="Comparison of different prior distribution and frequentist approximation" width="80%" />
<p class="caption">
图 33.20: Comparison of different prior distribution and frequentist approximation
</p>
</div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-32.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/winterwang/LSHTMlearningnote/edit/master/08-Intro-to-Bayes.Rmd",
"text": "编辑"
},
"download": ["bookdown.pdf", "bookdown.epub"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
