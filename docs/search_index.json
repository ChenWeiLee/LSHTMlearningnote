[
["index.html", "醫學統計學 前言", " 醫學統計學 王 超辰 Chaochen Wang 最近更新於 2018-02-22 前言 We are drowning in information and starving for knowledge. — Rutherford D. Roger 尚未想好寫什麼作前言。我只是默默地想留下一些筆記和思考。本書用了兩個 R 包編譯，分別是 knitr (Xie 2015) 和 bookdown (Xie 2018)。 王超辰 2017年9月於倫敦 References "],
["author.html", "我是誰", " 我是誰 歡迎參觀我的個人主頁。 "],
["intro.html", "第 1 章 概率論入門：定義與公理 1.1 三個概率公理： 1.2 條件概率 Conditional probability 1.3 獨立 (independence) 的定義 1.4 賭博問題 1.5 賭博問題的答案", " 第 1 章 概率論入門：定義與公理 1.1 三個概率公理： 對於任意事件 \\(A\\)，它發生的概率 \\(P(A)\\) 滿足這樣的不等式： \\(0 \\leqslant P(A) \\leqslant 1\\) \\(P(\\Omega)=1\\) , \\(\\Omega\\) 是全樣本空間 (total sample space) 對於互斥（相互獨立）的事件 \\(A_1, A_2, \\dots, A_n\\) 有如下的等式關係： \\(P(A_1\\cup A_2 \\cup \\cdots \\cup A_n)=P(A_1)+P(A_2)+\\cdots+P(A_n)\\) 你是不是覺得上面三條公理都是廢話。 不用擔心，我也是這麼覺得的。因爲所有人都認同的道理，才能成爲公理 (axiom)，因爲它們是不需要證明的自然而然形成的人人都接受的觀念。(axiom: a saying that is widely accepted on its own merits; its truth is assumed to be self-evident) 然而，正是這樣顯而易見的道理，確是拿來建築理論的基石，千萬不能小看了他們。例如，我們看下面這個看似也應該成爲公理的公式，你能證明嗎： \\(P(A_1\\cup A_2) = P(A_1) + P(A_2) - P(A_1 \\cap A_2)\\) 證明： 先考慮 \\(A_1 \\cup A_2\\) 是什麼（拆分成三個互斥事件） \\(A_1 \\cup A_2 = (A_1\\cap \\bar{A_2})\\cup(\\bar{A_1}\\cap A_2)\\cup(A_1\\cap A_2)\\) 運用上面的公理2 3 \\(\\therefore P(A_1 \\cup A_2) = P(A_1\\cap \\bar{A_2}) + P(\\bar{A_1}\\cap A_2) + P(A_1\\cap A_2) \\;\\;\\;\\;\\;\\;(1)\\) 再考慮 \\(A_1=(A_1\\cap A_2)\\cup(A_1\\cap\\bar{A_2})\\) 繼續拆分成兩個互斥事件 \\(\\therefore P(A_1)=P(A_1\\cap A_2)+P(A_1\\cap\\bar{A_2})\\) 整理一下： \\(P(A_1\\cap\\bar{A_2})=P(A_1)-P(A_1\\cap A_2)\\) 同理可得: \\(P(\\bar{A_1}\\cap A_2)=P(A_2)-P(A_1\\cap A_2)\\) 代入上面第(1)式可得： \\(P(A_1 \\cup A_2) =P(A_1)-P(A_1\\cap A_2)\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+P(A_2)-P(A_1\\cap A_2)\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+P(A_1\\cap A_2)\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=P(A_1) + P(A_2) - P(A_1 \\cap A_2)\\) 1.2 條件概率 Conditional probability \\(P(A|S)=\\frac{P(A\\cap S)}{P(S)}\\) \\(P(A\\cap S) = P(A|S)P(S)\\) 1.3 獨立 (independence) 的定義 兩個事件定義爲互爲獨立時 (\\(A\\) and \\(B\\) are said to be independent if and only if) \\[P(A\\cap B)=P(A)P(B)\\] 因爲從條件概率的概念我們已知 \\(P(A\\cap B) = P(A|B)P(B)\\) 所以\\(P(A|B)=P(A)\\) 即：事件 \\(B\\) 無法提供事件 \\(A\\) 的任何有效訊息 (\\(A, B\\) 互相獨立) 1.4 賭博問題 終於來到本次話題的“重點”了。 假設你在一個電視遊戲節目。有上圖一樣的三扇門。其中一扇門後面有一輛保時捷，另兩扇門後面則是(味道奇特的)山羊。遊戲規則是主持人會讓你先選擇其中一扇門（先不打開你選的這扇門）。主持人隨後打開另外兩扇門中的一扇沒有保時捷的門。主持人問你，你要堅持選擇之前選中的那扇門，還是要改變主意換一扇門去猜是否可以猜中保時捷。 請問，堅持選擇之前選中的門猜中保時捷的概率高，還是主持人打開一扇門以後改變主意猜中保時捷的概率更高呢？ 1.5 賭博問題的答案 答案是：必須改變主意才能提高中獎概率。 上述情況下，最簡單的是用概率樹 (probability tree) 來做決定： 解說一下： 假定保時捷在1號門後，你第一次選擇了1號門，那麼此時主持人可以任意打開2號或者三號門（因爲他們後面都沒有保時捷）。 假定保時捷在1號門後，你第一次選了2號門，那麼此時主持人只能打開3號門（因爲一號門後是保時捷，按照遊戲規則主持人不能打開）。 假定保時捷在1號門後，你第一次選了3號門，那麼此時主持人只能打開2號門（因爲一號門後是保時捷，按照遊戲規則主持人不能打開）。 所以按照圖中給出的計算概率樹的過程可以得到: \\[P[change]=\\frac{1}{3}+\\frac{1}{3}=\\frac{2}{3}\\\\ P[not\\; change]=\\frac{1}{6}+\\frac{1}{6}=\\frac{1}{3}\\] 你是否選擇了改變主意了呢？ "],
["Bayes-Definition.html", "第 2 章 Bayes 貝葉斯理論的概念", " 第 2 章 Bayes 貝葉斯理論的概念 許多時候，我們需要將概率中的條件相互對調。 例如： 在已知該人羣中有20%的人有吸菸習慣(\\(P(S)\\))，吸菸的人有9%的概率有哮喘(\\(P(A|S)\\))，不吸菸的人有7%的概率有哮喘(\\(P(A|\\bar{S})\\))的前提下，有個人前來門診，發現是哮喘患者，那麼這個人有多大的概率是一個菸民？也就是要求 \\(P(S|A)\\) 這裏先引入貝葉斯的概念： 我們可以將 \\(P(A\\cap S)\\) 寫成： \\[P(A\\cap S)=P(A|S)P(S)\\\\or\\\\ P(A\\cap S)=P(S|A)P(A)\\] 這兩個等式是完全等價的。我們將他們連起來： \\[P(S|A)P(A)=P(A|S)P(S)\\\\ \\Rightarrow P(S|A)=\\frac{P(A|S)P(S)}{P(A)}\\] 是不是看起來又像是寫了一堆廢話？ 沒錯，你看出來是一堆廢話的時候，證明你也同意這背後的簡單邏輯。 再繼續，我們可以利用另外一個廢話：\\(\\because S+\\bar{S}=1\\\\ \\therefore P(A)=P(A\\cap S)+P(A\\cap\\bar{S})\\) 用上面的公式替換掉 \\(P(A\\cap S)+P(A\\cap\\bar{S}） \\\\ \\therefore P(A)=P(A|S)P(S)+P(A|\\bar{S})P(\\bar{S})\\) 可以得到貝葉斯理論公式： \\[P(S|A)=\\frac{P(A|S)P(S)}{P(A|S)P(S)+P(A|\\bar{S})P(\\bar{S})}\\] 回到上面說到的哮喘人中有多少比例吸菸的問題。可以繼續使用概率樹來方便的計算： \\[\\begin{align} P(S|A) &amp;= \\frac{P(A|S)P(S)}{P(A|S)P(S)+P(A|\\bar{S})P(\\bar{S})} \\\\ &amp;= \\frac{0.09\\times0.2}{0.09\\times0.2+0.07\\times0.8} \\\\ &amp;= 0.24 \\end{align}\\] 所以我們的結論就是，在已知該人羣中有20%的人有吸菸習慣(\\(P(S)\\))，吸菸的人有9%的概率有哮喘(\\(P(A|S)\\))，不吸菸的人有7%的概率有哮喘(\\(P(A|\\bar{S})\\))的前提下，有個人前來門診，發現是哮喘患者，那麼這個人有24% 的概率是一個菸民(\\(P(S|A)\\))。 "],
["-expectation-or-mean-variance.html", "第 3 章 期望 Expectation (或均值 or mean) 和 方差 Variance 3.1 方差的性質：", " 第 3 章 期望 Expectation (或均值 or mean) 和 方差 Variance 期望（或均值）是用來描述一組數據中心位置的指標（另一個是中位數 Median）。 對於離散型隨機變量 \\(X\\) (discrete random variables)，它的期望被定義爲： \\[E(X)=\\sum_x xP(X=x)\\] 所以就是將所有 \\(X\\) 可能取到的值乘以相應的概率後求和。這個期望（或均值）常常用希臘字母 \\(\\mu\\) 來標記。 方差 Variance 是衡量一組數據變化幅度(dispersion/variability)的指標之一。 方差的定義是： \\[Var(X)=E((X-\\mu)^2)\\\\\\text{Where, }\\mu=E(x)\\] 實際上我們更加常用的是它的另外一個公式： \\[Var(X)=E(X^2)-E(X)^2\\] 證明 上面兩個方差公式相等 \\[\\begin{align} Var(x) &amp;= E((X-\\mu)^2) \\\\ &amp;= E(X^2-2X\\mu+\\mu^2)\\\\ &amp;= E(X^2) - 2\\mu E(X) + \\mu^2\\\\ &amp;= E(X^2) - 2\\mu^2 + \\mu^2 \\\\ &amp;= E(X^2) - \\mu^2 \\\\ &amp;= E(X^2) - E(X)^2 \\end{align}\\] 3.1 方差的性質： \\(Var(X+b)=Var(X)\\) \\(Var(aX)=a^2Var(X)\\) \\(Var(aX+b)=a^2Var(X)\\) "],
["-bernoulli-distribution.html", "第 4 章 伯努利分佈 Bernoulli distribution", " 第 4 章 伯努利分佈 Bernoulli distribution 伯努利分佈，說的就是一個簡單的二分變量 (1, 0)，它取1時的概率如果是 \\(\\pi\\)。那麼我們可以計算這個分佈的期望值: \\[\\begin{align} E(X) &amp;=\\sum_x xP(X=x) \\\\ &amp;=1\\times\\pi + 0\\times(1-\\pi)\\\\ &amp;=\\pi \\end{align}\\] 由於 \\(x=x^2\\)，因爲 \\(x=0,1\\), 所以 \\(E[X^2]=E[X]\\)，那麼方差爲： \\[\\begin{align} Var(X) &amp;=E[X^2]-E[X]^2 \\\\ &amp;=E[X]-E[X]^2 \\\\ &amp;=\\pi - \\pi^2 \\\\ &amp;=\\pi(1-\\pi) \\end{align}\\] 證明，\\(X,Y\\) 爲互爲獨立的隨機離散變量時，a) \\(E(XY)=E(X)E(Y)\\) ; b) \\(Var(X+Y)=Var(X)+Var(Y)\\) 證明 \\[\\begin{align} E(XY) &amp;= \\sum_x\\sum_y xyP(X=x, Y=y) \\\\ \\because &amp;\\; X,Y are\\;independent\\;to\\;each\\;other \\\\ \\therefore &amp;= \\sum_x\\sum_y xyP(X=x)P(Y=y)\\\\ &amp;=\\sum_x xP(X=x)\\sum_y yP(Y=y)\\\\ &amp;=E(X)E(Y) \\end{align}\\] 證明 根據方差的定義： \\[\\begin{align} Var(X+Y) &amp;= E((X+Y)^2)-E(X+Y)^2 \\\\ &amp; \\; Expand \\\\ &amp;=E(X^2+2XY+Y^2)-(E(X)+E(Y))^2\\\\ &amp;=E(X^2)+E(Y^2)+2E(XY)\\\\ &amp;\\;\\;\\; - E(X)^2-E(Y)^2-2E(X)E(Y)\\\\ &amp;\\; We\\;just\\;showed\\; E(XY)=E(X)E(Y)\\\\ &amp;=E(X^2)-E(X)^2+E(Y^2)-E(Y)^2 \\\\ &amp;=Var(X)+Var(Y) \\end{align}\\] "],
["-binomial-distribution.html", "第 5 章 二項分佈的概念 Binomial distribution 5.1 二項分佈的期望和方差 5.2 超幾何分佈 hypergeometric distribution 5.3 樂透中獎概率問題：", " 第 5 章 二項分佈的概念 Binomial distribution 二項分佈在醫學研究中至關重要，一組二項分佈的數據，指的通常是 \\(n\\) 次相互獨立的成功率爲 \\(\\pi\\) 的伯努利實驗 (\\(n\\) independent Bernoulli trials) 中成功的次數。 當 \\(X\\) 服從二項分佈，記爲 \\(X \\sim binomial(n, \\pi)\\) 或\\(X \\sim bin(n, \\pi)\\)。它的(第 \\(x\\) 次實驗的)概率被定義爲： \\[\\begin{align} P(X=x) &amp;= ^nC_x\\pi^x(1-\\pi)^{n-x} \\\\ &amp;= \\binom{n}{x}\\pi^x(1-\\pi)^{n-x} \\\\ &amp; for\\;\\; x = 0,1,2,\\dots,n \\end{align}\\] 5.1 二項分佈的期望和方差 期望 \\(E(X)\\) 若 \\(X \\sim bin(n,\\pi)\\)，那麼 \\(X\\) 就是這一系列獨立伯努利實驗中成功的次數。 用 \\(X_i, i =1,\\dots, n\\) 標記每個相互獨立的伯努利實驗。 那麼我們可以知道 \\(X=\\sum_{i=1}^nX_i\\)。 \\[\\begin{align} E(X) &amp;= E(\\sum_{i=1}^nX_i)\\\\ &amp;= E(X_1+X_2+\\cdots+X_n) \\\\ &amp;= E(X_1)+E(X_2)+\\cdots+E(X_n)\\\\ &amp;= \\sum_{i=1}^nE(X_i)\\\\ &amp;= \\sum_{i=1}^n\\pi \\\\ &amp;= n\\pi \\end{align}\\] 方差 \\(Var(X)\\) \\[\\begin{align} Var(X) &amp;= Var(\\sum_{i=1}^nX_i) \\\\ &amp;= Var(X_i+X_2+\\cdots+X_n) \\\\ &amp;= Var(X_i)+Var(X_2)+\\cdots+Var(X_n) \\\\ &amp;= \\sum_{i=1}^nVar(X_i) \\\\ &amp;= n\\pi(1-\\pi) \\\\ \\end{align}\\] 5.2 超幾何分佈 hypergeometric distribution 假設我們從總人數爲 \\(N\\) 的人羣中，採集一個樣本 \\(n\\)。假如已知在總體人羣中(\\(N\\))有 \\(M\\) 人患有某種疾病。請問採集的樣本 \\(X=n\\) 中患有這種疾病的人，服從怎樣的分佈？ 從人羣(\\(N\\))中取出樣本(\\(n\\))，有 \\(^NC_n\\) 種方法。 從患病人羣(\\(M\\))中取出患有該病的人(\\(x\\))有 \\(^MC_x\\) 種方法。 樣本中不患病的人(\\(n-x\\))被採樣的方法有 \\(^{N-M}C_{n-x}\\) 種。 採集一次 \\(n\\) 人作爲樣本的概率都一樣。因此： \\[P(X=x)=\\frac{\\binom{M}{x}\\binom{N-M}{n-x}}{\\binom{N}{n}}\\] 5.3 樂透中獎概率問題： 從數字 \\(1\\sim59\\) 中選取 \\(6\\) 個任意號碼 開獎時從 \\(59\\) 個號碼球中隨機抽取 \\(6\\) 個 如果六個號碼全部猜中(不分順序)，你可以成爲百萬富翁。請問一次猜中全部 \\(6\\) 個號碼的概率是多少？ 從 \\(59\\) 個號碼中隨機取出任意 \\(6\\) 個號碼的方法有 \\(^{59}C_6\\) 種。 \\[^{59}C_6=\\frac{59!}{6!(59-6)!}=45,057,474\\] 每次選取六個號碼做爲一組的可能性相同，所以，你買了一組樂透號碼，能中獎的概率就是 \\(1/45,057,474 = 0.00000002219\\)。你還會再去買彩票麼？ 5.3.1 如果我只想中其中的 \\(3\\) 個號碼，概率有多大？ 用超幾何分佈的概率公式： \\[\\begin{align} P(X=3) &amp;= \\frac{^6C_3\\times ^{53}C_3}{^{59}C_6} \\\\ &amp;= 0.010 \\end{align}\\] 你有 \\(1\\%\\) 的可能中獎。換句話說，如果中三個以上的數字算中獎的話，你買的彩票中獎的概率低於 \\(1\\%\\)。是不是覺得下次送錢給博彩公司的時候還不如跟我一起喝一杯咖啡划算？ "],
["poisson.html", "第 6 章 泊松分佈 Poisson Distribution", " 第 6 章 泊松分佈 Poisson Distribution 當一個事件，在一段時間 (\\(T\\)) 中可能發生的次數是 \\(\\lambda\\) 。那麼我們可以認爲，經過時間 \\(T\\)，該時間發生的期望次數是 \\(E(X)=\\lambda T\\)。 利用微分思想，將這段時間 \\(T\\) 等分成 \\(n\\) 個時間段，當 \\(n\\rightarrow\\infty\\) 直到每個微小的時間段內最多發生一次該事件。 那麼 每個微小的時間段，可以視爲是一個伯努利實驗（有事件發生或者沒有） 那麼這整段時間 \\(T\\) 內發生的事件可以視爲是一個二項分佈實驗。 令 \\(X=\\) 一次事件發生時所經過的所有時間段。 \\(X \\sim Bin(n, \\pi)\\)，其中 \\(n\\rightarrow\\infty\\)，\\(n\\) 爲時間段。 在每個分割好的時間段內，事件發生的概率都是：\\(\\pi=\\frac{\\lambda T}{n}\\) 期望 \\(\\mu=\\lambda T \\Rightarrow \\pi=\\mu/n\\) 所以 \\(X\\) 的概率方程就是： \\[\\begin{align} P(X=x) &amp;= \\binom{n}{x}\\pi^x(1-\\pi)^{n-x} \\\\ &amp;= \\binom{n}{x}(\\frac{\\mu}{n})^x(1-\\frac{\\mu}{n})^{n-x} \\\\ &amp;= \\frac{n!}{x!(n-x)!}(\\frac{\\mu}{n})^x(1-\\frac{\\mu}{n})^{n-x} \\\\ &amp;=\\frac{n!}{n^x(n-x)!}\\frac{\\mu^x}{x!}(1-\\frac{\\mu}{n})^{n-x}\\\\ \\text{when}\\; n\\rightarrow\\infty &amp;\\; x \\ll n\\\\ \\frac{n!}{n^x(n-x)!} &amp;=\\frac{n(n-1)\\dots(n-x+1)}{n^x} \\rightarrow 1\\\\ (1-\\frac{\\mu}{n})^{n-x} &amp;\\approx (1-\\frac{\\mu}{n})^n \\rightarrow e^{-\\mu}\\\\ \\text{the probability function } &amp; \\text{ of a Poisson distribution} \\\\ P(X=x) &amp;\\rightarrow \\frac{\\mu^x}{x!}e^{-\\mu} \\end{align}\\] 當數據服從泊松分佈時，記爲 \\(X\\sim Poisson(\\mu=\\lambda T)\\;\\; or\\;\\; X\\sim Poi(\\mu)\\) 證明泊松分佈的參數特徵： \\(E(X)=\\mu\\) \\[\\begin{align} E(X) &amp;= \\sum_{x=0}^\\infty xP(X=x) \\\\ &amp;= \\sum_{x=0}^\\infty x\\frac{\\mu^x}{x!}e^{-\\mu} \\\\ &amp;= 0+ \\sum_{x=1}^\\infty x\\frac{\\mu^x}{x!}e^{-\\mu} \\\\ &amp;= \\sum_{x=1}^\\infty \\frac{\\mu^x}{(x-1)!}e^{-\\mu} \\\\ &amp;= \\mu\\sum_{x=1}^\\infty \\frac{\\mu^{x-1}}{(x-1)!}e^{-\\mu} \\\\ replace\\; &amp;x\\; with\\; all\\; i=x-1 \\\\ &amp;= \\mu\\sum_{i=0}^\\infty \\frac{\\mu^{i}}{i!}e^{-\\mu} \\\\ notice\\; that\\; &amp;the\\; right\\; side \\sum_{i=0}^\\infty \\frac{\\mu^{i}}{i!}e^{-\\mu}=1 is \\\\ the\\;sum\\;of\\;all\\;&amp;probability\\;of\\;a\\;Poisson\\;distribution\\\\ &amp;= \\mu \\end{align}\\] \\(Var(x)=\\mu\\) 爲了找到 \\(Var(X)\\)，我們用公式 \\(Var(X)=E(X^2)-E(X)^2\\) 我們需要找到 \\(E(X^2)\\) \\[\\begin{align} E(X^2) &amp;= \\sum_{x=0}^\\infty x^2\\frac{\\mu^x}{x!}e^{-\\mu} \\\\ &amp;= \\mu \\sum_{x=1}^\\infty x\\frac{\\mu^{x-1}}{(x-1)!}e^{-\\mu} \\\\ replace\\; &amp;x\\; with\\; all\\; i=x-1 \\\\ &amp;= \\mu \\sum_{i=0}^\\infty (i+1)\\frac{\\mu^{i}}{i!}e^{-\\mu} \\\\ &amp;= \\mu(\\sum_{i=0}^\\infty i\\frac{\\mu^i}{i!}e^{-\\mu} + \\sum_{i=0}^\\infty \\frac{\\mu^i}{i!}e^{-\\mu}) \\\\ &amp;= \\mu(E(X)+1) \\\\ &amp;= \\mu^2+\\mu \\\\ Var(X) &amp;= E(X^2) - E(X)^2 \\\\ &amp;= \\mu^2 + \\mu -\\mu^2 \\\\ &amp;= \\mu \\end{align}\\] "],
["section-7.html", "第 7 章 正態分佈 7.1 概率密度曲線 probability density function， PDF 7.2 正態分佈 7.3 標準正態分佈", " 第 7 章 正態分佈 7.1 概率密度曲線 probability density function， PDF 一個隨機連續型變量 \\(X\\) 它的性質由一個對應的概率密度方程 (probability density function, PDF) 決定。 在給定的範圍區間內，如 \\(a\\sim b, (a &lt; b)\\)，它的概率滿足: \\[P(a\\leqslant X \\leqslant b) = \\int_a^bf(x)dx\\] 這個相關的方程，在 \\(a\\sim b\\) 區間內的積分，就是這個連續變量在這個區間內取值的概率。 # R codes for drawing a standard normal distribution by using ggplot2 p &lt;- ggplot(data.frame(x=c(-3,3)), aes(x=x)) + stat_function(fun = dnorm) p + annotate(&quot;text&quot;, x=2, y=0.3, parse=TRUE, label=&quot;frac(1, sqrt(2*pi)) * e ^(-z^2/2)&quot;) + theme(plot.subtitle = element_text(vjust = 1), plot.caption = element_text(vjust = 1), axis.text.x = element_text(size = 12), axis.text.y = element_text(size = 12), plot.title = element_text(size = 10, face = &quot;bold&quot;, hjust = 0.5), panel.background = element_rect(fill = &quot;ivory&quot;)) + labs(title = &quot;Probability density functions \\n for standard normal distribution&quot;, x = NULL, y = NULL) + stat_function(fun = dnorm, xlim = c(-1.3,0.4), geom = &quot;area&quot;,fill=&quot;#00688B&quot;, alpha= 0.2) 圖 7.1: Probability Density Function of a Standard Normal Distribution 注意：整個方程的曲線下面積等於 \\(1\\)： \\[\\int_{-\\infty}^\\infty f(x)dx=1\\] 期望 \\(E(X)=\\int_{-\\infty}^\\infty xf(x)dx\\) 方差 \\(Var(X)=\\int_{-\\infty}^\\infty (x-\\mu)^2f(x)dx\\) 7.2 正態分佈 如果一組數據服從正態分佈，我們通常用它的期望（或者叫平均值）\\(\\mu\\)，和它的方差 \\(\\sigma^2\\)，來描述這組數據。記爲： \\[X \\sim N(\\mu, \\sigma^2)\\] 它的概率密度方程可以表述爲： \\[f(x)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})\\] \\(E(x) =\\mu\\) \\(Var(x)=\\sigma^2\\) 7.3 標準正態分佈 標準正態分佈的期望（或者均值）爲 \\(0\\)，方差爲 \\(1\\) 記爲：\\(Z \\sim N(0,1)\\) 它的概率密度方程表述爲： \\[\\frac{1}{\\sqrt{2\\pi}}exp(-\\frac{z^2}{2})\\] 它的累積分佈方程 (cumulative distribution function， CDF)，是將概率密度方程 (PDF) 積分以後獲得的方程。通常我們記爲 \\(\\Phi(z)\\) 再看一下標準正態分佈的概率密度方程曲線： 圖 7.2: Probability Density function of a Standard Normal Distribution 95% 的曲線下面積在標準差 standard deviation \\(-1.96\\sim1.96\\) 之間的區域。 而且，\\(\\phi(-x)=1-\\phi(x)\\) 任何一個正態分佈都可以通過下面的公式，標準化成爲標準正態分佈： \\[Z=\\frac{X-\\mu}{\\sigma}\\] "],
["CLT.html", "第 8 章 中心極限定理 the Central Limit Theorem 8.1 協方差 Covariance 8.2 相關 Correlation 8.3 中心極限定理 the Central Limit Theorem 8.4 二項分佈的正態分佈近似 8.5 泊松分佈的正態分佈近似 8.6 正態分佈模擬的校正：continuity corrections 8.7 兩個連續隨機變量 8.8 兩個連續隨機變量 例子： 8.9 條件分佈和邊緣分佈的概念 8.10 條件分佈和邊緣分佈的例子", " 第 8 章 中心極限定理 the Central Limit Theorem 最近明顯可以感覺到課程的步驟開始加速。看我的課表： 手機畫面太小了。早上都是9點半開始，下午基本都是到5點。週一更慘，到7點。週二-週五中午都被統計中心的講座佔據。簡直是非人的生活。 這周概率論基礎結束。中心極限定理講完以後我們正式進入了 Inference 統計推斷的課程。我們花了一天時間講什麼是樣本估計 (Estimation)，什麼是參數精確度 (Precision)，什麼是自由度 (degree of freedom)，怎樣進行不偏的估計 (unbiased inference)。然後還有似然方程 (likelihood function)。 今天的更新還是簡單的把概率論掃尾一下。感受一下中心極限定理的偉大。 8.1 協方差 Covariance 之前我們定義過，兩個獨立連續隨機變量 \\(X,Y\\) 之和的方差 Variance ： \\[Var(X+Y)=Var(X)+Var(Y)\\] 然而如果他們並不相互獨立的話： \\[\\begin{aligned} Var(X+Y) &amp;= E[((X+Y)-E(X+Y))^2] \\\\ &amp;= E[(X+Y)-(E(X)+E(Y))^2] \\\\ &amp;= E[(X-E(X)) - (Y-E(Y))^2] \\\\ &amp;= E[(X-E(X))^2+(Y-E(Y))^2 \\\\ &amp; \\;\\;\\; +2(X-E(X))(Y-E(Y))] \\\\ &amp;= Var(X)+Var(Y)+2E[(X-E(X))(Y-E(Y))] \\end{aligned}\\] 可以發現在兩者和的方差公式展開之後多了一部分 \\(E[(X-E(X))(Y-E(Y))]\\)。 這個多出來的一部分就說明了二者 \\((X, Y)\\) 之間的關係。它被定義爲協方差 (Covariance): \\[Cov(X,Y) = E[(X-E(X))(Y-E(Y))]\\] 所以： \\[Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)\\] 要記住，協方差只能用於評價\\(X,Y\\)之間的線性關係 (Linear Association)。 以下是協方差 (Covariance) 的一些特殊性質： \\(Cov(X,X)=Var(X)\\) \\(Cov(X,Y)=Cov(Y,X)\\) \\(Cov(aX,bY)=ab\\:Cov(X,Y)\\) \\(Cov(aR+bS,cX+dY)=ac\\:Cov(R,X)+ad\\:Cov(R,Y)\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+bc\\:Cov(S,X)+bd\\:Cov(S,Y)\\) \\(Cov(aX+bY,cX+dY)=ac\\:Var(X)+ad\\:Var(Y)\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+(ad+bc)Cov(X,Y)\\) \\(Cov(X+Y,X-Y)=Var(X)-Var(Y)\\) If \\(X, Y\\) are independent. \\(Cov(X,Y)=0\\) But not vise-versa ! 8.2 相關 Correlation 協方差雖然\\(Cov(X,Y)\\) 的大小很大程度上會被他們各自的單位和波動大小左右。 我們將協方差標準化(除以各自的標準差 s.d.) (standardization) 之後，就可以得到相關係數 Corr (\\(-1\\sim1\\)): \\[Corr(X,Y)=\\frac{Cov(X,Y)}{SD(X)SD(Y)}=\\frac{Cov(X,Y)}{\\sqrt{Var(X)Var(Y)}}\\] 8.3 中心極限定理 the Central Limit Theorem 如果從人羣中多次選出樣本量爲 \\(n\\) 的樣本，並計算樣本均值, \\(\\bar{X}_n\\)。那麼這個樣本均值 \\(\\bar{X}_n\\) 的分佈，會隨着樣本量增加 \\(n\\rightarrow\\infty\\)，而接近正態分佈。 偉大的中心極限定理告訴我們： 當樣本量足夠大時，樣本均值 \\(\\bar{X}_n\\) 的分佈爲正態分佈，這個特性與樣本來自的人羣的分佈 \\(X_i\\) 無關。 再說一遍： 如果對象是獨立同分佈 i.i.d (identically and independently distributed)。那麼它的總體期望和方差分別是: \\(E(X)=\\mu;\\;Var(X)=\\sigma^2\\)。 根據中心極限定理，可以得到： 當樣本量增加，樣本均值的分佈服從正態分佈： \\[\\bar{X}_n\\sim N(\\mu, \\frac{\\sigma^2}{n})\\] 也可以寫作，當樣本量增加： \\[\\sum_{i=1}^nX_i \\sim N(n\\mu,n\\sigma^2)\\] 有了這個定理，我們可以拋開樣本空間(\\(X\\))的分佈，也不用假定它服從正態分佈。 但是樣本的均值，卻總是服從正態分佈的。簡直是太完美了！！！！！！ 8.4 二項分佈的正態分佈近似 假設我們有大量(\\(n\\rightarrow\\infty\\))的二項分佈實驗 \\(X\\sim Bin(n, \\pi)\\) 根據二項分佈的概率公式，計算將會變得很繁瑣複雜。 解決辦法：應用中心極限定理。 中心極限定理告訴我們，當樣本量足夠大時: \\[X\\sim N(n\\pi, n\\pi(1-\\pi))\\] 問題在於，多大的 \\(n\\) 才能算大樣本呢？ 當且僅當 (only and if only) \\(n&gt;20\\) AND \\(n\\pi&gt;5\\) AND \\(n(1-\\pi)&gt;5\\) 8.5 泊松分佈的正態分佈近似 假設時間 \\(t\\) 內某事件的發生次數服從泊松分佈 \\(X\\sim Po(\\mu)\\)。 考慮將這段時間 \\(t\\) 等分成 \\(n\\) 個時間段。那麼第 \\(i\\) 時間段內事件發生次數依舊服從泊松分佈 \\(X_i\\sim Po(\\frac{\\mu}{n})\\)。且 \\(E(X_i)=\\mu/n, Var(X_i)=\\mu/n\\)。 那麼原先的 \\(X\\) 可以被視爲是將這無數的小時間段的 \\(X_i\\) 相加。應用中心極限定理： \\[X=\\sum_{i=1}^nX_i\\sim N(\\frac{n\\mu}{n}, \\frac{n\\mu}{n})\\] 需要注意的是，這段時間 (\\(t\\)) 內發生的事件次數 (\\(\\lambda\\)) : \\(\\lambda t =\\mu&gt;10\\) ，這樣的正態分佈模擬才能成立。 8.6 正態分佈模擬的校正：continuity corrections 如果我們使用正態分佈來模擬離散變量的分佈，常常需要用到正態分佈模擬的矯正。 例如：我們如果用正態分佈模擬來計算 \\(P(X=15)\\)，那麼實際上我們應該計算的是 \\(P(14.5&lt;X&lt;15.5)\\)。 8.6.1 例題 已知 \\(X\\sim Bin(100,0.5)\\)，求 \\(P(X&gt;60)\\) 解 \\[\\begin{aligned} \\because X&amp;\\sim Bin(100, 0.5) \\\\ \\therefore E(X) &amp;=n\\pi=50 \\\\ Var(X) &amp;= n\\pi(1-\\pi) =25=5^2\\\\ P(X&gt;60) &amp;= 1-P(X\\leqslant60) \\\\ &amp;= 1-P(Z\\leqslant\\frac{60.5-50}{\\sqrt{25}}) \\\\ &amp;= 1-P(Z\\leqslant2.1) \\\\ &amp;= 1-\\Phi(2.1) \\\\ &amp;= 1-0.982 = 0.018 \\end{aligned}\\] # 快來看實際用傻瓜算法計算獲得的概率： 1-pbinom(60, size=100, prob=0.5) ## [1] 0.0176 # 快來看用中心極限定理模擬正態分佈獲得的概率： 1-pnorm((60.5-50)/sqrt(25)) ## [1] 0.01786 圖 8.1: Probability of 60 successes out of 100 Binomial trials, probability of success = 0.75 已知 \\(X\\sim Bin(48, 0.75)\\), 求 \\(P(30&lt;X&lt;39)\\) 解 \\[ \\begin{aligned} \\because B &amp;\\; \\sim Bin(48, 0.75) \\\\ \\therefore E(X) &amp;\\; =n\\pi=36 \\\\ Var(X) &amp;\\; =n\\pi(1-\\pi)=9=3^2 \\\\ P(30&lt;X&lt;39) &amp;\\; = P(31\\leqslant X\\leqslant 38)\\\\ &amp;\\; = P(30.5\\leqslant Y \\leqslant 38.5) \\\\ Y\\;is\\;the&amp;\\;normal\\;approximation \\\\ &amp;\\;= P(Y&lt;38.5) - P(Y&lt;30.5) \\\\ &amp;\\;= P(Z\\leqslant\\frac{38.5-36}{3})- P(Z\\leqslant\\frac{30.5-36}{3}) \\\\ &amp;\\;= P(Z\\leqslant0.833) - P(Z\\leqslant-1.833) \\\\ &amp;\\;= \\Phi(0.833)-\\Phi(-1.833) \\\\ &amp;\\;= 0.798-0.033 = 0.764 \\end{aligned} \\] # 快來看實際用傻瓜算法計算獲得的概率： pbinom(38, size=48, prob=0.75)-pbinom(30, size=48, prob=0.75) ## [1] 0.7578 # 快來看用中心極限定理模擬正態分佈獲得的概率： pnorm((38.5-36)/sqrt(9)) - pnorm((30.5-36)/sqrt(9)) ## [1] 0.7643 圖 8.2: Probability of 30-39 successes out of 48 Binomial trials, probability of success = 0.75 從上面兩個例題也能看出，\\(n\\) 越小，正態分佈模擬的誤差就越大。 已知 \\(X \\sim Poisson(30)\\) 求 \\(P(X\\leqslant20)\\)。 解 \\[\\because E(X)=\\mu=30, \\;Var(X)=\\mu=30=(\\sqrt{30})^2 \\\\ \\begin{aligned} Pr(X\\leqslant20) &amp;= P(Z\\leqslant\\frac{20.5-30}{\\sqrt{30}}) \\\\ &amp;= P(Z\\leqslant-1.734) \\\\ &amp;= \\Phi(-1.734) \\\\ &amp;= 0.0414 \\end{aligned} \\] # 快來看實際用傻瓜算法計算獲得的概率： ppois(20, lambda=30) ## [1] 0.03528 # 快來看用中心極限定理模擬正態分佈獲得的概率： pnorm((20.5-30)/sqrt(30)) ## [1] 0.04142 這兩個其實有些小差距。不過看下圖，其模擬還是很到位的。只是正態分佈的面積明顯確實比泊松分佈的小柱子面積要大一些。 圖 8.3: Probability of less than 20 events happen when the expectation is 30 已知 \\(X_1, X_2 \\stackrel{i.i.d}{\\sim} Poi(30)\\) 求 \\(P(X_1+X_2\\leqslant40)\\)。 解 \\[ \\begin{aligned} E(X_1+X_2) &amp;\\;= E(X_1)+E(X_2) = 30+30 = 60\\\\ Var(X_1+X_2) &amp;\\;= Var(X_1)+Var(X_2) = 30+30 \\\\ &amp;\\;= (\\sqrt{60})^2 \\\\ P(X_1+X_2\\leqslant 40) &amp;\\;= P(Z \\leqslant \\frac{40.5-60}{\\sqrt{60}}) \\\\ &amp;\\;= P(Z\\leqslant-2.517) \\\\ &amp;\\;= \\Phi(-2.517) \\\\ &amp;\\;= 0.006 \\end{aligned} \\] # 快來看實際用傻瓜算法計算獲得的概率： ppois(40, lambda=60) ## [1] 0.003983 # 快來看用中心極限定理模擬正態分佈獲得的概率： pnorm((40.5-60)/sqrt(60)) ## [1] 0.005911 圖 8.4: Probability of 2 identically and independently observed results of less or equal to 40 events happen in total when the expectation of each observation is 30 又一次，正態分佈的面積比泊松分佈的小柱子面積要大一些。 8.7 兩個連續隨機變量 假定 \\(X_1, X_2\\) 是兩個連續隨機變量： \\[E(X_1)=\\mu_1, Var(X_1)=\\sigma_1^2 \\\\ E(X_2)=\\mu_2, Var(X_2)=\\sigma_2^2 \\\\ Corr(X_1, X_2)=\\rho \\Rightarrow Cov(X_1, X_2)=\\rho\\sigma_1\\sigma_2=\\sigma_{12}\\] 利用矩陣的標記法，可以將 \\(X_1, X_2\\) 標記爲 \\(\\textbf{X}=(X_1, X_2)^T\\), 即： \\[\\textbf{X}=\\left( \\begin{array}{c} X_1\\\\ X_2\\\\ \\end{array} \\right)\\] 上面的所有內容都可以標記爲： \\[E(\\textbf{X})=\\mathbf{\\mu}=\\left( \\begin{array}{c} \\mu_1\\\\ \\mu_2\\\\ \\end{array} \\right)\\\\ Covariance \\;matrix: \\\\ Var(\\textbf{X})=\\mathbf{\\Sigma}=\\left( \\begin{array}{c} \\sigma_1^2 &amp; \\sigma_{12}\\\\ \\sigma_{12} &amp; \\sigma_1^2\\\\ \\end{array} \\right)\\] 8.8 兩個連續隨機變量 例子： 假如要看收縮期血壓 (\\(SBP\\)) 和舒張期血壓 (\\(DBP\\)) 之間的關係： 下列爲已知條件： \\(SBP\\) 的均值爲 \\(130\\)， 標準差爲 \\(15\\); \\(DBP\\) 的均值爲 \\(90\\), 標準差爲 \\(10\\); \\(SBP\\) 和 \\(DBP\\) 之間的相關係數爲 \\(0.75\\)。 那麼， 我們可以把這些信息用下面的方法來標記： \\[E(\\textbf{X})=\\mathbf{\\mu}=\\left( \\begin{array}{c} 130\\\\ 90\\\\ \\end{array} \\right)\\\\ Var(\\textbf{X})=\\mathbf{\\Sigma}=\\left( \\begin{array}{c} 225 &amp; 112.5\\\\ 112.5 &amp; 225\\\\ \\end{array} \\right)\\] 8.9 條件分佈和邊緣分佈的概念 如果 \\(\\textbf{X}=(X_1, X_2)^T\\) 的兩個變量都服從正態分佈； 那麼這兩個變量的邊緣分佈 (marginal distribution) 也服從正態分佈: \\[X_1\\sim N(\\mu_1,\\sigma_1^2), X_2\\sim N(\\mu, \\sigma_2^2)\\] 同樣的，\\(X_1\\) 的給出 \\(X_2\\) 的條件分佈 (condition distribution) 也服從正態分佈： \\[E(X_1|X_2)=\\mu_1+\\frac{\\rho\\sigma_1}{\\sigma_2}(X_2-\\mu_2) \\\\ Var(X_1|X_2)=\\sigma_1^2(1-\\rho^2)\\] 反之亦然。 8.10 條件分佈和邊緣分佈的例子 上面的概念過於抽象，用血壓的例子： 收縮期血壓和舒張期血壓各自服從正態分佈。那麼可以用上面的概念來寫出已知舒張期血壓時，收縮期血壓的分佈。 條件期望: \\[E(SBP|DBP)=130+\\frac{0.75\\times15}{10}(DBP-90)\\] 實際如果來了一個病人，他說他只記得自己測的舒張期血壓是95： 他的收縮期血壓的期望值就可以用上面的式子計算： \\[E(SBP|DBP=95)=136\\] 條件方差爲： \\[Var(SBP|DBP)=15^2(1-0.75^2)=98.4\\approx9.92^2&lt;15^2\\] 所以當我們知道了這個人的一部分信息以後，推測他的另一個相關連的變量變得更加準確(方差變小)了。 8.10.1 例題 有 (閒) 人記錄了 \\(1494\\) 名兒童在 \\(2, 4, 6\\) 歲時的腿長度。已知在記錄的這三個年齡時的平均腿長度分別爲 \\(85 cm, 103cm, 114cm\\)。協方差矩陣如下: \\[\\left( \\begin{array}{c} 22.2 &amp; 11.8 &amp; 13.7\\\\ 11.8 &amp; 26.3 &amp; 21.5\\\\ 13.7 &amp; 21.5 &amp; 29.0 \\end{array} \\right)\\] 假定，這三個年齡記錄的這些兒童的腿長度數據（聯合分佈, joint distribution）服從三個變量正態分佈。 求 \\(2\\) 歲時這些兒童的腿長度的邊緣分佈 (marginal distribution) 解 \\[X_{age=2} \\sim N(85, \\sigma_{age=2}^2=22.2)\\] 求他們 \\(6\\) 歲時腿長度的 \\(2\\) 歲時的條件分佈。(Find the distribution of leg length age 6 conditional on leg length at age 2.) 解 \\(6\\) 歲時和 \\(2\\) 歲時腿長的相關係數 (correlation, \\(\\rho_{6,2}\\)) 爲： \\[ \\begin{aligned} \\rho_{6,2} &amp;= \\frac{Cov_{6,2}}{\\sqrt{Var(length_6)}\\sqrt{Var(length_2)}}\\\\ &amp;= \\frac{13.7}{\\sqrt{22.2}\\sqrt{29}}=0.54 \\end{aligned} \\] 條件分佈套用上面提到的公式： \\[ \\begin{aligned} E(length_6 | length_2) &amp;= \\mu_6+\\frac{\\rho_{6,2}\\sigma_6}{\\sigma_2}(length_2-\\mu_2) \\\\ &amp;= 114+\\frac{0.54\\times\\sqrt{29.0}}{\\sqrt{22.2}}(length_2-85)\\\\ Var(length_6 | length_2) &amp;= \\sigma_6^2(1-\\rho_{6,2}^2) \\\\ &amp;= 29.0\\times(1-0.54^2) =20.5 \\end{aligned} \\] "],
["section-9.html", "第 9 章 統計推斷的概念 9.1 人羣與樣本 (population and sample) 9.2 樣本和統計量 (sample and statistic) 9.3 估計 Estimation 9.4 信賴區間 confidence intervals", " 第 9 章 統計推斷的概念 If people do not believe that mathematics is simple, it is only because they do not realize how complicated life is. — John von Neumann 9.1 人羣與樣本 (population and sample) 討論樣本時，需考慮下面幾個問題： 樣本是否具有代表性？ 人羣被準確定義了嗎？ 我們感興趣的“人羣”是否可以是無限大 (多) 的？ 我們研究的樣本，是僅僅用來觀察，亦或是計劃對之進行某種干預呢？ 我們從所有可能的人羣中抽樣了嗎？ 9.2 樣本和統計量 (sample and statistic) 通常我們在進行實驗或觀察時只是獲得了樣本的數據。而希望從樣本數據去推斷 (inference) 總體 (或人羣) 的一些特徵。我們也許只是想用樣本的平均值來估計整體人羣的某個特徵的平均值。不管是何種估計和推斷，都是基於對樣本數據的計算，從樣本中獲得想要推斷總體的統計量 (statistics)。我們用已知樣本去推斷未知總體的過程就叫做估計 (estimate)。這個想要被推斷的總體或人羣的值，被叫做參數 (parameter)，常常使用希臘字母來標記。用來估計總體或人羣的，從樣本數據計算得來的統計量，叫做估計量 (estimator)。 所有的統計量，都有樣本分佈 (sampling distributions，意爲重複無限次取樣後獲得的無限次統計量的分佈)。推斷的過程歸納如下： 從總體或人羣中抽樣 (樣本量 \\(n\\)) 計算這個樣本的合適統計量，從而用於估計它在整體或人羣中的值。 我們還需要決定計算獲得的統計量的樣本分佈 (假定會抽樣無數次) 。 一旦可以精確地確認樣本分佈，我們就可以定量地計算出使用步驟2中獲得的統計量估計總體或人羣的參數時的準確度。 9.3 估計 Estimation 從樣本的均值，推斷總體或人羣的均值是一種估計。我們的目的是，從已知樣本中計算一個儘可能接近那個未知的總體或人羣參數的值。一個估計量有兩個與生俱來的性質 (properties)：1) 偏倚 (bias); 2) 精確度 (precision)。這兩個性質都可以從樣本分佈和估計量獲得。 偏倚： 偏倚簡單說就是樣本分佈的均值，也就是我們從樣本中計算獲得的估計量，和我們想要拿它來估計的總體或人羣的參數之間的差距。(The bias is the difference between the mean of the sampling distribution – the expected or average value of the estimator – and the population parameter being estimated.) 一個小的偏倚，確保了我們從樣本中計算獲得的估計值 (假設我們抽樣無數次，計算無數個樣本估計值) 均勻地分佈在總體或人羣參數的左右兩邊。偏倚本身並不是太大的問題，但是假如樣本量增加，偏倚依然存在 (估計量不一致, inconsistent) ，那常常意味着是抽樣過程出現了問題。例如：用簡單隨機抽樣法獲得的樣本均值，就是總體或人羣均值的無偏估計 (unbiased estimator)。如果抽樣時由於某些主觀客觀的原因導致較小的樣本很少被抽樣 (抽樣過程出了問題，脫離了簡單隨機抽樣原則) ，那麼此時得到的樣本均值就會是一個過高的估計值 (upward biased estimator)。 精確度：估計值的精確度可以通過樣本分佈的方差或標準差來評價 (簡單說是樣本分佈的方差越低，波動越小，精確度越高) 。樣本分佈的標準差被定義爲估計值的標準誤。假如估計量是樣本均值，那麼樣本分佈的標準差 (估計量的標準誤) 和樣本數據之間有如下的關係： \\[true\\; stantdard\\; error\\;of\\;the\\;mean = \\frac{true\\;standard\\;deviation}{\\sqrt{sample\\;size}}\\] 在一些簡單的情況下，通常估計值的選用不言自明 (例如均值，或者百分比) 。但是在複雜的情況下，我們可能可以有多個不同類型的估計量可以選擇，他們也常常各有利弊，需要我們做出取捨。 9.4 信賴區間 confidence intervals 從樣本中計算估計量獲得的一個估計值，只是一個點估計 (point estimate)。對比之下，信賴區間就是一個對這個點估計的精確度的體現。信賴區間越窄，說明我們對於總體或人羣的參數的可能取值的範圍估計越精確。 信賴區間通常是成對成對的出現的，即有上限和下限。這樣的一對從樣本數據中計算得來的統計量，同樣也是有樣本分佈的。每次我們重新從總體或人羣中抽樣，計算獲得的信賴區間都不同，這些信賴區間就組成了信賴區間的樣本分佈。總體和人羣的參數落在這些信賴區間範圍內的概率，就是我們常說的信賴區間的水平 (\\(95\\%\\)) 。 常用的這個概率值就是 \\(95\\%, 90\\%, 99\\%\\)。 當從樣本數據計算獲得的估計量的信賴區間很寬，說明了這個收集來的數據提供了很少的參數信息，導致估計變得很不精確。 看到這裏的都是好漢一條啊！ 我不知道你暈了麼有，反正我是已經暈了。。。 "],
["-estimation-and-precision.html", "第 10 章 估計和精確度 Estimation and Precision 10.1 估計量和他們的樣本分佈 10.2 估計量的特質 10.3 總體方差的估計，自由度 10.4 樣本方差的樣本分佈", " 第 10 章 估計和精確度 Estimation and Precision 10.1 估計量和他們的樣本分佈 例子： 最大呼氣量 (Forced Expoiratory Volume in one second, FEV1) 用於測量一個人的肺功能，它的測量值是連續的。我們從前來門診的人中隨機抽取 \\(n\\) 人作爲樣本，用這個樣本的 FEV1 平均值來估計這個診所的患者的平均肺功能。 模型假設： 在這個例子中，我們的假設有如下：每個隨機抽取的 FEV1 測量值都是從同一個總體 (人羣) 中抽取，每一個觀察值 \\(Y_i\\) 都互相獨立互不影響。我們用縮寫 iid 表示這些隨機抽取的樣本是服從獨立同分佈 (independent and identically distributed)。另外，總體的分佈也假定爲正態分佈，且總體均值爲 \\(\\mu\\)，總體方差爲 \\(\\sigma^2\\)。那麼這個模型可以簡單的被寫成： \\[Y_i \\stackrel{i.i.d}{\\sim} N(\\mu, \\sigma^2), i=1,2,\\dots,n\\] 總體均值 \\(\\mu\\) 的估計量： 顯然算術平均值: \\(\\bar{Y}=\\frac{1}{n}\\sum_{i=1}^ny_i\\) 是我們用於估計總體均值的估計量。 估計量的樣本分佈： \\[\\bar{Y}\\stackrel{i.i.d}{\\sim}N(\\mu, \\frac{\\sigma^2}{n})\\] 證明 \\[ \\begin{aligned} E(\\bar{Y}) &amp;= E(\\frac{1}{n}\\sum Y_i) \\\\ &amp;= \\frac{1}{n}E(\\sum Y_i) \\\\ &amp;= \\frac{1}{n}\\sum E(Y_i) \\\\ &amp;= \\frac{1}{n}n\\mu = \\mu \\\\ Var(\\bar{Y}) &amp;= Var(\\frac{1}{n}\\sum Y_i) \\\\ \\because Y_i \\;\\text{are} &amp;\\; \\text{independent} \\\\ &amp;= \\frac{1}{n^2}\\sum Var(Y_i) \\\\ &amp;= \\frac{1}{n^2} n Var(Y_i) \\\\ &amp;= \\frac{\\sigma^2}{n} \\end{aligned} \\] 證明當 \\(Z=\\frac{\\bar{Y}-\\mu}{\\sqrt{Var(\\bar{Y})}}\\) 時， \\(Z\\sim N(0,1)\\): 由式子可知， \\(Z\\) 只是由一組服從正態分佈的數據 \\(\\bar{Y}\\) 線性轉換 (linear transformation) 而來，所以 \\(Z\\) 本身也服從正態分佈 \\[ \\begin{aligned} E(Z) &amp;= \\frac{1}{\\sqrt{Var(\\bar{Y})}}E[\\bar{Y}-\\mu] \\\\ &amp;= \\frac{1}{\\sqrt{Var(\\bar{Y})}}[\\mu-\\mu] = 0 \\\\ Var(Z) &amp;= \\frac{1}{Var(\\bar{Y})}Var[\\bar{Y}-\\mu] \\\\ &amp;= \\frac{1}{Var(\\bar{Y})}Var(\\bar{Y}) =1 \\\\ \\therefore Z \\;&amp;\\sim N(0,1) \\end{aligned} \\] 均值 \\(\\mu\\) 的信賴區間： 上節說道， 信賴區間通常是成對成對的出現的，即有上限和下限。這樣的一對從樣本數據中計算得來的統計量，同樣也是有樣本分佈的。每次我們重新從總體或人羣中抽樣，計算獲得的信賴區間都不同，這些信賴區間就組成了信賴區間的樣本分佈。總體和人羣的參數落在這些信賴區間範圍內的概率，就是我們常說的信賴區間的水平(\\(95\\%\\)) 。 常用的這個概率值就是 \\(95\\%, 90\\%, 99\\%\\)。 假定我們用 \\(95\\%\\) 作爲信賴區間的水平。那麼下面我們嘗試推導一下信賴區間的計算公式。從長遠來說 (也就是假設我們從總體中抽樣無數次，每次都進行信賴區間的計算，也獲得無數個信賴區間) ，這些信賴區間中有 \\(95\\%\\) 是包含了總體的真實均值 (但是卻是未知) 的，而且這些信賴區間由於是從一個服從正態分佈的數據而來，它們也服從正態分佈 (對真實均值左右對稱) 。所以我們有理由相信，可以找到一個數值 \\(c\\)： \\[Prob(\\bar{Y} &gt; \\mu+c) = 0.025 \\\\ Prob(\\bar{Y} &lt; \\mu-c) = 0.025\\] 因此，我們可以定義 \\(95\\%\\) 信賴區間的上限和下限分別是： \\[L=\\bar{Y}-c \\Rightarrow Prob(L&gt;\\mu)=0.025 \\\\ U=\\bar{Y}+c \\Rightarrow Prob(U&lt;\\mu)=0.025\\] 接下來就是推倒 (故意的) \\(c\\) 的過程啦： \\[ \\begin{aligned} Prob(\\bar{Y}&gt;\\mu+c)=Prob(\\bar{Y}-\\mu&gt;c) \\;&amp;= 0.025 \\\\ \\Rightarrow Prob(\\frac{\\bar{Y}-\\mu}{\\sqrt{Var(\\bar{Y})}} &gt; \\frac{c}{\\sqrt{Var(\\bar{Y})}}) \\;&amp;= 0.025 \\\\ \\Rightarrow Prob(Z&gt;\\frac{c}{\\sqrt{Var(\\bar{Y})}}) \\;&amp;= 0.025 \\\\ we\\;have\\;proved\\; Z\\sim N(0,1) \\\\ we\\;also\\;know\\; Prob(Z&gt;1.96) \\;&amp;= 0.025 \\\\ so\\;let\\; \\frac{c}{\\sqrt{Var(\\bar{Y})}} =1.96 \\\\ \\Rightarrow c=1.96\\sqrt{Var(\\bar{Y})} \\\\ the\\;95\\%\\;confidence\\;interval \\;of\\; &amp;the\\;population\\;mean\\;is\\\\ \\mu = \\bar{Y}\\pm1.96\\sqrt{Var(\\bar{Y})}=\\bar{Y}\\pm &amp; 1.96\\frac{\\sigma}{\\sqrt{n}} \\end{aligned} \\] 其中，\\(\\sqrt{Var(\\bar{Y})}\\) 就是我們熟知的估計量 \\(\\bar{Y}\\) 的標準誤。 10.2 估計量的特質 考慮以下的問題： 什麼因素決定了一個估計量 (estimator) 的好壞，是否實用？ 如果有其他的可選擇估計量，該如何取捨呢？ 當情況複雜的時候，我們該如何尋找合適的估計量？ 10.2.1 偏倚 假設 \\(T\\) 是我們估計總體參數 \\(\\theta\\) 的一個估計量。一般來說我們希望估計量的樣本分佈可以在 “正確的位置” 左右均勻分佈。換句話說我們希望： \\[E(T)=\\theta\\] 如果實現了這個條件，我們說這樣的估計量是無偏的 (unbiased)。然而，天下哪有這等好事，我們叫真實值和估計量之間的差距爲偏倚： \\[bias(T) = E(T)-\\theta\\] 其實偏倚完全等於零並不是最重要，許多常見的估計量都是有偏倚的。重要的是，這個偏倚會隨着樣本量的增加而逐漸趨近於零。所以我們就可以認爲這樣的估計量是漸進無偏的 (asymptotically unbiased)： \\[T\\;is\\;an\\;\\textbf{unbiased}\\;estimator\\;for\\;\\theta\\;if\\;\\\\E(T)=\\theta\\\\ T\\;is\\;an\\;\\textbf{asymptotically unbiased}\\;estimator\\;for\\;\\theta\\;if\\;\\\\lim_{n\\rightarrow\\infty}E(T)=\\theta\\] 10.2.2 估計量的效能 Efficiency 通常，我們希望一個估計量 (estimator) 的偏倚要小，同時，它的樣本分佈也希望能儘可能的不要波動太大。換句話說，我們還希望估計量的方差越小越好。 如果說，兩個估計量有相同的偏倚，均可以選擇來推斷總體，我們說，其中樣本分佈的方差小的那個 (波動幅度小) 的那個估計量是相對更好的。因爲樣本分佈方差越小，說明可以更加精確的估計總體參數。這兩個估計量的方差之比：\\(Var(S)/Var(T)\\) 被叫做這兩個估計量的相對效能 (relative efficiency)。所以我們用估計量去推斷總體時，需要選用效能最高，精確度最好的估計量 (the minimum variance unbiased estimator/an efficient estimator)。 10.2.3 均值和中位數的相對效能 在一個服從 \\(N(\\mu,\\sigma^2)\\) 正態分佈的數據中，中位數和均值是一樣的，也都同時等於總體均值參數 \\(\\mu\\)。而且，樣本均數 \\(\\bar{Y}\\) 和樣本中位數 \\(\\dot{Y}\\) 都是對總體均值的無偏估計量。那麼應該選用中位數還是平均值呢？ 之前證明過當 \\(Y_i \\sim N(\\mu,\\sigma^2)\\) 時， \\(Var(\\bar{Y}=\\sigma^2/n)\\)。然而，當 \\(n\\) 較大的時候，可以證明的是： \\[Var(\\dot{Y})=\\frac{\\pi}{2}\\frac{\\sigma^2}{n}\\approx1.571\\frac{\\sigma^2}{n}\\] 因此，這兩個估計量的相對效能就是： \\[\\frac{Var(\\dot{Y})}{Var(\\bar{Y})}\\approx1.571\\] 所以總體是正態分佈時，平均值就是較中位數更適合用來估計總體的估計量。 10.2.4 均方差 mean square error (MSE) 兩個估計量的偏倚不同時，可以比較他們和總體參數之間的差距，這被叫做均方差, Mean Square Error (MSE)。 \\[MSE(T)=E[(T-\\theta)^2]\\] 這裏用一個數學技巧，將式子中的估計量和總體參數之間的差，分成兩個部分：一是估計量本身的方差 (\\(T-E(T)\\))，一是估計量的偏倚 (\\(E(T)-\\theta\\))。 \\[ \\begin{aligned} MSE(T) &amp;= E[(T-\\theta)^2] \\\\ &amp;= E\\{[T-E(T)+E(T)-\\theta]^2\\} \\\\ &amp;= E\\{[T-E(T)]^2+[E(T)-\\theta]^2 \\\\ &amp; \\;\\;\\;\\;\\; \\;\\;+2[T-E(T)][E(T)-\\theta]\\} \\\\ &amp;= E\\{[T-E(T)]^2\\}+E\\{[E(T)-\\theta]^2\\} + 0\\\\ &amp;= Var(T) + [bias(T)^2] \\end{aligned} \\] 10.3 總體方差的估計，自由度 如果 \\(Y_i \\sim (\\mu, \\sigma^2)\\)，並不需要默認或者假定它服從正態分佈或者任何分佈。那麼它的方差我們會用： \\[V_{\\mu}=\\frac{1}{n}\\sum_{i=1}^n(Y_i-\\mu)^2\\] 證明 \\(V_{\\mu}\\) 是 \\(\\sigma^2\\) 的無偏估計： \\[ \\begin{aligned} V_{\\mu} &amp;= \\frac{1}{n}\\sum_{i=1}^n(Y_i-\\mu)^2 \\\\ we\\;need\\;to\\;prove &amp;E(V_{\\mu}) = \\sigma^2 \\\\ \\Rightarrow E(V_{\\mu}) &amp;= \\frac{1}{n}\\sum_{i=1}^nE(Y_i-\\mu)^2 \\\\ &amp;= \\frac{1}{n}\\sum_{i=1}^nVar(Y_i) \\\\ &amp;= \\frac{1}{n}\\sum_{i=1}^n\\sigma^2 \\\\ &amp;= \\sigma^2 \\end{aligned} \\] 然而通常情況下，我們並不知道總體的均值 \\(\\mu\\)。因此，只好用樣本的均值 \\(\\bar{Y}\\) 來估計 \\(\\mu\\)。所以上面的方程就變成了： \\[V_{\\mu}=\\frac{1}{n}\\sum_{i=1}^n(Y_i-\\bar{Y})^2\\] 你如果仔細觀察認真思考，就會發現，上面這個式子是有問題的。這個大問題就在於，\\(Y_i-\\bar{Y}\\) 中我們忽略掉了樣本均值 \\(\\bar{Y}\\) 和總體均值 \\(\\mu\\) 之間的差 (\\(\\bar{Y}-\\mu\\))。因此上面的計算式來估計總體方差時，很顯然是會低估平均平方差，從而低估了總體方差。 這裏需要引入自由度 (degree of freedom) 在參數估計中的概念。 字面上可以理解爲：自由度是估計過程中使用了多少互相獨立的信息。所以在上面第一個公式中：\\(V_{\\mu}=\\frac{1}{n}\\sum_{i=1}^n(Y_i-\\mu)^2\\)。所有的 \\(n\\) 個觀察值互相獨立，不僅如此，他們還對總體均值獨立。然而在第二個我們用 \\(\\bar{Y}\\) 取代了 \\(\\mu\\) 的公式中，樣本均數則與觀察值不互相獨立。因爲樣本均數必然總是落在觀察值的中間。然而總體均數並不一定就會落在觀察值中間。總體均數，和觀察值之間是自由，獨立的。因此，當我們觀察到 \\(n-1\\) 個觀察值時，剩下的最後一個觀察值，決定了樣本均值的大小。所以說，樣本均值的自由度，是 \\(n-1\\)。 所以，加入了自由度的討論，我們可以相信，用樣本估計總體的方差時，使用下面的公式將會是總體方差的無偏估計： \\[V_{n-1}=\\frac{1}{n-1}\\sum_{i=1}^n(Y_i-\\bar{Y})=\\frac{n}{n-1}V_n\\] 證明 利用上面也用到過的證明方法 – 把樣本和總體均值之間的差分成兩部分： \\[ \\begin{aligned} V_{\\mu} &amp;= \\frac{1}{n}\\sum_{i=1}^n(Y_i-\\mu)^2 \\\\ &amp;= \\frac{1}{n}\\sum_{i=1}^n[(Y_i-\\bar{Y})+(\\bar{Y}-\\mu)]^2 \\\\ &amp;= \\frac{1}{n}\\sum_{i=1}^n[(Y_i-\\bar{Y})^2+(\\bar{Y}-\\mu)^2\\\\ &amp;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+2(Y_i-\\bar{Y})(\\bar{Y}-\\mu)]\\\\ &amp;=\\frac{1}{n}\\sum_{i=1}^n(Y_i-\\bar{Y})^2+\\frac{1}{n}\\sum_{i=1}^n(\\bar{Y}-\\mu)^2\\\\ &amp;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+\\frac{2}{n}(\\bar{Y}-\\mu)\\sum_{i=1}^n(Y_i-\\bar{Y}) \\\\ &amp;= V_n+(\\bar{Y}-\\mu)^2 \\\\ &amp;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(\\text{note that}\\;\\sum_{i=1}^n(Y_i-\\bar{Y})=0) \\\\ \\Rightarrow V_n &amp;= V_{\\mu}-(\\bar{Y}-\\mu)^2 \\\\ \\therefore E(V_n)&amp;= E(V_{\\mu}) - E[(\\bar{Y}-\\mu)^2] \\\\ &amp;= Var(Y)-Var(\\bar{Y}) \\\\ &amp;= \\sigma^2-\\frac{\\sigma^2}{n} \\\\ &amp;= \\sigma^2(\\frac{n-1}{n}) \\end{aligned} \\] 因此，我們看見 \\(V_n\\) 正如上面討論的那樣，是低估了總體方差的。雖然當 \\(n\\rightarrow\\infty\\) 時無限接近 \\(\\sigma^2\\) 但是依然是低估了的。所以，我們可以對之進行修正： \\[ \\begin{aligned} E[\\frac{n}{n-1}V_n] &amp;= \\frac{n}{n-1}E[V_n] =\\sigma^2 \\\\ \\Rightarrow E[V_{n-1}] &amp;= \\sigma^2 \\end{aligned} \\] 10.4 樣本方差的樣本分佈 \\(S^2\\) 常用來標記樣本方差，取代上面我們用到的 \\(V_{n-1}\\)： \\[S^2=\\frac{1}{n-1}\\sum_{i=1}^n(Y_i-\\bar{Y})^2\\] 而且上面也證明了，\\(E(S^2)=\\sigma^2\\) 是總體方差的無偏估計。然而，要注意的是，樣本標準差 \\(\\sqrt{S^2}\\) 卻不是總體標準差 \\(\\sigma\\) 的無偏估計(因爲並不是線性變換，而是開了根號) 。 證明樣本標準差 \\(S\\) 不是總體標準差 \\(\\sigma\\) 的無偏估計 \\[ \\begin{aligned} Var(S) &amp;=E(S^2)-[E(S)]^2 \\\\ \\Rightarrow [E(S)]^2 &amp;=E(S^2)-Var(S) \\\\ \\because E(S^2) &amp;=\\sigma^2 \\\\ \\therefore [E(S)]^2 &amp;=\\sigma^2-Var(S) \\\\ E(S) &amp;=\\sqrt{\\sigma^2-Var(S)} \\\\ \\end{aligned}\\] 可見樣本標準差是低估了總體標準差的。 另外可以被證明的是： \\[\\frac{n-1}{\\sigma^2}S^2\\sim \\mathcal{X}_{n-1}^2\\\\ Var(S^2)=\\frac{2\\sigma^4}{n-1}\\] \\(\\mathcal{X}^2_m\\)： 自由度爲 \\(m\\) 的卡方分佈 (Section 11)。是在圖形上向右歪曲的分佈。當自由度增加時，會越來越接近正態分佈。 "],
["chi-square-distribution.html", "第 11 章 卡方分佈 Chi-square distribution 11.1 卡方分佈的期望和方差的證明 11.2 卡方分佈的期望 11.3 卡方分佈的方差 11.4 把上面的推導擴展", " 第 11 章 卡方分佈 Chi-square distribution 11.1 卡方分佈的期望和方差的證明 當 \\(X\\sim N(0,1)\\) 時， \\(X^2\\sim \\mathcal{X}_1^2\\) 如果 \\(X_1, \\dots, X_n\\stackrel{i.i.d}{\\sim} N(0,1)\\)， 那麼 \\(\\sum_{i=1}^nX_i^2\\sim\\mathcal{X}_n^2\\) 其中： \\(\\mathcal{X}_n^2\\) 表示自由度爲 \\(n\\) 的卡方分佈。 且 \\(X_m^2+X_n^2=\\mathcal{X}_{m+n}^2\\) 11.2 卡方分佈的期望 \\[E(X_1^2)=Var(X)+[E(X)]^2=1+0=1\\] \\[\\Rightarrow E(X_n^2)=n\\] 11.3 卡方分佈的方差 \\[ \\begin{aligned} Var(X_1^2) &amp;= E(X_1^{2^2}) - E(X_1^2)^2 \\\\ &amp;= E(X_1^4)-1 \\end{aligned} \\] 11.3.1 下面來求 \\(E(X_1^4)\\) \\[ \\begin{aligned} \\because E(X_1) &amp;= \\int_{-\\infty}^{+\\infty} xf(x)dx \\\\ \\therefore E(X_1^4) &amp;= \\int_{-\\infty}^{+\\infty} x^4f(x)dx \\end{aligned}\\] 已知： \\(f(x)=\\frac{1}{\\sqrt{2\\pi}}e^{(-\\frac{x^2}{2})}\\) 代入上式： \\[ \\begin{aligned} E(X_1^4) &amp;= \\int_{-\\infty}^{+\\infty} x^4f(x)dx \\\\ &amp;= \\int_{-\\infty}^{+\\infty} x^4\\frac{1}{\\sqrt{2\\pi}}e^{(-\\frac{x^2}{2})}dx\\\\ &amp;=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}x^4e^{(-\\frac{x^2}{2})}dx\\\\ &amp;=\\frac{-1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}x^3(-x)e^{(-\\frac{x^2}{2})}dx \\end{aligned} \\] 令 \\(u=x^3, v=e^{(-\\frac{x^2}{2})},t=-\\frac{x^2}{2}\\) 可以推導： \\[ \\begin{aligned} \\frac{dv}{dx} &amp;= \\frac{dv}{dt}\\frac{dt}{dx} \\\\ &amp;= e^t(-\\frac{1}{2}\\times2x) \\\\ &amp;= (-x)e^{(-\\frac{x^2}{2})} \\\\ \\Rightarrow dv &amp;= (-x)e^{(-\\frac{x^2}{2})}dx \\end{aligned} \\] 再代入上面的式子： \\[ \\begin{aligned} E(X_1^4) &amp;= \\frac{-1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}u\\:dv \\\\ integrate\\; &amp;by\\; parts:\\\\ E(X_1^4) &amp;= \\frac{-1}{\\sqrt{2\\pi}}\\{[u\\:v] \\rvert_{-\\infty}^{+\\infty}-\\int_{-\\infty}^{+\\infty}v\\:du\\} \\\\ &amp;= \\frac{-1}{\\sqrt{2\\pi}}\\{[x^3e^{(-\\frac{x^2}{2})}]\\rvert_{-\\infty}^{+\\infty} -\\int_{-\\infty}^{+\\infty}v\\:du\\} \\\\ &amp;=\\frac{-1}{\\sqrt{2\\pi}}\\{0-0-\\int_{-\\infty}^{+\\infty}e^{(-\\frac{x^2}{2})}dx^3\\} \\\\ &amp;=\\frac{-1}{\\sqrt{2\\pi}}[-3\\int_{-\\infty}^{+\\infty}x^2e^{(-\\frac{x^2}{2})}dx] \\\\ &amp;=\\frac{-3}{\\sqrt{2\\pi}}[\\int_{-\\infty}^{+\\infty}x(-x)e^{(-\\frac{x^2}{2})}dx] \\\\ \\end{aligned} \\] 再來一次分部積分： 令 \\(a=x,b=e^{(-\\frac{x^2}{2})},d\\:b = (-x)e^{(-\\frac{x^2}{2})}dx\\) \\[ \\begin{aligned} E(X_1^4) &amp;= \\frac{-3}{\\sqrt{2\\pi}}\\{[a\\:b] \\rvert_{-\\infty}^{+\\infty} - \\int_{-\\infty}^{+\\infty}b\\:da\\} \\\\ &amp;=\\frac{-3}{\\sqrt{2\\pi}}\\{[xe^{(-\\frac{x^2}{2})}]\\rvert_{-\\infty}^{+\\infty} -\\int_{-\\infty}^{+\\infty}b\\:da\\} \\\\ &amp;=\\frac{-3}{\\sqrt{2\\pi}}\\{0-0-\\int_{-\\infty}^{+\\infty}e^{(-\\frac{x^2}{2})}dx\\} \\\\ &amp;=\\frac{-3}{\\sqrt{2\\pi}}[-\\int_{-\\infty}^{+\\infty}e^{(-\\frac{x^2}{2})}dx] \\\\ &amp;=\\frac{3}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}e^{(-\\frac{x^2}{2})}dx \\end{aligned} \\] 下面令 \\(I=\\int_{-\\infty}^{+\\infty}e^{(-\\frac{x^2}{2})}dx\\\\ \\Rightarrow I^2=\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty}e^{(-\\frac{x^2+y^2}{2})}dxdy\\) 接下來需要用到 座標轉換的知識，將 \\(x,y\\) 表示的笛卡爾座標，轉換爲用角度 \\(\\theta\\) 和半徑 \\(r\\) 表示的形式。之後的證明可以在油管上看到，但是我還是繼續證明下去。 直角座標系 (cartesian coordinators) 和 極座標系 (polar coordinators) 之間轉換的關係如下： \\[ \\begin{aligned} x&amp;=r\\:cos\\theta\\\\ y&amp;=r\\:sin\\theta\\\\ r^2&amp;=x^2+y^2\\\\ \\end{aligned} \\] 座標轉換以後可以繼續求 \\(E(X_1^4)\\)。 在那之前我們先求 \\(I^2\\)。 注意轉換座標系統以後，\\(\\theta\\in[0,2\\pi], r\\in[0,+\\infty]\\) \\[ \\begin{aligned} I^2 &amp;= \\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty}e^{(-\\frac{x^2+y^2}{2})}dxdy \\\\ &amp;= \\int_{0}^{+\\infty}\\int_{0}^{2\\pi}e^{(-\\frac{r^2}{2})}rd\\theta dr \\\\ \\end{aligned} \\] 由於先從中間的 \\(\\int_{0}^{2\\pi}e^{(-\\frac{r^2}{2})}rd\\theta\\) 開始積分，\\(\\theta\\) 以外都可以視爲常數，那麼這個 \\([0,2\\pi]\\) 上的積分就的等於 \\(2\\pi e^{(-\\frac{r^2}{2})}r\\)。 因此上面的式子又變爲： \\[ \\begin{aligned} I^2 &amp;= 2\\pi\\int_{0}^{+\\infty}e^{(-\\frac{r^2}{2})}r\\:dr \\\\ \\because \\frac{d(e^{\\frac{-r^2}{2}})}{dr} &amp;= -e^{(-\\frac{r^2}{2})}r \\\\ \\therefore I^2 &amp;= 2\\pi(-e^{\\frac{-r^2}{2}})\\rvert_0^{+\\infty} \\\\ &amp;= 0-(2\\pi\\times(-1)) \\\\ &amp;= 2\\pi\\\\ \\Rightarrow I &amp;= \\sqrt{2\\pi} \\end{aligned} \\] 所以， \\[ \\begin{aligned} E(X_1^4) &amp;= \\frac{3}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}e^{(-\\frac{x^2}{2})}dx \\\\ &amp;= \\frac{3}{\\sqrt{2\\pi}}\\times I \\\\ &amp;= 3 \\\\ \\Rightarrow Var(X_1^2) &amp;= E(X_1^4) - 1 \\\\ &amp;= 3-1 =2 \\end{aligned} \\] 11.4 把上面的推導擴展 \\[ \\text{Suppose } \\mathcal{X}^2_1, \\cdots \\mathcal{X}^2_k \\stackrel{i.i.d}{\\sim} \\mathcal{X}^2_1 \\\\ \\Rightarrow \\sum_{i=1}^k \\mathcal{X}^2_i \\sim \\mathcal{X}^2_k \\\\ \\Rightarrow \\text{E}(\\sum_{i=1}^n\\mathcal{X}^2_i)=\\sum_{i-1}^n\\text{E}(\\mathcal{X}^2_i)=n\\times1=n\\\\ \\text{Var}(\\sum_{i=1}^n\\mathcal{X}^2_i)=\\sum_{i=1}^n\\text{Var}(\\mathcal{X}^2_i) = n\\times2=2n \\] 結論：\\(X_1, \\dots, X_n\\stackrel{i.i.d}{\\sim} N(0,1)\\) 時，\\(\\sum_{i=1}^nX_i^2\\sim\\mathcal{X}_n^2\\) 服從卡方分佈，其期望 \\(E(X_n^2)=n\\)，方差 \\(Var(X_n^2)=2n\\)。 根據中心極限定理(Section 8) \\[n\\rightarrow \\infty, X_n^2\\sim N(n, 2n)\\] "],
["likelihood-definition.html", "第 12 章 似然 Likelihood 12.1 概率 vs. 推斷 Probability vs. Inference 12.2 似然和極大似然估計 Likelihood and maximum likelihood estimators 12.3 似然方程的一般化定義 12.4 對數似然方程 log-likelihood 12.5 極大似然估計 (maximum likelihood estimator, MLE) 的性質： 12.6 率的似然估計 Likelihood for a rate 12.7 有 \\(n\\) 個獨立觀察時的似然方程和對數似然方程", " 第 12 章 似然 Likelihood 12.1 概率 vs. 推斷 Probability vs. Inference 在概率論的環境下，我們常常被告知的前提是：某某事件發生的概率是多少。例如： 一枚硬幣正面朝上的概率是 \\(0.5\\; Prob(coin\\;landing\\;heads)=0.5\\)。然後在這個前提下，我們又繼續去計算複雜的事件發生的概率(例如，10次投擲硬幣以後4次正面朝上的概率是多少？) 。 \\[ \\binom{10}{4}\\times(0.5^4)\\times(0.5^{10-4}) = 0.205 \\] dbinom(4, 10, 0.5) ## [1] 0.2051 # or you can calculate by hand: factorial(10)*(0.5^10)/(factorial(4)*(factorial(6))) ## [1] 0.2051 在統計推斷的理論中，我們考慮實際的情況，這樣的實際情況就是，我們通過觀察獲得數據，然而我們並不知道某事件發生的概率到底是多少(神如果存在話，只有神知道) 。故這個 \\(Prob(coin\\;landing\\;heads)\\) 的概率大小對於“人類”來說是未知的。我們可能觀察到投擲了10次硬幣，其中有4次是正面朝上的。那麼我們從這一次觀察實驗中，需要計算的是能夠符合觀察結果的“最佳”概率估計 (best estimate)。在這種情況下，似然法 (likelihood) 就是我們進行參數估計的最佳手段。 12.2 似然和極大似然估計 Likelihood and maximum likelihood estimators 此處用二項分佈的例子來理解似然法的概念：假設我們觀察到10個對象中有4個患中二病，我們假定這個患病的概率爲 \\(\\pi\\)。於是我們就有了下面的模型： 模型： 我們假定患病與否是一個服從二項分佈的隨機變量，\\(X\\sim Bin(10,\\pi)\\)。同時也默認每個人之間是否患病是相互獨立的。 數據： 觀察到的數據是，10人中有4人患病。於是 \\(x=4\\)。 現在按照觀察到的數據，參數 \\(\\pi\\) 變成了未知數： \\[Prob(X=4|\\pi)=\\binom{10}{4}\\pi^4(1-\\pi)^{10-4}\\] 此時我們會很自然的考慮，當 \\(\\pi\\) 是未知數的時候，它取值爲多大的時候才能讓這個事件(即：10人中4人患病) 發生的概率最大？ 所以我們可以將不同的數值代入 \\(\\pi\\) 來計算該事件在不同概率的情況下發生的可能性到底是多少： Table 12.1: The probability of observing \\(X=4\\) \\(\\pi\\) 事件 \\(X=4\\) 發生的概率 0.0 0.000 0.2 0.088 0.4 0.251 0.5 0.205 0.6 0.111 0.8 0.006 1.0 0.000 很顯然，如果 \\(\\pi=0.4\\) 時，我們觀察到的事件發生的概率要比 \\(\\pi\\) 取其它值時更大。於是小總結一下目前爲止的步驟如下： 觀察到實驗數據(10人中4個患病) ； 假定這數據服從二項分佈的概率模型，計算不同(\\(\\pi\\) 的取值不同的) 情況下，該事件按照假定模型發生的概率； 通過比較，我們選擇了能夠讓觀察事件發生概率最高的參數取值 (\\(\\pi=0.4\\))。 至此，我們可以知道，似然方程，是一個關於未知參數 \\(\\pi\\) 的函數，我們目前位置做的就是找到這個函數的最大值 (maximised)，和使之成爲最大值時的 \\(\\pi\\) ： \\[L(\\pi|X=4)=\\binom{10}{4}\\pi^4(1-\\pi)^{10-4}\\] 我們可以畫出這個似然方程的形狀， \\(\\pi\\in[0,1]\\) x &lt;- seq(0,1,by=0.001) y &lt;- (factorial(10)/(factorial(4)*(factorial(6))))*(x^4)*((1-x)^6) plot(x, y, type = &quot;l&quot;, ylim = c(0,0.3), ylab = &quot;L(\\U03C0)&quot;, xlab = &quot;\\U03C0&quot;) #title(&quot;Figure 1. Binomial Likelihood&quot;) abline(h=0.251, lty=2) abline(v=0.4, lty=2) 圖 12.1: Binomial Likelihood 從圖形上我們也能確認，\\(\\pi=0.4\\) 時能夠讓這個似然方程取得最大值。 12.3 似然方程的一般化定義 對於一個概率模型，如果其參數爲 \\(\\theta\\)，那麼在給定觀察數據 \\(\\underline{x}\\) 時，該參數的似然方程被定義爲： \\(L(\\theta|\\underline{x})=P(\\underline{x}|\\theta)\\) 注意： \\(P(\\underline{x}|\\theta)\\) 可以是概率(離散分佈) 方程，也可以是概率密度(連續型變量) 方程。對於此方程，\\(\\theta\\) 是給定的，然後再計算某些事件發生的概率。 \\(L(\\theta|\\underline{x})\\) 是一個關於參數 \\(\\theta\\) 的方程，此時，\\(\\underline{x}\\) 是固定不變的(觀察值) 。我們希望通過這個方程求出能夠使觀察到的事件發生概率最大的參數值。 似然方程不是一個概率密度方程。 另一個例子： 有一組觀察數據是離散型隨機變量 \\(X\\)，它符合概率方程 \\(f(x|\\theta)\\)。下表羅列了當 \\(\\theta\\) 分別取值 \\(1,2,3\\) 時的概率方程的值，試求每個觀察值 \\(X = 0,1,2,3,4\\) 的最大似然參數估計： Exercise 12.3 \\(x\\) \\(f(x|1)\\) \\(f(x|2)\\) \\(f(x|3)\\) 0 1/3 1/4 0 1 1/3 1/4 0 2 0 1/4 1/6 3 1/6 1/4 1/2 4 1/6 0 1/3 Exercise 12.3 answer \\(x\\) \\(f(x|1)\\) \\(f(x|2)\\) \\(f(x|3)\\) \\(\\theta\\) 0 1/3 1/4 0 1 1 1/3 1/4 0 1 2 0 1/4 1/6 2 3 1/6 1/4 1/2 3 4 1/6 0 1/3 3 12.4 對數似然方程 log-likelihood 似然方程的最大值，可通過求 \\(L(\\theta|data)\\) 的最大值獲得，也可以通過求該方程的對數方程 \\(\\ell(\\theta|data)\\) 的最大值獲得。傳統上，我們估計最大方程的最大值的時候，會給參數戴一頂“帽子”(因爲這是觀察獲得的數據告訴我們的參數) ： \\(\\hat{\\theta}\\)。並且我們發現對數似然方程比一般的似然方程更加容易微分，因此求似然方程的最大值就變成了求對數似然方程的最大值： \\[\\frac{d\\ell}{d\\theta}=\\ell^\\prime(\\theta)=0\\\\ AND\\\\ \\frac{d^2\\ell}{d\\theta^2}&lt;0\\] 要注意的是，微分不一定總是能幫助我們求得似然方程的最大值。如果說參數本身的定義域是有界限的話，微分就行不通了： x &lt;- seq(0,3,by=0.001) y &lt;- (x-1)^2-5 plot(x, y, type = &quot;l&quot;, ylim = c(-5,0-1), ylab = &quot;L(\\U03B8)&quot;, xlab = &quot;\\U03B8&quot;) #title(&quot;Figure 2. Likelihood function with \\n a limited domain&quot;) abline(v=3, lty=2) 圖 12.2: Likelihood function with a limited domain 證明：當 \\(L(\\theta|data)\\) 取最大值時，該方程的對數方程 \\(\\ell(\\theta|data)\\) 也是最大值： 如果似然方程是連續可導，只有一個最大值，且可以二次求導，假設 \\(\\hat{\\theta}\\) 使該方程取最大值，那麼： \\[\\frac{dL}{d\\theta}=0, \\frac{d^2L}{d\\theta^2}&lt;0 \\Rightarrow \\theta=\\hat{\\theta}\\] 令 \\(\\ell=\\text{log}L\\) 那麼 \\(\\frac{d\\ell}{dL}=\\ell^\\prime=\\frac{1}{L}\\)： \\[\\frac{d\\ell}{d\\theta}=\\frac{d\\ell}{dL}\\cdot\\frac{dL}{d\\theta}=\\frac{1}{L}\\cdot\\frac{dL}{d\\theta}\\] 當 \\(\\ell(\\theta|data)\\) 取最大值時： \\[\\frac{d\\ell}{d\\theta}=0\\Leftrightarrow\\frac{1}{L}\\cdot\\frac{dL}{d\\theta}=0\\\\ \\because \\frac{1}{L}\\neq0 \\\\ \\therefore \\frac{dL}{d\\theta}=0\\\\ \\Leftrightarrow \\theta=\\hat{\\theta}\\] \\[ \\begin{aligned} \\frac{d^2\\ell}{d\\theta^2} &amp;= \\frac{d}{d\\theta}(\\frac{d\\ell}{dL}\\cdot\\frac{dL}{d\\theta})\\\\ &amp;= \\frac{d\\ell}{dL}\\cdot\\frac{d^2L}{d\\theta^2} + \\frac{dL}{d\\theta}\\cdot\\frac{d}{d\\theta}(\\frac{d\\ell}{dL}) \\end{aligned} \\] 當 \\(\\theta=\\hat{\\theta}\\) 時，\\(\\frac{dL}{d\\theta}=0\\) 且 \\(\\frac{d^2L}{d\\theta^2}&lt;0 \\Rightarrow \\frac{d^2\\ell}{d\\theta^2}&lt;0\\) 所以，求獲得 \\(\\ell(\\theta|data)\\) 最大值的 \\(\\theta\\) 即可令 \\(L(\\theta|data)\\) 獲得最大值。 12.5 極大似然估計 (maximum likelihood estimator, MLE) 的性質： 漸進無偏 Asymptotically unbiased: \\(n\\rightarrow \\infty \\Rightarrow E(\\hat{\\Theta}) \\rightarrow \\theta\\) 漸進最高效能 Asymptotically efficient: \\(n\\rightarrow \\infty \\Rightarrow Var(\\hat{\\Theta})\\) 是所有參數中方差最小的估計 漸進正態分佈 Asymptotically normal: \\(n\\rightarrow \\infty \\Rightarrow \\hat{\\Theta} \\sim N(\\theta, Var(\\hat{\\Theta}))\\) 變形後依然保持不變 Transformation invariant: \\(\\hat{\\Theta}\\) 是 \\(\\theta\\) 的MLE時 \\(\\Rightarrow g(\\hat{\\Theta})\\) 是 \\(g(\\theta)\\) 的 MLE 信息足夠充分 Sufficient： \\(\\hat{\\Theta}\\) 包含了觀察數據中所有的能夠用於估計參數的信息 始終不變 consistent: \\(n\\rightarrow\\infty\\Rightarrow\\hat{\\Theta}\\rightarrow\\theta\\) 或者可以寫成：\\(\\varepsilon&gt;0, lim_{n\\rightarrow\\infty}P(|\\hat{\\Theta}-\\theta|&gt;\\varepsilon)=0\\) 12.6 率的似然估計 Likelihood for a rate 如果在一項研究中，參與者有各自不同的追蹤隨訪時間(長度) ，那麼我們應該把事件(疾病) 的發病率用率的形式(多少事件每單位人年, e.g. per person year of observation) 。如果這個發病率的參數用 \\(\\lambda\\) 來表示，所有參與對象的隨訪時間之和爲 \\(p\\) 人年。那麼這段時間內的期望事件(疾病發病) 次數爲：\\(\\mu=\\lambda p\\)。假設事件(疾病發病) 發生是相互獨立的，可以使用泊松分佈來模擬期望事件(疾病發病) 次數 \\(D\\)： \\[D\\sim Poi(\\mu)\\] 假設我們觀察到了 \\(D=d\\) 個事件，我們獲得這個觀察值的概率應該用以下的模型： \\[Prob(D=d)=e^{-\\mu}\\frac{\\mu^d}{d!}=e^{-\\lambda p}\\frac{\\lambda^dp^d}{d!}\\] 因此，\\(\\lambda\\) 的似然方程是： \\[L(\\lambda|observed \\;data)=e^{-\\lambda p}\\frac{\\lambda^dp^d}{d!}\\] 所以，\\(\\lambda\\) 的對數似然方程是： \\[ \\begin{aligned} \\ell(\\lambda|observed\\;data) &amp;= \\text{log}(e^{-\\lambda p}\\frac{\\lambda^dp^d}{d!}) \\\\ &amp;= -\\lambda p+d\\:\\text{log}(\\lambda)+d\\:\\text{log}(p)-\\text{log}(d!) \\\\ \\end{aligned} \\] 解 \\(\\ell^\\prime(\\lambda|data)=0\\): \\[ \\begin{aligned} \\ell^\\prime(\\lambda|data) &amp;= -p+\\frac{d}{\\lambda}=0\\\\ \\Rightarrow \\hat{\\lambda} &amp;= \\frac{d}{p} \\\\ \\end{aligned} \\] 注意： 在對數似然方程中，不包含參數的部分，對與似然方程的形狀不產生任何影響，我們在微分對數似然方程的時候，這部分也都自動消失。所以不包含參數的部分，與我們如何獲得極大似然估計是無關的。因此，我們常常在寫對數似然方程的時候就把其中沒有參數的部分直接忽略了。例如上面泊松分佈的似然方程中，\\(d\\:\\text{log}(p)-\\text{log}(d!)\\) 不包含參數 \\(\\lambda\\) 可以直接不寫出來。 12.7 有 \\(n\\) 個獨立觀察時的似然方程和對數似然方程 當有多個獨立觀察時，總體的似然方程等於各個觀察值的似然方程之乘積。如果 \\(X_1,\\dots,X_n\\stackrel{i.i.d}{\\sim}f(\\cdot|\\theta)\\) \\[L(\\theta|x_1,\\cdots,x_n)=f(x_1,\\cdots,x_n|\\theta)=\\prod_{i=1}^nf(x_i|\\theta)\\\\ \\Rightarrow \\ell(\\theta|x_1,\\cdots,x_n)=\\sum_{i=1}^n\\text{log}(f(x_i|\\theta))\\] "],
["llr.html", "第 13 章 對數似然比 Log-likelihood ratio 13.1 正態分佈數據的極大似然和對數似然比 13.2 \\(n\\) 個獨立正態分佈樣本的對數似然比 13.3 \\(n\\) 個獨立正態分佈樣本的對數似然比的分佈 13.4 似然比信賴區間 13.5 練習題", " 第 13 章 對數似然比 Log-likelihood ratio 對數似然比的想法來自於將對數似然方程圖形的 \\(y\\) 軸重新調節 (rescale) 使之最大值爲零。這可以通過計算該分佈方程的對數似然比 (log-likelihood ratio) 來獲得： \\[llr(\\theta)=\\ell(\\theta|data)-\\ell(\\hat{\\theta}|data)\\] 由於 \\(\\ell(\\theta)\\) 的最大值在 \\(\\hat{\\theta}\\) 時， 所以，\\(llr(\\theta)\\) 就是個當 \\(\\theta=\\hat{\\theta}\\) 時取最大值，且最大值爲零的方程。很容易理解我們叫這個方程爲對數似然比，因爲這個方程就是將似然比 \\(LR(\\theta)=\\frac{L(\\theta)}{L(\\hat{\\theta})}\\) 取對數而已。 之前我們也確證了，不包含我們感興趣的參數的方程部分可以忽略掉。還是用上一節 10人中4人患病的例子： \\[L(\\pi|X=4)=\\binom{10}{4}\\pi^4(1-\\pi)^{10-4}\\\\ \\Rightarrow \\ell(\\pi)=\\text{log}[\\pi^4(1-\\pi)^{10-4}]\\\\ \\Rightarrow llr(\\pi)=\\ell(\\pi)-\\ell(\\hat{\\pi})=\\text{log}\\frac{\\pi^4(1-\\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\\] 其實由上也可以看出 \\(llr(\\theta)\\) 只是將對應的似然方程的 \\(y\\) 軸重新調節了一下而已。形狀是沒有改變的： par(mfrow=c(1,2)) x &lt;- seq(0,1,by=0.001) y &lt;- (x^4)*((1-x)^6)/(0.4^4*0.6^6) z &lt;- log((x^4)*((1-x)^6))-log(0.4^4*0.6^6) plot(x, y, type = &quot;l&quot;, ylim = c(0,1.1),yaxt=&quot;n&quot;, frame.plot = FALSE, ylab = &quot;LR(\\U03C0)&quot;, xlab = &quot;\\U03C0&quot;) axis(2, at=seq(0,1, 0.2), las=2) title(main = &quot;Binomial likelihood ratio&quot;) abline(h=1.0, lty=2) segments(x0=0.4, y0=0, x1=0.4, y1=1, lty = 2) plot(x, z, type = &quot;l&quot;, ylim = c(-10, 1), yaxt=&quot;n&quot;, frame.plot = FALSE, ylab = &quot;llr(\\U03C0)&quot;, xlab = &quot;\\U03C0&quot; ) axis(2, at=seq(-10, 0, 2), las=2) title(main = &quot;Binomial log-likelihood ratio&quot;) abline(h=0, lty=2) segments(x0=0.4, y0=-10, x1=0.4, y1=0, lty = 2) 圖 13.1: Binomial likelihood ratio and log-likelihood ratio 13.1 正態分佈數據的極大似然和對數似然比 假設單個樣本 \\(y\\) 是來自一組服從正態分佈數據的觀察值：\\(Y\\sim N(\\mu, \\tau^2)\\) 那麼有： \\[ \\begin{aligned} f(y|\\mu) &amp;= \\frac{1}{\\sqrt{2\\pi\\tau^2}}e^{(-\\frac{1}{2}(\\frac{y-\\mu}{\\tau})^2)} \\\\ \\Rightarrow L(\\mu|y) &amp;=\\frac{1}{\\sqrt{2\\pi\\tau^2}}e^{(-\\frac{1}{2}(\\frac{y-\\mu}{\\tau})^2)} \\\\ \\Rightarrow \\ell(\\mu)&amp;=\\text{log}(\\frac{1}{\\sqrt{2\\pi\\tau^2}})-\\frac{1}{2}(\\frac{y-\\mu}{\\tau})^2\\\\ omitting&amp;\\;terms\\;not\\;in\\;\\mu \\\\ &amp;= -\\frac{1}{2}(\\frac{y-\\mu}{\\tau})^2 \\\\ \\Rightarrow \\ell^\\prime(\\mu) &amp;= 2\\cdot[-\\frac{1}{2}(\\frac{y-\\mu}{\\tau})\\cdot\\frac{-1}{\\tau}] \\\\ &amp;=\\frac{y-\\mu}{\\tau^2} \\\\ let \\; \\ell^\\prime(\\mu) &amp;= 0 \\\\ \\Rightarrow \\frac{y-\\mu}{\\tau^2} &amp;= 0 \\Rightarrow \\hat{\\mu} = y\\\\ \\because \\ell^{\\prime\\prime}(\\mu) &amp;= \\frac{-1}{\\tau^2} &lt; 0 \\\\ \\therefore \\hat{\\mu} &amp;= y \\Rightarrow \\ell(\\hat{\\mu}=y)_{max}=0 \\\\ llr(\\mu)&amp;=\\ell(\\mu)-\\ell(\\hat{\\mu})=\\ell(\\mu)\\\\ &amp;=-\\frac{1}{2}(\\frac{y-\\mu}{\\tau})^2 \\end{aligned} \\] 13.2 \\(n\\) 個獨立正態分佈樣本的對數似然比 假設一組觀察值來自正態分佈 \\(X_1,\\cdots,X_n\\stackrel{i.i.d}{\\sim}N(\\mu,\\sigma^2)\\)，先假設 \\(\\sigma^2\\) 已知。將觀察數據 \\(x_1,\\cdots, x_n\\) 標記爲 \\(\\underline{x}\\)。 那麼： \\[ \\begin{aligned} L(\\mu|\\underline{x}) &amp;=\\prod_{i=1}^nf(x_i|\\mu)\\\\ \\Rightarrow \\ell(\\mu|\\underline{x}) &amp;=\\sum_{i=1}^n\\text{log}f(x_i|\\mu)\\\\ &amp;=\\sum_{i=1}^n[-\\frac{1}{2}(\\frac{x_i-\\mu}{\\sigma})^2]\\\\ &amp;=-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(x_i-\\mu)^2\\\\ &amp;=-\\frac{1}{2\\sigma^2}[\\sum_{i=1}^n(x_i-\\bar{x})^2+\\sum_{i=1}^n(\\bar{x}-\\mu)^2]\\\\ omitting&amp;\\;terms\\;not\\;in\\;\\mu \\\\ &amp;=-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(\\bar{x}-\\mu)^2\\\\ &amp;=-\\frac{n}{2\\sigma^2}(\\bar{x}-\\mu)^2 \\\\ &amp;=-\\frac{1}{2}(\\frac{\\bar{x}-\\mu}{\\sigma/\\sqrt{n}})^2\\\\ \\because \\ell(\\hat{\\mu}) &amp;= 0 \\\\ \\therefore llr(\\mu) &amp;= \\ell(\\mu)-\\ell(\\hat{\\mu}) = \\ell(\\mu) \\end{aligned} \\] 13.3 \\(n\\) 個獨立正態分佈樣本的對數似然比的分佈 假設我們用 \\(\\mu_0\\) 表示總體均數這一參數的值。要注意的是，每當樣本被重新取樣，似然，對數似然方程，對數似然比都隨着觀察值而變 (即有自己的分佈)。 考慮一個服從正態分佈的單樣本 \\(Y\\): \\(Y\\sim N(\\mu_0,\\tau^2)\\)。那麼它的對數似然比： \\[llr(\\mu_0|Y)=\\ell(\\mu_0)-\\ell(\\hat{\\mu})=-\\frac{1}{2}(\\frac{Y-\\mu_0}{\\tau})^2\\] 根據卡方分佈 (Section 11) 的定義： \\[\\because \\frac{Y-\\mu_0}{\\tau}\\sim N(0,1)\\\\ \\Rightarrow (\\frac{Y-\\mu_0}{\\tau})^2 \\sim \\mathcal{X}_1^2\\\\ \\therefore -2llr(\\mu_0|Y) \\sim \\mathcal{X}_1^2\\] 所以，如果有一組服從正態分佈的觀察值：\\(X_1,\\cdots,X_n\\stackrel{i.i.d}{\\sim}N(\\mu_0,\\sigma^2)\\)，且 \\(\\sigma^2\\) 已知的話： \\[-2llr(\\mu_0|\\bar{X})\\sim \\mathcal{X}_1^2\\] 根據中心極限定理 (Section 8)，可以將上面的結論一般化： Theorem 13.1 如果 \\(X_1,\\cdots,X_n\\stackrel{i.i.d}{\\sim}f(x|\\theta)\\)。 那麼當重複多次從參數爲 \\(\\theta_0\\) 的總體中取樣時，那麼統計量 \\(-2llr(\\theta_0)\\) 會漸進於自由度爲 \\(1\\) 的卡方分佈： \\[-2llr(\\theta_0)=-2\\{\\ell(\\theta_0)-\\ell(\\hat{\\theta})\\}\\xrightarrow[n\\rightarrow\\infty]{}\\;\\sim \\mathcal{X}_1^2\\] 13.4 似然比信賴區間 如果樣本量 \\(n\\) 足夠大 (通常應該大於 \\(30\\))，根據上面的定理： \\[-2llr(\\theta_0)=-2\\{\\ell(\\theta_0)-\\ell(\\hat{\\theta})\\}\\sim \\mathcal{X}_1^2\\] 所以： \\[Prob(-2llr(\\theta_0)\\leqslant \\mathcal{X}_{1,0.95}^2=3.84) = 0.95\\\\ \\Rightarrow Prob(llr(\\theta_0)\\geqslant-3.84/2=-1.92) = 0.95\\] 故似然比的 \\(95\\%\\) 信賴區間就是能夠滿足 \\(llr(\\theta)=-1.92\\) 的兩個 \\(\\theta\\) 值。 13.4.1 以二項分佈數據爲例 繼續用本文開頭的例子： \\[llr(\\pi)=\\ell(\\pi)-\\ell(\\hat{\\pi})=\\text{log}\\frac{\\pi^4(1-\\pi)^{10-4}}{0.4^4(1-0.4)^{10-4}}\\] 如果令 \\(llr(\\pi)=-1.92\\) 在代數上可能較難獲得答案。然而從圖形上，如果我們在 \\(y=-1.92\\) 畫一條橫線，和該似然比方程曲線相交的兩個點就是我們想要求的信賴區間的上限和下限： x &lt;- seq(0,1,by=0.001) z &lt;- log((x^4)*((1-x)^6))-log(0.4^4*0.6^6) plot(x, z, type = &quot;l&quot;, ylim = c(-10, 1), yaxt=&quot;n&quot;, frame.plot = FALSE, ylab = &quot;llr(\\U03C0)&quot;, xlab = &quot;\\U03C0&quot; ) axis(2, at=seq(-10, 0, 2), las=2) abline(h=0, lty=2) abline(h=-1.92, lty=2) segments(x0=0.15, y0=-12, x1=0.15, y1=-1.92, lty = 2) segments(x0=0.7, y0=-12, x1=0.7, y1=-1.92, lty = 2) axis(1, at=c(0.15,0.7)) text(0.9, -1, &quot;-1.92&quot;) arrows(0.8, -1.92, 0.8, 0, lty = 1, length = 0.08) arrows( 0.8, 0, 0.8, -1.92, lty = 1, length = 0.08) 圖 13.2: Log-likelihood ratio for binomial example, with 95% confidence intervals shown 從上圖中可以讀出，\\(95\\%\\) 對數似然比信賴區間就是 \\((0.15, 0.7)\\) 13.4.2 以正態分佈數據爲例 本文前半部分證明過， \\(X_1,\\cdots,X_n\\stackrel{i.i.d}{\\sim}N(\\mu,\\sigma^2)\\)，先假設 \\(\\sigma^2\\) 已知。將觀察數據 \\(x_1,\\cdots, x_n\\) 標記爲 \\(\\underline{x}\\)。 那麼： \\[llr(\\mu|\\underline{x}) = \\ell(\\mu|\\underline{x})-\\ell(\\hat{\\mu}) = \\ell(\\mu|\\underline{x}) \\\\ =-\\frac{1}{2}(\\frac{\\bar{x}-\\mu}{\\sigma/\\sqrt{n}})^2\\] 很顯然，這是一個關於 \\(\\mu\\) 的二次方程，且最大值在 MLE \\(\\hat{\\mu}=\\bar{x}\\) 時取值 \\(0\\)。所以可以通過對數似然比法求出均值的 \\(95\\%\\) 信賴區間公式： \\[-2\\times[-\\frac{1}{2}(\\frac{\\bar{x}-\\mu}{\\sigma/\\sqrt{n}})^2]=3.84\\\\ \\Rightarrow L=\\bar{x}-\\sqrt{3.84}\\frac{\\sigma}{\\sqrt{n}} \\\\ U=\\bar{x}+\\sqrt{3.84}\\frac{\\sigma}{\\sqrt{n}} \\\\ note: \\;\\sqrt{3.84}=1.96\\] 注意到這和我們之前求的正態分佈均值的信賴區間公式 (Section 10.1) 完全一致。 13.5 練習題 13.5.1 Q1 假設十個對象中有三人死亡，用二項分佈模型來模擬這個例子，求這個例子中參數 \\(\\pi\\) 的似然方程和圖形 (likelihood) ? 解 \\[\\begin{aligned} L(\\pi|3) &amp;= \\binom{10}{3}\\pi^3(1-\\pi)^{10-3} \\\\ omitting\\;&amp;terms\\;not\\;in\\;\\pi \\\\ \\Rightarrow \\ell(\\pi|3) &amp;= \\text{log}[\\pi^3(1-\\pi)^7] \\\\ &amp;= 3\\text{log}\\pi+7\\text{log}(1-\\pi)\\\\ \\Rightarrow \\ell^\\prime(\\pi|3)&amp;= \\frac{3}{\\pi}-\\frac{7}{1-\\pi} \\\\ let \\; \\ell^\\prime&amp; =0\\\\ &amp;\\frac{3}{\\pi}-\\frac{7}{1-\\pi} = 0 \\\\ &amp;\\frac{3-10\\pi}{\\pi(1-\\pi)} = 0 \\\\ \\Rightarrow MLE &amp;= \\hat\\pi = 0.3 \\end{aligned}\\] 圖 13.3: Binomial likelihood function 3 out of 10 subjects 計算似然比，並作圖，注意方程圖形未變，\\(y\\) 軸的變化；取對數似然比，並作圖 LR &lt;- L/max(L) ; head(LR) ## [1] 0.0000000 0.0004192 0.0031234 0.0098111 0.0216286 0.0392577 plot(pi, LR, type = &quot;l&quot;, ylim = c(0, 1),yaxt=&quot;n&quot;, col=&quot;darkblue&quot;, frame.plot = FALSE, ylab = &quot;&quot;, xlab = &quot;\\U03C0&quot;) grid(NA, 5, lwd = 1) axis(2, at=seq(0,1,0.2), las=2) title(main = &quot;Binomial likelihood ratio function\\n 3 out of 10 subjects&quot;) 圖 13.4: Binomial likelihood ratio function 3 out of 10 subjects logLR &lt;- log(L/max(L)) plot(pi, logLR, type = &quot;l&quot;, ylim = c(-4, 0),yaxt=&quot;n&quot;, col=&quot;darkblue&quot;, frame.plot = FALSE, ylab = &quot;&quot;, xlab = &quot;\\U03C0&quot;) grid(NA, 5, lwd = 1) axis(2, at=seq(-4,0,1), las=2) #title(main = &quot;Binomial log-likelihood ratio function\\n 3 out of 10 subjects&quot;) abline(h=-1.92, lty=1, col=&quot;red&quot;) axis(4, at=-1.92, las=0) 圖 13.5: Binomial log-likelihood ratio function 3 out of 10 subjects 13.5.2 Q2 與上面用同樣的模型，但是觀察人數變爲 \\(100\\) 人 患病人數爲 \\(30\\) 人，試作對數似然比方程之圖形，與上圖對比： 圖 13.6: Binomial log-likelihood ratio function 3 out of 10 and 30 out of 100 subjects 可以看出，兩組數據的 MLE 都是一致的， \\(\\hat\\pi=0.3\\)，但是對數似然比方程圖形在 樣本量爲 \\(n=100\\) 時比 \\(n=10\\) 時窄很多，由此產生的似然比信賴區間也就窄很多(精確很多) 。所以對數似然比方程的曲率(二階導數) ，反映了觀察獲得數據提供的對總體參數 \\(\\pi\\) 推斷過程中的信息量。而且當樣本量較大時，對數似然比方程也更加接近左右對稱的二次方程曲線。 13.5.3 Q3 在一個實施了160人年的追蹤調查中，觀察到8個死亡案例。使用泊松分佈模型，繪製對數似然比方程圖形，從圖形上目視推測極大似然比的 \\(95\\%\\) 信賴區間。 解 \\[\\begin{aligned} d = 8, \\;p &amp;= 160\\; person\\cdot year \\\\ \\Rightarrow D\\sim Poi(\\mu &amp;=\\lambda p) \\\\ L(\\lambda|data) &amp;= Prob(D=d=8) \\\\ &amp;= e^{-\\mu}\\frac{\\mu^d}{d!} \\\\ &amp;= e^{-\\lambda p}\\frac{\\lambda^d p^d}{d!} \\\\ omitting&amp;\\;terms\\;not\\;in\\;\\lambda \\\\ &amp;= e^{-\\lambda p}\\lambda^d \\\\ \\Rightarrow \\ell(\\lambda|data)&amp;= \\text{log}(e^{-\\lambda p}\\lambda^d) \\\\ &amp;= d\\cdot \\text{log}(\\lambda)-\\lambda p \\\\ &amp; = 8\\times \\text{log}(\\lambda) - 160\\times\\lambda \\end{aligned}\\] 圖 13.7: Poisson log-likelihood ratio function 8 events in 160 person-years lambda LogLR 0.010 -6.4755 0.011 -5.8730 0.012 -5.3369 0.013 -4.8566 0.014 -4.4237 0.015 -4.0318 0.016 -3.6755 0.017 -3.3505 0.018 -3.0532 0.019 -2.7807 0.020 -2.5303 0.021 -2.3000 0.022 -2.0878 0.023 -1.8922 0.024 -1.7118 0.025 -1.5452 0.026 -1.3914 0.027 -1.2495 0.028 -1.1185 0.029 -0.9978 0.030 -0.8866 0.031 -0.7843 0.032 -0.6903 0.033 -0.6041 0.034 -0.5253 0.035 -0.4534 0.036 -0.3880 0.037 -0.3288 0.038 -0.2755 0.039 -0.2277 0.040 -0.1851 0.041 -0.1476 0.042 -0.1148 0.043 -0.0866 0.044 -0.0627 0.045 -0.0429 0.046 -0.0271 0.047 -0.0150 0.048 -0.0066 0.049 -0.0016 0.050 0.0000 0.051 -0.0016 0.052 -0.0062 0.053 -0.0138 0.054 -0.0243 0.055 -0.0375 0.056 -0.0534 0.057 -0.0718 0.058 -0.0926 0.059 -0.1159 0.060 -0.1414 0.061 -0.1692 0.062 -0.1991 0.063 -0.2311 0.064 -0.2651 0.065 -0.3011 0.066 -0.3389 0.067 -0.3786 0.068 -0.4201 0.069 -0.4633 0.070 -0.5082 0.071 -0.5547 0.072 -0.6029 0.073 -0.6525 0.074 -0.7037 0.075 -0.7563 0.076 -0.8103 0.077 -0.8657 0.078 -0.9225 0.079 -0.9806 0.080 -1.0400 0.081 -1.1006 0.082 -1.1624 0.083 -1.2255 0.084 -1.2896 0.085 -1.3550 0.086 -1.4214 0.087 -1.4889 0.088 -1.5575 0.089 -1.6271 0.090 -1.6977 0.091 -1.7693 0.092 -1.8419 0.093 -1.9154 0.094 -1.9898 0.095 -2.0652 0.096 -2.1414 0.097 -2.2185 0.098 -2.2964 0.099 -2.3752 0.100 -2.4548 所以從列表數據結合圖形， 可以找到信賴區間的下限在 0.022~0.023 之間， 上限在 0.093～0.094 之間。 "],
["quadratic-llr.html", "第 14 章 二次方程近似法求對數似然比 approximate log-likelihood ratios 14.1 正態近似法求對數似然 Normal approximation to the log-likelihood 14.2 參數转换 parameter transformations 14.3 練習題", " 第 14 章 二次方程近似法求對數似然比 approximate log-likelihood ratios 爲什麼要用二次方程近似對數似然比方程？ 上節也看到，我們會碰上難以用代數學計算獲得對數似然比信賴區間的情況 (Section 13.4.1: binomial example)。 我們同時知道，對數似然比方程會隨着樣本量增加而越來越漸進於二次方程，且左右對稱。 所以，我們考慮當樣本量足夠大時，用二次方程來近似對數似然比方程從而獲得參數估計的信賴區間。 14.1 正態近似法求對數似然 Normal approximation to the log-likelihood 根據前一節 (Section 13.4.2)，如果樣本均數的分佈符合正態分佈：\\(\\bar{X}\\sim N(\\mu, \\sigma^2/n)\\)。那麼樣本均數的對數似然比爲： \\[llr(\\mu|\\bar{X})=\\ell(\\mu|\\bar{X})=-\\frac{1}{2}(\\frac{\\bar{x}-\\mu}{\\sigma/\\sqrt{n}})^2\\] 其中， \\(\\bar{x}\\) 是正態分佈總體均數 \\(\\mu\\) 的極大似然估計 (maximum likelihood estimator, MLE)。如果已知總體的方差參數，那麼 \\(\\sigma/\\sqrt{n}\\) 是 \\(\\bar{x}\\) 的標準誤 (standard error)。 因此，假設 \\(\\theta\\) 是我們想尋找的總體參數。有些人提議可以使用下面的關於 \\(\\theta\\) 的二次方程來做近似： \\[f(\\theta|data)=-\\frac{1}{2}(\\frac{\\theta-M}{S})^2\\] 上述方程具有一個正態二次對數似然 (比) 的形式，而且該方程的極大似然估計(MLE)， \\(M\\) 的標準誤爲 \\(S\\)。如果我們正確地選用 \\(M\\) 和 \\(S\\)，那我們就可以用這樣的方程來近似求真實觀察數據的似然 \\(\\ell(\\theta|data)\\)。 通過近似正態對數似然比，\\(M\\) 應當選用使方程取最大值時，參數 \\(\\theta\\) 的極大似然估計 \\(M=\\hat{\\Theta}\\)。 但是在選用標準誤 \\(S\\) 上必須滿足下列條件： \\(S\\) 是極大似然估計 \\(\\hat{\\Theta}\\) 的標準誤。 被選擇的 \\(S\\) 必須儘可能的使該二次方程形成一個十分接近真實的對數似然比方程。特別是在最大值的部分必須與之無限接近或者一致。所以二者在 MLE 的位置應當有相同的曲率(二階導數) 。 由於，一個方程的曲率是該方程的二階導數(斜線斜率變化的速度) 。所以對數似然比方程在 MLE 取最大值時的曲率(二階導數) 爲： \\[\\left.\\frac{d^2}{d\\theta^2}\\ell(\\theta)\\right\\vert_{\\theta=\\hat{\\theta}}=\\ell^{\\prime\\prime}(\\hat{\\theta})=-\\frac{1}{S^2}\\\\ \\Rightarrow S^2=\\left.-\\frac{1}{\\ell^{\\prime\\prime}(\\theta)}\\right\\vert_{\\theta=\\hat{\\theta}} \\] 在正態分佈的例子下，\\(M=\\bar{x}, S=\\sigma/\\sqrt{n}\\)。對數似然比方程最大值時的曲率(二階導數) 恰好就爲標準誤的平方的負倒數： \\(\\ell^{\\prime\\prime}(\\theta)=-\\frac{1}{SE^2}\\) \\(\\Rightarrow\\) 被叫做 Fisher information。 稍微總結一下： 任意的對數似然比方程 \\(llr(\\theta)\\) 都可以考慮用一個二次方程來近似： \\[f(\\theta|data)=-\\frac{1}{2}(\\frac{\\theta-M}{S})^2\\] 其中 \\(\\begin{aligned} &amp;M=\\hat\\theta\\\\ &amp;S^2=\\left.-\\frac{1}{\\ell^{\\prime\\prime}(\\theta)}\\right\\vert_{\\theta=\\hat{\\theta}}\\\\ &amp;when \\\\ &amp; n\\rightarrow\\infty \\Rightarrow \\begin{cases} S^2\\rightarrow Var(\\hat\\theta) \\\\ S\\rightarrow SE(\\hat\\theta) \\end{cases} \\end{aligned}\\) 14.1.1 近似法估算對數似然比的信賴區間 一旦我們決定了使用正態近似法來模擬對數似然比方程，對數似然比的信賴區間算法就回到了前一節中我們算過的方法，也就是： \\[-2f(\\theta)&lt;\\mathcal{X}_{1,(1-\\alpha)}^2\\] 故信賴區間爲： \\(m\\pm\\sqrt{\\mathcal{X}_{1,(1-\\alpha)}^2}S\\)。求\\(95\\%\\) 水平的信賴區間時，\\(\\mathcal{X}_{1,0.95}^2=3.84\\)，所以就又看到了熟悉的 \\(M\\pm1.96S\\)。 14.1.2 以泊松分佈爲例 一個被追蹤的樣本，經過了 \\(p\\) 人年的觀察，記錄到了 \\(d\\) 個我們要研究的事件： \\[D\\sim Poi(\\mu), where \\mu=\\lambda p\\] Step 1. 找極大似然估計 (MLE)，之前介紹似然方程時推導過的泊松分佈的似然方程 (Section 12.6)： \\[\\begin{aligned} P(D=d|\\lambda) &amp;= \\frac{e^{-\\mu}\\cdot\\mu^d}{d!} \\\\ &amp;=\\frac{e^{-\\lambda p}\\cdot\\lambda^d p^d}{d!} \\\\ omitting&amp;\\;terms\\;not\\;in\\;\\mu \\\\ &amp;\\Rightarrow \\ell(\\lambda) = d\\text{log}\\lambda - \\lambda p \\\\ &amp;\\Rightarrow \\ell^\\prime(\\lambda) = \\frac{d}{\\lambda} -p \\\\ &amp;\\Rightarrow \\hat\\lambda=\\frac{d}{p} = \\textbf{M} \\end{aligned}\\] Step 2. 求似然方程的二階導數，確認 MLE 是使方程獲得最大值的點，然後確定 \\(S^2\\)： \\[\\begin{aligned} &amp; \\ell^\\prime(\\lambda) = \\frac{d}{\\lambda} -p \\\\ &amp; \\Rightarrow \\ell^{\\prime\\prime}(\\lambda) = -\\frac{d}{\\lambda^2}&lt;0 \\Rightarrow \\textbf{MLE is maximum} \\\\ &amp; S^2 = \\left.-\\frac{1}{\\ell^{\\prime\\prime}(\\lambda)}\\right\\vert_{\\lambda=\\hat{\\lambda}=d/p} = -\\frac{1}{-d/\\hat\\lambda^2} = -\\frac{1}{-d/(d/p)^2} \\\\ &amp;\\Rightarrow S^2 = \\frac{d}{p^2} \\\\ \\end{aligned}\\] Step 3. 把前兩部求得的 \\(MLE\\) 和 \\(S^2\\) 代入近似的二次方程： \\[\\begin{aligned} &amp; \\hat\\lambda=\\frac{d}{p}=M,\\; S^2 = \\frac{d}{p^2} \\\\ &amp; using\\;approximate\\;quadratic\\;llr \\\\ &amp; q(\\lambda) = -\\frac{1}{2}(\\frac{\\lambda-M}{S})^2\\\\ &amp;\\Rightarrow q(\\lambda) = -\\frac{1}{2}(\\frac{\\lambda-\\frac{d}{p}}{\\frac{\\sqrt{d}}{p}})^2\\\\ &amp; let \\; q(\\lambda)=-1.92\\\\ &amp;\\Rightarrow -\\frac{1}{2}(\\frac{\\lambda-\\frac{d}{p}}{\\frac{\\sqrt{d}}{p}})^2=-1.92\\\\ &amp;(\\frac{\\lambda-\\frac{d}{p}}{\\frac{\\sqrt{d}}{p}})^2=3.84\\\\ &amp;\\frac{\\lambda-\\frac{d}{p}}{\\frac{\\sqrt{d}}{p}} = \\pm1.96\\\\ &amp;\\Rightarrow 95\\%CI \\;for \\;\\lambda = \\frac{d}{p}\\pm1.96\\frac{\\sqrt{d}}{p} \\end{aligned}\\] 結論就是： 發病(死亡) 率 \\(\\lambda\\) 的 \\(95\\%\\) 信賴區間爲： \\(M\\pm1.96S\\)。所以我們不需要每次都代入對數似然比方程，只要算出 \\(MLE = M\\) 和 \\(S\\) 之後代入這個公式就可以用二次方程近似法算出信賴區間。 14.1.3 以二項分佈爲例 \\[K\\sim Bin(n,\\pi)\\] Step 1. 找極大似然估計 (MLE)： \\[ \\begin{aligned} &amp; Prob(K=k) = \\pi^k(1-\\pi)\\binom{n}{k}\\\\ &amp;\\Rightarrow L(\\pi|k) = \\pi^k(1-\\pi)\\binom{n}{k}\\\\ &amp;omitting\\;terms\\;not\\;in\\;\\pi \\\\ &amp;\\Rightarrow \\ell(\\pi) = k\\:\\text{log}\\pi+(n-k)\\text{log}(1-\\pi) \\\\ &amp;\\ell^\\prime(\\pi) = \\frac{k}{\\pi}-\\frac{n-k}{1-\\pi} \\\\ &amp; let\\;\\ell^\\prime(\\hat\\pi) =0 \\\\ &amp;\\Rightarrow \\frac{k}{\\hat\\pi}-\\frac{n-k}{1-\\hat\\pi}=0\\\\ &amp;\\Rightarrow \\frac{\\hat\\pi}{1-\\hat\\pi}=\\frac{k}{n-k}\\\\ &amp;\\Rightarrow \\frac{\\hat\\pi}{1-\\hat\\pi}=\\frac{k/n}{1-k/n}\\\\ &amp;\\Rightarrow \\hat\\pi=\\frac{k}{n} = p = \\textbf{M} \\end{aligned} \\] Step 2. 將對數似然方程的二次微分 (二階導數)，確認在 MLE 爲極大值，並確認 \\(S^2\\)： \\[ \\begin{aligned} &amp;\\ell^\\prime(\\pi) = \\frac{k}{\\pi}-\\frac{n-k}{1-\\pi} \\\\ &amp;\\ell^{\\prime\\prime}(\\pi)=\\frac{-k}{\\pi^2}-\\frac{n-k}{(1-\\pi)^2} &lt;0 \\\\ &amp;\\therefore at\\;\\textbf{MLE}\\;\\ell(\\pi)\\;has\\;maximum \\\\ S^2&amp;=\\left.-\\frac{1}{\\ell^{\\prime\\prime}(\\pi)}\\right\\vert_{\\pi=\\hat\\pi=k/n=p}\\\\ &amp;=\\frac{1}{\\frac{k}{\\hat\\pi^2}+\\frac{n-k}{(1-\\hat\\pi)^2}}\\\\ &amp;=\\frac{\\hat\\pi^2(1-\\hat\\pi)^2}{k(1-\\hat\\pi)^2+(n-k)\\hat\\pi^2}\\\\ &amp;=\\frac{P^2(1-P)^2}{np(1-p)^2+(n-np)p^2}\\\\ &amp;=\\frac{p(1-p)}{n(1-p)+np}\\\\ &amp;=\\frac{p(1-p)}{n}\\\\ &amp;\\Rightarrow S=\\sqrt{\\frac{p(1-p)}{n}} \\end{aligned} \\] Step 3. 將求得的 MLE 和 \\(S^2\\) 代入近似信賴區間： \\[ 95\\% CI \\;for \\; \\pi:\\\\ M\\pm1.96S=p\\pm1.96\\sqrt{\\frac{p(1-p)}{n}}\\\\ \\] 14.2 參數转换 parameter transformations 如果將參數 \\(\\theta\\) 通過某種數學方程轉化成 \\(g(\\theta)\\)，那麼我們可以認爲，轉化後的方程的 MLE 爲 \\(g(\\hat\\theta)\\)，其中 \\(\\hat\\theta\\) 是參數 \\(\\theta\\) 的 MLE。 類似地，如果 \\(\\theta_1 \\sim \\theta_2\\) 是參數 \\(\\theta\\) 的似然比信賴區間，那麼 \\(g(\\theta_1)\\sim g(\\theta_2)\\) 就是 \\(g(\\theta)\\) 的似然比信賴區間。 以下爲轉換參數以後獲取信賴區間的步驟： 將參數通過某些數學方程(通常是取對數) 轉化，使新的對數似然比方程更加接近二次方程的對稱圖形。 Transform parameter so that \\(llr\\) is closer to a quadratic shape. 用本節學到的二次方程近似法，求得轉化後的參數的似然比信賴區間。 Use our quadratic approximation on the transformed parameter to calculate our likelihood ratio confidence intervals. 將第2步計算獲得的似然比信賴區間再通過轉化參數時的逆函數轉換回去，以獲得原參數的似然比信賴區間。 Transform the confidence intervals back, or to any scale we wish – they remain valid. 14.2.1 以泊松分佈爲例 當我們用泊松分佈模擬事件在某段時間內發生率 \\(\\lambda\\) 時，注意到這個事件發生率必須滿足 \\(\\lambda&gt;0\\)。當事件發生次數較低時，會讓似然方程的圖形被擠壓在低值附近。如果嘗試用對數轉換 \\(\\lambda \\rightarrow \\text{log}(\\lambda)\\) 此時 \\(\\text{log}(\\lambda)\\) 就不再被限制與 \\(&gt;0\\)。下面我們嘗試尋找對數轉換過後的 \\(M\\) 和 \\(S\\)。 令 \\(\\beta=\\text{log}(\\lambda), \\Rightarrow e^\\beta=\\lambda\\) 從本文上半部分中我們已知 \\(\\hat\\lambda=\\frac{d}{p}\\)。 對數轉換以後的 \\(M\\) 是什麼? 根據定義，\\(MLE(\\beta)=MLE[\\text{log}(\\lambda)]=\\text{log}(\\hat\\lambda)\\) \\(\\Rightarrow M=\\hat\\beta=\\text{log}(\\frac{d}{p})\\) 對數轉換以後的 \\(S\\) 是什麼? 泊松分佈的對數似然方程是：\\(\\ell(\\lambda|d)=d \\text{log}(\\lambda) - \\lambda p\\) 用 \\(\\beta\\) 替換掉 \\(\\lambda\\) \\(\\begin{aligned} &amp; \\ell(\\beta|d)=d \\beta - pe^\\beta\\\\ &amp; \\Rightarrow \\ell^\\prime(\\beta)=d-pe^\\beta \\Rightarrow \\ell^{\\prime\\prime}(\\beta)=-pe^\\beta \\\\ &amp; S^2 = \\left.-\\frac{1}{\\ell^{\\prime\\prime}(\\beta)}\\right\\vert_{\\beta=\\hat{\\beta}} = \\left.\\frac{1}{pe^\\beta}\\right\\vert_{\\beta=\\hat{\\beta}} = \\frac{1}{pe^{\\text{log}(d/p)}}\\\\ &amp;\\Rightarrow S^2=\\frac{1}{d} \\therefore S=\\frac{1}{\\sqrt{d}} \\end{aligned}\\) 轉換後的近似二次方程： \\(\\begin{aligned} &amp; q(\\beta) = -\\frac{1}{2}(\\frac{\\beta-M}{S})^2 = -\\frac{1}{2}(\\frac{\\beta-\\text{log}(\\frac{d}{p})}{\\frac{1}{\\sqrt{d}}})^2 \\end{aligned}\\) \\(\\beta\\) 的 \\(95\\%\\) 信賴區間 \\(=\\text{log}(\\frac{d}{p})\\pm1.96\\frac{1}{\\sqrt{d}}\\) \\(\\lambda\\) 的 \\(95\\%\\) 信賴區間 \\(=exp(\\text{log}(\\frac{d}{p})\\pm1.96\\frac{1}{\\sqrt{d}})\\) 14.2.2 以二項分佈爲例 在研究對象 \\(n\\) 人中觀察到 \\(k\\) 個人患有某種中二疾病。 令 \\(\\beta=\\text{log}(\\pi) \\Rightarrow \\pi=e^\\beta\\) 從上文的推倒也已知 \\(\\hat\\pi=\\frac{k}{n}=p\\) \\(\\begin{aligned} &amp;\\Rightarrow \\ell(\\beta)=k\\text{log}\\pi+(n-k)\\text{log}(1-\\pi)=k\\beta+(n-k)\\text{log}(1-e^\\beta) \\\\ &amp;\\Rightarrow \\ell^{\\prime}(\\beta)=k-\\frac{(n-k)(e^\\beta)}{1-e^\\beta} \\\\ &amp;\\Rightarrow \\ell^{\\prime\\prime}(\\beta)=-(n-k)\\frac{e^\\beta(1-e^\\beta)+e^{2\\beta}}{(1-e^\\beta)^2} \\\\ &amp; \\ell^{\\prime\\prime}(\\beta)= -(n-k)\\frac{e^\\beta}{(1-e^\\beta)^2}\\\\ &amp;\\Rightarrow S^2 = \\left.-\\frac{1}{\\ell^{\\prime\\prime}(\\beta)}\\right\\vert_{\\beta=\\hat{\\beta}} = \\frac{(1-e^{\\hat\\beta})^2}{(n-k)e^{\\hat\\beta}} \\\\ &amp;\\because \\hat\\beta=\\text{log}(\\hat\\pi) \\\\ &amp;\\therefore e^{\\hat\\beta} = \\frac{k}{n}\\\\ &amp;\\Rightarrow S^2=\\frac{(1-\\frac{k}{n})^2}{(n-k)\\frac{k}{n}}=\\frac{n-k}{nk}=\\frac{1}{k}-\\frac{1}{n}\\\\ &amp; \\Rightarrow S=\\sqrt{\\frac{1}{k}-\\frac{1}{n}}\\\\ \\end{aligned}\\) 14.3 練習題 14.3.1 Q1 在\\(n=100\\)人中觀察到有\\(k=40\\)人患病，假設每個人只有患病，不患病兩個狀態，用二項分佈來模擬這個數據，\\(\\pi\\) 爲患病的概率。下面是 \\(\\pi \\in [0.2,0.6]\\) 區間的對數似然比方程曲線。 pi &lt;- seq(0.2, 0.6, by=0.01) L &lt;- (pi^40)*((1-pi)^60) Lmax &lt;- rep(max(L), 41) LR &lt;- L/Lmax logLR &lt;- log(LR) plot(pi, logLR, type = &quot;l&quot;, ylim = c(-11, 0),yaxt=&quot;n&quot;, frame.plot = FALSE, ylab = &quot;logLR(\\U03C0)&quot;, xlab = &quot;\\U03C0&quot;) grid(NA, 5, lwd = 2) # add some horizontal grid on the background axis(2, at=seq(-12,0,2), las=2) 圖 14.1: Binomial log-likelihood ratio between 0.2-0.6 #title(main = &quot;Figure 1. Binomial log-likelihood ratio&quot;) 用一個二次方程來模擬上面的對數似然比曲線：\\(f(\\pi)=-\\frac{(\\pi-M)^2}{2S^2}\\)，其中 \\(M=\\hat\\pi=\\frac{k}{n}=0.4\\)，\\(S^2=\\frac{p(1-p)}{n}=0.0024\\) par(mai = c(1.2, 0.5, 1, 0.7)) quad &lt;- -(pi-0.4)^2/(2*0.0024) plot(pi, quad, type = &quot;l&quot;, ylim = c(-4, 0),yaxt=&quot;n&quot;, col=&quot;red&quot;, frame.plot = FALSE, ylab = &quot;&quot;, xlab = &quot;\\U03C0&quot;) lines(pi, logLR, col=&quot;black&quot;) grid(NA, 4, lwd = 1) # add some horizontal grid on the background axis(2, at=seq(-4,0,1), las=2) #title(main = &quot;Figure 2. Quadratic approximation\\n of binomial log-likelihood ratio \\n 40 out of 100 subjects&quot;) abline(h=-1.92, lty=1, col=&quot;red&quot;) axis(4, at=-1.92, las=2) legend(x=0.27, y= -5.5 ,xpd = TRUE, legend=c(&quot;logLR&quot;,&quot;Quadratic&quot;), bty = &quot;n&quot;, col=c(&quot;black&quot;,&quot;red&quot;), lty=c(1,1), horiz = TRUE) #the legend is below the graph 圖 14.2: Quadratic approximation of binomial log-likelihood ratio 40 out of 100 subjects 14.3.2 Q2 依舊使用二項分佈數據來模擬，觀察不同的事件數量和樣本量對近似計算的影響。 類比上面的問題，用同樣的 \\(\\hat\\pi=0.4\\)，但是 \\(n=10, k=4\\) 時的圖形： par(mai = c(1.2, 0.5, 1, 0.7)) pi &lt;- seq(0.0, 0.85, by=0.01) L &lt;- (pi^4)*((1-pi)^6) logLR &lt;- log(L/max(L)) quad &lt;- -(pi-0.4)^2/(2*0.4*0.6/10) plot(pi, quad, type = &quot;l&quot;, ylim = c(-5, 0),yaxt=&quot;n&quot;, col=&quot;red&quot;, frame.plot = FALSE, ylab = &quot;&quot;, xlab = &quot;\\U03C0&quot;) lines(pi, logLR, col=&quot;black&quot;) grid(NA, 4, lwd = 1) axis(2, at=seq(-5,0,1), las=2) #title(main = &quot;Figure 3. Quadratic approximation\\n of binomial log-likelihood ratio\\n 4 out of 10 subjects&quot;) abline(h=-1.92, lty=1, col=&quot;red&quot;) axis(4, at=-1.92, las=2) legend(x=0.17, y= -6.5 ,xpd = TRUE, legend=c(&quot;logLR&quot;,&quot;Quadratic&quot;), bty = &quot;n&quot;, col=c(&quot;black&quot;,&quot;red&quot;), lty=c(1,1), horiz = TRUE) #the legend is below the graph 圖 14.3: Quadratic approximation of binomial log-likelihood ratio 4 out of 10 subjects \\(\\hat\\pi=0.4, n=1000, k=400\\) 圖 14.4: Quadratic approximation of binomial log-likelihood ratio 400 out of 1000 subjects \\(\\hat\\pi=0.01, n=100, k=1\\) 注意此圖中紅線提示的近似二次曲線，信賴區間的下限已經低於0，是無法接受的近似。 圖 14.5: Quadratic approximation of binomial log-likelihood ratio 1 out of 100 subjects \\(\\hat\\pi=0.01, n=1000, k=10\\) 圖 14.6: Quadratic approximation of binomial log-likelihood ratio 10 out of 1000 subjects \\(\\hat\\pi=0.01, n=10000, k=100\\) 圖 14.7: Quadratic approximation of binomial log-likelihood ratio 100 out of 10000 subjects \\(\\hat\\pi=0.99, n=100, k=99\\) 注意此圖中紅線提示的近似二次曲線，信賴區間的上限已經大於1，和上面的 Figure 5. 一樣也是無法接受的近似。 圖 14.8: Quadratic approximation of binomial log-likelihood ratio 99 out of 100 subjects 總結： 二次方程近似時，在二項分佈的情況下，隨着 \\(n, k\\) 增加，近似越理想。 "],
["-construction-of-a-hypothesis-test.html", "第 15 章 假設檢驗的構建 Construction of a hypothesis test 15.1 什麼是假設檢驗 Hypothesis testing 15.2 錯誤概率和效能方程 error probabilities and the power function 15.3 如何選擇要檢驗的統計量 15.4 複合假設 composite hypotheses 15.5 爲反對零假設 \\(H_0\\) 的證據定量 15.6 雙側替代假設情況下，雙側 \\(p\\) 值的定量方法 15.7 假設檢驗構建之總結 15.8 練習題", " 第 15 章 假設檢驗的構建 Construction of a hypothesis test 15.1 什麼是假設檢驗 Hypothesis testing 一般來說，我們的假設(或者叫假說) 是對與我們實驗觀察數據來自的總體(或人羣) 的概率分佈的描述。在參數檢驗的背景下，就是要檢驗描述這個總體(或人羣) 的概率分佈的參數 (parameters)。最典型的情況是，我們提出兩個互補的假設，一個叫作零假設(或者叫原假設) ，null hypothesis (\\(H_0\\))；另一個是與之對應的(互補的) 替代假設，althernative hypothesis (\\(H_1/H_A\\))。 例如，若 \\(X\\) 是一個服從二項分佈的隨機離散變量 \\(X\\sim Bin(5, \\theta)\\)。可以考慮如下的零假設和替代假設：\\(H_0: \\theta=\\frac{1}{2}; H_1: \\theta=\\frac{2}{3}\\)。 當建立了零假設和替代假設以後，假設檢驗就是要建立如下的規則以確定： 從樣本中計算所得的參數估計值爲多少時，拒絕零假設。(接受替代假設爲“真”) 從樣本中計算所得的參數估計值爲多少時，零假設不被拒絕。(接受零假設爲“真”) 注意：(這一段很繞) 上面的例子是零假設和替代假設均爲簡單假設的情況，實際操作中常常會設計更加複雜的(不對稱的) 假設：即簡單的 \\(H_0\\)，複雜的 \\(H_1\\)。如此一來當零假設 \\(H_0\\) 不被拒絕時，我們並不一定就接受之。因爲無證據證明 \\(H_1\\) 不等於有證據證明 \\(H_0\\)。(Absence of evidence is not evidence of absence). 換句話說，無證據讓我們拒絕 \\(H_0\\) 本身並不成爲支持 \\(H_0\\) 爲“真”的證據。因爲在實際操作中，當我們設定的簡單的零假設沒有被拒絕，可能還存在其他符合樣本數據的零假設；相反地，當樣本數據的計算結果拒絕了零假設，我們只能接受替代假設。所以，反對零假設的證據，同時就是支持替代假設的證據。 在樣本空間 sample space 中，決定了零假設 \\(H_0\\) 會被拒絕的子集 subset，被命名爲拒絕域 rejection region 或者 判別區域 critical region，用 \\(\\mathfrak{R}\\) 來標記。 15.2 錯誤概率和效能方程 error probabilities and the power function 這一部分也可以參考本書臨牀試驗樣本量計算 (Section 33) 部分。 表 15.1 : Definition of Type I and Type II error SAMPLE \\(\\underline{x} \\notin \\mathfrak{R}\\) Accept \\(H_0\\) \\(\\underline{x} \\in \\mathfrak{R}\\) Reject \\(H_0\\) TRUTH \\(H_0\\) is true \\(\\checkmark\\) \\(\\alpha\\) Type I error \\(H_1\\) is true \\(\\beta\\) Type II error \\(\\checkmark\\) 假如一個假設檢驗是關於總體參數 \\(\\theta\\) 的： \\[H_0: \\theta=\\theta_0 \\text{ v.s. } H_1: \\theta=\\theta_1 \\] 這個檢驗的效能被定義爲當替代假設爲“真”時，拒絕零假設的概率(該檢驗方法能夠檢驗出有真實差別的能力) ： \\[\\text{Power}=\\text{Prob}(\\underline{x}\\in\\mathfrak{R}|H_1\\text{ is true}) = 1-\\text{Prob}(\\text{Type II error})\\] 觀察數據只有兩種可能：落在拒絕域內，或者落在拒絕域之外。第二類錯誤我們常常使用 \\(\\beta\\) 來表示，所以 \\(\\text{Power}=1-\\beta\\)。 檢驗的顯著性水平用 \\(\\alpha\\) 來表示。\\(\\alpha\\) 的直觀意義就是，檢驗結果錯誤的拒絕了零假設 \\(H_0\\)，接受了替代假設 \\(H_1\\)，即假陽性的概率。 \\[\\text{Prob}(\\underline{x}\\in \\mathfrak{R} |H_0 \\text{ is true})=\\text{Prob(Type I error)}\\] 15.2.1 以二項分佈爲例 用本文開頭的例子： \\(X\\sim Bin(5,\\theta)\\)。和我們建立的零假設和替代假設：\\(H_0: \\theta=\\frac{1}{2}; H_1: \\theta=\\frac{2}{3}\\)： 考慮兩種檢驗方法： A 方法：當且僅當5次觀察都爲“成功”時才拒絕 \\(H_0 (\\text{i.e.}\\; X=5)\\)。所以此時判別區域 \\(\\mathfrak{R}\\) 爲 \\(5\\)。檢驗效能 \\(\\text{Power}=1-\\beta\\) 爲：\\(Prob(X=5|H_1 \\text{ is true})=(\\frac{2}{3})^5=0.1317\\)。顯著性水平 \\(\\alpha\\) 爲 \\(Prob(X=5|H_0 \\text{ is true})=(\\frac{1}{2})^5=0.03125\\)。 B 方法：當觀察到3,4,5次“成功”時，拒絕 \\(H_0 (\\text{i.e.} X=3,4,5)\\)。此時判別區域 \\(\\mathfrak{R}\\) 爲 \\(3,4,5\\)。檢驗效能 \\(Power\\) 爲：\\(Prob(X=3,4,\\text{ or }5|H_1 \\text{ is ture})=\\sum_{i=3}^5(\\frac{2}{3})^i(\\frac{1}{3})^{5-i}\\approx0.7901\\)；顯著性水平 \\(\\alpha\\) 爲：\\(Prob(X=3,4,5|H_0 \\text{ is true})=\\sum_{i=3}^5(\\frac{1}{2})^i(\\frac{1}{2})^{5-i}=0.5\\) # the power in test B dbinom(3,5,2/3)+dbinom(4,5,2/3)+dbinom(5,5,2/3) ## [1] 0.7901 # the size in test B dbinom(3,5,0.5)+dbinom(4,5,0.5)+dbinom(5,5,0.5) ## [1] 0.5 比較上面兩種檢驗方法，可以看到，用B方法時，我們有更高的概率獲得假陽性結果(犯第一類錯誤，錯誤地拒絕 \\(H_0\\)，接受 \\(H_1\\))，但是也有更高的檢驗效能 \\(1-\\beta\\)(真陽性更高) 。這個例子就說明了，試圖提高檢驗效能的同時，會提高犯第一類錯誤的概率。實際操作中我們常常將第一類錯誤的概率固定，例如 \\(\\alpha=0.05\\)，然後儘可能選擇檢驗效能最高的檢驗方法。 15.3 如何選擇要檢驗的統計量 在上面的二項分佈的實驗中，“成功的次數” 是我們感興趣的要檢驗的統計量。但也可能是第一次出現 “成功” 之前的實驗次數，或者，任何與假設相關的統計量。相似的，如果觀察不是離散變量而是連續的，可以拿來檢驗的指標就有很多，如均值，中位數，衆數，幾何平均值等。 幸運地是，當明確了零假設和替代假設後，我們可以利用 Neyman-Pearson lemma 似然比公式1: 來決定使用哪個統計量做檢驗最有效： \\[\\text{Neyman-Pearson lemma}=\\frac{L_{H_0}}{L_{H_1}}\\] 這公式很直觀，因爲當觀察數據更加支持 \\(H_1\\) 時 (\\(L_{H_1}\\) 更大)，\\(H_0\\) 的可能性相對更小，就更應該被拒絕。而且，由於似然比越小，他的對數就越小，實際計算時我們常使用對數似然比：\\(\\ell_{H_0}-\\ell_{H_1}\\)。 問題來了，那到底要多小才算小？這個進入拒絕域的閾值由兩個指標來決定： 被檢驗統計量的樣本分佈 (the sampling distribution of the test statistic) 第一類錯誤概率 \\(\\alpha\\) (the required value of \\(\\alpha\\)) 15.3.1 以已知方差的正態分佈爲例 假如已知 \\(X_1, \\cdots, X_n \\stackrel{i.i.d}{\\sim} N(\\mu, \\sigma^2)\\) 而且方差 \\(\\sigma^2\\) 也是已知的。如果令 \\(H_0: \\mu=5\\; ;H_1: \\mu=10\\) 可以通過如下的方法找到我們需要的最佳檢驗統計量 best statistic 根據之前的推導 (Section 13) 可知正態分佈的似然方程如下： \\[\\ell(\\mu|\\underline{x}) =-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(x_i-\\mu)^2\\] 所以已知 \\(\\sigma^2\\) 時，我們的零假設和替代假設之間的對數似然比 \\(\\ell_{H_0}-\\ell_{H_1}\\) 爲: \\[\\ell_{H_0}-\\ell_{H_1}=-\\frac{1}{2\\sigma^2}(\\sum_{i=1}^n(x_i-5)^2-\\sum_{i=1}^n(x_i-10)^2)\\] 然而，我們只需要考慮隨着數據變化的部分，所以忽略掉不變的部分2： \\[ \\begin{aligned} \\ell_{H_0}-\\ell_{H_1} &amp; = -(\\sum_{i=1}^n(x_i-5)^2-\\sum_{i=i}^n(x_i-10)^2)\\\\ &amp; = 75n - 2\\times(10-5)\\sum_{i=1}^nx_i \\\\ \\end{aligned} \\] 所以只要樣本和 (sum of sample) \\(\\sum_{i=1}^nx_i\\) (最佳統計量 best statistic) 足夠大，零假設就會被拒絕。而且注意到最佳統計量可以乘以任何常數用作新的最佳統計量。爲了方便我們就用樣本均數 \\(\\frac{1}{n}\\sum_{i=1}^nx_i\\) 作此處的最佳統計量。所以此時，我們的最佳檢驗就是當樣本均值足夠大，超過某個閾值時，我們拒絕零假設。而且，樣本均值的樣本分佈是可以知道的，這樣就便於我們繼續計算下一步：拒絕域 (判別區域) 。 15.4 複合假設 composite hypotheses 目前爲止我們討論的假設檢驗限制太多，實際操作時，我們多考慮類似如下的假設： \\(H_0: \\theta=\\theta_0 \\;\\text{v.s.}\\; H_1: \\theta&gt;\\theta_0\\) [單側的替代假設] \\(H_0: \\theta=\\theta_0 \\;\\text{v.s.}\\; H_1: \\theta\\neq\\theta_0\\) [雙側的替代假設] 所以我們面臨的問題是簡單假設中用於判定的最佳統計量，是始終如一地適用？我們一一來看： 15.4.1 單側替代假設 本章目前爲止的推導中我們發現，樣本均值越大，零假設和替代假設的對數似然比 \\(\\ell_{H_0}-\\ell_{H_1}\\) 越小。所以我們在樣本均值較大時，拒絕零假設，那麼就可以把原來使用的簡單替代假設 \\(H_1: \\mu=10\\) 擴展爲，任意大於 \\(5\\) 的 \\(\\mu\\) ，即 \\(\\mu&gt;5\\) 。因爲大於 \\(5\\) 的任何均值，都提供了更小的對數似然比，都會讓我們拒絕零假設。所以在正態分佈時，單側替代假設的最佳檢驗統計量還是樣本均值。 15.4.2 雙側替代假設 雙側替代假設的情況下，我們無法繼續使用樣本均值作爲最佳統計量。因爲當我們想檢驗：\\(H_0: \\mu=5 \\;\\text{v.s.}\\; H_1: \\mu&lt;5\\) 時，必須獲得足夠小的樣本均值才能讓我們拒絕零假設。此處暫且先按下不表。 15.5 爲反對零假設 \\(H_0\\) 的證據定量 重新再考慮複合假設：\\(H_0: \\theta=\\theta_0\\;\\text{v.s.}\\;H_1: \\theta&gt;\\theta_0\\) 假如存在一個總是可用的最佳檢驗統計量，用 \\(T\\) 來標記 (或 \\(T(x)\\))， 這個統計量足夠大時，我們拒絕 \\(H_0\\)。 別忘了我們還要給事先固定好的顯著性水平 \\(\\alpha\\) 定義與之相關的判別區域： \\[\\text{Prob}(\\underline{x}\\in\\mathfrak{R}|H_0)=\\alpha\\] 如果我們知道 \\(T\\) 的樣本分佈，我們就可以使用一個閾值 \\(c\\) 來定義這個判別區域： \\[Prob(T\\geqslant c|H_0)=\\alpha\\] 更加正式的，我們定義判別區域 \\(\\mathfrak{R}\\) 爲： \\[\\{\\underline{x}:\\text{Prob}(T(x)\\geqslant c|H_0)=\\alpha\\}\\] 換句話說，當統計量 \\(T&gt;c\\) 時，我們拒絕 \\(H_0\\) 。如果先不考慮拒絕或不拒絕的二元判定，我們可以用一個連續型測量值來量化反對零假設 \\(H_0\\) 的證據。再考慮從觀察數據中獲得的 \\(T\\) ，即數據告訴我們的 \\(t\\) 。所以，當 \\(t\\) 值越大，說明觀察值相對零假設 \\(H_0\\) 越往極端的方向走。因此我們可以用 \\(T\\) 的樣本分佈來計算觀察值大大於等於這個閾值(極端值) 時的概率： \\[p=\\text{Prob}(T\\geqslant t|H_0)\\] 這個概率公式被稱爲是單側 \\(p\\) 值 (one-side p-value)。單側 \\(p\\) 值越小，統計量 \\(T\\) 的樣本空間就有越小比例(越強) 的證據支持零假設 \\(H_0\\)。 我們把這以思想用到假設檢驗中時，就可以認爲： \\[p&lt;\\alpha \\Leftrightarrow t&gt;c\\] 所以用我們一貫的設定 \\(\\alpha=0.05\\)，所以如果計算獲得 \\(p&lt;0.05\\) 我們就認爲獲得了足夠強的拒絕零假設 \\(H_0\\) 的證據。 15.5.1 回到正態分佈的均值比較問題上來(單側替代假設) 繼續考慮 \\(X_1,\\cdots,X_n\\stackrel{i.i.d}{\\sim} N(\\mu, \\sigma^2)\\)，假設 \\(\\sigma^2=10\\)，我們要檢驗的是 \\(H_0: \\mu=5 \\;\\text{v.s}.\\; H_1: \\mu&gt;5\\) 確定最佳檢驗統計量：已經證明過，單側替代假設的最佳檢驗統計量是樣本均值 \\(\\bar{x}\\)。 確定該統計量的樣本分佈：已知樣本均數的樣本分佈是 \\(\\bar{X}\\sim N(\\mu,\\sigma^2/n)\\) 。\\(\\Rightarrow Z=\\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1)\\)，所以在 \\(H_0\\) 條件下，\\(\\Rightarrow Z=\\frac{\\bar{X}-5}{\\sqrt{10}/\\sqrt{n}} \\sim N(0,1)\\) 所以當一個檢驗的顯著性水平設定爲 \\(\\alpha=0.05\\) 時，我們用判別區域 \\(\\mathfrak{R}\\)，使統計量據落在該判別區域內的概率爲 \\(0.05\\)： \\(\\text{Prob}(\\bar{X}\\geqslant c|H_0) = 0.05\\) 已知在標準正態分佈時，\\(\\text{Prob}(Z\\geqslant1.64)=0.05=\\text{Prob}(\\frac{\\bar{X}-5}{\\sqrt{10}/\\sqrt{n}}\\geqslant1.64)\\) 假設樣本量是 \\(10\\)，那麼數據的判別區域 \\(\\mathfrak{R}\\) 就是 \\(\\bar{X}\\geqslant6.64\\)。 假設觀察數據告訴我們，\\(\\bar{X}=7.76\\) 。那麼這一組觀察數據計算得到的統計量落在了判別區域內，就提供了足夠的證據拒絕接受 \\(H_0\\)。 我們可以給這個觀察數據計算相應的單側 \\(p\\) 值： \\(p=\\text{Prob}(\\bar{X}\\geqslant7.76|H_0)=\\text{Prob}(Z+5\\geqslant7.76)\\\\=\\text{Prob}(Z\\geqslant2.76)=0.003\\) 所以，觀察數據告訴我們，在 \\(H_0\\) 的前提下，觀察值出現的概率是 \\(0.3\\%\\) 。即，在無數次重複取樣實驗中，僅有 \\(0.3\\%\\) 的結果可以給出支持 \\(H_0\\) 的證據。因此我們拒絕 \\(H_0\\) 接受 \\(H_1\\)。 15.6 雙側替代假設情況下，雙側 \\(p\\) 值的定量方法 圖 15.1: Deliberately use an assymmetrical distribution to highlight the issues 此處故意使用一個左右不對稱的概率密度分佈來解釋。 現在的替代假設是雙側的： \\[H_0: \\theta=\\theta_0 \\;\\text{v.s.}\\; H_1: \\theta\\neq\\theta_0\\] 正常來說，雙側的假設檢驗應該分成兩個單側檢驗。即： \\(H_1: \\theta&gt;\\theta_0\\); \\(H_1: \\theta&lt;\\theta_0\\). 每個單側檢驗都有自己的最佳檢驗統計量。令 \\(T\\) 是 1. 的最佳檢驗統計量，該統計量的樣本分佈如上圖 15.1 所示(左右不對稱) 。假如觀察數據給出的統計量爲 \\(t_{\\text{obs}}\\)，那麼在概率上反對零假設的情況可以有兩種： \\(T\\geqslant t_{\\text{obs}}\\) 其中， \\(\\text{Prob}(T\\geqslant t_{\\text{obs}}|H_0)=\\tilde p\\); \\(T\\leqslant t^\\prime\\) 其中，\\(t^\\prime\\) 滿足： \\(\\text{Prob}(T\\leqslant t^\\prime|H_0) =\\tilde p\\)。(圖15.1) 所以概率密度分佈兩側的距離可以不對稱，但是只要左右兩側概率密度分佈的面積(\\(=\\tilde p\\))相同，那麼就可以直接認爲，雙側 \\(p\\) 值是兩側面積之和 (\\(p=2\\times \\tilde p\\))，且觀察數據提供的統計量落在這兩個面積內的話，都足以提供證據拒絕零假設 \\(H_0\\)。 注意： 被選中的 \\(t^\\prime\\) 值大小不大可能滿足：\\(|t^\\prime - E(T|\\theta_0)|=|t_{obs}-E(T|\\theta_0)|\\)。因爲那只有在完全左右對稱的分佈中才會出現。但是，此處我們關心的是面積左右兩邊的尾部要相等即可，所以我們只需要知道右半邊，較大的那個 \\(t_{obs}\\) 就完全足夠了。 回到上面的均值比較問題 (Section 15.5.1)。現在我們要進行雙側假設檢驗，即： \\(H_0: \\mu=5 \\text{ v.s. } H_1: \\mu\\neq5\\)，最佳統計量依然還是樣本均數 \\(\\bar{X}\\)。數據告訴我們說 \\(\\bar{X}=7.76\\)，因此雙側 \\(p\\) 值就是將已求得的單側 \\(\\tilde p\\) 值乘以 \\(2\\)： \\(\\text{two-sided } p=2\\tilde p= 0.006\\) 當然，實際操作中我們很少進行這樣繁瑣的論證，多數情況下就直接報告雙側 \\(p\\) 值。 15.7 假設檢驗構建之總結 按照如下的步驟一一構建我們的假設檢驗過程： 先建立零假設，和替代假設 (Section 15.1)； 定義最佳檢驗統計量 (用 Neyman-Pearson lemma) (Section 15.3)； 取得零假設條件下，最佳統計量的樣本分佈(通常都較爲困難，有時候我們會傾向於使用“不太理想”，但是計算較爲簡便的過程。) ； 定義拒絕域(判別區域) (常用 \\(\\alpha=0.05\\)) ； 計算觀察數據的檢驗統計量； 如果觀察數據的檢驗統計量落在了提前定義好的拒絕域內，那麼我們的檢驗結論就是：觀察數據拒絕了零假設支持替代假設。然而在實際操作時，如果發現數據的檢驗統計量不在拒絕域內，我們僅僅只能下結論說：觀察數據無法拒絕零假設(而不是接受零假設！) ； 報告計算得到的反對零假設的定量 \\(p\\) 值。 作爲統計學家，我們的任務是評價數據提供的證據，而不是簡單的去接受或者拒絕一個假設。 15.8 練習題 15.8.1 Q1 某種藥物有兩種使用方法：可以口服，也可以注射。兩種方法都被認爲可以使血漿中藥物濃度在24小時候達到相似的平均水平，\\(3 \\mu \\text{g/L}\\)。已知口服該藥物後，濃度的方差爲 \\(1\\)，而如果是注射的話方差只有 \\(1/4\\)。因此設計了一個口服臨牀實驗，觀察到24小時後血漿中藥物濃度數據爲：2.54, 0.93, 2.75, 4.51, 3.71, 1.62, 3.01, 4.13, 2.08, 3.33。假設這組觀察數據獨立同分佈 \\(\\stackrel{i.i.d}{\\sim} N(3, \\sigma^2)\\) 證明以下的假設的最佳檢驗統計量是 \\(\\sum_{i=1}^{10}(x_i-3)^2\\)： \\[H_0: \\sigma^2=1/4 \\text{ v.s. } H_1: \\sigma^2=1\\] 解 根據 Neyman-Pearson lemma (Section 15.3) 來判斷最佳檢驗統計量： 下面用 \\(\\sigma^2_0, \\sigma^2_1\\) 分別標記零假設和替代假設時的方差。 \\[ \\begin{aligned} L(\\sigma^2|\\underline{x},\\mu=3) &amp;= \\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}(-\\frac{1}{2}(\\frac{x_i-3}{\\sigma})^2) \\\\ \\Rightarrow \\ell(\\sigma^2) &amp;=-\\frac{1}{2}\\sum_{i=1}^n\\text{log}\\sigma^2-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(x_i-3)^2 \\\\ &amp;= -\\frac{n}{2}\\text{log}\\sigma^2-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(x_i-3)^2 \\\\ \\Rightarrow \\ell(\\sigma_0^2)-\\ell(\\sigma_1^2)&amp;= \\frac{n}{2}\\text{log}\\sigma_1^2+\\frac{1}{2\\sigma_1^2}\\sum_{i=1}^n(x_i-3)^2\\\\ &amp;\\;\\;\\;\\;\\;\\;-\\frac{n}{2}\\text{log}\\sigma_0^2-\\frac{1}{2\\sigma_0^2}\\sum_{i=1}^n(x_i-3)^2\\\\ &amp;=\\frac{n}{2}(\\text{log}\\sigma_1^2-\\text{log}\\sigma_0^2)+\\frac{1}{2}(\\frac{1}{\\sigma_1^2}-\\frac{1}{\\sigma_0^2})\\sum_{i=1}^n(x_i-3)^2\\\\ &amp;=\\frac{n}{2}\\text{log}\\frac{\\sigma_1^2}{\\sigma_0^2}+\\frac{1}{2}(\\frac{1}{\\sigma_1^2}-\\frac{1}{\\sigma_0^2})\\sum_{i=1}^n(x_i-3)^2 \\end{aligned} \\] 觀察上面的式子就會發現，當實驗重複後唯一會發生變化的就是後面的 \\(\\sum_{i=1}^n(x_i-3)^2\\)。 由於，\\(\\sigma_0^2=1/4, \\; \\sigma_1^2=1\\)，所以 \\((\\frac{1}{\\sigma_1^2}-\\frac{1}{\\sigma_0^2})&lt;0\\)。那麼當 \\(\\sum_{i=1}^n(x_i-3)^2\\) 越大，\\(\\ell(\\sigma_0^2)-\\ell(\\sigma_1^2)\\) 就越小。因此，這就是我們尋找的最佳檢驗統計量。 證明上面的檢驗統計量總是可以作爲最佳檢驗統計量，用於檢驗單側替代假設：\\(H_1: \\sigma^2&gt;1/4\\)。 上面的替代假設中 \\(\\sigma_1^2=1\\)，如果將替代假設改成 \\(\\sigma_1^2&gt;1/4\\)，那麼 \\((\\frac{1}{\\sigma_1^2}-\\frac{1}{\\sigma_0^2})&lt;0\\) 依然成立。所以，\\(\\sum_{i=1}^n(x_i-3)^2\\)，或者這部分乘以任何一個不變的常數依然是替代假設爲 \\(H_1: \\sigma^2&gt;1/4\\) 時的最佳檢驗統計量。 在 \\(H_0\\) 條件下，樣本分佈 \\(\\sum_{i=1}^{10}(x_i-3)^2\\) 是怎樣的分佈？利用這個分佈來定義顯著性水平爲 \\(\\alpha=0.05\\) 時的拒絕域。 在\\(H_0\\) 條件下，有： \\[X_1,\\cdots,X_n\\stackrel{i.i.d}{\\sim}N(3,1/4)\\\\ \\Rightarrow \\frac{X_i-3}{\\sqrt{1/4}}\\sim N(0,1)\\\\ \\Rightarrow (\\frac{X_i-3}{\\sqrt{1/4}})^2 \\sim \\mathcal{X}_1^2\\\\ \\Rightarrow \\sum_{i=1}^{10}(\\frac{X_i-3}{\\sqrt{1/4}})^2 \\sim \\mathcal{X}_{10}^2\\\\ \\Rightarrow 4\\sum_{i=1}^{10}(X_i-3)^2\\sim \\mathcal{X}_{10}^2\\\\ \\text{Let } T=\\sum_{i=1}^{10}(X_i-3)^2\\\\ \\Rightarrow 4T \\sim \\mathcal{X}_{10}^2\\] 拒絕域被定義爲檢驗統計量取大於等於某個臨界值時概率爲 \\(0.05\\)，即 \\(\\text{Prob}(T\\geqslant t)=0.05\\) \\[\\text{Prob}(4T\\geqslant \\mathcal{X}^2_{10,0.95})=0.05\\\\ \\Rightarrow \\text{Prob}(T\\geqslant 1/4\\mathcal{X}^2_{10,0.95})=0.05\\] 所以，此處當顯著性水平定爲 \\(\\alpha=0.05\\) 時，拒絕域就是要大於自由度爲 \\(10\\) 的卡方分佈的 \\(95\\%\\) 分位點。 在 \\(H_0\\) 條件下，該檢驗統計量的正態分佈模擬是怎樣的？ 根據中心極限定理(Section 8) 和 卡方分佈的性質 (Section 11) \\[n\\rightarrow \\infty, X_n^2\\sim N(n, 2n)\\] 所以近似地， \\[\\mathcal{X}_{10}^2\\sim N(\\text{E}(\\mathcal{X}_{10}^2)=10,\\text{Var}(\\mathcal{X}_{10}^2)=20)\\\\ \\Rightarrow 4T\\sim \\text{approx} N(10,20)\\\\ \\Rightarrow \\frac{4T-10}{\\sqrt{20}} \\stackrel{\\cdot}{\\sim} N(0,1)\\] 用上面的正態分佈模擬，和觀察嘗試對單側替代假設作統計檢驗並依據所得結果作出結論：\\[H_0: \\sigma^2=1/4 \\text{ v.s. } H_1: \\sigma^2&gt;1/4\\] 用上面的正態分佈近似法，我們可以計算拒絕域： \\[\\text{Prob}(\\frac{4T-10}{\\sqrt{20}}\\geqslant Z_{0.95})=0.05\\] 已知標準正態分佈的 \\(95\\%\\) 分位點取值 \\(1.64\\)，所以拒絕域： \\[\\frac{4T-10}{\\sqrt{20}}\\geqslant 1.64\\\\ \\Rightarrow T\\geqslant1/4(10+1.64\\sqrt{20})=1/4\\times17.33\\] 由觀察數據可得：\\(T=11.5\\) ，所以觀察數據的檢驗統計量落在了拒絕域內。我們的結論是：觀察數據提供了極強的證據證明在顯著性水平爲 \\(5\\%\\) 時，口服該藥物24小時後的血漿藥物濃度的方差大於 \\(1/4\\)。 區分與之前討論的對數似然比 (Section 13)，之前討論的對數似然比指的是所有的似然和極大似然之間的比，此處的似然比只是純粹在探討兩個假設之間的似然比，與極大似然無關。↩ Rememer that \\(\\ell_{H_0}-\\ell_{H_1}\\) is a random variable: the data varies each time we sample, with consequently varying relative support for the hypotheses, and so we are only interested in that part of \\(\\ell_{H_0}-\\ell_{H_1}\\) which depends on the results, the data, which vary with each sample (i.e. which contains the random part); the constant part provides no information on the relative support the data give to the hypotheses, so we ignore it.↩ "],
["section-16.html", "第 16 章 假設檢驗的近似方法 16.1 近似和精確檢驗 approximate and exact tests 16.2 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test 16.3 練習題 16.4 近似檢驗法之 – Wald 檢驗 16.5 近似檢驗法之 – Score 检验 16.6 LRT, Wald, Score 檢驗三者的比較 16.7 練習題", " 第 16 章 假設檢驗的近似方法 本章教你怎麼徒手搞似然比檢驗 (likelihood ratio test)，Wald 檢驗 (Wald test)，和 Score 檢驗 (Score test)。 16.1 近似和精確檢驗 approximate and exact tests 前一章描述了如何用對數似然比尋找最佳檢驗統計量 (Section 15.3)。一旦找到並確定了最佳檢驗統計量，接下去還需要確定這個最佳檢驗統計量的樣本分佈，用定好的顯著性水平(\\(\\alpha=0.05\\))確定拒絕域，再使用觀察數據計算數據本身的統計量，然後對反對零假設的證據定量(計算 \\(p\\) 值) 。前一章用的例子均來自於正態分佈，所以我們都能夠不太複雜地獲得樣本均值，樣本方差等較容易取得樣本分佈的檢驗統計量。正如我們在前一章最後部分 (Section 15.7) 總結的那樣，大多數情況下我們沒有那麼幸運。最佳檢驗統計量的樣本分佈會很難確定。所以另一個進行假設檢驗的途徑就是近似檢驗法 (approximate tests)。 16.2 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test 記得我們之前說到，簡單假設 \\(H_0: \\theta=\\theta_0\\text{ v.s. } H_1: \\theta=\\theta_1\\) 的檢驗的最佳檢驗統計量可以使用 Neyman-Pearson lemma (尼曼皮爾森輔助定理) (Section 15.3) 來確定： \\[\\ell_{H_0}-\\ell_{H_1} = \\ell(\\theta_0)-\\ell(\\theta_1)\\] 如果假設變成了複合型假設：\\(H_0: \\theta\\in\\omega_0 \\text{ v.s. } H_1: \\theta\\in\\omega_1\\)。此時，\\(\\omega_0, \\omega_1\\) 分別指兩種假設條件下我們關心的總體參數的可能取值範圍。那麼可以把上面的定理擴展成，在 \\(\\omega_0, \\omega_1\\) 兩個取值範圍內，零假設和對立假設在給出的觀察數據條件下的極大似然之比： \\[\\text{log}\\frac{\\text{max}_{H_0}[L(\\theta|data)]}{\\text{max}_{H_1}[L(\\theta|data)]}=\\text{max}_{H_0}[\\ell(\\theta|data)]-\\text{max}_{H_1}[\\ell(\\theta|data)]\\\\ =\\text{max}_{\\theta\\in\\omega_0}[\\ell(\\theta|data)]-\\text{max}_{\\theta\\in\\omega_1}[\\ell(\\theta|data)]\\] 典型的假設檢驗情況下，我們面對的是簡單的零假設和複合型的替代假設： \\[H_0: \\theta=\\theta_0 \\text{ v.s. } H_1: \\theta\\neq\\theta_0\\] 所以在這個情況下，套用擴展以後的 Neyman-Pearson lemma： \\[\\text{max}_{H_0}[\\ell(\\theta)]-\\text{max}_{H_1}[\\ell(\\theta)]=\\ell(\\theta_0) - \\ell(\\hat\\theta)=llr(\\theta_0)\\] 之前討論對數似然比 (Section 13.3) 時我們已知： \\[\\text{Under }H_0: \\theta=\\theta_0\\Rightarrow -2llr(\\theta_0)\\stackrel{\\cdot}{\\sim}\\mathcal{X}_1^2\\] 於是利用自由度爲 \\(1\\) 的卡方檢驗的特徵我們就可以爲反對零假設的證據定量，計算關鍵的拒絕域。如果說顯著性水平爲 \\(\\alpha\\) 那麼，我們拒絕零假設 \\(H_0:\\theta=\\theta_0\\) 的拒絕域是： \\[-2llr(\\theta_0)&gt;\\mathcal{X}^2_{1,1-\\alpha}\\] 當使用 \\(\\alpha=0.05\\) 時，這個關鍵的拒絕域就是：\\(-2llr(\\theta_0)&gt;3.84\\)。 這就是傳說中的 (對數) 似然比檢驗，(log-)Likelihood ratio test (LRT)。 LRT 的優點： 簡單； \\(p\\) 值不會被參數尺度 (parameter scale) 左右，也就是說如果我們對參數進行了數學轉換 (Section 14.2) 也不會影響似然比檢驗計算得到的 \\(p\\) 值大小。 LRT 的缺點： 非正態分佈的數據時，LRT 只能算是漸進有效 (asymptotic valid)，即樣本量要足夠大時結果才能令人滿意； 無法總是保證這是最佳檢驗統計量； 需要計算兩次對數似然 (MLE 和 零假設時)。 16.3 練習題 假設有在觀察對象 \\(n=100\\) 人中發生了 \\(k=40\\) 個事件。假定數據服從二項分佈，已知人羣中每個人發生該事件的概率爲 \\(\\pi_0=0.5\\)。嘗試計算似然比檢驗統計量：\\(-2llr(\\pi_0)\\)，並進行顯著性水平爲 \\(\\alpha=0.05\\) 的假設檢驗：\\(H_0: \\pi=\\pi_0 \\text{ v.s. }H_1: \\pi\\neq\\pi_0\\) 解 \\[ \\begin{aligned} &amp;\\because f(k=40|\\pi) = \\binom{100}{40}\\pi^{40}(1-\\pi)^{100-40} \\\\ &amp;\\text{Ignoring terms} \\text{ not with } \\pi \\\\ &amp;\\therefore \\ell(\\pi|k=40) = 40\\text{log}\\pi+60\\text{log}(1-\\pi) \\\\ &amp;\\Rightarrow \\ell^\\prime(\\pi|k=40) = \\frac{40}{\\pi}-\\frac{60}{1-\\pi} \\\\ &amp;\\text{Let } \\ell^\\prime(\\pi|k=40) = 0 \\\\ &amp;\\Rightarrow \\frac{40}{\\pi}-\\frac{60}{1-\\pi} =0 \\\\ &amp;\\Rightarrow \\text{ MLE } \\hat\\pi=0.4 \\\\ &amp;\\Rightarrow llr(\\pi_0)=\\ell(\\pi_0)-\\ell(\\hat\\pi) \\\\ &amp;\\;\\;\\;\\;\\;\\;\\;\\;\\;=40\\text{log}0.5+60\\text{log}(1-0.5)-40\\text{log}0.4-60\\text{log}(1-0.4)\\\\ &amp;\\;\\;\\;\\;\\;\\;\\;\\;\\;=-2.013\\\\ &amp;\\Rightarrow -2llr=4.026 &gt; \\text{Pr}(\\mathcal{X}^2_{1,0.95})=3.84 \\end{aligned} \\] 所以當顯著性水平爲 \\(\\alpha=0.05\\) 時，數據提供了足夠拒絕零假設的證據。該事件在此人羣中發生的概率要低於人羣的 \\(0.5\\)。 16.4 近似檢驗法之 – Wald 檢驗 和 LRT 一樣， Wald 檢驗也適用於檢驗 \\(H_0: \\theta=\\theta_0 \\text{ v.s. } H_1: \\theta\\neq\\theta_0\\)。但是本方法其實是使用對數似然比方程的近似二次方程 (Section 14)。相比之下，LRT 使用的是精確的對數似然比，只對檢驗統計量 \\(-2llr\\) 進行了自由度爲 \\(1\\) 的卡方分佈 \\(\\mathcal{X}_1^2\\) 近似。本節介紹的 Wald 檢驗過程中使用了兩次近似，一次是計算對數似然比時使用了二次方程，一次則是和 LRT 一樣對檢驗統計量進行 \\(\\mathcal{X}_1^2\\) 近似。 根據之前的對數似然比近似結論 (Section 14.1) ： \\[llr(\\theta)\\approx-\\frac{1}{2}(\\frac{M-\\theta}{S})^2\\text{ asymptotically}\\] 其中，\\(M\\) 是 \\(\\text{MLE }\\hat\\theta\\)，\\(S=\\sqrt{\\left.-\\frac{1}{\\ell^{\\prime\\prime}(\\theta)}\\right\\vert_{\\theta=\\hat{\\theta}}}\\) 而且前一節我們也看到， \\[ \\text{Under }H_0: \\theta=\\theta_0\\Rightarrow -2llr(\\theta_0) \\stackrel{\\cdot}{\\sim}\\mathcal{X}_1^2\\\\ \\Rightarrow -2\\times-\\frac{1}{2}(\\frac{M-\\theta_0}{S})^2 \\stackrel{\\cdot}{\\sim}\\mathcal{X}_1^2 \\\\ \\Rightarrow (\\frac{M-\\theta_0}{S}) \\stackrel{\\cdot}{\\sim} N(0,1)\\\\ \\text{Let } W=(\\frac{M-\\theta_0}{S}) \\] \\(W\\) 就是我們在 Wald 檢驗中用到的檢驗統計量。接下來就可以計算給定顯著水平 \\(\\alpha\\) 時的拒絕域，給 \\(p\\) 值定量： 當 \\(W&gt;N(0,1)_{1-\\alpha/2}\\) 或 \\(W&lt;N(0,1)_{\\alpha/2}\\)時，拒絕 \\(H_0: \\theta=\\theta_0\\)； 或者，當 \\(W^2&gt;\\mathcal{X}^2_{1,1-\\alpha}\\) 時，拒絕 \\(H_0: \\theta=\\theta_0\\)。 這就是我們心心念念的 Wald 檢驗。 圖 16.1: Likelihood ratio and Wald tests: solid (green) line is log-likelihood ratio, dashed (red) is quadratic approximation 上圖 16.1 解釋了 LRT 和 Wald 檢驗的不同之處。紅色虛線是二次方程，用於近似似然比方程(綠色實線) 。二者在 \\(\\text{MLE}=\\hat\\theta\\) 時同時取極大值。Wald 檢驗的是，數據提供的 \\(\\hat\\theta\\) 和我們想要比較的零假設 \\(\\theta_0\\) 之間的橫軸差距。在檢驗量 \\(W\\) 中我們還把這個差除以觀察數據均值的標準差(數據的標準誤) 。 如果數據本身波動大，\\(W\\) 的分母(標準誤) 較大，那麼即使 \\(\\hat\\theta - \\theta_0\\) 保持不變，統計量變小，反對零假設的證據也就越小。反觀，LRT 檢驗的檢驗統計量就是上圖 16.1 顯示的縱軸差 \\(\\ell(\\theta_0)-\\ell(\\hat\\theta)\\) 的大小。二者之間的關係被直觀的顯示在圖中。 Wald 檢驗優點： 比 LRT 略簡單； 不必再計算零假設時的對數似然，只需要 \\(MLE\\) 和它的標準誤。 Wald 檢驗缺點： 兩次近似(LRT只用了一次近似) ； 無法總是保證這是最佳檢驗統計量； 參數如果被數學轉換 (Section 14.2)，\\(p\\) 值會跟着變化。 16.4.1 再以二項分佈爲例 在 \\(n\\) 個實驗對象中觀察到 \\(k\\) 個事件，使用參數爲 \\(\\pi\\) 的二項分佈模型來模擬。使用 Wald 檢驗法對下列假設做出統計檢驗： \\(H_0: \\pi=\\pi_0 \\text{ v.s. } H1: \\pi\\neq\\pi_0\\)。將參數 logit 轉換 (log-odds) 之後，對轉換後的新參數再做一次 Wald 檢驗。 解 根據之前的二次方程近似法推導 (Section 14.1.3)： \\[ \\begin{aligned} &amp; M=\\text{MLE}=\\hat\\pi=\\frac{k}{n}=p\\\\ &amp; S=se(\\hat\\pi)=\\sqrt{\\frac{p(1-p)}{n}}\\\\ &amp; \\Rightarrow \\text{Under } H_0: \\pi=\\pi_0\\\\ &amp; W=(\\frac{p-\\pi_0}{\\sqrt{\\frac{p(1-p)}{n}}})\\stackrel{\\cdot}{\\sim} N(0,1) \\end{aligned} \\] 根據參數數學轉換的性質 (Section 14.2) \\[ \\begin{aligned} &amp;\\text{New parameter } \\beta=g(\\pi)=\\text{logit}(\\pi)=\\text{log}\\frac{\\pi}{1-\\pi}\\\\ &amp; \\text{MLE}=\\text{logit}(\\hat\\pi)=\\text{log}\\frac{\\hat\\pi}{1-\\hat\\pi} \\\\ &amp; \\text{Here we need to use delta-method to approximate standard error of } g(\\pi)\\\\ &amp; S=se[g(\\hat\\pi)]\\approx g^\\prime(\\pi)\\times se(\\hat\\pi) \\\\ &amp; = \\frac{1}{\\hat\\pi(1-\\hat\\pi)}\\sqrt{\\frac{p(1-p)}{n}}\\\\ &amp; =\\sqrt{\\frac{1}{k}+\\frac{1}{n-k}} \\\\ &amp; \\text{So the Wald test becomes}\\\\ &amp; H_0: \\beta=\\beta_0\\\\ &amp; \\Rightarrow W=\\frac{\\text{log}(\\frac{\\hat\\pi}{1-\\hat\\pi})-\\text{log}(\\frac{\\pi_0}{1-\\pi_0})}{\\sqrt{\\frac{1}{k}+\\frac{1}{n-k}}}\\stackrel{\\cdot}{\\sim} N(0,1) \\end{aligned} \\] 可見對參數進行了數學轉換之後，檢驗統計量的計算式發生了變化。因此 \\(p\\) 值也會不同。 16.5 近似檢驗法之 – Score 检验 注意到 Wald 檢驗使用的近似二次方程是在 MLE， 也就是極大似然比時的點 \\(\\hat\\theta\\) 和對數似然比方程取相同的值和相同曲率 (二次導數)。 可以類比的是，Score 检验是基于另一種二次方程模擬，Score 檢驗的近似二次方程和對數似然比方程在零假設 (\\(\\theta_0\\)) 時取相同的曲率。所以，Score 檢驗使用的近似方程在 \\(\\theta_0\\) 時和對數似然比方程在相同位置時的傾斜度 (一階導數)，和曲率 (坡度的變化程度，二階導數) 相同。所以令 \\(U\\) 爲對數似然比方程在 \\(\\theta_0\\) 時的坡度，定義 \\(V\\) 是對數似然比方程在 \\(\\theta_0\\) 時的曲率的負數： \\[ \\begin{aligned} &amp; U=\\ell^\\prime(\\theta)|_{\\theta=\\theta_0}=\\ell^\\prime(\\theta_0)\\\\ &amp; V=-E[\\ell^{\\prime\\prime}(\\theta)]|_{\\theta=\\theta_0}=-E[\\ell^{\\prime\\prime}(\\theta_0)] \\end{aligned} \\] 注：此處的 \\(V=-E[l^{\\prime\\prime}(\\theta_0)]\\) 又常常被叫做 Expected Fisher information。 記得在 Wald 檢驗中使用的近似方程： \\[llr(\\theta)\\approx-\\frac{1}{2}(\\frac{M-\\theta}{S})^2\\text{ asymptotically}\\] 令 \\(q(\\theta)=-\\frac{1}{2}(\\frac{M-\\theta}{S})^2\\) 就有： \\[ \\begin{aligned} &amp; q^\\prime(\\theta) =\\frac{M-\\theta}{S^2}\\\\ &amp; \\Rightarrow q^\\prime(\\theta_0) =\\frac{M-\\theta_0}{S^2}\\\\ &amp; q^{\\prime\\prime}(\\theta) =-\\frac{1}{S^2}\\\\ &amp; \\Rightarrow q^{\\prime\\prime}(\\theta_0)=E[l^{\\prime\\prime}(\\theta_0)]\\\\ &amp; \\Rightarrow \\frac{1}{S^2} =-E[l^{\\prime\\prime}(\\theta_0)]\\\\ &amp; q^\\prime(\\theta_0) = \\frac{M-\\theta_0}{S^2} = -E[l^{\\prime\\prime}(\\theta_0)](M-\\theta_0)\\\\ &amp; = \\ell^\\prime(\\theta_0)\\\\ &amp; \\Rightarrow M-\\theta_0 = -\\frac{\\ell^\\prime(\\theta_0)}{E[l^{\\prime\\prime}(\\theta_0)]}\\\\ &amp; \\Rightarrow M = -\\frac{\\ell^\\prime(\\theta_0)}{E[l^{\\prime\\prime}(\\theta_0)]}+\\theta_0\\\\ &amp; q(\\theta)=-\\frac{1}{2}(\\frac{M-\\theta}{S})^2=\\frac{E[l^{\\prime\\prime}(\\theta_0)]}{2}(-\\frac{\\ell^\\prime(\\theta_0)}{E[l^{\\prime\\prime}(\\theta_0)]}+\\theta_0-\\theta)^2\\\\ &amp; q(\\theta)=-\\frac{V}{2}(\\frac{U}{V}+\\theta_0-\\theta)^2\\\\ &amp; \\Rightarrow \\text{ Under } H_0: \\theta=\\theta_0\\\\ &amp; \\Rightarrow q(\\theta_0)=-\\frac{V}{2}(\\frac{U}{V})^2=-\\frac{U^2}{2V}\\\\ &amp; \\Rightarrow -2q(\\theta_0)=\\frac{U^2}{V} \\stackrel{\\cdot}{\\sim}\\mathcal{X}_1^2\\\\ &amp; \\text{Or equivalently} \\frac{U}{\\sqrt{V}} \\stackrel{\\cdot}{\\sim} N(0,1) \\end{aligned} \\] 這就是 Score 檢驗時使用的檢驗統計量。相應的拒絕域就可以被定義爲： 當 \\(\\frac{U^2}{V}&gt;\\mathcal{X}_{1,1-\\alpha}^2\\) 時，拒絕 \\(H_0\\) 如下面的示意圖 16.2 所示，Score 檢驗，比較的是 \\(\\theta_0\\) 時的校正後似然方程的坡度 (一階導數/二階導數)，和極大似然時的坡度 (一階導數=0) 的差別。如果這個值越大，說明零假設時的似然和極大似然 (觀察數據的信息) 的距離越遠，拒絕零假設的證據就越有力。 圖 16.2: Score test: solid (green) line is log-likelihood ratio, dashed (red) is quadratic approximation Score 檢驗優點： 比 LRT 簡單； 不需要計算 MLE，只需要計算零假設時的對數似然比方程之坡度和曲率； 在流行病學用到的檢驗方法中最常用，也最容易擴展 (Mantel-Haenszel test, log rank test, generalised linear models such as logistic, Poisson, Cox regressions)。 Score 檢驗缺點： 和 Wald 檢驗一樣用到了兩次近似； 無法總是保證這是最佳檢驗統計量； 參數如果被數學轉換 (Section 14.2)，\\(p\\) 值會跟着變化。 16.5.1 再再以二項分佈爲例 \\(K\\sim Bin(n, \\pi)\\) 假如已知人羣中事件發生的概率是 \\(\\pi_0\\)。試推導此時的 Score 檢驗的檢驗統計量。 解 對二項分佈數據進行 Score 檢驗的時候我們需要計算 \\(U, V\\)，然後計算統計量 \\(\\frac{U^2}{V}\\) 和 \\(\\mathcal{X}_1^2\\) 比較即可。 \\[ \\begin{aligned} &amp; \\text{Let } p=\\frac{k}{n} \\\\ &amp; \\ell(\\pi|k) = k\\text{log}(\\pi)+(n-k)\\text{log}(1-\\pi)\\\\ &amp; \\ell^\\prime(\\pi)=\\frac{k}{\\pi}-\\frac{n-k}{1-\\pi}=\\frac{k-n\\pi}{\\pi(1-\\pi)}\\\\ &amp; = \\frac{p-\\pi}{\\pi(1-\\pi)/n}\\\\ &amp; \\Rightarrow U = \\ell^\\prime(\\pi_0)=\\frac{p-\\pi_0}{\\pi_0(1-\\pi_0)/n}\\\\ &amp; \\ell^{\\prime\\prime}(\\pi|K)=-\\frac{K}{\\pi^2}-\\frac{n-K}{(1-\\pi)^2}\\\\ &amp; \\Rightarrow -\\ell^{\\prime\\prime}(\\pi|K)=\\frac{K}{\\pi^2}+\\frac{n-K}{(1-\\pi)^2}\\\\ &amp; \\because E(K)=n\\pi\\\\ &amp; \\therefore -E[\\ell^{\\prime\\prime}(\\pi|K)]=\\frac{n\\pi}{\\pi^2}+\\frac{n-n\\pi}{(1-\\pi)^2}\\\\ &amp; =\\frac{n}{\\pi}+\\frac{n}{1-\\pi}=\\frac{n}{\\pi(1-\\pi)}\\\\ &amp; \\text{ Under } H_0: \\pi=\\pi_0 \\Rightarrow V=-E[\\ell^{\\prime\\prime}(\\pi_0)]=\\frac{n}{\\pi_0(1-\\pi_0)}\\\\ &amp; \\Rightarrow \\frac{U^2}{V}=\\frac{(p-\\pi_0)^2}{\\pi_0(1-\\pi_0)/n} \\stackrel{\\cdot}{\\sim}\\mathcal{X}_1^2\\\\ &amp; \\text{OR } \\frac{U}{\\sqrt{V}} = \\frac{p-\\pi_0}{\\sqrt{\\pi_0(1-\\pi_0)/n}} \\stackrel{\\cdot}{\\sim} N(0,1) \\end{aligned} \\] 16.6 LRT, Wald, Score 檢驗三者的比較 LRT 比較的是對數似然方程在零假設 \\(H_0\\) 和極大似然估計 (MLE) 時之間的縱軸差 (圖 16.1)；Wald 檢驗試圖直接比較 MLE 和 \\(H_0\\) 的橫軸差 (二次方程近似法，並用標準誤校正) (圖 16.1)；Score 檢驗比較的是對數似然方程在 \\(H_0\\) 時的切線斜率 (二次方程近似法，用曲率也就是二階導數校正) (圖 16.2)。三種檢驗比較的東西各不相同，但是這種差距大到進入拒絕域時，數據就會拒絕零假設。其中 Score 檢驗的計算過程最爲簡便，只需要計算 \\(H_0\\) 時對數似然方程的一階和二階導數，而不用去計算 MLE，因此更多的被應用在流行病學數據計算中。 如果對數似然方程本身就是左右對稱的 (正態分佈的情況下)，這三個檢驗方法計算的所有結果都是完全一致的。如果對數似然方程只是近似左右對稱，那麼三者的計算結果會十分接近。可以說，三種檢驗方法是漸進等價的。 如果對觀測值進行了數學轉換，三者中只有 LRT 的計算結果保持不變。如果對參數的數學轉換使得對數似然方程更加接近左右對稱的二次方程，那麼 Wald 和 Score 檢驗的計算結果可以得到改善。 如果說，MLE 和 零假設之間的差距很大，那麼 Wald 或者 Score 檢驗所使用的二次方程近似法的誤差會增加，此時傾向於使用 LRT 來進行精確檢驗。當然如果當樣本量較大，要檢驗的差距也很大，三種檢驗方案都能夠提供證據拒絕零假設 (\\(p\\) 值都會很小)。 如果三種檢驗方案給出的計算結果迥異，即使使用了數學轉換結果也沒有明顯改善的話，那麼最大的問題是樣本量太小。這時候還是老老實實用 LRT 吧。 幾乎所有的參數檢驗都歸類與這章節介紹的三種檢驗方法。比如說 \\(Z\\) 檢驗， \\(t\\) 檢驗， \\(F\\) 檢驗都是 LRT。在流行病學研究中最常用的還是 Score 檢驗。 我們的結論是，當條件允許的情況下，統計檢驗都推薦儘量使用精確檢驗 LRT。 16.7 練習題 16.7.1 Q1 在對數似然比章節 (Section 13.2)，我們曾經證明過，已知方差時： \\[ \\begin{aligned} &amp; llr(\\mu|\\underline{x})=\\ell(\\mu|\\underline{x})=-\\frac{1}{2}(\\frac{\\bar{x}-\\mu}{\\sigma/\\sqrt{n}})^2\\\\ &amp; \\Rightarrow -2llr(\\mu|\\underline{x})=-2\\ell(\\mu|\\underline{x})=(\\frac{\\bar{x}-\\mu}{\\sigma/\\sqrt{n}})^2 \\end{aligned} \\] 當觀察數據 \\(X_1,\\cdots,X_n\\sim N(\\mu,1^2)\\) ，求 LRT, Wald, Score 三種檢驗方法對下列假設進行檢驗時的檢驗統計量： \\(H_0: \\mu=\\mu_0 \\text{ v.s. } H_1: \\mu\\neq\\mu_0\\) 解 \\[ \\begin{aligned} &amp; \\text{Model: } X_1, \\cdots, X_n \\stackrel{i.i.d}{\\sim} N(\\mu, 1)\\\\ &amp; H_0: \\mu=\\mu_0 \\text{ v.s. } H_1: \\mu\\neq\\mu_0\\\\ &amp; \\text{Model } \\Rightarrow \\bar{X} \\sim N(\\mu, \\frac{1}{n}) \\\\ &amp; \\text{If we observe } \\bar{X} = \\bar{x}\\\\ &amp; \\ell(\\mu|\\bar{x})=-\\frac{1}{2}(\\frac{\\bar{x}-\\mu}{1/\\sqrt{n}})^2\\\\ &amp; \\textbf{For LRT, under } H_0: \\mu=\\mu_0 \\Rightarrow -2llr(\\mu_0) \\stackrel{\\cdot}{\\sim}\\mathcal{X}_1^2\\\\ &amp; \\Rightarrow \\frac{\\bar{x}-\\mu}{1/\\sqrt{n}} \\sim N(0,1)\\\\ &amp; \\textbf{For Wald test, under } H_0: \\mu=\\mu_0 \\Rightarrow \\frac{M-\\mu_0}{S}\\sim N(0,1) \\\\ &amp; \\Rightarrow \\frac{\\bar{x}-\\mu}{1/\\sqrt{n}} \\sim N(0,1)\\\\ &amp; \\textbf{For Score test, under } H_0: \\mu=\\mu_0 \\Rightarrow U=\\ell^\\prime(\\mu_0), V=-E[\\ell^{\\prime\\prime}(\\mu_0)]\\\\ &amp; U=\\ell^\\prime(\\mu_0)=(\\frac{\\bar{x}-\\mu_0}{1/\\sqrt{n}})\\sqrt{n}=\\frac{\\bar{x}-\\mu_0}{1/n}\\\\ &amp; \\ell^{\\prime\\prime}(\\mu_0)=-\\frac{1}{1/n}=-n \\Rightarrow V=-E[n]=n\\\\ &amp; \\frac{U^2}{V}=(\\frac{\\bar{x}-\\mu_0}{1/n})^2/n=(\\frac{\\bar{x}-\\mu_0}{1/\\sqrt{n}})^2\\\\ &amp; \\Rightarrow \\frac{U^2}{V} \\sim \\mathcal{X}_1^2 \\Rightarrow \\frac{U}{\\sqrt{V}}=\\frac{\\bar{x}-\\mu_0}{1/\\sqrt{n}} \\sim N(0,1) \\end{aligned} \\] 本題證明了，當數據服從正態分佈時，三種檢驗方法使用的檢驗統計量，是完全一致的。 16.7.2 Q2 根據醫生的觀察，某種癌症患者的生存時間服從平均值爲 \\(1/\\beta_0\\) 的指數分佈 (exponentially distributed)。有一種新藥物可以改善平均生存時間 (仍然服從指數分佈)。已知指數分佈的密度方程是：\\(f(x|\\beta)=\\beta \\text{exp} (-\\beta x), \\text{ where } \\beta, x&gt;0\\)。 證明指數分佈的均值是 \\(1/\\beta\\) 解 \\[ \\begin{aligned} &amp; X\\sim f(x|\\beta), x&gt;0 \\Rightarrow E(X)=\\int_0^\\infty x\\cdot f(x)\\text{d} x = \\int_0^\\infty x\\cdot \\beta \\cdot e^{-\\beta x} \\text{d}x\\\\ &amp; E(x)= - \\int_0^\\infty x\\cdot \\frac{\\text{d}e^{-\\beta x}}{\\text{d}x} \\cdot \\text{d}x\\\\ &amp; \\text{We can now integrate by parts, using } \\int_a^b u \\frac{\\text{d}v}{\\text{d}x} \\text{d}x = [uv]_a^b-\\int_a^b v \\frac{\\text{d}u}{\\text{d}x} \\text{d}x \\\\ &amp; E(X) = -[x\\cdot e^{-\\beta x}]_0^\\infty + \\int_0^\\infty e^{-\\beta x} \\text{d} x \\\\ &amp; \\;\\;\\;\\; = -0+\\int_0^\\infty e^{-\\beta x} \\text{d} x\\\\ &amp; \\;\\;\\;\\; = \\int_0^\\infty\\frac{\\text{d}}{\\text{d}x} \\frac{e^{-\\beta x}}{-\\beta} \\text{d} x\\\\ &amp; \\;\\;\\;\\; = [\\frac{e^{-\\beta x}}{-\\beta}]_0^\\infty = \\frac{1}{-\\beta}[0-1]=\\frac{1}{\\beta} \\end{aligned} \\] 請寫下本題設定條件下的數學模型，零假設和替代假設 解： 假設患者人數爲 \\(n\\)，他們的生存時間爲相互獨立的隨機變量： \\(X_1,\\cdots,X_n\\)。那麼本例中的數學模型爲：\\(\\text{Model: } X_1,\\cdots,X_n\\stackrel{i.i.d}{\\sim}f(x|\\beta)=\\beta e^{-\\beta x}\\)。我們可以提出如下的零假設和替代假設：\\(H_0: \\beta=\\beta_0 \\text{ v.s. } H_1: \\beta\\neq\\beta_0\\)。 推導此模型參數 \\(\\beta\\) 的極大似然估計 (MLE)，試使用似然比檢驗法來推導進行假設檢驗時使用的檢驗統計量。 解 \\[ \\begin{aligned} &amp; L(\\beta|\\underline{x}) = \\prod_{i=1}^n f(x_i|\\beta)=\\prod_{i=1}^n\\beta e^{-\\beta x_i} \\\\ &amp; \\ell(\\beta)=\\sum_{i=1}^n\\text{log}(\\beta e^{-\\beta x_i})=\\sum\\text{log}\\beta-\\sum\\beta x_i=n\\text{log}\\beta-\\beta\\sum x_i \\\\ &amp; \\;\\;\\;\\; = n\\text{log}\\beta-\\beta n \\bar{x} \\\\ &amp; \\Rightarrow \\ell^\\prime(\\beta)=\\frac{n}{\\beta}-n\\bar{x}\\text{ MLE solves } \\ell^\\prime(\\beta)=0 \\text{ when }\\ell^{\\prime\\prime}(\\beta) &lt; 0 \\\\ &amp; \\ell^\\prime(\\beta)=0 \\Rightarrow \\hat\\beta=\\frac{1}{\\bar{x}}, \\text{ and } \\ell^{\\prime\\prime}(\\beta)=-n\\frac{1}{\\beta^2} &lt; 0\\\\ &amp; \\Rightarrow \\text{ LRT test statistic: Under } H_0: \\beta=\\beta_0 \\Rightarrow -2llr(\\beta_0) \\sim \\mathcal{X}_1^2\\\\ &amp; llr(\\beta_0)=\\ell(\\beta_0)-\\ell(\\hat\\beta)=n\\text{log}\\beta_0-\\beta_0n\\bar{x}-n\\text{log}\\hat\\beta+\\hat\\beta n \\bar{x}\\\\ &amp; \\text{ Substituting with MLE } \\hat\\beta=\\frac{1}{\\bar{x}}\\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\;\\;\\; = n\\text{log}\\beta_0-\\beta_0n\\bar{x}+n\\text{log}\\bar{x}+ n\\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\;\\;\\; = n(\\text{log}\\beta_0\\bar{x}-\\beta_0\\bar{x}+1) \\textbf{ this is the statistic for LRT} \\end{aligned} \\] 推導 Score 和 Wald 檢驗法時的檢驗統計量 解 \\[ \\begin{aligned} &amp; \\textbf{Score test: under } H_0 \\Rightarrow \\frac{U^2}{V}\\sim \\mathcal{X}_1^2 \\text{ where } U=\\ell^\\prime(\\beta_0), V=-E[\\ell^{\\prime\\prime}(\\beta_0)]\\\\ &amp; \\Rightarrow U=\\frac{n}{\\beta_0}-n\\bar{x}; V = -E[-n\\frac{1}{\\beta_0^2}] = n\\frac{1}{\\beta_0^2} \\\\ &amp; \\Rightarrow \\frac{U^2}{V}=(\\frac{n}{\\beta_0}-n\\bar{x})^2\\cdot\\frac{\\beta_0^2}{n} = (\\frac{(\\frac{n}{\\beta_0}-n\\bar{x})\\beta_0}{\\sqrt{n}})^2\\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\;\\; = n(1-\\bar{x}\\beta_0)^2\\\\ &amp; \\textbf{This is the statistic for Score test}\\\\ &amp; \\textbf{Wald test: under } H_0: \\beta=\\beta_0 \\Rightarrow W=(\\frac{M-\\beta_0}{S})^2 \\sim \\mathcal{X}_1^2, \\\\ &amp; \\text{ where } M=\\hat\\beta=\\frac{1}{\\bar{x}}, \\text{ and } S^2=-\\frac{1}{\\ell^{\\prime\\prime}(\\hat\\beta)}\\\\ &amp; \\ell^{\\prime\\prime}(\\beta)=-n\\frac{1}{\\beta^2}\\Rightarrow \\ell^{\\prime\\prime}(\\hat\\beta)=-n\\bar{x}^2\\Rightarrow S^2=\\frac{1}{n\\bar{x}^2}\\\\ &amp; \\Rightarrow W=(\\frac{M-\\beta_0}{S})^2=\\frac{(\\frac{1}{\\bar{x}}-\\beta_0)^2}{\\frac{1}{n\\bar{x}^2}}=n(1-\\beta_0\\bar{x})^2\\\\ &amp; \\textbf{This is the statistic for Wald test} \\end{aligned} \\] 注意到在這個特例中， Score 和 Wald 檢驗的統計量竟然不謀而合。 觀察5名患者，獲得診斷後的生存數據 (年)： \\(0.5,1,1.25,1.5,0.75\\)。用上面推導的統計量對這個數據進行假設檢驗：\\(H_0: \\beta=0.5 \\text{ v.s. } \\beta\\neq0.5\\)，你如何下結論？ 解 \\[ \\begin{aligned} &amp;\\text{Data: } x_1,\\cdots,x_n=0.5,1,1.25,1.5,0.75. \\Rightarrow \\bar{x}=1\\\\ &amp;H_0: \\beta=0.5 \\text{ v.s. } \\beta\\neq0.5\\\\ &amp;\\textbf{LRT test: } \\\\ &amp; llr(\\beta_0) = n(\\text{log}\\beta_0\\bar{x}-\\beta_0\\bar{x}+1) = 5\\times(\\text{log}0.5-0.5\\times1+1) = -0.966\\\\ &amp;\\Rightarrow -2llr=1.93 &lt; \\text{Prob}(\\mathcal{X}^2_{1,0.95}) = 3.84 \\\\ &amp; \\text{There is no evidence that } \\beta\\neq0.5.\\\\ &amp;\\textbf{Score test: } \\\\ &amp; \\frac{U^2}{V} = n(1-\\bar{x}\\beta_0)^2 = 5\\times(1-1\\times0.5)^2=1.25 &lt; \\text{Prob}(\\mathcal{X}^2_{1,0.95}) = 3.84 \\\\ &amp; \\text{There is no evidence that } \\beta\\neq0.5.\\\\ &amp;\\textbf{Wald test: } \\\\ &amp; W=n(1-\\beta_0\\bar{x})^2=5\\times(1-0.5\\times1)^2=1.25&lt; \\text{Prob}(\\mathcal{X}^2_{1,0.95}) = 3.84 \\\\ &amp; \\text{There is no evidence that } \\beta\\neq0.5.\\\\ \\end{aligned} \\] 16.7.3 Q3 隨機變量 \\(X_1,\\cdots,X_n\\) 互相獨立且在區間 \\([0,\\alpha]\\) 內服從相同的恆定概率分佈 (identical uniform distribution)。 試着畫出參數 \\(\\alpha\\) 的似然方程示意圖。不進行任何數學計算，試着想象一下如果對 \\(\\alpha\\) 進行某種假設檢驗會出現什麼問題嗎？ "],
["-normal-error-models.html", "第 17 章 正態誤差模型 Normal error models 17.1 服從正態分佈的隨機變量 17.2 \\(F\\) 分佈和 \\(t\\) 分佈的概念 17.3 兩個參數的模型 17.4 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 \\(t\\) 檢驗 one sample \\(t\\) test 的統計學推導) 17.5 比較兩組獨立數據的均值 two sample \\(t\\) test with equal unknown \\(\\sigma^2\\) 17.6 各個統計分佈之間的關係", " 第 17 章 正態誤差模型 Normal error models 正態誤差模型，其實沒有其名字那麼複雜，就是討論在正態分布條件下，均值和方差都需要被估計 (都是未知狀態) 的模型。 本章還介紹 \\(F\\) 分佈和 \\(t\\) 分佈，試着闡述如何將 \\(t\\) 分佈應用於兩個獨立樣本均值的比較； \\(\\chi^2\\) 分佈在統計學中各種常用分佈中的中心位置。 17.1 服從正態分佈的隨機變量 \\[ X_1,\\cdots,X_n \\stackrel{i.i.d}{\\sim} N(\\mu,\\sigma^2) \\Leftrightarrow \\bar{X} \\sim N(\\mu, \\frac{\\sigma^2}{n}) \\] 如果總體方差 \\(\\sigma^2\\) 已知 (理想狀態，現實中不太可能)： \\[ \\begin{aligned} &amp; Z=\\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1) \\\\ &amp; 95\\% \\text{CI for } \\mu = \\bar{X} \\pm Z_{0.975}\\frac{\\sigma}{\\sqrt{n}} \\\\ &amp; \\text{H}_0: \\mu=\\mu_0 \\Rightarrow \\frac{\\bar{X}-\\mu_0}{\\sigma/\\sqrt{n}} \\sim N(0,1) \\end{aligned} \\] 如果總體方差 \\(\\sigma^2\\) 是未知的，腫麼辦？ (模型中出現了兩個參數 \\(\\mu \\;\\&amp;\\; \\sigma^2\\)) \\[ T=\\frac{\\bar{X}-\\mu_0}{\\hat\\sigma/\\sqrt{n}} \\sim ????????? \\] 17.2 \\(F\\) 分佈和 \\(t\\) 分佈的概念 如果 \\(X\\sim N(0,1)\\)，那麼 \\(X^2 \\sim \\chi^2_1\\) (Section 11)。類似地，如果 \\(X_1,\\cdots,X_n \\stackrel{i.i.d}{\\sim} N(0,1)\\) 那麼 \\(\\sum_{i=1}^n X^2_i \\sim \\chi^2_k\\)。 \\(F\\) 分佈和 \\(t\\) 分佈是建立在 \\(\\chi^2\\) 分佈的基礎上的： \\(F\\) 分佈： \\(Y_1, Y_2\\) 是獨立的兩個隨機變量，且 \\(Y_1 \\sim \\chi^2_{k_1}; Y_2 \\sim \\chi^2_{k_2}\\)，那麼 \\[ F=\\frac{Y_1/k_1}{Y_2/k_2} \\sim F_{k_1, k_2} \\] \\(t\\) 分佈，是 \\(F\\) 分佈的特殊情況 \\((k_1=1)\\)： \\[ T\\sim t_{k_2} \\Rightarrow T^2 = \\frac{Y_1/1}{Y_2/k_2} \\sim F_{1,k_2} \\] 此時我們再來考慮正態分佈模型中有兩個參數 \\(\\mu, \\sigma^2\\) 需要被估計的模型： \\[ Y_i \\stackrel{i.i.d}{\\sim} N(\\mu,\\sigma^2) \\text{ where } i = 1, \\cdots, n \\] 其實可以改寫爲 \\[ \\begin{aligned} &amp; Y_i = \\mu + \\varepsilon_i \\\\ &amp; \\text{Where } \\varepsilon_i \\stackrel{i.i.d}{\\sim} N(0,\\sigma^2) \\end{aligned} \\] 其中 \\(\\varepsilon_i \\stackrel{i.i.d}{\\sim} N(0,\\sigma^2)\\) 就是正態誤差 normal (random) error。\\(Y_i = \\mu + \\varepsilon_i\\) 就是正態誤差模型 normal error model。誤差的含義就是統計模型中的隨機誤差 (模型不能解釋的部分)。如果一個正態誤差模型像前面的式子這樣沒有其他變量，那麼所有的觀察值 \\(Y_i\\)，就是由總體均值 \\(\\mu\\) population mean，和隨機誤差 \\(\\varepsilon\\) random error 來說明 (就是這個式子 \\(Y_i = \\mu + \\varepsilon_i\\))。 如果觀察值 \\(Y_i\\) 的一部分除了可以用均值解釋，還可以由某個變量 \\(x\\) 來說明 (叫做解釋變量 explanatory variable 詳見線性迴歸部分 Section 26.3.3)，即： \\[ \\begin{aligned} &amp;Y_i | x \\stackrel{i.i.d}{\\sim} N(\\mu+\\beta x_i, \\sigma^2)\\\\ &amp; E(Y|x) = \\mu+\\beta x, \\text{Var}(Y|x) = \\sigma^2 \\\\ &amp; \\text{ or } Y_i|x = \\mu + \\beta x_i + \\varepsilon_i ; \\text{ where } \\varepsilon_i \\stackrel{i.i.d}{\\sim} N(0, \\sigma^2) \\end{aligned} \\] 上面的模型會在後面講線性迴歸的部分深入探討，此處簡單用下面的圖形來輔助理解。圖 17.1 中繪製的是 \\(Y_i|x = \\mu + \\beta x_i + \\varepsilon_i ; \\text{ where } \\varepsilon_i \\stackrel{i.i.d}{\\sim} N(0, \\sigma^2)\\) 的示意圖，用 \\(x_i\\) 標記兩個組，其中 \\(x_i = 0\\) 時爲組 A 的人的觀察值，\\(x_i=1\\) 時爲組 B 的人的觀察值。兩組的平均值如 Y 軸顯示的那樣，組 A 是 \\(\\mu\\)，組 B 是 \\(\\mu+\\beta\\)。所以，這裏可以看到，正態誤差模型是假定兩組具有相同的方差的 common variance，如圖 17.2。如果解釋變量 (explanatory variable) 是一個連續型變量，則解釋爲在 X 軸上的任意一點對應的 Y 值的誤差都服從相同的方差，如圖 17.3 圖 17.1: Normal error models with categorical explanatory variable 圖 17.2: Normal error models shown with common error variance 圖 17.3: Normal error models shown with continuous variable and common error variance 17.3 兩個參數的模型 17.3.1 一組數據兩個參數 如果觀察數據 \\(\\underline{x} = x_1, \\cdots, x_n\\) 是互相獨立的，該觀察數據的模型可以用一個包含兩個參數 \\(\\theta,\\phi\\) 的概率方程 \\(f\\) 來描述，那麼這個包含兩個參數的概率方程的似然和對數似然分別是： \\[ \\begin{aligned} L(\\theta, \\phi | \\underline{x}) &amp;= \\prod_{i=1}^nf(x_i | \\theta, \\phi) \\\\ \\ell(\\theta, \\phi | \\underline{x}) &amp;= \\sum_{i=1}^n\\text{log}f(x_i | \\theta, \\phi) \\end{aligned} \\] 兩個參數的 \\(\\text{MLE}\\) 可以通過對對數似然方程進行兩次偏微分，然後解連立方程組： \\[ \\left\\{ \\begin{array}{ll} \\frac{\\partial\\ell}{\\partial\\theta} = 0\\\\ \\frac{\\partial\\ell}{\\partial\\phi} = 0 \\\\ \\end{array} \\right. \\] 17.3.2 兩組數據各一個參數 如果是兩組獨立數據，各由一個參數描述他們各自的概率方程： \\[ X_1, \\cdots, X_n \\stackrel{i.i.d}\\sim f(\\theta_1) \\\\ Y_1, \\cdots, Y_m \\stackrel{i.i.d}\\sim f(\\theta_2) \\] 那麼以兩組數據爲聯合條件 (應該可以理解爲同時觀察到時的) 的聯合似然 (joint likelihood)： We describe the likelihood as the joint likelihood, conditional on jointly observing both datasets: \\[ L(\\theta_1, \\theta_2|\\underline{x},\\underline{y}) = \\prod_{i=1}^nf_1(x_{1i}|\\theta_1) \\times \\prod_{i=1}^mf_2(y_{i}|\\theta_2) \\] 所以，聯合之後的對數似然方程就是兩個對數似然方程之和： \\[ \\ell(\\theta_1,\\theta_2|\\underline{x},\\underline{y}) = \\sum_{i=1}^n\\text{log} f(x_i|\\theta_1) + \\sum_{i=1}^m\\text{log} f(y_i|\\theta_2) \\] 你會發現，分成兩組數據兩個獨立的概率方程之後的聯合對數似然方程求 \\(\\text{MLE}\\) 時需要用偏微分。可是偏微分之後的結果，和兩組數據合二爲一，用含有兩個參數的概率方程，計算其 \\(\\text{MLE}\\) 的結果會完全相同。 17.4 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 \\(t\\) 檢驗 one sample \\(t\\) test 的統計學推導) 此時的情況如同前面的把兩組數據合二爲一的情況，用正態分佈的概率方程，然後有兩個參數 \\(\\mu, \\sigma^2\\)。 \\[ Y_1,\\cdots,Y_n \\stackrel{i.i.d}{\\sim} N(\\mu, \\sigma^2) \\\\ \\ell(\\mu, \\sigma^2 | \\underline{y}) = -\\frac{n}{2}\\text{log}\\sigma^2 - \\frac{1}{2\\sigma^2}\\sum^n_{i=1} (x_i - \\mu)^2 \\] \\[ \\begin{aligned} &amp; \\mu: \\frac{\\partial \\ell}{\\partial \\mu} = \\frac{\\sum^n_{i=1}(y_i-\\mu)}{2\\sigma^2} = 0 \\Rightarrow \\hat\\mu = \\bar{y}\\\\ &amp; \\sigma^2: \\frac{\\partial \\ell}{\\partial (\\sigma^2)} = -\\frac{n}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2}\\sum^n_{i=1}(y_i-\\mu)^2 \\\\ &amp; \\text{ Substituting } \\mu=\\hat\\mu = \\bar{y} \\text{ and set equal to } 0\\\\ &amp; \\frac{n}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2}\\sum^n_{i=1}(y_i-\\bar{y})^2 = 0 \\\\ &amp; \\Rightarrow \\hat\\sigma^2 = \\frac{1}{n}\\sum^n_{i=1}(y_i - \\bar{y})^2 \\end{aligned} \\] 有沒有覺得這裏的方差的極大似然估計似曾相識 (Section 10.3)。在早期的章節中，我們學到了分部法 (“把樣本和總體均值之間的差的平方和分成兩部分”)： \\[ \\begin{aligned} \\sum^n_{i=1}(y_i-\\mu)^2 &amp; = \\sum^n_{i=1}(y_i - \\bar{y} + \\bar{y} -\\mu)^2 \\\\ &amp; = \\sum^n_{i=1}(y_i - \\bar{y})^2 + \\sum^n_{i=1}(\\bar{y}-\\mu)^2 \\\\ \\Rightarrow \\sum^n_{i=1}(y_i - \\bar{y})^2 &amp; = \\sum^n_{i=1}(y_i-\\mu)^2 - \\sum^n_{i=1}(\\bar{y}-\\mu)^2 \\end{aligned} \\] 當時分的是平方和，這裏再介紹一種把概率分部的方法 partition the probabilities。 We can “partition” the probability of observing the data, conditional on unknown \\(\\mu\\) and \\(\\sigma^2\\), into the probability of observing the data conditional on the observed sample mean \\(\\bar{y}\\) and unknown \\(\\sigma^2\\) ; the probability of observing the sample mean \\(\\bar{y}\\) conditional on the two unknown parameters. \\[ \\begin{aligned} &amp; \\text{Prob}(\\underline{y} | \\mu, \\sigma^2) = \\text{Prob}(\\underline{y}|\\bar{y}, \\sigma^2) \\times \\text{Prob}(\\bar{y}|\\mu, \\sigma^2) \\\\ &amp;\\Rightarrow \\text{Prob}(\\underline{y} | \\bar{y}, \\sigma^2) = \\frac{\\text{Prob}(\\underline{y} | \\mu, \\sigma^2)}{\\text{Prob}(\\bar{y}|\\mu, \\sigma^2)} \\end{aligned} \\] 看到這裏你是否會想起概率論中討論的條件概率方程 (Section 1.2)： \\[ f(x|Y=y) = \\frac{f(x,y)}{f(y)} \\] 利用上述概率分佈的方法，我們可以進而推導方差 \\(\\sigma^2\\) 的 \\(\\text{MLE}\\)： \\[ \\begin{aligned} f(\\underline{y} | \\bar{y}, \\sigma^2) &amp;= \\frac{ \\color{red}{f(\\underline{y} | \\mu, \\sigma^2)} }{f(\\bar{y}|\\mu, \\sigma^2)} \\\\ &amp;= \\frac{ \\color{red}{(\\frac{1}{\\sqrt{2\\pi\\sigma^2}})^ne^{-\\frac{1}{2\\sigma^2}\\sum^n_{i=1}(y_i - \\mu)^2}} }{(\\frac{1}{\\sqrt{2\\pi\\sigma^2/n}})e^{-\\frac{1}{2\\sigma^2/n}(\\bar{y}-\\mu)^2}} \\\\ \\Rightarrow \\ell(\\sigma^2| \\underline{y}, \\bar{y}) &amp;= \\color{red}{-\\frac{n}{2}\\text{log}\\sigma^2 - \\frac{1}{2\\sigma^2}\\sum^n_{i=1}(y_i-\\mu)^2} \\\\ &amp; \\;\\;\\;+\\frac{1}{2}\\text{log}\\frac{\\sigma^2}{n} + \\frac{1}{2\\sigma^2/n}(\\bar{y}-\\mu)^2 \\\\ &amp;= -\\frac{n-1}{2}\\text{log}\\sigma^2 - \\frac{1}{2\\sigma^2}(\\sum^n_{i=1}(y_i-\\mu)^2 - n(\\bar{y}-\\mu)^2) \\\\ \\text{Because } &amp;\\sum^n_{i=1}(y_i - \\bar{y})^2 = \\sum^n_{i=1}(y_i-\\mu)^2 - \\sum^n_{i=1}(\\bar{y}-\\mu)^2 \\\\ \\Rightarrow \\ell(\\sigma^2| \\underline{y}, \\bar{y}) &amp;= -\\frac{n-1}{2}\\text{log}\\sigma^2 -\\frac{1}{2\\sigma^2}\\sum^n_{i=1}(y_i - \\bar{y})^2 \\\\ \\text{Note that the } &amp;\\text{above conditional log-likelihood is now free of } \\mu \\\\ \\Rightarrow \\ell^\\prime(\\sigma^2) &amp;= -\\frac{n-1}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2}\\sum^n_{i=1}(y_i-\\bar{y})^2 \\\\ \\text{Set equal } &amp; \\text{to zero and rearrange} \\\\ \\Rightarrow \\hat\\sigma^2 &amp;= \\frac{1}{n-1}\\sum^n_{i=1}(y_i-\\bar{y})^2\\\\ \\text{This is the } &amp;\\color{red}{\\text{unbiased estimate of } \\sigma^2} \\end{aligned} \\] 現在再重新考慮對數據 \\(Y_1, \\cdots, Y_n \\stackrel{i.i.d}{\\sim} N(\\mu, \\sigma^2)\\) 進行均值的假設檢驗： \\[ \\text{H}_0: \\mu = \\mu_0 \\text{ v.s H}_1: \\mu &gt; \\mu_0 \\] 當 \\(\\sigma^2\\) 是已知的，在零假設條件下的檢驗統計量是： \\[ \\begin{aligned} &amp; \\text{H}_0 \\Rightarrow (\\frac{\\bar{Y}-\\mu_0}{\\sigma/\\sqrt{n}}) \\sim N(0,1) \\\\ &amp; \\text{Or equivalently, } \\\\ &amp; (\\frac{\\bar{Y}-\\mu_0}{\\sigma/\\sqrt{n}})^2 \\sim \\chi_1^2 \\end{aligned} \\tag{17.1} \\] 當 \\(\\sigma^2\\) 是未知的，它需要通過樣本數據來估計時。我們就該使用前面從條件對數似然方程推導出的方差無偏估計： \\[ \\hat\\sigma^2 = S^2 = \\frac{1}{n-1}\\sum^n_{i=1}(y_i-\\bar{y})^2 \\] 但是，假如只把無偏估計的方差放到公式 (17.1) 裏去，可以當作新的檢驗統計量嗎？有這麼簡單嗎？ \\[ (\\frac{\\bar{Y}-\\mu_0}{s/\\sqrt{n}})^2 \\] 當然沒有這麼簡單！這種方式僅僅考慮了樣本的方差估計，卻忽略了這個估計是有不確定性的 (uncertainty)，它並不是真實的 \\(\\sigma^2\\)，只是個估計 (estimator)。我們需要找到一種方法把方差的不確定性也考慮進新的檢驗統計量裏去。利用章節 10.4 的結論： \\[ \\begin{equation} \\frac{n-1}{\\sigma^2}S^2 \\sim \\chi^2_{n-1}\\\\ \\Rightarrow \\frac{S^2}{\\sigma^2} = \\frac{\\chi^2_{n-1}}{n-1} \\end{equation} \\tag{17.2} \\] 把公式 (17.1) 除以 (17.2) 獲得： \\[ \\frac{(\\bar{Y}-\\mu_0)^2}{S^2/n} \\sim \\frac{\\chi^2_1/1}{\\chi^2_{n-1}/n-1} = F_{1,n-1} \\] 這樣我們就同時考慮了方差估計本身，和它的不確定性了。這個新的統計量被定義爲 \\(T\\)： \\[ \\begin{aligned} &amp; T=\\frac{\\bar{Y}-\\mu_0}{S/\\sqrt{n}} \\\\ &amp; \\text{Then under H}_0: T^2 \\sim F_{1,n-1} \\text{ or equivalently } T \\sim \\sqrt{F_{1,n-1}}=t_{n-1} \\end{aligned} \\] 這個特殊的 \\(F\\) 分佈，就是我們之前定義過的，這裏用手紮紮實實地推導出來的檢驗統計量 \\(t\\) 和 \\(t\\) 分佈。利用這個方差未知時的分佈，均值的 \\(95\\%\\) 信賴區間的估計就是： \\[ 95\\% \\text{ CI for } \\mu: \\bar{Y} \\pm t_{n-1,0.975}\\frac{S}{\\sqrt{n}} \\] 17.5 比較兩組獨立數據的均值 two sample \\(t\\) test with equal unknown \\(\\sigma^2\\) 本節要來推導方差齊時的兩個獨立樣本的均值比較 two sample \\(t\\) test。兩個獨立樣本用下面的數學符號標記： \\[ X_1, \\cdots, X_n \\stackrel{i.i.d}{\\sim} N(\\mu_1, \\sigma^2); Y_1, \\cdots, Y_m, \\stackrel{i.i.d}{\\sim} N(\\mu_2, \\sigma^2) \\] 要進行的假設檢驗是： \\[ \\text{H}_0: \\mu_1 = \\mu_2 \\text{ v.s. } \\text{H}_1: \\mu_1 &gt; \\mu_2 \\] 此時，兩組獨立樣本的共同方差 \\(\\hat\\sigma^2\\) 需要被估計，利用上面相同的推導過程，可以獲得合併後的共同方差的無偏估計： \\[ \\begin{equation} \\hat\\sigma^2 = S^2_p = \\frac{\\sum^n_{i=1}(X_i-\\bar{X})^2 + \\sum^m_{i=1}(Y_i-\\bar{Y})^2}{n+m-2}\\\\ \\end{equation} \\tag{17.3} \\] 因爲兩組數據互相獨立，所以有： \\[ \\begin{aligned} &amp; \\frac{1}{\\sigma^2}\\sum^n_{i=1}(X_i - \\bar{X})^2 \\sim \\chi^2_{n-1} \\\\ &amp; \\frac{1}{\\sigma^2}\\sum^m_{i=1}(Y_i - \\bar{Y})^2 \\sim \\chi^2_{m-1} \\\\ \\Rightarrow &amp;\\frac{1}{\\sigma^2}\\{ \\sum^n_{i=1}(X_i - \\bar{X})^2 + \\sum^m_{i=1}(Y_i - \\bar{Y})^2 \\} \\sim \\chi^2_{n+m-2} \\end{aligned} \\] 把公式 (17.3) 代入此式可得： \\[ \\begin{equation} (n+m-2)\\frac{S^2_p}{\\sigma^2} \\sim \\chi^2_{n+m-2} \\end{equation} \\tag{17.4} \\] 由於 \\(\\bar{X} \\sim N(\\mu_1, \\frac{\\sigma^2}{n}); \\bar{Y} \\sim N(\\mu_2, \\frac{\\sigma^2}{m})\\)，所以在零假設條件下 \\(\\text{H}_0: \\mu_1=\\mu_2\\Rightarrow \\bar{X}-\\bar{Y} \\sim N(0,\\sigma^2(\\frac{1}{n}+\\frac{1}{m}))\\)。 \\[ \\begin{equation} \\Rightarrow \\frac{\\bar{X}-\\bar{Y}}{\\sqrt{\\sigma^2(\\frac{1}{n}+\\frac{1}{m})}} \\sim N(0,1) \\\\ \\Leftrightarrow \\frac{(\\bar{X}-\\bar{Y})^2}{\\sigma^2(\\frac{1}{n}+\\frac{1}{m})} \\sim \\chi^2_1 \\end{equation} \\tag{17.5} \\] 現在把公式 (17.5) 除以 (17.4) 可得： \\[ \\begin{aligned} &amp;\\frac{(\\bar{X}-\\bar{Y})^2}{\\sigma^2(\\frac{1}{n}+\\frac{1}{m})} \\times \\frac{\\sigma^2}{S^2_p(n+m-2)} = \\frac{\\chi^2_1/1}{\\chi^2_{n+m-2}} \\\\ &amp;\\Rightarrow T^2 = \\frac{(\\bar{X}-\\bar{Y})^2}{S^2_p(\\frac{1}{n}+\\frac{1}{m})} = \\frac{\\chi^2_1/1}{\\chi^2_{n+m-2}/(n+m-2)} \\sim F_{1,n+m-2} \\\\ &amp;\\Rightarrow T = \\frac{\\bar{X}-\\bar{Y}}{S_p\\sqrt{\\frac{1}{n}+\\frac{1}{m}}} \\sim t_{n+m-2} \\end{aligned} \\] 這就是標準的兩個齊方差的獨立樣本均值比較的 \\(t\\) 檢驗，two-sample \\(t\\) test with pooled variance。這裏推導的兩個 \\(t\\) 檢驗，是都是精確的似然比檢驗 (likelihood ratio test) (Section 16.2)。壯士請自己跟着似然比檢驗的方法推導一次。 17.6 各個統計分佈之間的關係 卡方分佈 \\(\\chi^2\\) 是統計學常用分佈中極爲重要的分佈，其他的許多分佈都與之相關。 \\[ \\{N(0,1)\\}^2 = \\chi^2_1 \\\\ \\chi^2_k = \\sum_{i-1}^k \\chi^2_1 \\\\ F_{k,n} = \\frac{\\chi^2_k/k}{\\chi^2_n/n}\\\\ t^2_n = F_{1,n} =\\frac{\\chi^2_1/1}{\\chi^2_n/n} \\] "],
["-inference-with-multiple-parameters-i.html", "第 18 章 多個參數時的統計推斷 Inference with multiple parameters I 18.1 多參數 multiple parameters - LRT 18.2 多參數 Wald 檢驗 - Wald test 18.3 多參數 Score 檢驗 - Score test 18.4 條件似然 conditional likelihood 18.5 練習", " 第 18 章 多個參數時的統計推斷 Inference with multiple parameters I 前一章介紹單樣本和雙樣本 \\(t\\) 檢驗時已經接觸到了 2 個未知參數情況下的檢驗統計量推導，本章把之前用到的方法擴展到 2 個以上參數的情況。帶你推導兩個以上參數的似然比檢驗 likelihood ratio test，Wald 檢驗，和 Score 檢驗推論。 18.1 多參數 multiple parameters - LRT 18.1.1 似然 likelihood 如果一個觀察數據 \\(\\underline{x} = (x_1, \\cdots, x_n)\\) 相互獨立，可以用含有 \\(k\\) 個參數 \\(\\theta_1,\\cdots,\\theta_k\\) 的數學模型 \\(f\\) 來描述，那麼它的似然公式爲： \\[ L(\\theta_1,\\cdots,\\theta_k | \\underline{x}) = f(\\underline{x} | \\theta_1,\\cdots,\\theta_k) = \\prod^n_{i=1}f(x_i|\\theta_1,\\cdots,\\theta_k) \\] 它的對數似然公式爲： \\[ \\ell(\\theta_1,\\cdots,\\theta_k|\\underline{x}) = \\sum^n_{i=1}\\text{log}f(x_1|\\theta_1,\\cdots,\\theta_k) \\] 每個參數的 \\(\\text{MLE}\\) 通過解下面的 \\(k\\) 個連立方程組獲得： \\[ \\left\\{ \\begin{array}{c} \\frac{\\partial \\ell}{\\partial \\theta_1} = \\ell^\\prime(\\theta_1) = 0 \\\\ \\frac{\\partial \\ell}{\\partial \\theta_2} = \\ell^\\prime(\\theta_k) = 0 \\\\ \\vdots \\\\ \\frac{\\partial \\ell}{\\partial \\theta_k} = \\ell^\\prime(\\theta_k) = 0 \\\\ \\end{array} \\right. \\] 這些連立方程有時被叫做 score equations； \\(\\text{MLE}\\) 的恆定性，不變性 invariance 在多個參數時同樣適用。 當參數只有一個 \\(\\theta\\) 時，其 \\(\\text{MLE}\\) 的方差是 \\(S^2=\\left.-\\frac{1}{\\ell^{\\prime\\prime}(\\theta)}\\right\\vert_{\\theta=\\hat{\\theta}}\\) 當參數有多個時，\\(k\\) 個 \\(\\text{MLE}\\) 的方差是一個 \\(k\\times k\\) 的對稱矩陣，其中二次微分矩陣 (18.1) 的昵稱是海森矩陣 Hessian matrix： \\[ \\begin{equation} \\underline{\\ell^{\\prime\\prime}(\\theta)} = \\left( \\begin{array}{c} \\frac{\\partial^2\\ell}{\\partial\\theta^2_1} &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_2\\partial\\theta_1} &amp; \\cdots &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_k\\partial\\theta_1} \\\\ \\frac{\\partial^2\\ell}{\\partial\\theta_1\\partial\\theta_2} &amp; \\frac{\\partial^2\\ell}{\\partial\\theta^2_2} &amp; \\cdots &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_k\\partial\\theta_2} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial^2\\ell}{\\partial\\theta_1\\partial\\theta_k} &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_2\\partial\\theta_k} &amp; \\cdots &amp; \\frac{\\partial^2\\ell}{\\partial\\theta^2_k} \\\\ \\end{array} \\right) \\end{equation} \\tag{18.1} \\] \\[ \\Rightarrow \\underline{\\ell^{\\prime\\prime}(\\theta)} |_{\\color{red}{\\theta=\\hat\\theta}} = \\left( \\begin{array}{c} \\frac{\\partial^2\\ell}{\\partial\\theta^2_1} &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_2\\partial\\theta_1} &amp; \\cdots &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_k\\partial\\theta_1} \\\\ \\frac{\\partial^2\\ell}{\\partial\\theta_1\\partial\\theta_2} &amp; \\frac{\\partial^2\\ell}{\\partial\\theta^2_2} &amp; \\cdots &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_k\\partial\\theta_2} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial^2\\ell}{\\partial\\theta_1\\partial\\theta_k} &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_2\\partial\\theta_k} &amp; \\cdots &amp; \\frac{\\partial^2\\ell}{\\partial\\theta^2_k} \\\\ \\end{array} \\right)_{\\color{red}{\\theta=\\hat\\theta}} \\] \\[ \\Rightarrow \\underline{\\text{Var}(\\hat\\theta)} = - \\left( \\begin{array}{c} \\frac{\\partial^2\\ell}{\\partial\\theta^2_1} &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_2\\partial\\theta_1} &amp; \\cdots &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_k\\partial\\theta_1} \\\\ \\frac{\\partial^2\\ell}{\\partial\\theta_1\\partial\\theta_2} &amp; \\frac{\\partial^2\\ell}{\\partial\\theta^2_2} &amp; \\cdots &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_k\\partial\\theta_2} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial^2\\ell}{\\partial\\theta_1\\partial\\theta_k} &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_2\\partial\\theta_k} &amp; \\cdots &amp; \\frac{\\partial^2\\ell}{\\partial\\theta^2_k} \\\\ \\end{array} \\right)^{\\color{red}{-1}}_{\\color{red}{\\theta=\\hat\\theta}} \\] 18.1.2 對數似然比檢驗 多個參數未知時的對數似然比檢驗可以被這樣拓展： \\[ \\begin{aligned} &amp; \\text{H}_0: \\underline{\\theta} = \\underline{\\theta_0} \\\\ &amp; \\Rightarrow -2llr(\\underline{\\theta_0}) = -2(\\ell(\\underline{\\theta_0})- \\ell(\\hat{\\underline{\\theta}})) \\stackrel{\\cdot}{\\sim} \\chi^2_r \\\\ &amp; \\text{Where } r \\text{ is the number of parameters restricted under H}_0 \\end{aligned} \\] 18.2 多參數 Wald 檢驗 - Wald test 單個參數時的 Wald 檢驗的檢驗統計量： \\[ \\begin{aligned} &amp; \\text{H}_0: \\theta=\\theta_0 \\Rightarrow W_\\theta = (\\frac{M-\\theta_0}{S})^2 \\stackrel{\\cdot}{\\sim} \\chi^2_1 \\\\ &amp; \\text{Where } M=\\hat\\theta, S^2=\\left.-\\frac{1}{\\ell^{\\prime\\prime}(\\theta)}\\right\\vert_{\\theta=\\hat{\\theta}} \\\\ &amp; \\Rightarrow W=(\\hat\\theta-\\theta_0)^2(-\\ell^{\\prime\\prime}(\\hat\\theta)) \\stackrel{\\cdot}{\\sim} \\chi^2_1 \\end{aligned} \\] 如果是兩個參數 \\(\\lambda, \\psi\\) 的 Wald 檢驗： \\(\\text{H}_0: \\lambda=\\lambda_0, \\psi=\\psi_0 \\text{ v.s. H}_1: \\lambda \\neq \\lambda_0 \\text{ or } \\psi \\neq \\psi_0\\)。 我們可以先一個一個考慮參數： \\[ \\begin{aligned} &amp; W_\\lambda = (\\hat\\lambda-\\lambda_0)^2(-\\ell^{\\prime\\prime}(\\hat\\lambda)) \\stackrel{\\cdot}{\\sim} \\chi^2_1 \\\\ &amp; W_\\psi = (\\hat\\psi-\\psi_0)^2(-\\ell^{\\prime\\prime}(\\hat\\psi)) \\stackrel{\\cdot}{\\sim} \\chi^2_1 \\\\ &amp; \\Rightarrow W_\\lambda + W_\\psi \\stackrel{\\cdot}{\\sim} \\chi^2_2 \\\\ &amp; \\Rightarrow W = (\\hat\\lambda-\\lambda_0)^2(-\\ell^{\\prime\\prime}(\\hat\\lambda)) + (\\hat\\psi-\\psi_0)^2(-\\ell^{\\prime\\prime}(\\hat\\psi)) \\stackrel{\\cdot}{\\sim} \\chi^2_2 \\end{aligned} \\] 也可以一開始就兩個參數一起考慮： \\[ \\underline{\\ell^\\prime} = \\left( \\begin{array}{c} \\frac{\\partial\\ell}{\\partial\\lambda}\\\\ \\frac{\\partial\\ell}{\\partial\\psi} \\end{array} \\right) \\Rightarrow \\underline{\\ell^{\\prime\\prime}} = \\left( \\begin{array}{c} \\frac{\\partial^2\\ell}{\\partial\\lambda^2} &amp; \\frac{\\partial^2\\ell}{\\partial\\lambda\\partial\\psi} \\\\ \\frac{\\partial^2\\ell}{\\partial\\psi\\partial\\lambda} &amp; \\frac{\\partial^2\\ell}{\\partial\\psi^2} \\end{array} \\right) \\] 然後單參數時 \\(W\\) 的分子 \\((\\theta_0-\\hat\\theta)^2\\) 此時變爲： \\[ (\\hat\\lambda-\\lambda_0)^2+(\\hat\\psi-\\psi_0)^2 = (\\hat\\lambda-\\lambda_0, \\hat\\psi-\\psi_0)\\left( \\begin{array}{c} \\hat\\lambda-\\lambda_0 \\\\ \\hat\\psi-\\psi_0 \\end{array} \\right) \\] 所以兩個參數時的 Wald 檢驗統計量爲： \\[ \\begin{aligned} W = &amp; (\\hat\\lambda-\\lambda_0, \\hat\\psi-\\psi_0)(-\\underline{\\ell^{\\prime\\prime}}(\\hat\\lambda,\\hat\\psi))\\left( \\begin{array}{c} \\hat\\lambda-\\lambda_0 \\\\ \\hat\\psi-\\psi_0 \\end{array} \\right) \\\\ = &amp; - (\\hat\\lambda-\\lambda_0, \\hat\\psi-\\psi_0)\\left( \\begin{array}{c} \\frac{\\partial^2\\ell}{\\partial\\lambda^2} &amp; \\frac{\\partial^2\\ell}{\\partial\\lambda\\partial\\psi} \\\\ \\frac{\\partial^2\\ell}{\\partial\\psi\\partial\\lambda} &amp; \\frac{\\partial^2\\ell}{\\partial\\psi^2} \\end{array} \\right)_{\\hat\\lambda,\\hat\\psi} \\left( \\begin{array}{c} \\hat\\lambda-\\lambda_0 \\\\ \\hat\\psi-\\psi_0 \\end{array} \\right)\\\\ &amp; \\text{ Because } \\lambda \\text{ and } \\psi \\text{ are independent,} \\\\ &amp; \\text{ so their covariance } \\frac{\\partial^2\\ell}{\\partial\\lambda\\partial\\psi} = \\frac{\\partial^2\\ell}{\\partial\\psi\\partial\\lambda} = 0\\\\ \\Rightarrow = &amp; - (\\hat\\lambda-\\lambda_0, \\hat\\psi-\\psi_0)\\left( \\begin{array}{c} \\ell^{\\prime\\prime}(\\hat\\lambda) &amp; 0 \\\\ 0 &amp; \\ell^{\\prime\\prime}(\\hat\\psi) \\end{array} \\right) \\left( \\begin{array}{c} \\hat\\lambda-\\lambda_0 \\\\ \\hat\\psi-\\psi_0 \\end{array} \\right)\\\\ = &amp; - (\\hat\\lambda-\\lambda_0, \\hat\\psi-\\psi_0)\\left( \\begin{array}{c} \\ell^{\\prime\\prime}(\\hat\\lambda)(\\hat\\lambda-\\lambda_0) \\\\ \\ell^{\\prime\\prime}(\\hat\\psi)(\\hat\\psi-\\psi_0) \\end{array} \\right) \\\\ = &amp; (\\hat\\lambda-\\lambda_0)^2(-\\ell^{\\prime\\prime}(\\hat\\lambda)) + (\\hat\\psi-\\psi_0)^2(-\\ell^{\\prime\\prime}(\\hat\\psi)) \\stackrel{\\cdot}{\\sim} \\chi^2_2 \\end{aligned} \\] 由此可見，兩個參數分開來考慮之後把統計量相加，和一開始就把兩個參數放在一起，利用矩陣計算後獲得的檢驗統計量完全相同。用矩陣的好處是可以把上面的推導過程直接擴展成 \\(k\\) 個參數的形式，且標記簡便： \\[ W = -(\\hat{\\underline{\\theta}} - \\underline{\\theta_0})^T\\underline{\\ell^{\\prime\\prime}(\\hat\\theta)}(\\underline{\\hat\\theta} - \\underline{\\theta_0}) \\stackrel{\\cdot}{\\sim} \\chi^2_k \\] 18.3 多參數 Score 檢驗 - Score test 單個參數時的 Score 檢驗的檢驗統計量： \\[ \\text{H}_0: \\theta=\\theta_0 \\text{ v.s. H}_1: \\theta \\neq \\theta_0 \\\\ \\frac{U^2}{V} \\stackrel{\\cdot}{\\sim} \\chi^2_1 \\\\ \\text{Where } U=\\ell^\\prime(\\theta_0), V=E[-\\ell^{\\prime\\prime}(\\theta_0)] \\] 類似 Wald 檢驗法的矩陣推導過程和標記法，\\(k\\) 個參數的 Score 檢驗的統計量可以標記爲： \\[ \\underline{U}^T\\underline{V}^{-1}\\underline{U} \\stackrel{\\cdot}{\\sim} \\chi^2_k \\\\ \\text{Where } \\underline{U} = \\left.\\frac{\\partial\\ell}{\\partial\\underline{\\theta}} \\right\\vert_{\\underline{\\theta}=\\underline{\\theta_0}}, \\underline{V} = E[-\\underline{\\ell^{\\prime\\prime}(\\theta)}]_{\\underline{\\theta}=\\underline{\\theta_0}} \\] 所以如果是兩個參數 \\(\\lambda, \\psi\\) 那麼檢驗 \\(\\text{H}_0:\\lambda = \\lambda_0, \\psi = \\psi_0 \\text{ v.s. H}_1: \\lambda \\neq \\lambda_0 \\text{ or } \\psi\\neq\\psi_0\\) 的 Score 檢驗統計量是： \\[ (\\frac{\\partial\\ell}{\\partial\\lambda}, \\frac{\\partial\\ell}{\\partial\\psi})_{\\lambda_0, \\psi_0}\\left( E\\left[ -\\left( \\begin{array}{c} \\frac{\\partial^2\\ell}{\\partial\\lambda^2} &amp; \\frac{\\partial^2\\ell}{\\partial\\lambda\\partial\\psi} \\\\ \\frac{\\partial^2\\ell}{\\partial\\psi\\partial\\lambda} &amp; \\frac{\\partial^2\\ell}{\\partial\\psi^2} \\end{array} \\right)_{\\lambda_0,\\psi_0} \\right] \\right)^{-1}\\left( \\begin{array}{c} \\frac{\\partial\\ell}{\\partial\\lambda}\\\\ \\frac{\\partial\\ell}{\\partial\\psi} \\end{array} \\right)_{\\lambda_0,\\psi_0} \\stackrel{\\cdot}{\\sim} \\chi^2_2 \\] 18.4 條件似然 conditional likelihood 現實的例子中，參數可能有非常多，但是我們可能只關心其中幾個。下章介紹的子集似然函數 (profile likelihood) 是可以在多種情況下應用的好方法。本節介紹的方法是條件似然法。簡單原理是，把模型中不能提供我們感興趣的參數的有效信息的那些參數 (“nuisance” parameters) 當作是固定的 (fixed)。由此可以定義一個新的概率模型 – 條件概率模型 conditional probability model。 我們用泊松模型來解釋如何建立這樣的模型。 兩個獨立的人羣追蹤樣本，在 \\(p_0, p_1\\) 人年的隨訪中發生事件 A 的次數分別是 \\(k_0, k_1\\)。假設我們只關心兩組的事件 A 發生率的比 \\(\\text{Rate ratio:} \\theta=\\frac{\\lambda_1}{\\lambda_0}\\)。 合併兩個人羣，發生事件 A 的總次數爲 \\(k=k_0+k_1\\)。只知道 \\(k\\) 並不能讓我們推算兩個人羣中各發生了多少次事件 A，也無法用它來計算發生率的比 \\(\\theta\\)，而這個 \\(k\\) 就是條件概率模型中的條件。 \\[ K_0 \\sim Po(\\mu_0); K_1 \\sim Po(\\mu_1) ; \\text{ where } \\mu_0 = \\lambda_0 p_0 \\mu_1 = \\lambda_1 p_1\\\\ k=k_0 + k_1 \\Rightarrow K_0+K_1 \\sim Po(\\mu_0 + \\mu_1) \\] \\[ \\begin{aligned} &amp; \\text{Prob}(k_0 \\text{events in group 0} | k \\text{ events in total}) \\\\ = &amp; \\frac{\\text{Prob}(k_0 \\text{ events in group }0 \\text{ and } k-k_0 \\text{ events in group } 1)} {\\text{Prob}(k \\text{ events in total})} \\\\ \\end{aligned} \\tag{18.2} \\] 由於兩個樣本是來自獨立的人羣，所以公式 (18.2) 的分母，和分子分別是 \\[ \\begin{aligned} \\text{Prob}(k &amp;\\text{ events in total}) \\\\ = &amp; \\frac{(\\lambda_0 p_0 + \\lambda_1 p_1)^k e^{-(\\lambda_0 p_0 + \\lambda_1 p_1)}}{k!} \\\\ \\text{Prob}(k_0 &amp;\\text{ events in group }0 \\text{ and } k-k_0 \\text{ events in group } 1) \\\\ = &amp; \\frac{(\\lambda_0 p_0)^{k_0}e^{-\\lambda_0 p_0}}{k_0!}\\times\\frac{(\\lambda_1 p_1)^{k-k_0}e^{-\\lambda_1 p_1}}{(k-k_0)!} \\end{aligned} \\] 所以公式 (18.2) 可以整理成： \\[ \\begin{aligned} &amp; \\frac{\\frac{(\\lambda_0 p_0)^{k_0}e^{-\\lambda_0 p_0}}{k_0!}\\times\\frac{(\\lambda_1 p_1)^{k-k_0}e^{-\\lambda_1 p_1}}{(k-k_0)!}} {\\frac{(\\lambda_0 p_0 + \\lambda_1 p_1)^k e^{-(\\lambda_0 p_0 + \\lambda_1 p_1)}}{k!}} \\\\ = &amp; \\frac{e^{-(\\lambda_0 p_0 + \\lambda_1 p_1)}(\\lambda_0 p_0)^{k_0}(\\lambda_1 p_1)^{k-k_0}\\cdot k!}{e^{-(\\lambda_0 p_0 + \\lambda_1 p_1)}(\\lambda_0p_0+\\lambda_1p_1)^k\\cdot k_0!\\cdot (k-k_0)!}\\\\ = &amp; (\\frac{\\lambda_0 p_0}{\\lambda_0 p_0+\\lambda_1 p_1})^{k_0}(\\frac{\\lambda_1 p_1}{\\lambda_0 p_0+\\lambda_1 p_1})^{k-k_0}\\cdot\\frac{k!}{k_0!(k-k_0)!} \\\\ = &amp; (\\pi)^{k_0}(1-\\pi)^{k-k_0}\\cdot\\frac{k!}{k_0!(k-k_0)!} \\\\ \\text{Where } &amp; \\pi = \\frac{\\lambda_0 p_0}{\\lambda_0 p_0 + \\lambda_1 p_1} = \\frac{p_0}{p_0+(\\lambda_1/\\lambda_0)p_1} = \\frac{p_0}{p_0+\\theta p_1}\\\\ \\Rightarrow &amp;\\text{ Given } K_0+K_1=K, K_0 \\sim Bin(k, \\pi=\\frac{p_0}{p_0+\\theta p_1}) \\end{aligned} \\] 我們就把兩個泊松分佈的模型，變形成爲了一個條件二項分佈，而且只有一個未知參數 \\(\\theta\\)。之後就可以用二項分佈的對數似然方程進行下一步的假設檢驗的構建： \\[ \\begin{aligned} L(\\pi) &amp; = (\\pi)^{k_0}(1-\\pi)^{k-k_0} \\\\ \\Rightarrow \\ell(\\pi) &amp; = k_0 \\text{log}\\pi + (k-k_0)\\text{log} (1-\\pi) \\\\ \\text{Because } \\pi &amp; = \\frac{p_0}{p_0+\\theta p_1} \\\\ \\ell_c(\\theta) &amp; = k_0 \\text{log}(\\frac{\\pi}{1-\\pi}) + k\\text{log}(1-\\pi) \\\\ &amp; = k_0 \\text{log}(\\frac{p_0}{\\theta p_1}) + k\\text{log}(\\frac{\\theta p_1}{p_0 + \\theta p_1}) \\\\ \\text{Ignoring} &amp; \\text{ terms not involving } \\theta \\\\ \\ell_c(\\theta)&amp; = k_1 \\text{log}\\theta - k\\text{log}(p_0 + \\theta p_1) \\end{aligned} \\tag{18.3} \\] 至此，推導發生率比 \\(\\theta = \\frac{\\lambda_1}{\\lambda_0}\\) 的條件對數似然就完成了。Elegant and Bravo! 關於條件對數似然： 推導出的條件對數似然是一個真實的以觀察數據爲條件的對數似然，可以用於假設檢驗； 條件似然過程依賴於我們能否找到這樣一個“條件似然”，使得模型的對數似然只取決於我們關心的參數，我們幸運地找到了發生率比的對數似然方程，但是至今沒有人找到發生率差 \\(\\lambda_1-\\lambda_0\\) 的條件對數似然； 與此相對地是，下一章介紹的子集似然函數 (profile likelihood)，可以用於幾乎所有的多參數模型的假設檢驗之構建； 但是，條件對數似然相當之重要，特別是它作爲 Cox proportional hazard model 模型的基本模型構架在生存分析 (survival analysis) 中的應用，以及在配對病例對照分析 (matched case-control study) 中用於條件邏輯迴歸 (conditional logistic regression) 的理論基礎 (將會在第二學期的碩士課程中介紹，敬請期待)。 18.5 練習 某項研究追蹤隨訪 50-69 歲男性的心臟病發病率。研究對象根據心臟病發病史的有無分成兩組。有心臟病史的對象被隨訪 512 人・年，觀察到 25 例新的心臟病發作病例；無心臟病史的對象被隨訪 4862 人・年，觀察到 52 例新的心臟病發作病例。 如果需要檢驗的零假設是 \\(\\text{H}_0:\\) 有心臟病史的男性發病率的對數等於 \\(-3\\)，無心臟病史的男性發病率的對數等於 \\(-4.5\\)。請推導該實驗的聯合對數似然比檢驗，Wald 檢驗兩種檢驗法的檢驗統計量，並進行假設檢驗。 解 模型： 令隨機變量 \\(K_i\\) 標記新發生的心臟病病例數，其中當 \\(i=0\\) 時代表無心臟病史組；當 \\(i=1\\) 時代表有心臟病史組。所以可以用下面的泊松模型來標記兩組的新發生心臟病病例數： \\[ K_i \\sim \\text{Poisson}(\\mu_i); \\mu_i = \\lambda_i p_i\\\\ \\text{Where } \\lambda_i \\text{ is the rate parameter in group } i, \\\\ p_i \\text{ is the person-years at risk in group }i \\\\ \\] 有無心臟病史組之間由於是相互獨立的，故兩組的對數似然相加之後就可得到合併後的對數似然。 數據： \\[ k_0 = 52, p_0 = 4862; k_1 = 25, p_1 = 512 \\] 泊松模型的對數似然方程爲 (Section 12.6)： \\[ \\ell(\\lambda | \\text{data}) = -\\lambda p + k \\text{log} \\lambda \\] 令 \\(\\psi = \\text{log} \\lambda\\) 有： \\[ \\ell(\\psi) = k \\psi - e^\\psi p \\] 令 \\(\\psi_0 = \\text{log}\\lambda_0; \\psi_1 = \\text{log}\\lambda_1\\)，那麼本題中的假設檢驗可以寫成是： \\[\\text{H}_0: {\\psi_0}_0 = -4.5, {\\psi_1}_0 = -3 \\text{ v.s. H}_1: {\\psi_0}_0 \\neq -4.5 \\text{ or } {\\psi_1}_0 \\neq -3\\] 對數似然比檢驗需要尋找的檢驗統計量是 \\(-2llr({\\psi_0}_0,{\\psi_1}_0)\\)，其中： \\[ llr({\\psi_0}_0,{\\psi_1}_0) = \\ell({\\psi_0}_0,{\\psi_1}_0) - \\ell(\\hat\\psi_0,\\hat\\psi_1) \\] 所以我們分別來計算 \\(\\ell({\\psi_0}_0,{\\psi_1}_0)\\) 和 \\(\\ell(\\hat\\psi_0,\\hat\\psi_1)\\)： \\[ \\begin{equation} \\ell(\\psi_0, \\psi_1) = k_0 \\psi_0 - e^{\\psi_0} p_0 + k_1 \\psi_1 - e^{\\psi_1} p_1 \\end{equation} \\tag{18.4} \\] \\[ \\Rightarrow \\frac{\\partial\\ell}{\\partial\\psi_0} = k_0 - e^{\\psi_0}p_0 \\\\ \\text{and} \\\\ \\frac{\\partial\\ell}{\\partial\\psi_1} = k_1 - e^{\\psi_1}p_1 \\] 然後我們把這兩個偏微分式子等於零時的解作爲 \\(\\psi_0, \\psi_1\\) 的 \\(\\text{MLE}\\)： \\[ \\begin{aligned} \\frac{\\partial\\ell}{\\partial{\\psi}_0} &amp; = 0 \\\\ \\Rightarrow e^{{\\hat\\psi}_0} &amp; = \\frac{k_0}{p_0} \\\\ \\Rightarrow {\\hat\\psi}_0 &amp; = \\text{log}(\\frac{k_0}{p_0}) \\\\ \\text{And similarly } {\\hat\\psi}_1 &amp; = \\text{log}(\\frac{k_1}{p_1}) \\end{aligned} \\] 所以， \\[ \\begin{aligned} \\ell({\\psi_0}_0,{\\psi_1}_0) &amp; = 52\\times(-4.5) - e^{-4.5}\\times4862+25\\times(-3)-e^{-3}\\times512 \\\\ &amp; = -388.5029 \\\\ \\ell(\\hat\\psi_0,\\hat\\psi_1) &amp; = 52\\times\\text{log}\\frac{52}{4862} - e^{\\text{log}\\frac{52}{4862}}\\times4862 + 25\\times\\text{log}\\frac{25}{512} - e^{\\text{log}\\frac{25}{512}}\\times512 \\\\ &amp; = 52\\times\\text{log}\\frac{52}{4862} - 52 + 25\\times\\text{log}\\frac{25}{512} - 25 \\\\ &amp; = -388.4602 \\\\ \\Rightarrow llr({\\psi_0}_0,{\\psi_1}_0) &amp; = -388.5029 - (-388.4602) = - 0.0427 \\\\ \\Rightarrow -2llr({\\psi_0}_0,{\\psi_1}_0) &amp; = 0.0854 \\end{aligned} \\] 因爲在零假設條件下 \\(-2llr \\stackrel{\\cdot}{\\sim} \\chi^2_2\\)，本次檢驗的拒絕域是 \\(\\mathfrak{R} &gt; \\chi^2_{2,0.95} = 5.99\\)，所以，檢驗的結果 \\(-2llr = 0.0854 &lt; 5.99\\)，在顯著性水平爲 \\(5\\%\\) 時，沒有證據反對零假設。There is no evidence at the \\(5\\%\\) level against the null hypothesis. Wald 檢驗時我們需要的檢驗統計量爲： \\[ W = (\\hat\\psi_0-{\\psi_0}_0, \\hat\\psi_1-{\\psi_1}_0)(-\\underline{\\ell^{\\prime\\prime}}(\\hat\\psi_0,\\hat\\psi_1))\\left( \\begin{array}{c} \\hat\\psi_0-{\\psi_0}_0 \\\\ \\hat\\psi_1-{\\psi_1}_0 \\end{array} \\right) \\] 先處理中間那個看起來比較棘手的 \\((-\\underline{\\ell^{\\prime\\prime}}(\\hat\\psi_0,\\hat\\psi_1))\\)： \\[ \\begin{aligned} \\underline{\\ell^\\prime}(\\psi_0, \\psi_1) &amp; = \\left( \\begin{array}{c} k_0 - e^{\\psi_0}p_0 \\\\ k_1 - e^{\\psi_1}p_1 \\end{array} \\right) \\\\ \\Rightarrow \\underline{\\ell^{\\prime\\prime}}(\\psi_0,\\psi_1) &amp; = \\left( \\begin{array}{c} \\frac{\\partial^2\\ell}{\\partial\\psi^2_0} &amp; \\frac{\\partial^2\\ell}{\\partial\\psi_1\\partial\\psi_0} \\\\ \\frac{\\partial^2\\ell}{\\partial\\psi_0\\partial\\psi_1} &amp; \\frac{\\partial^2\\ell}{\\partial\\psi^2_1} \\end{array} \\right) = \\left( \\begin{array}{c} -e^{\\psi_0}p_0 &amp; 0\\\\ 0 &amp; -e^{\\psi_1}p_1 \\end{array} \\right) \\\\ \\Rightarrow -\\underline{\\ell^{\\prime\\prime}}(\\hat\\psi_0,\\hat\\psi_1) &amp; = \\left( \\begin{array}{c} -e^{\\hat\\psi_0}p_0 &amp; 0\\\\ 0 &amp; -e^{\\hat\\psi_1}p_1 \\end{array} \\right) \\\\ &amp; = \\left( \\begin{array}{c} -e^{\\text{log}(\\frac{52}{4862})}\\times4862 &amp; 0\\\\ 0 &amp; -e^{\\text{log}(\\frac{25}{512})}\\times512 \\end{array} \\right) \\\\ &amp; = \\left( \\begin{array}{c} 52 &amp; 0\\\\ 0 &amp; 25 \\end{array} \\right) \\end{aligned} \\] 又有 \\(\\hat\\psi_1-{\\psi_1}_0 = \\text{log}(\\frac{25}{512})-(-3) = -0.0194\\) 和 \\(\\hat\\psi_0-{\\psi_0}_0 = \\text{log}(\\frac{52}{4862})-(-4.5) = -0.0379\\) 所以 \\[ \\begin{aligned} W &amp; = (\\hat\\psi_0-{\\psi_0}_0, \\hat\\psi_1-{\\psi_1}_0)(-\\underline{\\ell^{\\prime\\prime}}(\\hat\\psi_0,\\hat\\psi_1))\\left( \\begin{array}{c} \\hat\\psi_0-{\\psi_0}_0 \\\\ \\hat\\psi_1-{\\psi_1}_0 \\end{array} \\right) \\\\ &amp; = (-0.0379, -0.0194)\\left( \\begin{array}{c} 52 &amp; 0\\\\ 0 &amp; 25 \\end{array} \\right)\\left( \\begin{array}{c} -0.0379 \\\\ -0.0194 \\end{array} \\right) = 0.08439208 \\end{aligned} \\] Wald 檢驗的檢驗統計量也一樣服從 \\(\\chi^2_2\\)，所以拒絕域同對數似然比檢驗法的\\(\\mathfrak{R} &gt; \\chi^2_{2,0.95} = 5.99\\)，所以，檢驗的結果 \\(W = 0.08439208 &lt; 5.99\\)，在顯著性水平爲 \\(5\\%\\) 時，沒有證據反對零假設。There is no evidence at the \\(5\\%\\) level against the null hypothesis. 利用本節推導出的發生率比的條件對數似然方程，請嘗試進行對數似然比檢驗：心臟病發作率在無病史男性中和有病史男性中的比例爲 \\(0.2\\)。 本章推導的發生率的比值的條件對數似然方程爲： \\[ \\ell_c(\\theta) = k_1 \\text{log}\\theta - k\\text{log}(p_0 + \\theta p_1) \\\\ \\text{Where } \\theta = \\frac{\\lambda_1}{\\lambda_0} \\] 題目要求比較的是 \\(\\frac{\\lambda_0}{\\lambda_1} = 0.2\\)，用本題中的 \\(\\lambda_0\\) 取代條件對數似然方程中的 \\(\\lambda_1\\) 則有： \\[ \\ell_c{\\theta} = k_0\\text{log}\\theta - k\\text{log}(p_1 + \\theta p_0) \\\\ \\text{H}_0: \\theta_0 = 0.2 \\text{ v.s. H}_1: \\theta_0 \\neq 0.2 \\] 對於條件對數似然比檢驗，需要的檢驗統計量是 \\(-2llr_c(\\theta_0)\\) 其中： \\[ llr_c(\\theta_0) = \\ell_c(\\theta_0) - \\ell_c(\\hat\\theta) \\] 先計算 \\(\\ell_c(\\hat\\theta)\\)： \\[ \\begin{aligned} \\text{Let }\\ell_c^\\prime &amp; = \\frac{k_0}{\\theta} - \\frac{kp_0}{p_1+\\theta p_0} = 0 \\\\ \\Rightarrow \\frac{k_0}{\\theta} &amp; = \\frac{kp_0}{p_1+\\theta p_0} \\\\ \\Rightarrow \\hat\\theta &amp; = \\frac{k_0p_1}{p_0k_1} = \\frac{k_0/p_0}{k_1/p_1} \\\\ \\Rightarrow \\hat\\theta &amp; = \\frac{52\\times512}{4862\\times25} = 0.219037 \\\\ \\Rightarrow \\ell_c(\\theta_0) &amp; = k_0\\text{log}0.2 - k\\text{log}(p_1 + \\theta p_0) \\\\ &amp; = 52\\times\\text{log}0.2 - 77\\times\\text{log}(512 + 0.2\\times4862) \\\\ &amp; = -646.003 \\\\ \\ell_c{\\hat\\theta} &amp; = 52\\times\\text{log}0.219037 - 77\\times\\text{log}(512 + 0.219037\\times4862)\\\\ &amp; = -645.933 \\\\ \\Rightarrow -2llr(\\theta_0) &amp; = -2\\times(-646.003-(-645.933)) = 0.14 \\end{aligned} \\] 因爲在零假設條件下 \\(-2llr \\stackrel{\\cdot}{\\sim} \\chi^2_1\\)，本次檢驗的拒絕域是 \\(\\mathfrak{R} &gt; \\chi^2_{1,0.95} = 3.84\\)，所以，檢驗的結果 \\(-2llr = 0.14 &lt; 3.84\\)，在顯著性水平爲 \\(5\\%\\) 時，沒有證據反對零假設。There is no evidence at the \\(5\\%\\) level against the null hypothesis. "],
["profile-log-likelihood.html", "第 19 章 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods 19.1 子集似然法推導的過程總結 19.2 子集對數似然比的近似 19.3 練習 Practical 19.4 總結", " 第 19 章 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods 本章介紹的子集似然法是處理多個參數模型的主要方法。前章介紹的條件似然法也是相當出色的方法，但是許多情況下我們無法找到合適的“條件”來輔助我們擺脫那些模型中不需要的，障礙 (或者叫噪音) 參數 nuisance parameters。 我們還是沿用上一節的例子。 兩個獨立的人羣追蹤樣本，在 \\(p_0, p_1\\) 人年的隨訪中發生事件 A 的次數分別是 \\(k_0, k_1\\)。我們只關心兩組的事件 A 發生率的比 \\(\\text{Rate ratio:} \\theta=\\frac{\\lambda_1}{\\lambda_0}\\)。兩個人羣的聯合對數似然函數如下： \\[ \\ell(\\lambda_0, \\lambda_1) = k_0\\text{log}\\lambda_0 - \\lambda_0p0 + k_1\\text{log}\\lambda_1 - \\lambda_1p1 \\] Step 1. 先用 \\(\\lambda_1 = \\lambda_0\\theta\\) 取代掉上面式子中的 \\(\\lambda_1\\)。 \\[ \\begin{aligned} \\Rightarrow \\ell(\\lambda_0, \\theta) &amp; = k\\text{log}\\lambda_0 + k_1\\text{log}\\theta - \\lambda_0(P_0 + \\theta p_1) \\\\ \\text{Where } k &amp; = k_0 + k_1 \\end{aligned} \\tag{19.1} \\] 這一步先是消滅了一個障礙參數 \\(\\lambda_1\\)，獲得了一個我們關心的參數 \\(\\theta\\)，和 \\(\\lambda_0\\) 的對數似然方程。接下來，我們尋找用 \\(\\theta\\) 表示 \\(\\lambda_0\\) (用 \\(\\hat\\lambda_0(\\theta)\\) 標記) 的似然方程，使得只包含一個參數 \\(\\theta\\) 的對數似然方程可以在每個 \\(\\lambda_0\\) 時取得極大值。此時我們定義 \\(\\theta\\) 的子集對數似然方程 profile log-likelihood是： \\[ \\ell_p(\\theta) = \\ell(\\hat\\lambda_0(\\theta),\\theta) \\] Step 2. 爲了求 \\(\\hat\\lambda_0(\\theta)\\)，先視 \\(\\theta\\) 爲不變的，對上式 (19.1) 求 \\(\\lambda_0\\) 的微分： \\[ \\frac{\\partial\\ell(\\lambda_0,\\theta)}{\\partial\\lambda_0}=\\frac{k}{\\lambda_0} - (p_0+\\theta p_1) \\] 把該微分方程等於0，推導出 \\(\\hat\\lambda_0=\\frac{k}{p_0+\\theta p_1}\\) 就是 \\(\\theta\\) 在取值範圍內所有能使對數似然方程 (19.1) 取極大值的對應 \\(\\lambda_0\\)。 Step 3. 將這個 \\(\\theta\\) 表示的 \\(\\lambda_0\\text{ MLE}\\) 代替 \\(\\lambda_0\\) 代入對數似然方程 (19.1) 中去： \\[ \\begin{aligned} \\ell_p(\\theta) &amp;= k\\text{log}\\frac{k}{p_0 + \\theta p_1} + k_1 \\text{log}\\theta - k \\\\ \\text{Ignoring} &amp;\\text{ items not involving } \\theta\\\\ \\Rightarrow &amp;= k_1\\text{log}\\theta - k\\text{log}(p_0+\\theta p_1) \\end{aligned} \\] 這個用子集似然法推導的關於參數 \\(\\theta\\) 的似然方程和前一章用條件似然法 (Section 18.4) 推導的結果是完全一致的 (18.3)。 19.1 子集似然法推導的過程總結 多個參數中區分出我們感興趣的參數 \\(\\psi\\) 和其餘的障礙(噪音)參數 \\(\\lambda\\)； 爲了從對數似然方程中消除噪音參數，把它們一一通過微分求極值的辦法表達成用 \\(\\psi\\) 標記的表達式，用這些包含了 \\(\\psi\\) 的 \\(\\text{MLE}\\) 代替所有的噪音參數； 整理最終獲得的只有感興趣的參數的對數似然方程，記得把不包含參數的部分忽略掉。 19.1.1 子集對數似然方程的分佈 \\[ -2pllr(\\psi) = -2\\{ \\ell_p(\\psi) - \\ell(\\hat\\psi)\\} \\stackrel{\\cdot}{\\sim} \\chi^2_r \\] 其中自由度 \\(r\\) 是想要檢驗的零假設中受限制的參數的個數。Degree of freedom \\(r\\) is the number of parameters restricted under the null hypothesis. 所以，如果 \\(\\psi\\) 是一個維度 (dimension) 爲 \\(p\\) 的向量，如果零假設是 \\(\\text{H}_0: \\psi = \\psi_0\\)，那麼自由度就是 \\(p\\)。 19.1.2 假設檢驗過程舉例 兩個獨立的二項分佈樣本：\\(K_0 \\sim \\text{Bin}(n_0, \\pi_0), K_1 \\sim \\text{Bin}(n_1, \\pi_1)\\)。它們的聯合對數似然爲： \\[ \\ell(\\pi_0, \\pi_1) = \\ell(\\pi_0) + \\ell(\\pi_1) \\] 如果要檢驗的零假設和替代假設分別是 \\(\\text{H}_0: \\pi_0 = \\pi_1 \\text{ v.s. H}_1: \\pi_0 \\neq \\pi_1\\)。 如果令 \\(\\theta=\\frac{\\pi_1}{\\pi_0}\\)，那麼要檢驗的零假設和替代假設就變成了： \\[ \\text{H}_0: \\theta = 1 \\text{ v.s. H}_1: \\theta \\neq 1 \\\\ \\Rightarrow -2 pllr \\stackrel{\\cdot}{\\sim} \\chi^2_1 \\] 而且在零假設條件下，\\(\\text{H}_0: K_0+K_1 \\sim \\text{Bin}(n_0+n_1, \\pi)\\)，那麼自己對數似然比檢驗的統計量是： \\[ \\begin{aligned} -2 pllr &amp; = -2\\{ \\text{max}[\\underset{\\text{H}_0}{\\ell(\\pi_0,\\theta\\pi_0)}] -\\text{max}[\\underset{\\text{H}_1}{\\ell(\\pi_0,\\theta\\pi_0)}] \\} \\\\ \\Rightarrow -2 pllr &amp; = -2\\{ \\text{max}[\\underset{\\text{H}_0}{\\ell(\\pi,\\theta\\pi)}] -\\text{max}[\\underset{\\text{H}_1}{\\ell(\\pi_0,\\pi_1)}] \\} \\\\ \\Rightarrow -2 pllr &amp; = -2\\{ \\ell{(\\hat\\pi)} - \\ell{(\\hat\\pi_0, \\hat\\pi_1)} \\} \\end{aligned} \\] 19.2 子集對數似然比的近似 假如有兩個獨立樣本數據，參數分別只有一個 \\(\\beta_0, \\beta_1\\)，我們關心他們二者之間的差是否有意義 \\(\\gamma = \\beta_1-\\beta_0\\)。如果 \\(\\beta_0\\) 的對數似然比檢驗統計量的相應的 Wald 檢驗統計量 (二次方程近似法 Section 16.4) 可以用 \\(\\hat\\beta_0, S_0\\) 定義，其中 \\(\\beta_0\\) 是 \\(\\text{MLE}\\)，\\(S_0\\) 是標準誤差。類似的，\\(\\beta_1\\) 的 Wald 檢驗統計量可以用 \\(\\hat\\beta_1, S_1\\) 定義。那麼，我們關心的參數，\\(\\gamma = \\beta_1 - \\beta_0\\) 的 Wald 檢驗統計量可以用 \\(\\hat\\gamma = \\hat\\beta_1 - \\hat\\beta_1, S=\\sqrt{S^2_1 + S^2_0}\\) 定義： \\[ \\begin{aligned} pllr(\\gamma) &amp; = -\\frac{1}{2}(\\frac{\\gamma-\\hat\\gamma}{\\sqrt{S^2_1+S^2_0}})^2 \\\\ &amp; = -\\frac{1}{2}(\\frac{(\\beta_1-\\beta_0)-(\\hat\\beta_1-\\hat\\beta_0)}{\\sqrt{S^2_1+S^2_0}})^2 \\end{aligned} \\] 19.2.1 子集對數似然比近似的一般化 如果我們關心的參數，和模型參數的關係可以用下面的表達式來表示： \\[ \\gamma = W_0\\beta_0 + W_1\\beta_1 + \\cdots \\\\ \\text{ Where } W_i \\text{ are arbitrary cosntants} \\] 如果，模型中的每個參數 \\(\\beta_0, \\beta_1, \\cdots\\) 的 \\(\\text{MLE}\\) 是 \\(\\hat\\beta_0, \\hat\\beta_1, \\cdots\\)，標準誤是 \\(S=\\sqrt{(W_0S_0)^2+(W_1S_2)^2+\\cdots}\\) 19.2.2 事件發生率之比的 Wald 檢驗統計量 事件發生率 (Possion rate ratio) \\(\\theta = \\frac{\\lambda_1}{\\lambda_0}\\) 令 \\(\\beta_1 = \\text{log}\\lambda_1, \\beta_0 = \\text{log}\\lambda_0, \\gamma = \\text{log}\\theta\\)。 所以有 \\(\\gamma=\\beta_1-\\beta_0\\)。 由於 \\[ \\begin{aligned} \\hat\\beta_0 &amp; = \\text{log}(\\frac{k_0}{p_0}), \\\\ \\hat\\beta_1 &amp; = \\text{log}(\\frac{k_1}{p_1}) \\\\ \\end{aligned} \\] 因而 \\[ \\begin{aligned} \\hat\\gamma &amp; = \\text{log}\\frac{k_1}{p_1} - \\text{log}\\frac{k_0}{p_0} \\\\ &amp; = \\text{log}\\frac{k_1/p_1}{k_0/p_0} \\end{aligned} \\] 又由於 \\(S_0 = \\frac{1}{\\sqrt{k_0}}, S_1 = \\frac{1}{\\sqrt{k_1}}\\) (Section 14.2.1)。 所以 \\(S=\\sqrt{\\frac{1}{k_0}+\\frac{1}{k_1}}\\)。 綜上，事件發生率之比的 Wald 檢驗統計量爲 \\[ \\begin{aligned} pllr(\\gamma) &amp; = -\\frac{1}{2}(\\frac{\\gamma - \\hat\\gamma}{\\sqrt{\\frac{1}{k_0}+\\frac{1}{k_1}}})^2 \\\\ &amp; = -\\frac{1}{2}(\\frac{\\text{log}\\theta - \\text{log}\\frac{k_1/p_1}{k_0/p_0}}{\\sqrt{\\frac{1}{k_0}+\\frac{1}{k_1}}})^2 \\end{aligned} \\] 19.3 練習 Practical \\(n\\) 名肺癌 I 期患者的倖存時間 \\(X_1, X_2, \\cdots, X_n\\) 被認爲服從指數分佈 (參數 \\(\\lambda_x\\))，概率方程爲 \\(\\lambda_x e^{-x\\lambda_x},\\text{ where } x &gt; 0\\)。 證明 \\(\\lambda_x\\) 的 \\(\\text{MLE}\\) 是 \\(\\hat\\lambda_x = \\frac{1}{\\bar{x}}\\), 對數似然方程是 \\[\\ell(\\lambda_x | \\underline{x}) = n\\text{log}\\lambda_x - \\lambda_x n \\bar{x}\\] 解 \\[ \\begin{aligned} f(\\underline{x}|\\lambda_x) &amp; = \\lambda_x\\cdot e^{-x\\lambda_x} \\\\ F(\\underline{x}|\\lambda_x) &amp; = \\prod_{i=1}^n\\lambda_{x}\\cdot e^{-x_i\\lambda_{x}} \\\\ \\Rightarrow L(\\lambda_x | \\underline{x}) &amp; = \\prod_{i=1}^n\\lambda_xe^{-x_i\\lambda_{x}} \\\\ \\Rightarrow \\ell(\\lambda_x|\\underline{x}) &amp; = \\sum_{i=1}^n(\\text{log}\\lambda_x + \\text{log}e^{-x_i\\lambda_{x}}) \\\\ &amp; = n\\text{log}\\lambda_x + \\sum_{i=1}^n(-x_i\\lambda_{x}) \\\\ &amp; = n\\text{log}\\lambda_x - n\\bar{x}\\lambda_x \\\\ \\Rightarrow \\ell^\\prime(\\lambda_x) &amp; = \\frac{n}{\\lambda_x} - n\\bar{x}\\lambda_x \\\\ \\text{Let } \\ell^\\prime(\\lambda_x) &amp; = 0 \\Rightarrow \\text{ MLE of } \\lambda_x \\text{ is } \\hat\\lambda_x = \\frac{1}{\\bar{x}} \\\\ \\because \\ell^{\\prime\\prime} = -\\frac{n}{\\lambda^2_x} &amp; &lt; 0 \\therefore \\frac{1}{\\bar{x}} \\text{ is the MLE} \\end{aligned} \\] 另一組獨立數據是樣本量爲 \\(n\\) ，但是肺癌診斷爲 II 期的患者的倖存時間 \\(Y_1, \\cdots, Y_n\\)。這組數據也被認爲服從參數爲 \\(\\lambda_y\\) 的指數分佈。用 \\(\\theta=\\frac{\\lambda_x}{\\lambda_y}\\) 標記兩組患者倖存時間之比，用 \\(r=\\frac{\\bar{x}}{\\bar{y}}\\) 標記樣本的倖存時間均值之比。證明使兩個樣本數據的聯合對數似然取極大值的 \\(\\hat\\lambda_y(\\theta) = \\frac{2}{\\bar{y}(\\theta r+1)}\\)。 解 \\[ \\begin{aligned} \\ell(\\lambda_x|\\underline{x}) &amp; = n\\text{log}\\lambda_x - n \\bar{x} \\lambda_x \\\\ \\ell(\\lambda_y|\\underline{y}) &amp; = n\\text{log}\\lambda_y - n \\bar{y} \\lambda_y \\\\ \\Rightarrow \\text{ Joint log-likelihood: } &amp; \\ell(\\lambda_x, \\lambda_y | \\underline{x}, \\underline{y}) = n\\text{log}\\lambda_x - n\\bar{x}\\lambda_x \\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+ n\\text{log} \\lambda_y - n\\bar{y}\\lambda_y \\\\ \\text{Subsitute } \\lambda_x &amp; =\\theta\\cdot\\lambda_y \\\\ \\Rightarrow \\ell(\\theta, \\lambda_y) &amp;= n\\text{log}\\theta\\lambda_y - n\\bar{x}\\theta\\lambda_y + n\\text{log} \\lambda_y - n\\bar{y}\\lambda_y \\\\ \\ell(\\theta, \\lambda_y) &amp; = n(\\text{log}\\theta + \\text{log}\\lambda_y - \\bar{x}\\theta\\lambda_y + \\text{log}\\lambda_y - \\bar{y}\\lambda_y) \\\\ &amp; = n[\\text{log}\\theta + 2\\text{log}\\lambda_y - \\lambda_y(\\bar{x}\\theta + \\bar{y})] \\\\ \\Rightarrow \\frac{\\partial\\ell(\\theta, \\lambda_y)}{\\partial \\lambda_y} &amp; = n[\\frac{2}{\\lambda_y} - (\\bar{x}\\theta + \\bar{y})] \\\\ \\text{Let } \\frac{\\partial\\ell(\\theta, \\lambda_y)}{\\partial \\lambda_y} &amp; = 0 \\text{ and because } r = \\frac{\\bar{x}}{\\bar{y}} \\\\ \\hat\\lambda_y(\\theta) &amp; = \\frac{2}{\\bar{x}\\theta + \\bar{y}} = \\frac{2}{\\bar{y}(r\\cdot\\theta +1)} \\end{aligned} \\] 證明參數 \\(\\theta\\) 的子集對數似然是 \\(\\ell_p(\\theta|r) = n\\text{log}\\theta - 2n \\text{log}(\\theta\\cdot r + 1)\\)，且 \\(\\text{MLE}\\) 是 \\(\\hat\\theta = \\frac{1}{r}\\) 解 \\[ \\begin{aligned} \\ell_p (\\theta) &amp; = n[\\text{log}\\theta + 2\\cdot\\text{log}\\frac{2}{\\bar{y}(r\\cdot\\theta +1)} - \\text{log}\\frac{2}{\\bar{y}(r\\cdot\\theta +1)}(\\bar{x}\\theta+\\bar{y})] \\\\ &amp; = n\\{\\text{log}\\theta + 2\\cdot\\text{log}2 - 2\\cdot\\text{log}[\\bar{y}(r\\theta+1)] -2 \\} \\\\ \\text{Ignoring } &amp; \\text{ items not involving } \\theta\\\\ &amp; = n[\\text{log}\\theta - 2\\text{log}(r\\theta+1)] \\\\ \\Rightarrow \\ell_p^{\\prime}(\\theta) &amp; = n(\\frac{1}{\\theta} - \\frac{2r}{r\\theta+1}) \\\\ \\text{Let } \\ell_p^{\\prime}(\\theta) &amp; = 0 \\Rightarrow n(\\frac{1}{\\theta} - \\frac{2r}{r\\theta+1}) = 0 , \\hat\\theta=\\frac{1}{r}\\\\ \\because \\ell_p^{\\prime\\prime}(\\theta) &amp; = -\\frac{1}{\\theta^2} - \\frac{2r^2}{(r\\theta^2+1)^2} &lt; 0 \\\\ \\therefore \\hat\\theta &amp; =\\frac{1}{r} \\text{ is the MLE} \\end{aligned} \\] 根據 \\(\\text{MLE}\\) 的恆定性，可以直接推導出 \\(\\theta\\) 的 \\(\\text{MLE}\\) 嗎? 解 \\[ \\because \\hat\\lambda_x = \\frac{1}{x} , \\hat\\lambda_y = \\frac{1}{y} \\\\ \\therefore \\theta = \\frac{\\lambda_x}{\\lambda_y} \\Rightarrow \\hat\\theta = \\frac{\\hat\\lambda_x}{\\hat\\lambda_y} = \\frac{1}{r} \\] 證明檢驗下列假設 \\(\\text{H}_0: \\theta_0 = 1 \\text{ v.s. H}_1: \\theta_0 \\neq 1\\) 的子集對數似然比檢驗統計量是 \\(2n\\text{log}\\frac{(r+1)^2}{4r}\\)，並進行 \\(n=16, r=2\\) 的假設檢驗。 解 \\[ \\begin{aligned} \\text{Under H}_0 &amp; \\Rightarrow \\text{ test statistic is } \\\\ -2llr(\\theta_0) &amp; = -2[\\ell(\\theta_0) - \\ell(\\hat\\theta)] \\stackrel{\\cdot}{\\sim} \\chi^2_1 \\\\ \\Rightarrow \\ell_p(\\theta_0) &amp; = n\\text{log}1 - 2n \\text{log}(r+1) = -2n\\text{log}(r+1) \\\\ \\ell_p(\\hat\\theta) &amp; = n\\text{log}\\frac{1}{r} - 2n\\text{log}(2) \\\\ &amp; = -n\\text{log}r-2n\\text{log}2 = -n\\text{log}4r\\\\ \\Rightarrow \\ell_p(\\theta_0) - \\ell_p(\\hat\\theta) &amp; = -2n\\text{log}(r+1) + n\\text{log}4r = n\\text{log}\\frac{4r}{(r+1)^2} \\\\ \\Rightarrow -2llr(\\theta_0) &amp; = -2n\\text{log}\\frac{4r}{(r+1)^2} = 2n\\text{log}\\frac{(r+1)^2}{4r} \\\\ \\text{ When } n=16, r=2 -2llr(\\theta_0) &amp; = 2\\times16\\times\\text{log}(\\frac{2+1}{4\\times2})^2 = 3.769 &lt; \\chi^2_{1,0.95} = 3.84\\\\ \\text{ We do not reject }&amp;\\text{ the null hypothesis at the } 5% \\text{ level.} \\end{aligned} \\] 此時如果精確計算可以獲得 \\(p=0.052\\)，從檢驗統計量的計算值我們也能看出距離拒絕零假設的拒絕域十分接近。此時可以認爲是一個臨界的 \\(p\\) 值。所以數據提供了臨界 \\(p=0.052\\) 的證據證明肺癌 II 期患者的倖存時間平均要少於 I 期患者。 19.4 總結 推斷是十分具有挑戰性的一個章節，我們在此做個簡單的複習和總結，用一些常見的問題來結束本章。 19.4.1 快速複習 對於收集到的樣本數據 data，我們需要提出一個所謂的“科學問題 scientific question”。 爲了回答這個“科學問題”，我們會設想，並提出一個合適的 統計學模型 statistical model，確認提出的統計學模型中的參數 parameters。通過樣本數據的信息對參數進行估計 estimation，或者進行假設檢驗 hypothesis tests。 統計學模型具有自己的概率分佈，通過相應的參數，和模型的分佈可以解釋觀察數據的分佈，並且利用這些信息進行我們需要的推斷。同時，我們還需要利用觀察數據對我們提出的模型是否擬合數據做出合適的診斷。 估計和假設檢驗，是以似然方程爲基礎的。通常我們會利用便於計算的對數似然(比)，進行假設檢驗。 獲得似然方程以後，我們可以用對數似然比，進一步進行推斷： 確認最佳估計 \\(MLE\\)，和它的方差 (標準誤)； 計算參數的點估計量，和信賴區間； 爲感興趣的參數實施假設檢驗。 19.4.2 試爲下面的醫學研究問題提出合適的統計學模型 在一所醫院收集了 80 名患者的血壓和體重的數據，醫生想要分析血壓 (bp) 跟體重 (weight) 之間是否有相關性。 答： 用簡單線性迴歸模型。(r.v. = random variable) \\[ Y \\text{ r.v. for bp } Y_j | \\text{weight}_j \\stackrel{i}{\\sim} N(\\alpha + \\beta \\text{weight}, \\sigma^2), j = 1,2,\\cdots,80; \\text{H}_0: \\beta=0 \\] 爲了調查某市青光眼的患病率 (prevalence)，從一般人羣中隨機抽取了 100 人進行眼部檢查。 答：用二項分佈模型。 \\[ K \\text{ r.v. for number of people found with glaucoma } \\\\ K \\sim \\text{Bin}(100, \\pi); \\text{ Estimate } \\pi \\text{ with CI.} \\] 另一個醫生拿到了 2. 的數據，打算分析這100人中青光眼的患病與否是否和血壓相關。 答：用邏輯迴歸模型。 \\(\\text{logit}\\pi = \\text{log}\\frac{\\pi}{1-\\pi}\\) \\[ K_i | bp_i \\sim \\text{Bin}(100, \\pi_i), \\text{logit}(\\pi_i) = \\alpha + \\beta bp_i; \\text{H}_0: \\beta = 0 \\] 有好事者打算調查 25 名研究對象的血清膽固醇水平是否在實驗前後 (實驗時間3個月) 發生有意義的改變。 答：正態分佈模型，單樣本 \\(t\\) 檢驗。 \\[ D \\text{ r.v. for cholesterol change; } D_j \\stackrel{i.i.d}{\\sim} N(\\delta, \\sigma^2), j= 1,\\cdots,25; \\text{H}_0: \\delta = 0\\\\ \\text{Where } D_j = \\text{chol}_{j,3m} - \\text{chol}_{j,entry} \\] 前一題的好事者，打算進一步分析膽固醇水平的變化在某些進行特殊飲食的觀察對象中是否更加顯著。 答：簡單線性迴歸模型。 \\[ D_j | \\text{diet}_j \\stackrel{i}{\\sim} N(\\alpha + \\beta \\text{diet}_j, \\sigma^2), j=1,\\cdots,25; \\text{H}_0: \\beta = 0 \\] 某降壓藥物已知能有效地降低高血壓患者的血壓。某項實驗將收集來的高血壓患者分成 6 個小組，每組給予的藥物劑量不同，最低 1 毫克每次，最高 6 毫克每次，每組相差 1 毫克劑量。研究者希望通過實驗確定該藥物的降壓效果是否在某個劑量時達到最大，如果沒有，是否降壓藥物的效果隨着劑量增加而增加。 \\[ \\begin{aligned} &amp; bp_j | \\text{dose}_j \\stackrel{\\cdot}{\\sim} N(\\alpha + \\beta\\text{dose}_j + \\gamma\\text{dose}^2_j, \\sigma^2), j=1,\\cdots,n;\\\\ \\text{1) test } &amp; \\text{ H}_0: \\gamma=0; \\text{ if do not reject, then do next test } \\\\ &amp; bp_j | \\text{dose}_j \\stackrel{\\cdot}{\\sim} N(\\alpha + \\beta\\text{dose}_j, \\sigma^2) \\text{2) test } &amp; \\text{ H}_0: \\beta=0 \\end{aligned} \\] 19.4.3 醫生來找統計學家問問題 一個“臨牀醫生”來找你問了這樣的一個常見的問題：當我們使用 \\(t\\) 檢驗的時候，爲什麼前提假設是數據服從 正態分佈? 而不使用服從 \\(t\\) 分佈 這樣的前提條件，因爲我們實施該檢驗的時候明明就在用 \\(t\\) 分佈？ 答：我們從未假定觀察數據服從 \\(t\\) 分佈，我們假定的前提是檢驗統計量，也就是樣本均值和標準誤服從 \\(t\\) 分佈。因爲我們不知道收集獲得的數據來自的人羣的方差是多少，需要使用樣本數據對方差也進行估計的時候，不得已而必須使用 \\(t\\) 分佈來獲得估計的樣本均值的標準誤差，用於計算信賴區間和實施假設檢驗。 還是那個有好奇心的“臨牀醫生”又來問一個弱智問題：當我們使用正態分佈近似法對一個服從二項分佈的比例的單樣本檢驗的時候，我們把計算的檢驗統計量拿去跟正態分佈的特徵值作比較。然而，不用正態分佈近似，直接對連續型變量實施單樣本 \\(t\\) 檢驗的時候卻把計算的檢驗統計量拿去和 \\(t\\) 分佈的特徵值作比較，這是爲什麼？ 答：對連續型變量實施單樣本 \\(t\\) 檢驗的時候，我們需要用樣本數據同時估計均值和標準誤。但是對於二項分佈的數據來說，它的樣本比例的標準誤是總體比例的一個方程，所以只要用樣本比例估計總體比例以後，總體的標準誤就已經可以知道，不必再作估計。所以，二項分佈的正態近似法就真的使用標準正態分佈的特徵值，但是連續型變量的總體標準誤同時被估計，它的不確定性也要考慮進來，只能使用 \\(t\\) 分佈。 某“臨牀醫生”假裝很熱心想學習統計跑來問問題：該醫生實施的臨牀試驗，比較病例和對照之間某指標是否不同。但是，病例組看上去的年齡似乎比對照組要高一些，該醫生記得自己統計課上聽老師說過混雜因素的知識。所以他跑回家自己實施了一下病例組和對照組之間年齡是否有差別的 \\(t\\) 檢驗，結果顯示病例組對照組的年齡沒有顯著性差異。所以他認爲可以從線性模型中去掉年齡這一變量。但是身爲統計學家的你堅持必須要保留年齡在模型裏。所以醫生問你是否關心年齡有差別所以才堅持要調整年齡。你的回答是“對不起大哥，我對病例對照之間的年齡差是否有統計學意義完全沒有興趣。”醫生更加困惑了。\\(\\text{variable}_i = \\alpha + \\beta\\text{patient}_i + \\gamma\\text{age}_i + \\varepsilon_i\\) 答：年齡是否會混雜了病人分組和指標之間的關係，不是通過比較兩組來自的人羣的年齡是否有差別來判斷的。如果樣本的年齡有差別，就很有可能會對你想要分析的關係造成混淆。因爲你進行的年齡均值是否有差異的 \\(t\\) 檢驗，比較的並不是樣本年齡的差別，而是用樣本估計來自的人羣的年齡之間的比較。 "],
["section-20.html", "第 20 章 探索數據和簡單描述 20.1 數據分析的流程 20.2 數據類型 20.3 如何總結並展示數據 20.4 數據總結方案：位置，分散，偏度，和峰度", " 第 20 章 探索數據和簡單描述 Happy families are all alike, every unhappy family is unhappy in its own way. —- Leo Tolstoy Tidy datasets are all alike, but every messy dataset is messy in its own way. —- Hadley Wickham 20.1 數據分析的流程 圖 20.1: Population, sample and statistical inference 統計推斷的目的，是通過從人群中取樣本，經過對樣本特徵的 (描述) 統計分析 (summary statistic)，去推斷人群的相應特徵。 所以，無論什麼數據，到手以後我們一定要做的第一件事情，就是對其進行總結和描述，其過程又要盡可能地簡單明了。 在絕大多數的科學研究中數據分析都很重要，然而現實是，它多數情況下只出現在研究的第三部分： 研究設計 實施研究，收集數據 數據分析 結果報告 20.1.1 研究設計和實施 正確的統計推斷需要獲得具有代表性可以值得分析的數據，這必須建立在實驗研究設計良好，實施過程縝密的基礎上。設計糟糕，執行效率低下或者漏洞百出的實驗，給出的實驗數據必然是不可靠的，分析它也沒有意義。但是，不是說設計和實施階段就不需要統計學家的參與了。相反地，統計學家必須在研究實施過程中盡可能早的階段 (實驗設計) 參與進來。因為理解了實驗的目的，統計學家才能真正決定這個實驗要收集怎樣的數據，多大的樣本量，實施怎樣的分析方法。這些決定，注定了一項實驗研究的成敗。 20.1.2 數據分析 然而現實很殘酷，多數情況下實驗設計階段好像沒有統計學家什麼事，等到了數據分析階段，某些人才拍腦袋想讓統計學家來拯救他們收集的垃圾數據。通常都太晚了 (too late!)。 假設理想狀態下，我們收集到了想要分析的數據，可是接下來的工作流程的第一步，又常常被太多人忽略。許多 “科學家” 興奮地把數據輸入軟件，立刻就開始著手建立數學模型，進行假設檢驗，卻對數據的特徵一無所知！要知道，建立怎樣的模型，做怎樣的推斷，選用什麼樣的分析手段，都必須建立在你對數據內容完全熟悉的前提下，才能正確地實施。 數據分析第一步：數據清理, data cleaning。 這一步的目的很簡單，把收集來的粗糙的，充滿了缺失值和數據類型註解等等無法直接分析的數據，整理打扮成可以建模的數據庫。這個過程中，你可能需要對某些變量進行分類，可能兩三個實驗的結果需要被合併協調，可能在這個過程中你會發現數據錄入出現了一些錯誤導致數據庫裡有一些異常值，甚至是重複錄入。所以，各位小伙伴當你拿到一個數據準備分析的第一步，你必須要先了解你的數據。常用的手段包括簡單作圖，對感興趣的變量做概括分析 (summary your data!)。除此之外，由於沒有人能保證實驗中能收集到所有對象的完整數據，我們還需要分析缺失數據的特徵，思考他們為什麼會變成缺失數據。 20.2 數據類型 不同類型的數據，使用的初步描述手段各不相同。因此區分定性數據和定量數據，連續型數據，離散型數據，分類型數據顯得十分必要。 連續型變量，continuous data 連續型數據多來自實驗中對某些特徵的測量，例如身高，體重等，它們本質上是一組連續型的數據。現實生活中接觸到的許多數據也都是連續型的，例如：時間，距離，骨骼密度，藥物濃度等等。所謂連續型變量是由於它理論上可以取某段數值區間內的任何值。當然我們還會被測量尺度的精確度所局限。 離散型變量，discrete data 許多數據，是通過計數來收集的。離散型變量的本質上也是屬於數值型數據 (numeric)，特徵是這種數值型數據總是取正整數或者零。例如，醫院中發生感染的次數，一個家庭中兄弟姐妹的人數，術後患者存活天數等等。 分類型變量，categorical data 分類型變量的數據，其每一個觀察值都歸類於一種類別 (或者屬性)。分類型數據和離散型數據最大的不同是，它從本質上說就不屬於數值型數據。例如，頭髮的顏色 (紅色，黃色，黑色)，職業類型 (裝修工人，教師，總統)。儘管分類型數據本質上不是數值，分析過程中我們常常會給它們賦予一定的數值以便於計算。 二分類型數據，binary：十分常見，例如，生存/死亡，有效/無效，成功/失敗； 名義型數據，nominal：數據本身沒有高低順序之分，例如，種族，血型等； 排序型數據，ordinal：每個分類是包函了順序含義的數據，例如，回答某些問卷問題時用的 “十分同意，同意，不同意，十分不同意”，某些癌症使用的分級診斷 “一級，二級，三級，終級”，對一些結果的評價時使用的 “優，良，中，差”。 其實，對於連續型變量我們還常常會將它們轉化成分類型變量，使用一些特定的或者事先定義好的閾值 (cutoff values) 把連續型數據分組，分級，分層等等。最常見的例子就是體重指數 (BMI)，它本身是一個連續型的變量，但是又可以根據定義好的閾值把它分類成低體重 (\\(&lt; 18.5 \\; kg/m^2\\))，正常體重 (\\(18.5 - 24.9 \\; kg/m^2\\))，超重 (\\(25-29.9 \\; kg/m^2\\))，肥胖 (\\(\\geqslant 30 \\; kg/m^2\\))。另一個例子是血紅蛋白 (haemoglobin, \\(g/l\\))，它本身是一個連續型變量，但是我們利用它的閾值 (女性，\\(&lt;120 \\; g/l\\)；男性，\\(&lt; 130 \\; g/l\\))，作為診斷是否患有貧血症的依據。 把連續型變量進行分類處理的代價是信息的丟失。如果一個人的體重指數是 \\(25\\)，他/她的數據被和體重指數為 \\(29.9\\) 的人當作相同數值來對待是否合理是我們需要考慮的問題。而且許多情況下閾值的定義並不能達成共識，即使達成共識的閾值又是十分人為且恣意的，它可能導致一些相關關係被“強化”，或者反過來被“弱化”。所以，如果要對連續型數值進行分組，現在的要求是，在實驗設計階段就必須明確分組的閾值之定義，而不能在看到數據以後進行人為地劃分。更加不推薦的是直接使用四分位或者五分位來對數據分組。 20.3 如何總結並展示數據 光觀察原始數據很難真正明白數據的分佈特徵和形式，所以使用表格，或者用散點圖，柱狀圖等形式來描述數據就成為了常用的手段。前一節所描述的數據類型，決定了一組數據該如何被描述。 20.3.1 離散型分類型數據的描述 - 頻數分佈表 frequency table 下面的表格就是使用頻數分佈表來描述 cars 這個數據包中不同車速 (mph) 的分佈。汽車車速本身應該是一個連續型變量，但是這是1920年的數據當時的記錄只精確到整數，因此人為地造成了一組離散型變量的情況。下面的第二個表格使用的是繪圖瑞士軍刀包 ggplot2 裡自帶的鑽石數據。其中 cut 是對於鑽石切割水平的評價，所以是一個帶有排序性質的分組型變量。 data(&quot;cars&quot;) epiDisplay::tab1(cars$speed, graph = FALSE) ## cars$speed : ## Frequency Percent Cum. percent ## 4 2 4 4 ## 7 2 4 8 ## 8 1 2 10 ## 9 1 2 12 ## 10 3 6 18 ## 11 2 4 22 ## 12 4 8 30 ## 13 4 8 38 ## 14 4 8 46 ## 15 3 6 52 ## 16 2 4 56 ## 17 3 6 62 ## 18 4 8 70 ## 19 3 6 76 ## 20 5 10 86 ## 22 1 2 88 ## 23 1 2 90 ## 24 4 8 98 ## 25 1 2 100 ## Total 50 100 100 data(&quot;diamonds&quot;) epiDisplay::tab1(diamonds$cut, graph = FALSE) ## diamonds$cut : ## Frequency Percent Cum. percent ## Fair 1610 3.0 3.0 ## Good 4906 9.1 12.1 ## Very Good 12082 22.4 34.5 ## Premium 13791 25.6 60.0 ## Ideal 21551 40.0 100.0 ## Total 53940 100.0 100.0 離散型變量和分類型變量的描述還可以使用柱狀圖的形式來展示如下： 圖 20.2: Bar chart displaying the speed of cars 圖 20.3: Bar chart displaying distribution of evaluation of diamonds cut 上面這兩圖的 y 軸都用的是頻率，當然還可以使用百分比。不同組間分類型變量的分佈比較的話更常使用百分比作為 y 軸。如下面的表格及百分比條形圖所示。 diamonds$clarity2g &lt;- &quot;Good&quot; diamonds$clarity2g[(diamonds$clarity==&quot;I1&quot;)| (diamonds$clarity==&quot;SI2&quot;)| (diamonds$clarity==&quot;SI1&quot;)| (diamonds$clarity==&quot;VS2&quot;)] &lt;- &quot;Poor&quot; tab &lt;- stat.table(index=list(Cut=cut,Clarity=clarity2g), contents=list(count(),percent(cut)), data=diamonds, margins=T) print(tab, digits = 2) ## --------------------------------------- ## ----------Clarity----------- ## Cut Good Poor Total ## --------------------------------------- ## Fair 265.00 1345.00 1610.00 ## 1.42 3.81 2.98 ## ## Good 1191.00 3715.00 4906.00 ## 6.38 10.54 9.10 ## ## Very Good 4067.00 8015.00 12082.00 ## 21.77 22.73 22.40 ## ## Premium 3705.00 10086.00 13791.00 ## 19.83 28.61 25.57 ## ## Ideal 9454.00 12097.00 21551.00 ## 50.60 34.31 39.95 ## ## ## Total 18682.00 35258.00 53940.00 ## 100.00 100.00 100.00 ## --------------------------------------- 圖 20.4: Bar chart displaying distribution of evaluation of diamonds cut by clarity 20.3.2 連續型變量 連續型變量如果做頻數分佈表一般提供的信息量就較小。常用來描述連續型變量的手段是柱狀圖，histogram，和箱形圖，boxplot。柱狀圖應該不必過多解釋。箱形圖，展示的是連續型變量的中位數，四分位，範圍值，以及異常值。一個典型的箱形圖，中間的方形區域包括了該數據的四分位距，interquartile range (即中間 50% 的數據, IQR)。 圖 20.5: Boxplot of the diamond carat data R作出的箱形圖如 20.5 所示，箱子以上的橫線，意為最高值為75%分位值加上1.5倍的IQR；箱子以下橫線，意為最低值為25%分位值減去1.5倍的IQR。其他的觀察值如果不在這個上下限範圍之內的，會用黑點標記出來。這些值被認為是異常值 (outliers)。 20.4 數據總結方案：位置，分散，偏度，和峰度 20.4.1 位置 描述一組連續型變量的位置，location，此處的位置指的是數據分佈的中心位置，常用的數值是眾數 (mode)，中位數 (median)，均值 (mean)。 眾數 mode，的定義是，一組數據中出現最多次的數值大小； 中位數 median，的定義是，一組數據中從小到大/或者從大到小排序後50%位置的數值大小，如果觀察值有偶數個，中位數的定義是中間兩個數值的平均值大小； 算術平均值 arithmetic mean 的大小受異常值影響較大，通常簡略為均值，其定義可以用下面的表達式：\\[\\bar{X}=\\frac{1}{n}\\sum_{i=1}^n X_i\\] 幾何平均值 geometrix mean，常用在正偏態分佈數據 (positively skewed data)，其定義為： \\[\\sqrt[n]{\\prod_{i=1}^n X_i}=exp[\\frac{1}{n}\\sum_{i=1}^n log_e(X_i)]\\] 調和平均值 harmonic mean，是所有觀察值的倒數和的倒數，定義為：\\[\\frac{1}{\\frac{1}{n}\\sum_{i=1}^n\\frac{1}{X_i}}\\] 20.4.2 分散 數據的分散程度，dispersion，也就是數據的波動大小 variation。同樣均值的數據，他們的分散可能差別很大： 圖 20.6: Distributions with similar central location but different dispersion 分散程度的描述方法花樣不少，我們這裡先考慮範圍 (range)，四分位差 (interquartile range)，方差 (variance)，標準差 (standard deviation)。 20.4.2.1 範圍 range 定義：最大值和最小值的差。 缺點：受樣本量大小，以及異常值影響較大。 在表格，論文中需要同時報告最大值和最小值。 20.4.2.2 四分位差 interquartile range (IQR) 定義：四分位差是包含了數據中間 50% 數值的範圍。即，75%分位數-25%分位數的差值。 當觀察值數量為奇數個時，計算方法為：去掉中位數，計算大於中位數和小於兩個部分數值的中位數，求其差，例如：\\(5,10,12,14,16,19,22\\) 這組數字，25%分位數為10，75%分位數為19，所以IQR等於9。 當觀察值數量為偶數個時，計算方法為：計算較小的50%數值的中位數，和較大50%數值的中位數，求其差，例如：\\(5,10,12,14,16,19,22,38\\) 這組數字，上下兩半部分的中位數分別是 \\(Q_L=\\frac{10+12}{2}=11;\\;Q_U=\\frac{19+22}{2}=20.5\\)，所以，其IQR等於9.5. 在表格，論文中需要同時報告25%，75%分位數兩個數值，例：[11,20.5]。 20.4.2.3 方差和標準差 variance and standard deviation 先定義每一個觀察值和均值之間的差為 \\(D_i = X_i - \\bar{X}\\)。 根據定義，\\(\\frac{1}{n}\\sum_{i=1}^n D_i=0\\)。 樣本方差 Variance 被定義為 \\(\\frac{1}{n-1}\\sum_{i=1}^n D_i^2\\)。 樣本方差的平方根，被定義為標準差 standard deviation，\\(\\text{SD}=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n D_i^2}\\) 更常見的表達式為： \\[ \\begin{aligned} \\text{Var} &amp;= \\frac{1}{n-1}\\sum_{i=1}^n (X_i-\\bar{X})^2 \\\\ &amp;= \\frac{1}{n-1}[(\\sum_{i=1}^nX_i^2)-n\\bar{X}^2] \\end{aligned} \\] 此處分母為 \\(n-1\\) 而不是 \\(n\\) 的原因，需要參考推斷部分的解釋 (Section 10.3)。 方差標準差受異常值影響較大。例如，下面的數據： \\[ 5, 9, 12, 14, 14, 15, 16, 19, 22\\;\\;\\; \\text{Var}=25.5\\\\ 5, 9, 12, 14, 14, 15, 16, 19, 58\\;\\; \\text{Var}=241.5 \\] 20.4.3 偏度 skewness 使用柱狀圖來描述數據時，如果柱狀圖左右基本對稱 (中位數和均值基本一致)，偏度為零，正態分佈數據都是左右對稱的。如果柱狀圖右側的尾巴較長，偏度為正；如果左側的尾巴較長，偏度為負。偏度計算公式為： \\[ \\frac{\\frac{1}{n}\\sum_{i=1}^n D_i^3}{(\\frac{1}{n}\\sum_{i=1}^n D_i^2)^{\\frac{3}{2}}} \\] 圖 20.7: Relationship between skew and measures of location 20.4.4 峯度 kurtosis 峯度是描述數據分佈的最後一個指標。峯度衡量的是一組數據分佈的尾部的厚度。一個正態分佈數據，大約 5% 的數據分佈在左右兩邊的尾部 (2.5% 低於 \\(\\mu-2\\sigma\\)，2.5% 高於 \\(\\mu +2\\sigma\\))。峯度測量的是一組數據尾部數據的分佈和正態分佈兩側尾部數據之間的差距。 峯度的計算公式爲： \\[ \\frac{\\frac{1}{n}\\sum_{i=1}^nD_i^4}{(\\frac{1}{n}\\sum_{i=1}^nD_i^2)^2} \\] 一個正態分佈數據，峯度值爲 3。當左右兩段的數值佔比低於正態分佈預期時，峯度值小於 3。反之，峯度大於 3。尾部較厚 (峯度較大) 的典型分佈之一是 \\(t\\) 分佈 (圖 20.8) 圖 20.8: t distributions with 5 and 10 degrees of freedom compared with a standard normal distribution "],
["-confidence-intervals-1.html", "第 21 章 信賴區間 confidence intervals 21.1 定義 21.2 利用總體參數的樣本分佈求信賴區間 21.3 情況1：已知方差的正態分佈數據均值的信賴區間 21.4 信賴區間的意義 21.5 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間 21.6 情況3：服從正態分佈的隨機變量方差的信賴區間 21.7 當樣本量足夠大時 21.8 情況4：求人羣百分比的信賴區間 21.9 率的信賴區間", " 第 21 章 信賴區間 confidence intervals 21.1 定義 信賴區間的定義，曾經在統計推斷中介紹過 (Section 10.1)。信賴區間 (CI)，提供了一種對參數估計精確度的度量。CI，也是一種統計量，有自己的樣本分佈，它總是成對成對地出現的。L，表示下限，U，表示上限。顯著性水平 (confidence level) 下的下限和上限之間的間距大小，是由信賴區間本身的樣本分佈決定的。 一般地，對於一個總體參數 \\(\\mu\\)，它的 \\(100(1-\\alpha)\\%\\text{CI}\\) 信賴區間的含義爲： \\[ \\begin{equation} \\text{Prob}\\{\\mu\\in (\\text{L}, \\text{U}) | \\mu\\} = (1-\\alpha) \\end{equation} \\tag{21.1} \\] 所以，一個總體參數 \\(\\mu\\)，的 \\(95\\%\\text{CI}\\) 信賴區間爲： \\[ \\begin{equation} \\text{Prob}\\{ \\mu \\in (\\text{L, U}) | \\mu\\} =0.95 \\end{equation} \\tag{21.2} \\] 用公式 (21.2) 來解釋就是，區間 \\(\\text{(L, U)}\\) 內包含了總體參數 \\(\\mu\\) 的概率爲 \\(95\\%\\)。本文以下部分從公式中省略 \\(|\\mu\\) 部分。但是必須要記住，概率論環境下的信賴區間 (或者其他統計學參數估計) 都是總體參數的條件概率。在概率論語境下，信賴區間一般是左右對稱的。所以 \\(100(1-\\alpha)\\%\\text{CI}\\) 的含義可以解讀爲： \\[ \\begin{equation} \\text{Prob} \\{ \\mu \\leqslant \\text{L} \\} = \\text{Prob} \\{ \\mu \\geqslant \\text{U} \\} = \\frac{\\alpha}{2} \\end{equation} \\tag{21.3} \\] 圖 21.1: General definition of a CI for a 95% CI 21.2 利用總體參數的樣本分佈求信賴區間 總體參數的樣本分佈是求其信賴區間的關鍵。假設 \\(\\hat\\mu\\) 是總體參數 \\(\\mu\\) 的估計量。且已知存在兩個單調遞增函數 \\(A(\\mu), B(\\mu)\\) 來描述該總體參數 \\(\\mu\\) ： \\[ \\begin{equation} \\text{Prob} \\{ \\hat\\mu \\leqslant A(\\mu) \\} = \\text{Prob} \\{ \\hat\\mu \\geqslant B(\\mu) \\} = \\frac{\\alpha}{2} \\end{equation} \\tag{21.4} \\] 所以， \\[ \\begin{equation} \\text{Prob} \\{ A^{-1} (\\hat\\mu) \\leqslant \\mu \\} = \\text{Prob} \\{ B^{-1}(\\hat\\mu) \\geqslant \\mu \\} = \\frac{\\alpha}{2} \\end{equation} \\tag{21.5} \\] 因此，\\(A^{-1}(\\hat\\mu), B^{-1}(\\hat\\mu)\\) 就是我們想要找的公式 (21.3) 參數的估計信賴區間的下限 \\(\\text{L}\\)，和上限 \\(\\text{U}\\)。所以，關鍵的任務就在於，每一次尋找計算參數樣本分佈的方程 \\(A, B\\) 。 21.3 情況1：已知方差的正態分佈數據均值的信賴區間 從已知正態分佈且方差爲 \\(\\sigma^2\\) 的人羣中抽取樣本量爲 \\(n\\) 的相互獨立觀察數據 \\(Y_i (i=1,2,\\cdots,n)\\)。該樣本均值的估計量 \\(\\hat\\mu=\\bar{Y}\\)，也服從方差已知的 \\((\\frac{\\sigma^2}{n})\\) 正態分佈： \\[ \\begin{equation} \\bar{Y}\\sim N(\\mu, \\frac{\\sigma^2}{n}) \\Leftrightarrow Z=\\frac{\\bar{Y}-\\mu}{\\sqrt{\\frac{\\sigma^2}{n}}} \\sim N(0,1) \\end{equation} \\tag{21.6} \\] 所以利用標準正態分佈，往公式 (21.3) 儘可能靠：\\(\\text{Prob}\\{ Z \\leqslant z_{\\alpha/2}\\} = \\text{Prob}\\{ Z \\geqslant z_{1-\\alpha/2}\\} = \\frac{\\alpha}{2}\\) 。 把式子 (21.6) 代入以後： \\[ \\begin{equation} \\text{Prob}\\{ \\bar{Y} \\leqslant \\mu+z_{\\alpha/2}\\frac{\\alpha}{\\sqrt{n}} \\} = \\text{Prob}\\{ \\bar{Y} \\geqslant \\mu+z_{1-\\alpha/2}\\frac{\\alpha}{\\sqrt{n}} \\} = \\frac{\\alpha}{2} \\end{equation} \\tag{21.7} \\] 至此，我們找到了描述總體均值的單調函數： \\[ \\begin{aligned} A(\\mu) &amp;= \\mu + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\\\ B(\\mu) &amp;= \\mu + z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\end{aligned} \\] 由於標準正態分佈左右對稱，所以 \\(z_{\\alpha/2}=-z_{1-\\alpha/2}\\) ，因而，\\(A(\\mu) = \\mu - z_{1-\\alpha/2}\\frac{\\sigma}{n}\\)。 此時，求信賴區間上限和下限的方法應該已經一目瞭然： \\[ \\begin{equation} \\text{U} =A^{-1}(\\bar{Y})=\\bar{Y} + z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\\\ \\text{L} = B^{-1}(\\bar{Y})=\\bar{Y} - z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\end{equation} \\tag{21.8} \\] 我們也常將它簡寫成爲：\\(\\text{CI} = \\bar{Y} \\pm z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\)。 它的意義是： \\[ \\begin{equation} \\text{Prob} \\{ \\bar{Y} - z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} &lt; \\mu &lt; \\bar{Y} + z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\} = 1-\\alpha \\end{equation} \\tag{21.9} \\] 所以區間 \\((\\bar{Y} - z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}, \\bar{Y} + z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}})\\) 包含了總體參數均值 \\((\\mu)\\) 的概率是 \\(1-\\alpha\\)。我們把這個區間叫做總體均值 \\(\\mu\\) 的 \\(100(1-\\alpha)\\%\\) 信賴區間。常說的 \\(95\\%\\) 信賴區間我們使用的 \\(z_{0.975} = 1.96\\)。其他置信水平的 \\(z\\) 值舉例如下： \\[ \\begin{array}{lr} z_{0.90} = 1.28 &amp; \\text{for } 80\\% \\text{ level} \\\\ z_{0.95} = 1.645 &amp; \\text{for } 90\\% \\text{ level} \\\\ z_{0.995} = 2.58 &amp; \\text{for } 99\\% \\text{ level} \\\\ z_{0.9995} = 3.29 &amp; \\text{for } 99.9\\% \\text{ level} \\\\ \\end{array} \\] 所以，根據上面羅列的不同置信水平下 \\(z\\) 值的大小，我們不難判斷 \\(\\text{CI} = \\bar{Y} - z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\) 範圍隨着標準差增大而變寬 (不精確)，隨着樣本量增加而變窄 (精確)。 這裏補充另一個容易混淆的概念，參數估計的信賴區間公式 \\(\\text{CI} = \\bar{Y} \\pm z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\) ，和參考值範圍 (reference range) 是不同的概念。後者的公式爲 \\(\\bar{Y}\\pm z_{1-\\alpha/2} \\sigma\\)。參考值範圍的意義是， \\(95\\%\\) 的樣本數據包含在這個區間內。信賴區間，給出的是這個樣本對總體均值的估計的精確度。 21.4 信賴區間的意義 當 \\(\\alpha = 0.05\\) 時，我們說\\((\\bar{Y} - z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}, \\bar{Y} + z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}})\\) 包含了總體參數均值 \\((\\mu)\\) 的概率是 \\(95\\%\\)。但是要記住，千萬不能說：總體參數 \\(\\mu\\) 有 \\(95\\%\\) 的概率落在這個信賴區間內。因爲總體參數不是隨機變量，它不會隨我們的樣本變化而變化，它是恆定不變的。我們每一次實驗，每一次採樣，獲得的樣本數據，計算出一個新的信賴區間，這樣的區間都是在估計這個未知位置的總體參數。所以，從長遠來說，相同的實驗，重複20次，其中19次計算獲得的信賴區間，會包含真實的總體參數。 21.5 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間 多數情況下，總體的方差我們無從知曉。它也必須通過實驗數據來估計 \\(\\hat\\sigma^2\\)。那麼，下面的公式計算的統計量 \\(T\\) 服從自由度爲 \\(n-1\\) 的 \\(t\\) 分佈： \\[ T=\\frac{\\bar{Y}-\\mu}{\\sqrt{\\hat\\sigma^2/n}} \\sim t_{n-1} \\] 用跟前面類似的辦法，用統計量 \\(T\\) 取代 \\(Z\\)，我們可以求未知方差時正態分佈數據均值的信賴區間 (類比 (21.8))： \\[ \\begin{aligned} &amp;\\text{U} = \\bar{Y} + t_{n-1, 1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\\\ &amp;\\text{L} = \\bar{Y} - z_{n-1, 1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\\\ &amp;\\text{Or, equivalently :} \\\\ &amp;\\text{CI } = \\bar{Y} \\pm t_{n-1, 1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\end{aligned} \\tag{21.10} \\] 21.6 情況3：服從正態分佈的隨機變量方差的信賴區間 用 \\(Y_i (i=1,2,\\cdots,n)\\) 標記樣本量爲 \\(n\\) 的獨立觀察數據。已知該數據來自的人羣服從正態分佈，但是方差未知。那麼從統計推斷第二章 (Section 10.4) 推導過的內容，我們知道： \\[ \\begin{aligned} &amp;\\text{Sample variance is defined as: } \\\\ &amp;\\hat\\sigma^2 = \\frac{\\sum_{i=1}^n(Y_i-\\bar{Y})^2}{n-1} \\\\ &amp;\\text{and } \\\\ &amp;\\frac{(n-1)\\hat\\sigma^2}{\\sigma^2} \\sim \\chi^2_{n-1} \\\\ &amp;\\text{It follows that we want } \\\\ &amp;\\text{Prob}\\{ \\hat\\sigma^2 \\leqslant \\frac{\\sigma^2}{n-1}\\chi^2_{n-1, \\alpha/2} \\} = \\text{Prob}\\{ \\hat\\sigma^2 \\geqslant \\frac{\\sigma^2}{n-1}\\chi^2_{n-1, 1-\\alpha/2} \\} = \\frac{\\alpha}{2} \\\\ &amp; \\Rightarrow \\text{U} = \\frac{(n-1)\\hat\\sigma^2}{\\chi^2_{n-1, \\alpha/2}} \\; \\text{L} = \\frac{(n-1)\\hat\\sigma^2}{\\chi^2_{n-1, 1-\\alpha/2}} \\\\ \\end{aligned} \\] 21.7 當樣本量足夠大時 根據中心極限定理，當樣本量足夠大時，樣本均數服從正態分佈，即使樣本數據並不服從正態分佈。這就意味着，樣本足夠大，章節 21.4 中用到的均值信賴區間公式，也可適用於樣本數據不服從正態分佈的情況下。我們常使用這個定理，和章節 21.4 中的公式去計算許多總體均數以外的參數的 \\(95\\%\\) 信賴區間，通過正態分佈近似法計算獲得的信賴區間，被叫做近似信賴區間。 21.8 情況4：求人羣百分比的信賴區間 21.8.1 一般原則 用 \\(R\\) 表示 \\(n\\) 次實驗中成功的次數。如果滿足實驗相互獨立的條件，那麼 \\(R\\sim \\text{Binomial}(n,\\pi)\\)。那麼樣本比例 \\(P=\\frac{R}{n}\\) 是人羣比例 \\(\\pi\\) 的無偏估計。如果想要求 \\(\\pi\\) 的 \\(95\\%\\) 信賴區間 \\((\\pi_L, \\pi_U)\\)，我們可能自然而讓想到用成功次數 \\(R\\) 來計算。然而，由於 \\(R\\) 本身是離散型變量 (只能取大於等於零的整數)，恰好加起來概率等於 \\(95\\%\\) 的 \\(\\pi\\) 的區間是幾乎不可能計算的。我們處理比例的信賴區間的問題時，要計算的兩個下限值和上限值要滿足的條件： 尋找最小的 \\(\\pi_L\\) 滿足 \\(\\text{Prob}(\\pi_L&gt;\\pi) \\leqslant 0.025\\) 尋找最大的 \\(\\pi_U\\) 滿足 \\(\\text{Prob}(\\pi_U&lt;\\pi) \\leqslant 0.025\\) 有兩種方案可供選擇： 利用樣本分佈服從二項分佈 \\(R \\sim \\text{Binomial}(n, \\pi)\\) 的原則來“精確”計算； 正態近似法計算。 第一種方法被叫做精確法，並不是因爲它能夠精確計算恰好概率和等於 \\(95\\%\\) 的所有的 \\(\\pi\\)，而是因爲它利用的是樣本分佈的二項分佈屬性進行計算。然而隨着樣本量的增加，兩種方法計算的信賴區間結果越來越接近概率和 \\(95\\%\\)。 21.8.2 二項分佈的“精確法”計算信賴區間 例：樣本量 \\(n=20\\), 成功次數 \\(r=5\\) 時，你可以用查水錶的辦法，也可以利用 R 進行精確計算 binom.test(5, 20, conf.level = 0.95) ## ## Exact binomial test ## ## data: 5 and 20 ## number of successes = 5, number of trials = 20, p-value = 0.04 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.08657 0.49105 ## sample estimates: ## probability of success ## 0.25 下面兩個圖分別展示了當 \\(\\pi\\) 等於精確法計算的下限和上限時的概率分佈。可以看出 \\(\\pi=0.0866\\) 時，\\(\\text{Prob}\\{R \\geqslant 5\\} \\leqslant 0.025\\)。同時，當 \\(\\pi = 0.4910\\) 時， \\(\\text{Prob}\\{ R\\leqslant 5 \\} \\leqslant 0.025\\) 圖 21.2: Sampling distribution of number of successes out of 20 (R) conditional on the probability of success being 0.0866 圖 21.3: Sampling distribution of number of successes out of 20 (R) conditional on the probability of success being 0.4910 21.8.3 二項分佈的近似法計算信賴區間 當 \\(n\\) 較大時，百分比 \\(P\\) 分佈 可以用正態分佈來近似： \\[ P\\sim N(\\pi, \\sigma^2) \\text{ where } \\sigma^2 = \\frac{\\pi(1-\\pi)}{n} \\] 總體均值用樣本百分比 \\(p\\) 替代，方差用樣本方差 \\(\\hat\\sigma^2 = \\frac{p(1-p)}{n}\\)，因此，當樣本量較大時二項分佈的近似正態分佈特徵可以描述爲： \\[ P \\sim N(p, \\hat\\sigma^2) \\text{ where } \\hat\\sigma^2 = \\frac{p(1-p)}{n} \\] 接下去對與百分比的信賴區間的計算就可以套用章節 21.4 中用到的均值信賴區間公式： \\[ \\begin{aligned} &amp; P\\pm z_{1-\\alpha/2}\\sqrt{\\frac{P(1-P)}{n}} \\\\ &amp; \\text{ where } z_{1-\\alpha/2} = 1.96 \\text{ for } 95\\% \\text{CI} \\end{aligned} \\tag{21.11} \\] 正態近似法的好處是簡單，但是代價就是樣本量小時不準確。 例如： \\(n=10, r=4, p=0.4\\) 時 精確法 \\(95\\%\\) 信賴區間：0.1216, 0.7376 正態近似法 \\(95\\%\\) 信賴區間：\\(0.4\\pm1.96\\sqrt{\\frac{0.4\\times0.6}{10}} =\\) 0.0964, 0.7036 \\(n=50, r=20, p=0.4\\) 時 精確法 \\(95\\%\\) 信賴區間：0.2641, 0.5482 正態近似法 \\(95\\%\\) 信賴區間： \\(0.4\\pm1.96\\sqrt{\\frac{0.4\\times0.6}{50}} =\\) 0.2642, 0.5358 \\(n=1000, r=400, p=0.4\\) 時 精確法 \\(95\\%\\) 信賴區間：0.3695, 0.4311 正態近似法 \\(95\\%\\) 信賴區間： \\(0.4\\pm1.96\\sqrt{\\frac{0.4\\times0.6}{1000}} =\\) 0.3696, 0.4304 可以明顯看到隨着樣本量增加，信賴區間本身的範圍在不斷變小 (精確)。且正態近似法計算的信賴區間也越來越接近“精確法”。“Statistical Methods in Medical Research” (Armitage, Berry, and Matthews 2008) 書中建議，滿足 \\(n\\pi \\geqslant 10 \\text{ or } n(1-\\pi) \\geqslant 10\\) 時，正態近似法可以給出較爲滿意的百分比的信賴區間估計。 21.9 率的信賴區間 21.9.1 利用泊松分佈精確計算 假設在一段時間 \\(t\\) 內某事件發生的次數記爲 \\(Y\\)。如果每個相同事件的發生相互獨立那麼 \\(Y \\sim \\text{Poisson}(\\mu t)\\)。樣本率 \\(R=\\frac{Y}{t}\\)，是人羣事件發生概率 \\(\\mu\\) 的無偏估計。 \\[ \\text{The probability that } Y=y \\text{ is given by } \\frac{(\\mu t)^y e^{-\\mu t}}{y!} \\text{ for } y= 0,1,2,\\cdots,\\infty \\] 與前一節百分比的精確計算信賴區間相類似 (Section 21.8.2)，我們可以使用泊松分佈的性質進行計算： 尋找最小的 \\(\\mu_L\\) 滿足 \\(\\text{Prob}(\\mu_L&gt;\\mu) \\leqslant 0.025\\) 尋找最大的 \\(\\mu_U\\) 滿足 \\(\\text{Prob}(\\mu_U&lt;\\mu) \\leqslant 0.025\\) 例：某核電站附近的村莊從1968年起的10年內，發生了 6 人死於白血病。平均死亡率爲 0.6/年。計算死亡率的95%信賴區間。 可以利用 R 的精確計算發病率的代碼 poission.test 來獲得精確法率的信賴區間： poisson.test(6, 10) ## ## Exact Poisson test ## ## data: 6 time base: 10 ## number of events = 6, time base = 10, p-value = 0.3 ## alternative hypothesis: true event rate is not equal to 1 ## 95 percent confidence interval: ## 0.2202 1.3059 ## sample estimates: ## event rate ## 0.6 21.9.2 利用正態近似法計算 當樣本量較大時，發生事件次數 \\(Y\\) 近似服從正態分佈，其均值和方差均等於 \\(\\mu t\\) (參考 Section 6 推導)： \\[ Y \\sim N(\\mu t, \\sigma^2) \\text{ where } \\sigma^2=\\mu t \\] 所以事件發生率 \\(\\mu\\) 的信賴區間公式爲 \\(\\frac{Y\\pm 1.96\\sqrt{Y}}{t}\\)。 References "],
["section-22.html", "第 22 章 假設檢驗 22.1 拋硬幣的例子 22.2 二項分佈的精確假設檢驗 22.3 當樣本量較大 22.4 二項分佈的正態近似法假設檢驗 22.5 情況1：對均值進行假設檢驗 (方差已知) 22.6 情況2：對均值進行假設檢驗 (方差未知) the one-sample t-test 22.7 情況3：對配對實驗數據的均值差進行假設檢驗 the paired t-test", " 第 22 章 假設檢驗 22.1 拋硬幣的例子 對數據進行假設檢驗是統計分析最重要的部分。一般進行實驗或者調查時我們會先設定一個零假設。假如實驗或者調查中獲得的一系列數據可以認爲是相互獨立且隨機地從人羣中抽取的樣本，那麼根據零假設爲真的條件，樣本數據提供的參數估計和零假設條件下的參數應該是差距不大 (一致) 的。因爲概率論環境下，我們用樣本數據來作假設檢驗，如果樣本提供的數值比起零假設條件下的參數大很多或者小很多，我們就有理由，有證據拒絕零假設。 下面用投硬幣作爲例子說明。硬幣如果是公平的，那麼拋硬幣後正反面出現的概率應該一樣，都是 \\(50\\%\\) (零假設：\\(p=0.5\\))。假如有一枚硬幣，拋了 \\(10\\) 次只有一次是反面朝上的，我們可能就會懷疑，這枚資本主義硬幣一定是被做了手腳 (變得不再公平了)，這就是通過實驗質疑和挑戰零假設的思想。如此粗糙的想法卻是統計學假設檢驗的理論起源。只是在統計學裏面，需要制定一些規則來規定，實驗數據跟零假設 (設想) 差異達到多大時 (檢驗)，認爲證據足夠達到相信零假設“非真” (挑戰權威)。 檢驗的過程，就是計算我們朝思暮想的 \\(p\\) 值。\\(p\\) 值的定義是，當零假設爲真時，我們觀察到的實驗結果以及比這個結果更加極端 (雙側) 的情況在所有可能的情況中出現的概率。繼續使用拋硬幣的例子來說的話，跟 “\\(10\\) 次拋硬幣出現一次反面朝上” 一樣極端或者更加極端的事件有： “一次反面朝上”， “零次反面朝上”， “九次反面朝上 (或者說一次正面朝上)”， “十次反面朝上 (或者說零次正面朝上)”。 相反地，沒有觀察事件 “\\(10\\) 次拋硬幣出現一次反面朝上” 那麼極端的事件就包括了： “兩次反面朝上”， “三次反面朝上”， “四次反面朝上”， “五次反面朝上”， “六次反面朝上”， “七次反面朝上”， “八次反面朝上”。 檢驗的過程我們會定義一個被檢驗的統計量，一般就是我們感興趣的參數的估計 (estimator of a parameter of interest)。在上面拋硬幣的例子中，這個檢驗統計量就是 “硬幣反面朝上的次數”。觀察到的反面朝上次數除以拋硬幣次數 (\\(10\\) 次) 就是獲得硬幣反面朝上的概率 (參數) 的估計。用 \\(R\\) 表示十次拋硬幣中觀察到反面朝上的次數，那麼此時 \\(R\\) 就是一個服從二項分佈的隨機變量，其服從的二項分佈成功 (反面朝上事件發生) 的概率 (參數) 是\\(\\pi\\)。所以某一次實驗中 (拋十次硬幣算一次實驗)，\\(R=r\\)，那麼這次試驗的參數估計的 \\(p\\) 值被定義爲： \\[ \\begin{equation} \\text{Prob}\\{ R \\text{ as or more extreme than } r | \\pi=0.5 \\} \\end{equation} \\tag{22.1} \\] 零假設：反面朝上出現的概率是 \\(\\pi=0.5\\)；替代假設： \\(\\pi\\neq 0.5\\)。當零假設爲真時，\\(R\\sim \\text{Bin}(10, 0.5)\\)，它的零假設分佈如下圖 22.1： 圖 22.1: Binomial distribution n=10, π = 0.5 本節拋硬幣的例子我們觀察到十次拋硬幣只有一次反面朝上，\\(r=1\\)。其發生的概率等於上面列舉的四種與之同等極端或者更加極端的情況發生概率之和： \\[ \\begin{aligned} &amp;\\text{Prob} \\{R=0|\\pi=0.5\\} + \\text{Prob} \\{R=1|\\pi=0.5\\} + \\text{Prob} \\{R=9|\\pi=0.5\\} + \\text{Prob} \\{R=10|\\pi=0.5\\} \\\\ &amp; = (\\binom{10}{0} + \\binom{10}{1} + \\binom{10}{9} + \\binom{10}{10})\\times(0.5)^{10} = 0.021 \\end{aligned} \\] 22.1.1 單側和雙側檢驗 在上面的例子中其實我們已經用到了雙側檢驗的概念。例如，我們把 “九次反面朝上” 事件發生的概率當作和 “一次反面朝上” 事件發生的概率具有同等 “極端”概率事件，但是其實在圖 22.1 中也能看出兩種事件發生的方向是在概率分佈的左右兩側，這就是典型的雙側檢驗思想。一個“單側”檢驗則不考慮另一個方向發生的極端事件。 還是用本節的例子，如果要計算單側檢驗 \\(p\\) 值： \\[ \\begin{aligned} &amp;\\text{Prob}\\{R\\leqslant r| \\pi=0.5\\}\\\\ &amp;\\text{In the example } r=1 \\\\ &amp;\\Rightarrow \\text{Prob}\\{R=0 | \\pi = 0.5\\} + \\text{Prob}\\{ R=1 | \\pi = 0.5 \\} = 0.011 \\end{aligned} \\] 此時零假設爲 \\(\\pi=0.5\\)，替代假設爲 \\(\\pi &lt; 0.5\\)。 大多數時候，單側檢驗的 \\(p\\) 值十分接近雙側檢驗 \\(p\\) 值的一半。但是實施單側假設檢驗的前提是，我們有絕對的把握事件不會發生另一個方向上，但是這種情況少之又少，所以基本上你能看到的絕大多數假設檢驗計算的 \\(p\\) 值都是雙側檢驗 \\(p\\) 值。 22.1.2 \\(p\\) 值的意義 假設檢驗被認爲是作決策的一種手段。你會看到一些人使用 \\(0.05\\) 作閾值來作爲拒絕 (\\(&lt;0.05\\)) 或接受 (\\(&gt;0.05\\)) 零假設的依據。許多醫學實驗，醫學研究的結果確實是用來作決策的依據。例如某個臨牀試驗用隨機雙盲對照實驗法比較新藥物和已有藥物對某種疾病的治療效果差異，通過實驗結果來決定是否向市場和患者推廣新的治療藥物，此時 \\(p\\) 值的大小就是作決斷的重大依據。然而還有另外的很多實驗/研究並非爲了作什麼直接的決策，可能只是爲了更多的瞭解疾病發生的原因和機制。例如可能乳腺癌多發在女性少發在男性人羣，這顯然是十分顯著的差異，但是這種結果不能讓我們決策說要不要改變一個人的性別，而只是提供了疾病發生發展過程的機理上的證據。因此，許多研究者主張把 \\(p\\) 值大小當作是反對零假設證據的強弱指標。但是此處要指出的是，並非所有統計學家都認同 \\(p\\) 值大小真的可以度量證據的強弱水平。 所以，建議在寫論文，作報告時，儘量避免說：“本次實驗研究結果具有顯著的統計學意義，there was evidence that the result was statistically significant”。建議使用的語言類似這樣：“在顯著性水平爲 5% 時，本研究結果達到了統計學意義，statistically significant at the 5% level”；或者 “在顯著性水平爲 5% 時，我們的研究提供了足夠的證據證明零假設是不正確的，there was evidence that at the 5% level, that the hypothesis being tested was incorrect”。 如果一個實驗結果 \\(p\\) 值大於 0.05，可以被解讀爲：實驗結果不能提供足夠的證據證明零假設是錯誤的，there was no (or insufficient) evidence against the null hypothesis。另外還有一些人會使用一些詞語來描述 \\(p\\) 值大小：如果 \\(p=0.0001\\)，可能會被解讀爲實驗提供了“強有力的證據”，反對零假設；如果 \\(p=0.06; p=0.04\\)，會被人解讀爲是具有“臨界統計學意義，borderline statistically significant”，或者試驗結果提供了“一些證據，some evidence” 反對零假設。 22.1.3 \\(p\\) 值和信賴區間的關係 總體參數 \\(\\mu\\) 如果真的被我們計算的估計值的 \\(95\\%\\) 信賴區間所包含，那麼 \\(p &gt; 0.05\\)。如果參數 \\(\\mu\\) 不被計算的 \\(95\\%\\) 信賴區間所包含，那麼 \\(p &lt; 0.05\\)。 22.2 二項分佈的精確假設檢驗 若 \\(n\\) 次實驗中成功次數爲 \\(R\\)，那麼樣本百分比 (估計，estimator) \\(P=\\frac{R}{n}\\) 是它的人羣比例 \\(\\pi\\) (參數，parameter) 的無偏估計。欲檢驗的零假設 \\(\\pi=\\pi_0\\)，替代假設 \\(\\pi\\neq\\pi_0\\)，且某一次觀察結果爲 \\(R=r\\)，我們要計算的 \\(p\\) 值就是在零假設條件下，所有情況中 \\(R=r\\) 或者與之同等極端甚至更加極端的事件所佔的比例。 如果 \\(r&lt;n\\pi_0\\)，單側 \\(p\\) 值等於 \\[ \\begin{aligned} p &amp; = \\text{Prob}\\{ r\\text{ or fewer successes out of n | \\pi=\\pi_0} \\} \\\\ &amp; = P_0 + P_1 + P_2 + \\cdots + P_r \\\\ \\text{Where } &amp; P_x = \\binom{n}{x} \\pi_0^x (1-\\pi_0)^{n-x} \\end{aligned} \\] 如果 \\(r&gt;n\\pi_0\\)，單側 \\(p\\) 值等於 \\[ \\begin{aligned} p &amp; = \\text{Prob}\\{ r\\text{ or more successes out of n | \\pi=\\pi_0} \\} \\\\ &amp; = P_r + P_{r+1} + P_{r+2} + \\cdots + P_{n} \\\\ \\text{Where } &amp; P_x = \\binom{n}{x} \\pi_0^x (1-\\pi_0)^{n-x} \\end{aligned} \\] 一般情況下兩個單側 \\(p\\) 值很接近，所以雙側 \\(p\\) 值就可以計算其中一個然後乘以 \\(2\\)。你也可以計算兩側的單側 \\(p\\) 值然後相加。 22.3 當樣本量較大 如果樣本量 \\(n\\) 比較大，那麼計算上面的精確法是十分繁瑣的 (計算器也會累。。。)。可以考慮利用中心極限定理用正態近似法進行假設檢驗。此時需要做的就是把近似後的正態分佈標準化，然後和標準正態分佈做比較獲得 \\(p\\) 值即可： \\[ \\begin{equation} Z=\\frac{R-E(R)}{\\sqrt{\\text{Var}(R)}} = \\frac{R-E(R)}{\\text{SE}(R)} \\end{equation} \\tag{22.2} \\] 在目前爲止人類所知道的範圍內，上面公式的 \\(Z\\) 值隨着實驗樣本量 \\(n\\) 的增加而無限接近標準正態分佈 \\(N(0,1)\\)。 22.4 二項分佈的正態近似法假設檢驗 二項分佈的特徵值： \\[ E(R) = n\\pi_0; \\text{ and Var}(R) = n\\pi_0(1-\\pi_0) \\] 套用公式 (22.2)，計算 \\(Z\\) 值如下： \\[ \\begin{aligned} Z &amp; = \\frac{R-E(R)}{\\sqrt{\\text{Var}(R)}} \\\\ &amp; = \\frac{R-n\\pi_0}{\\sqrt{n\\pi_0(1-\\pi_0)}} \\\\ &amp; = \\frac{P-\\pi_0}{\\sqrt{\\frac{\\pi_0(1-\\pi_0)}{n}}} \\\\ \\text{Where } &amp; P=\\frac{R}{n} \\end{aligned} \\] 利用實驗數據的 \\(p=r/n\\)，以及零假設時的 \\(\\pi_0\\)，就可以計算上面的觀察 \\(Z\\) 值，之後查閱標準正態分佈的概率表格就可以獲得單側 \\(p\\) 值，別忘了乘以 \\(2\\)。 22.4.1 連續性校正 continuity correction 在使用正態分佈近似法進行二項分佈數據的假設檢驗時，我們其實是在使用一個連續型分佈近似一個離散型分佈，誤差通常會比較大。我們會使用矯正後的正態近似法計算 \\(Z\\) 值： \\[ Z=\\frac{|R-n\\pi_0|-\\frac{1}{2}}{\\sqrt{n\\pi_0(1-\\pi_0)}} \\text{ or } Z=\\frac{|P-\\pi_0|-\\frac{1}{2n}}{\\sqrt{\\frac{\\pi_0(1-\\pi_0)}{n}}} \\] “Statistical Methods in Medical Research” (Armitage, Berry, and Matthews 2008) 書中建議，滿足 \\(n\\pi \\geqslant 10 \\text{ or } n(1-\\pi) \\geqslant 10\\) 時近似法計算的 \\(p\\) 值可以給出較爲滿意的結果。另外，當 \\(n&gt;100\\) 則建議不再進行連續性校正，即把校正部分的 \\(-\\frac{1}{2}\\) 或者 \\(-\\frac{1}{2n}\\) 去掉。 22.5 情況1：對均值進行假設檢驗 (方差已知) 假設從已知方差 \\((\\sigma^2)\\) 的人羣中隨機抽取樣本進行血糖值測量 \\((Y_n)\\)，該樣本測量的人羣的平均血糖值爲 \\(\\mu=\\bar{Y}\\)，假設我們要比較該人羣的血糖值和某個理想血糖值 \\(\\mu_0\\)，進行假設檢驗： \\[\\text{H}_0: \\mu=\\mu_0 \\text{ v.s. H}_1: \\mu\\neq\\mu_0\\] 根據中心極限定理，當 \\(n\\) 足夠大，樣本均值 \\(\\bar{Y}\\) 的分佈接近正態分佈，且均值 \\(\\mu\\)，方差 \\(\\frac{\\sigma^2}{n}\\)。所以可以計算 \\(Z\\) 值： \\[ Z = \\frac{\\bar{Y}-E(\\bar{Y})}{\\sqrt{\\text{Var}\\bar{Y}}} = \\frac{\\bar{Y}-\\mu_0}{\\sqrt{\\sigma^2/n}} \\] 進而計算其 \\(p\\) 值： \\[ \\begin{aligned} p &amp;= \\text{Prob}(\\bar{Y}\\leqslant\\bar{y}|\\mu=\\mu_0) \\\\ &amp;= \\text{Prob}(Z&lt;\\frac{\\bar{y}-\\mu_0}{\\sqrt{\\sigma^2/n}}) \\\\ &amp;= \\Phi(\\frac{\\bar{y}-\\mu_0}{\\sqrt{\\sigma^2/n}}) \\\\ \\text{Where } &amp; \\Phi \\text{ is the distribution function for a } N(0,1) \\text{distribution} \\end{aligned} \\] 所以計算了上面的單側 \\(p\\) 值以後別忘了乘以 \\(2\\) 以獲得雙側 \\(p\\) 值： \\[ \\text{Two-sided } p \\text{ value } = 2\\times[1-\\Phi(\\frac{\\bar{y}-\\mu_0}{\\sqrt{\\sigma^2/n}})] \\] 22.6 情況2：對均值進行假設檢驗 (方差未知) the one-sample t-test 如果方差未知，我們仍要比較一個樣本均值和一個數值的話，零假設和替代假設依然不變： \\[\\text{H}_0: \\mu=\\mu_0 \\text{ v.s. H}_1: \\mu\\neq\\mu_0\\] 但是此時計算的統計量的分母，總體方差的地方使用了樣本方差 \\(\\frac{\\hat\\sigma^2}{n}\\) 替代時，該統計量不再服從標準正態分佈，而服從自由度爲 \\(n-1\\) 的 \\(t\\) 分佈。\\(t\\) 分佈看上去和標準正態分佈很像，但是其分佈的雙側尾部“較厚”，峯度大於 3： \\[ T = \\frac{\\bar{Y}-\\mu_0}{\\sqrt{\\hat\\sigma^2/n}} \\sim t_{n-1} \\] 圖 22.2: Student t distributions with 1, 4 and infinity degrees of freedom compared with a standard normal distribution 22.7 情況3：對配對實驗數據的均值差進行假設檢驗 the paired t-test 配對 t 檢驗可以用於實驗前後數據的比較，或者是某兩個對象兩兩配對時的均值比較。這樣的實驗數據我們就可以去配對數據的差值，然後利用單樣本 t 檢驗比較這個配對數據的差是否等於零。 References "],
["-association.html", "第 23 章 相關 association 23.1 背景介紹 23.2 兩個連續型變量的相關分析 23.3 二元變量之間的相關性 association between pairs of binary variables 23.4 多分類 (無排序) 的情況 \\(M\\times N\\) 表格", " 第 23 章 相關 association 23.1 背景介紹 兩個變量如果相關 (associated)，那麼它們二者中的一個的分佈是依賴另一個的分佈的 the distribution of one is dependent on the value taken by the other and vice-versa。統計學中如何描述兩個變量之間的相關關係取決於兩個變量的性質 (連續型還是分類型，continuous or categorical variables)。本章討論不同情形下兩個變量相關關係及統計學上的假設檢驗方法。 兩個變量之間的關係除了可以用相關來描述，還可以利用迴歸的手段來分析。但是迴歸分析，和本章討論的相關性分析的本質區別在於，相關分析着重討論兩個變量的聯合分佈 (joint distribution)，而迴歸分析則是要探索一個變量在另一個變量的條件下的條件分佈 (conditional distribution)。因此，相關分析從某種意義上來說是對稱的 (X 與 Y 的相關性等同於 Y 與 X 的相關性)，迴歸分析則不然 (Y 對 X 的迴歸不等同與 X 對 Y 的迴歸)。 另外一個要點是，相關分析絕不討論因果關係。 23.2 兩個連續型變量的相關分析 23.2.1 相關係數的定義 在概率論 (Section 8.2) 中也已經介紹過相關係數 \\(\\rho\\) 的定義： \\[ \\begin{equation} \\rho=\\frac{E[(X-E(X))(Y-E(Y))]}{\\sqrt{E(X-E(X))^2E(Y-E(Y))^2}} = \\frac{\\text{Cov}(X,Y)}{\\sqrt{V(X)V(Y)}} \\end{equation} \\tag{23.1} \\] 用 \\(\\textbf{x}=\\{x_1, x_2, \\cdots, x_n \\}\\) 和 \\(\\textbf{y}=\\{ y_1, y_2, \\cdots, y_n \\}\\) 表示對 \\(n\\) 個隨機研究對象測量的兩個變量。那麼這兩個變量的相關關係 \\(r\\) 的計算式爲： \\[ \\begin{equation} r = \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum(x_i-\\bar{x})^2\\sum(y_i-\\bar{y})^2}} = \\frac{S_{xy}}{S_xS_y} \\end{equation} \\tag{23.2} \\] \\(S_{xy}\\) 代表樣本數據的協方差 (Section 8.1)，\\(S_x\\) 是變量 \\(X\\) 的樣本標準差 (有時會記爲 \\(\\hat\\rho_x\\))，\\(S_y\\) 是變量 \\(Y\\) 的樣本標準差。\\(r\\) 被命名爲相關係數 \\(\\rho\\) 的 Pearson 积矩估計 (Pearson Product-Moment estimator)。 23.2.2 相關係數的性質 圖 23.1: Examples of Peason correlation coefficients 上圖 23.1 描述了9種不同設定時的相關係數 \\(r\\)。\\(r\\) 的主要性質可以總結爲： \\(r\\) 的取值範圍是 \\(-1\\sim1\\text{, i.e. } -1\\leqslant r \\leqslant 1\\)； \\(r&gt;0\\) 時，二者呈正相關， \\(r&lt;0\\) 時，二者呈負相關； 當且僅當兩個變量的散點圖呈現圖 23.1 中 A，B 顯示的直線時才有 \\(|r|=1\\)，然而直線的坡度卻與相關係數無關； 如果兩個變量之間沒有直線的 linear相關關係，那麼相關係數 \\(r\\) 會接近於零； 求 X 和 Y 的相關係數，等同於求 Y 和 X 的相關係數 (與迴歸不同)； 相關係數 \\(r\\) 沒有單位，並且位置不會發生改變 (location invariant)，如果兩個變量乘以或者除以，加上或者減去任意常數，不會改變相關係數的大小 (與迴歸不同)。 圖 23.1 中 F 顯示的相關關係可以看出，\\(r\\) 受異常值的影響很大，如果將右上角的異常值從數據中去除掉的話，該圖中的相關係數會變小到幾乎爲零。G 和 H 則表示非線性相關時，Pearson 相關係數不適用。I 則告訴我們如果不熟悉數據本身的分佈的話，如果只看總體的相關是多麼的危險 (總體爲負相關，但是在不同的分層數據中卻是呈正相關的)。 23.2.3 對相關係數是否爲零進行假設檢驗 在線性迴歸 (Section 27.6) 中會討論和證明 Pearson 相關係數和統計量 \\(t\\) 之間的關係，該公式也被用於檢驗相關係數是否爲零： \\[ \\begin{equation} T=r\\sqrt{\\frac{n-2}{1-r^2}} \\sim t_{n-2} \\end{equation} \\tag{23.3} \\] 23.2.4 相關係數的 \\(95\\%\\) 信賴區間 如果要計算相關係數 \\(r\\) 的信賴區間，我們需要知道兩個變量 \\(X,Y\\) 之間的聯合分佈 (joint distribution)。\\(X,Y\\) 如果服從二元正態分佈，可以利用 Fisher’s Z-transformation 計算相關係數的信賴區間。圖 23.2 完美展示了兩個服從二元正態分佈的三維立體概率密度分布圖。可以用鼠標拖動下面那個三維圖，就能理解什麼叫做二元正態分佈。就是無論是在 X 軸看 Y，還是在 Y 軸看 X，每一個切面都呈現正態分佈。因此二元正態分佈的概率密度方程繪製出來是成爲一個完美的鍾罩形狀。很美吧！ \\[ X|Y \\sim N(\\mu_x, \\sigma_x^2) \\text{ AND } Y|X \\sim N(\\mu_y, \\sigma_y^2) \\] 圖 23.2: Bivariate normal distribution of X and Y x10000 &lt;- rmvnorm(n=10000, mean=c(0,0), sigma=sigma.zero)#乱数10000個 plot3d(x10000[,1], x10000[,2],col = &quot;lightblue&quot;, xlab = &quot;X&quot;, ylab = &quot;Y&quot;, zlab = &quot;Probability Density&quot;, dmvnorm(x10000, mean=c(0,0), sigma=sigma.zero), type=&quot;s&quot;, size=1, lit=TRUE, main = &quot;&quot;,sub=&quot;Interactive way to see bivariate normal distribution of X and Y&quot;) You must enable Javascript to view this page properly. 如果 \\(\\rho\\neq0\\)，相關係數的樣本分佈雖然不是正態分佈，但是只要 \\(X,Y\\) 服從上面的圖形顯示的二元正態分佈，就可以利用Fisher’s Z-transformation 公式計算統計量 \\(Z_r\\)： \\[ \\begin{equation} Z_r = \\frac{1}{2}\\text{log}_e(\\frac{1+r}{1-r}) = \\text{tanh}^{-1} (r) \\end{equation} \\tag{23.4} \\] \\(Z_r\\)，近似服從正態分佈： \\[ \\begin{equation} Z_r \\sim N(\\frac{1}{2}\\text{log}_e(\\frac{1+\\rho}{1-\\rho}), \\frac{1}{n-3}) \\end{equation} \\tag{23.5} \\] 利用這個性質，我們可以計算 \\(Z_\\rho\\) 的信賴區間，然後再通過逆運算轉換之後獲得 \\(\\rho\\) 的信賴區間： \\[ \\begin{equation} \\rho = \\frac{exp(2Z_\\rho)-1}{exp(2Z_\\rho)+1} = \\text{tanh}(Z_\\rho) \\end{equation} \\tag{23.6} \\] 23.2.5 比較兩個相關係數是否相等 假設需要比較兩個相關係數，可以繼續使用 Fisher’s Z-transformation 計算相關係數之差的統計量，它服從標準正態分佈 \\(N(0,1)\\)。很少會碰到比較兩個相關係數，但是偶爾碰到的實例有這樣的：要比較男性和女性之間，食鹽攝入量和血壓的相關關係是否相同。 \\[ \\text{Test statistics} = \\frac{Z_{r_2}-Z_{r_1}}{\\sqrt{\\frac{1}{n_2-3}+\\frac{1}{n_1-3}}} \\sim N(0,1) \\] 在實際應用中，其實相關係數的比較意義並不是很大。更常見的是使用迴歸分析的手段比較兩個人羣 (男性女性) 中血壓和食鹽攝入量的迴歸係數 (即，性別對實驗和血壓的關係是否產生了交互作用，interaction)。 23.2.6 相關係數那些事兒 醫學文獻中你會碰見非常多的人使用相關係數，但是相信我，許多人都用錯了。其實比起相關係數，能提供更多信息的手段是進行迴歸分析。下面羅列一些常見的錯誤使用相關係數的例子： 圖 23.3: Effect of data restrictions on the Pearson correlation coefficient 圖 23.3 展示了同樣的一組數據，如果只是斷章取義，其相關係數可能發生極大的變化。所以，想用相關係數作合理的統計推斷，必須保證數據的完整性，否則就有玩弄數據之嫌。然而，如果你用的是線性迴歸的方法，受數據限制 (data restriction) 的影響就幾乎可以忽略不計。 圖 23.4: Effect of regression to the mean 均數迴歸現象，regression to the mean phenomenon，是指在進行重複測量時，前次測量中獲得的極高或極低分數會在後期測量時傾向於向平均值偏移，即隨着時間的推移，高分者成績下降，低分者成績升高的一種自然迴歸效應。所以在一些臨牀實驗中宣稱自己發現的測量值的變化和基線值之間的相關關係 (correlation between initial measurement and a change in that measurement)，其實是一種自然現象而不是真的存在什麼相關關係，如圖 23.4。要避免這樣的低級失誤，可以計算測量值的變化 (\\(X_2-X_1\\)) 和前後兩次測量值的均值 (\\((X_2+X_1)/2\\)) 之間的相關關係。 有些科學家聲稱自己用迴歸係數來衡量兩個變量之間的一致性 (assess agreement between variables)，這當然是完全錯誤的。兩個變量之間高度相關，和他們高度一致是完全不同的概念 (單位，測量方法，可能都不一樣怎麼可能一致呢)。你完全可以將同一個變量乘以2以後和它原來的值作相關分析，就會發現二者相關係數等於 1，但是二者數值上相差兩倍。 一般來說，迴歸模型 (regression models) 顯得比 Pearson 相關係數更加實用，能提供更多的信息用於推斷 (甚至是用一個值的變化預測另一個變量的大小)，也能避免上面舉例的錯誤使用。 23.2.7 在 R 裏面計算相關係數 圖 23.5: Association between age and height in children aged 6-36 months 在 R 裏面用 cor() 可以簡單的獲得兩個變量之間的相關係數，cor.test() 可以用於獲得相關係數的信賴區間和是否爲零的假設檢驗結果： cor(growgam1$age, growgam1$len) ## [1] 0.8676 cor.test(growgam1$age, growgam1$len) ## ## Pearson&#39;s product-moment correlation ## ## data: growgam1$age and growgam1$len ## t = 24, df = 190, p-value &lt;2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.8275 0.8990 ## sample estimates: ## cor ## 0.8676 23.3 二元變量之間的相關性 association between pairs of binary variables 兩個二元變量之間的相關性常用比值比 Odds Ratio (OR) 來衡量。跟連續型變量的 Pearson 相關係數一樣，二元變量之間的比值比也是一種對稱的特徵值。所以，X 對於 Y 的 OR，和 Y 對於 X 的 OR 是一樣的。令 \\(\\pi_{ij}\\) 表示 \\(X=i, Y=j\\) 時的概率。 表23.1： Population parameters in a \\(2\\times2\\) contingency table \\(Y = 0\\) \\(Y = 1\\) Total \\(X = 0\\) \\(\\pi_{00}\\) \\(\\pi_{01}\\) \\(\\pi_{0\\cdot}\\) \\(X = 1\\) \\(\\pi_{10}\\) \\(\\pi_{11}\\) \\(\\pi_{1\\cdot}\\) Total \\(\\pi_{\\cdot 0}\\) \\(\\pi_{\\cdot 1}\\) 1 利用表格可以看出，求 Y 對 X 的 OR 計算式爲 (horizontal)： \\[ \\Psi = \\frac{\\pi_{00}/\\pi_{01}}{\\pi_{10}/\\pi_{11}} = \\frac{\\pi_{00}\\times\\pi_{11}}{\\pi_{10}\\times\\pi_{01}} \\] 求 X 對 Y 的 OR 計算式爲 (vertical)： \\[ \\Psi = \\frac{\\pi_{00}/\\pi_{10}}{\\pi_{01}/\\pi_{11}} = \\frac{\\pi_{00}\\times\\pi_{11}}{\\pi_{10}\\times\\pi_{01}} \\] 可見兩個計算 OR (parameter) 值關係的計算式是完全等價的。 表23.2： Observed data in a \\(2\\times2\\) contingency table \\(Y = 0\\) \\(Y = 1\\) Total \\(X = 0\\) \\(O_{00}\\) \\(O_{01}\\) \\(O_{0\\cdot}\\) \\(X = 1\\) \\(O_{10}\\) \\(O_{11}\\) \\(O_{1\\cdot}\\) Total \\(O_{\\cdot 0}\\) \\(O_{\\cdot 1}\\) 1 所以用觀察數據 (Observed data, all “O”s in the table) 替代掉 OR 計算式中的 \\(\\pi\\) 可得觀察數據的 OR 估計值 (estimator) 的計算公式： \\[ \\begin{equation} \\hat\\Psi = \\frac{\\hat\\pi_{00}\\times\\hat\\pi_{11}}{\\hat\\pi_{10}\\times\\hat\\pi_{01}} = \\frac{O_{00}\\times O_{11}}{O_{10}\\times O_{01}} \\end{equation} \\tag{23.7} \\] 23.3.1 OR 的信賴區間 由於 OR 是乘法計算的結果，我們習慣上使用對數轉換 OR 以後 \\((\\text{log}(\\hat\\Psi))\\) 計算完對稱的 95% 信賴區間，然後再通過對數的反函數獲得 OR 的 95% 信賴區間。 樣本量足夠大時， \\(\\text{log}(\\hat\\Psi)\\) 的分佈是正態分佈，標準誤 (standard error) 是： \\[ \\begin{equation} \\sqrt{\\frac{1}{N\\pi_{00}}+\\frac{1}{N\\pi_{01}}+\\frac{1}{N\\pi_{10}}+\\frac{1}{N\\pi_{11}}} \\end{equation} \\tag{23.8} \\] 其中 \\(N\\pi_{ij}\\) 表示的是 \\(2\\times2\\) 表格中四個觀察數據的觀察樣本量 (sample size in the contingency table)。 所以一個 OR 的信賴區間的計算流程如下： 計算 OR 值 \\(\\hat\\Psi\\) (用公式 (23.7))； 取對數 \\(\\text{log}\\Psi\\)； 求 \\(\\text{SE}(\\text{log}\\Psi)\\) (用公式 (23.8))； 計算 \\(\\text{log}\\Psi\\) 的 \\(95\\%\\) 信賴區間：\\(\\text{log}\\Psi \\pm 1.96\\text{SE}(\\text{log}\\Psi)\\)； 求獲得的 \\(\\text{log}\\Psi\\) 的 \\(95\\%\\) 信賴區間的下限上限的對數的反函數 (自然底數的指數函數) 作爲 OR \\(\\hat\\Psi\\) 值的信賴區間。 23.3.2 比值比的假設檢驗 比值比 OR 假設檢驗時的零假設爲，二者不相關，比值比 \\(\\Psi=1\\)。所以：\\(\\text{H}_0: \\Psi = 1 \\text{ or log}_e(\\Psi) = 0\\)。 這個零假設可以用計算信賴區間時的性質進行： \\[ z=\\frac{\\text{log}(\\hat\\Psi)}{SE(\\text{log}_e(\\Psi))} \\sim N(0,1) \\] 另外更加常用的檢驗 OR 值是否等於 1 的檢驗方法有下面兩種： 樣本量大時：\\(\\chi^2\\) 的擬合優度檢驗 goodness of fit test； 小樣本時：Fisher 的精確檢驗法 Fisher’s exact test。 23.3.3 兩個百分比的卡方檢驗 檢驗統計量如下： \\[ \\begin{aligned} \\chi^2 &amp;= \\sum_i\\sum_i(\\frac{(O_{ij}-E_{ij})^2}{E_{ij}}) \\\\ \\text{Where } &amp;E_{ij} = \\frac{O_{i\\cdot}\\times O_{\\cdot j}}{O_{\\cdot\\cdot}} \\end{aligned} \\tag{23.9} \\] 計算獲得了卡方值之後和自由度爲 1 的卡方分佈相比較獲得雙側 \\(p\\) 值。 優化版本 用連續性校正法： \\[ \\begin{aligned} \\chi^2 &amp;= \\sum_i\\sum_i(\\frac{(|O_{ij}-E_{ij}| - 0.5)^2}{E_{ij}}) \\\\ \\text{Where } &amp;E_{ij} = \\frac{O_{i\\cdot}\\times O_{\\cdot j}}{O_{\\cdot\\cdot}} \\end{aligned} \\tag{23.10} \\] 23.3.4 確切檢驗法 Fisher’s “exact” test 如果 \\(2\\times2\\) 表格中的四個數字的 期待值 均大於 5，那麼用上面的卡方檢驗沒有問題，如果期待值都很小，就建議要使用精確檢驗法。 確切檢驗法的思想理論是超幾何分佈 (Section 5.2)，在四個表格邊緣合計固定不變的條件下，利用下面公式 (23.11) 直接計算表內四個格子數據的各種組合的概率，然後計算單側或者雙側累計概率，與顯著性水平 \\(\\alpha\\) 比較。 \\[ \\begin{aligned} P_{O_{00}} &amp; = \\text{Prob}(O_{00},O_{01},O_{10},O_{11}|O_{0\\cdot},O_{1\\cdot},O_{\\cdot0},O_{\\cdot1}) \\\\ &amp; = \\frac{O_{0\\cdot}!O_{1\\cdot}!O_{\\cdot0}!O_{\\cdot1}!}{O_{\\cdot\\cdot}!O_{00}!O_{01}!O_{10}!O_{11}!} \\end{aligned} \\tag{23.11} \\] 在 R 裏可以用 fisher.test 對四格表內容進行確切檢驗。 x3 &lt;- matrix(c(7,5,3,8), ncol = 2, byrow = TRUE) addmargins(x3) ## Sum ## 7 5 12 ## 3 8 11 ## Sum 10 13 23 fisher.test(x3) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: x3 ## p-value = 0.2 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 0.4942 31.9433 ## sample estimates: ## odds ratio ## 3.513 23.4 多分類 (無排序) 的情況 \\(M\\times N\\) 表格 卡方檢驗可以推廣到兩個多分類變量之間的相關分析。 \\[ \\begin{aligned} &amp; \\chi^2 = \\sum_i\\sum_j(\\frac{(O_{ij}-E_{ij})^2}{E_{ij}}) \\\\ &amp; \\text{Where } E_{ij} = \\frac{O_{i\\cdot}O_{\\cdot j}}{O_{\\cdot\\cdot}} \\\\ &amp; \\text{Under H}_0: \\chi^2 \\sim \\chi^2_{(m-1)\\times(n-1)} \\end{aligned} \\] 表23.3： Observed data in a \\(M\\times N\\) contingency table \\(Y = 1\\) \\(Y = 2\\) \\(\\cdots\\) \\(Y = n\\) Total \\(X = 1\\) \\(O_{11}\\) \\(O_{12}\\) \\(\\cdots\\) \\(O_{1n}\\) \\(O_{1\\cdot}\\) \\(X = 2\\) \\(O_{21}\\) \\(O_{22}\\) \\(\\cdots\\) \\(O_{2n}\\) \\(O_{2\\cdot}\\) \\(\\cdots\\) \\(\\cdots\\) \\(\\cdots\\) \\(\\cdots\\) \\(\\cdots\\) \\(\\cdots\\) \\(X = m\\) \\(O_{m1}\\) \\(O_{m2}\\) \\(\\cdots\\) \\(O_{mn}\\) \\(O_{m\\cdot}\\) Total \\(O_{\\cdot 1}\\) \\(O_{\\cdot 2}\\) \\(\\cdots\\) \\(O_{\\cdot n}\\) \\(O_{\\cdot\\cdot}\\) "],
["-comparisons.html", "第 24 章 比較 Comparisons 24.1 比較兩個均值 comparing two population means 24.2 兩個人羣的方差比較 24.3 比較兩個百分比", " 第 24 章 比較 Comparisons 本章暫且只討論兩組之間的比較 (均值，方差，百分比)； 本章也只討論兩種類型的變量，連續型和二分類型變量； 本章會介紹點估計 (point estimation)，信賴區間計算 (confidence intervals)，假設檢驗 (hypothesis testing)。 24.1 比較兩個均值 comparing two population means 24.1.1 當方差已知，且數據服從正態分佈 Z-test 令 \\(Y_{1i} (i=1,2,\\cdots, n_1); Y_{2i} (i=1,2,\\cdots, n_2)\\) 表示兩個獨立且隨機的變量，他們來自兩個人羣 (1 和 2)，且各自的人羣均值爲 \\(\\mu_k\\)，方差爲 \\(\\sigma_k^2\\)： \\[ E(Y_{ki})=\\mu_k \\text{ and Var}(Y_{ki}) = \\sigma_k^2 \\text{ for } k=1,2 \\text{ and } i= 1,2,\\cdots,n_k \\] 用樣本均值 \\(\\bar{Y}_k\\) 作爲總體均值 \\(\\mu_k\\) 的估計： \\[ \\bar{Y}_k \\sim N(\\mu_k, \\frac{\\sigma_k^2}{n_k}) \\text{ for } k=1,2 \\] 如果兩個樣本的觀察值互相獨立，我們知道均值差 \\(\\bar{Y}_2 - \\bar{Y}_1\\)，也服從下面描述的正態分佈： \\[ \\begin{equation} \\bar{Y}_2-\\bar{Y}_1 \\sim N(\\mu_2-\\mu_1, \\frac{\\sigma^2_2}{n_2}+\\frac{\\sigma^2_1}{n_1}) \\end{equation} \\tag{24.1} \\] 根據這個性質，可以計算均值差的統計量 \\(Z\\)： \\[ \\begin{equation} Z=\\frac{\\bar{Y}_2-\\bar{Y}_1}{\\sqrt{(\\sigma_2^2/n_2)+(\\sigma_1^2)/n_1}} \\sim N(\\frac{\\mu_2-\\mu_1}{\\sqrt{(\\sigma_2^2/n_2)+(\\sigma_1^2)/n_1}},1) \\end{equation} \\tag{24.2} \\] 所以 \\(\\bar{Y}_2-\\bar{Y}_1\\) 的樣本分佈 (24.2)，就可以應用於爲 \\(\\mu_2-\\mu_1\\) 計算顯著性水平爲 \\(\\alpha\\) 的 \\(100(1-\\alpha)\\%\\) 信賴區間，或者進行假設檢驗。 用信賴區間章節 (Section 21.4) 學到的方法，均值差的信賴區間的下限 \\(L\\)，和上限 \\(U\\)，分別是： \\[ \\begin{aligned} L &amp; = (\\bar{Y}_2 - \\bar{Y}_1) + z_{\\alpha/2}\\sqrt{\\frac{\\sigma_2^2}{n_2}+\\frac{\\sigma_1^2}{n_1}}\\\\ U &amp; = (\\bar{Y}_2 - \\bar{Y}_1) + z_{1-\\alpha/2}\\sqrt{\\frac{\\sigma_2^2}{n_2}+\\frac{\\sigma_1^2}{n_1}} \\end{aligned} \\] 由於標準正態分佈左右對稱 \\(z_{\\alpha/2}=-z_{1-\\alpha/2}\\)，所以\\(100(1-\\alpha)\\%\\) 信賴區間爲： \\[ \\begin{equation} (\\bar{Y}_2 - \\bar{Y}_1) \\pm z_{1-\\alpha/2}\\sqrt{\\frac{\\sigma_2^2}{n_2}+\\frac{\\sigma_1^2}{n_1}} \\end{equation} \\tag{24.3} \\] 進行均值差的假設檢驗時，零假設是均值差等於零 \\(\\text{H}_0: \\mu_2-\\mu_1 = 0\\)；替代假設是均值差不等於零 \\(\\text{H}_1: \\mu_2-\\mu_1\\neq0\\)。 在零假設條件下 \\(\\mu_2-\\mu_1 = 0\\)，公式 (24.2) 計算的均值差的檢驗統計量 \\(Z\\) 服從標準正態分佈 \\(Z\\sim N(0,1)\\)。根據章節 22.5 同理知雙側 \\(p\\) 值的計算式爲： \\[ \\begin{equation} 2[1-\\Phi(\\frac{|\\bar{y}_2-\\bar{y}_1|}{\\sqrt{(\\sigma_2^2/n_2)+(\\sigma_1^2/n_1)}})] \\end{equation} \\tag{24.4} \\] 此時，我們進行的假設檢驗，計算的信賴區間用到的前提有： 兩組的觀察數據 \\(Y_{ki}\\) 均服從正態分佈； 所有的觀察對象互相獨立； 兩組數據來自的人羣的方差已知。 違反這些前提的話： 1. 如果不滿足前提 1，對統計結果影響不會很大，只要觀察樣本較大，均值或者均值差本身的樣本分佈也就服從了正態分佈 (中心極限定理)； 2. 如果不滿足前提 2，則不應該採用此方法，觀察對象本身如果有一定的結構構成或者不滿足相互獨立，本方法不適用； 3. 前提 3，大多數現實例子中都不太可能滿足，因爲總體/人羣的方差多數情況下都是未知的，所以，下一小節討論方差未知的情況，逐漸放寬我們的統計分析前提條件。 24.1.2 當方差未知，但是方差可以被認爲相等，且數據服從正態分佈 two sample \\(t\\) test 如果兩組數據來自的人羣可以被認爲方差是齊的 \\(\\sigma_1^2=\\sigma_2^2=\\sigma^2\\)，公式 (24.1) 可以變爲： \\[ \\bar{Y}_2-\\bar{Y}_1 \\sim N(\\mu_2-\\mu_1, \\sigma^2(\\frac{1}{n_2}+\\frac{1}{n_1})) \\] 但是這個分佈中的方差是未知的，所以除了均值和均值差，這個共同的方差也變成了需要用樣本方差 \\(\\hat{\\sigma}^2\\) 來作估計。此時，兩個樣本的方差的無偏估計爲，加權方差： \\[ \\begin{equation} \\hat\\sigma^2 = \\frac{(n_1-1)\\hat\\sigma^2_1+(n_2-1)\\hat\\sigma^2_2}{n_1+n_2-2} \\end{equation} \\tag{24.5} \\] 因爲 \\(\\frac{(n_1-1)\\hat\\sigma^2_1}{\\sigma^2} \\sim \\chi^2_{n_1-1}; \\frac{(n_2-1)\\hat\\sigma^2_2}{\\sigma^2} \\sim \\chi^2_{n_2-1}\\)，所以兩樣本的加權方差 \\(\\hat\\sigma^2\\) 服從自由度爲 \\(n_1+n_2-2\\) 的卡方分佈： \\[ \\frac{(n_1+n_2-2)\\hat\\sigma^2_1}{\\sigma^2} \\sim \\chi^2_{n_1+n_2-2} \\] 所以，此時的檢驗統計量 \\(T\\)，服從自由度爲 \\(n_1+n_2-2\\) 的 \\(t\\) 分佈： \\[ T=\\frac{(\\bar{Y}_2-\\bar{Y}_1) - (\\mu_2-\\mu_1)}{\\hat\\sigma\\sqrt{(1/n_2)+(1/n_1)}} \\sim t_{n_1+n_2-2} \\] 接下來就可以利用這個統計量進行假設檢驗，求均值差的 \\(100(1-\\alpha)\\%\\) 信賴區間，類比章節 21.5： \\[ (\\bar{Y}_2-\\bar{Y}_1) \\pm t_{n_1+n_2-2, 1-\\alpha/2}\\hat\\sigma\\sqrt{(1/n_2)+(1/n_1)} \\] 24.1.3 練習 下表展示的是，隨機將11名嬰兒分配到實驗組和對照組，記錄嬰兒能夠獨立行走的月齡。試用表格總結的數據進行能獨立行走的月齡的均值是否在實驗組和對照組之間有差異的假設檢驗，並求月齡均差的 \\(95\\%\\) 信賴區間。 表 24.1: Children’s ages at time of first walking alone by randomisation group Age in months for walking alone Active exercise group (i=1) Eight week control group (i=2) 9.00, 9.50, 9.75, 10.00, 13.00, 9.50 13.25, 11.50, 12.00, 13.50, 11.50 \\(n_i\\) 6 5 \\(\\bar{Y}_i\\) 10.125 12.350 \\(\\hat\\sigma_i\\) 1.447 0.962 解 假設 \\(\\text{H}_0: \\mu_2-\\mu_1 = 0 \\text{ v.s } \\text{H}_1: \\mu_2-\\mu_1 \\neq 0\\) 假如，實驗組對照組的月齡方差可以認爲是方差相同的，那麼他們的加權方差則可以計算爲： \\[ \\hat\\sigma^2 = \\frac{(6-1)\\times(1.447)^2+(5-1)\\times(0.962)^2}{6+5-2} = \\frac{14.172}{9} = 1.575 \\] 零假設條件下，則檢驗統計量 \\(T\\) 服從自由度爲 \\(9\\) 的 \\(t\\) 分佈，本例的數據給出的檢驗統計量大小爲： \\[ T=\\frac{12.350-10.125}{\\sqrt{1.575\\times(1/5+1/6)}} = \\frac{2.225}{0.76} = 2.928 \\] 通過查閱統計數據表格： 圖 24.1: T-Distribution table (0ne-Tail) 圖 24.1 中顯示統計量 \\(t=2.928\\) 的單側 \\(p\\) 值介於 \\(0.01\\sim0.005\\) 之間，所以此例的雙側 \\(0.01 &lt; p &lt; 0.02\\)。 均值差 \\(\\mu_2-\\mu_1\\) 的 \\(95\\%\\) 信賴區間爲： \\[ \\begin{aligned} (\\bar{Y}_2-\\bar{Y}_1) &amp;\\pm t_{9, 0.975}\\hat\\sigma\\sqrt{(1/n_2)+(1/n_1)} \\\\ = 2.225 &amp;\\pm 2.262 \\times 0.76 = (0.51, 3.94) \\end{aligned} \\] 上面的手計算過程，如果你像我一樣運氣好可能在考場上碰到，實際生活中我們肯定是使用 R 進行計算拉。下面用了兩種不同的代碼，但是結果和目的都是一樣的： t.test() 時指定 var.equal = TRUE或者用簡單線性迴歸的代碼 lm()。 t.test(Walk$Age ~ Walk$Group, var.equal = TRUE) ## ## Two Sample t-test ## ## data: Walk$Age by Walk$Group ## t = -2.9, df = 9, p-value = 0.02 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -3.9437 -0.5063 ## sample estimates: ## mean in group exercise mean in group control ## 10.12 12.35 summary(lm(Age ~ Group, data = Walk)) ## ## Call: ## lm(formula = Age ~ Group, data = Walk) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.125 -0.738 -0.375 0.388 2.875 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.125 0.512 19.77 1e-08 *** ## Groupcontrol 2.225 0.760 2.93 0.017 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.25 on 9 degrees of freedom ## Multiple R-squared: 0.488, Adjusted R-squared: 0.431 ## F-statistic: 8.58 on 1 and 9 DF, p-value: 0.0168 24.1.4 當方差未知，但是方差不可以被認爲相等，且數據服從正態分佈 下一節會討論如何比較方差是否齊的手段，用於本節分析方法在實際應用時的參考。 當兩組連續型正態分佈的數據不能被認爲方差相同時，有幾種方法可以採用。一是將數據通過數學轉換 (log-transformed, etc.)，人爲的把方差的差異縮小以後，使用前一節的齊方差時的均值比較法 (two-sample \\(t\\) test)。另一種方法是，既然方差不齊，那就用各自的觀察數據來估計其方差 \\((\\hat\\sigma_1^2, \\hat\\sigma_2^2)\\)。只要各自的樣本量較大 \\(n_1, n_2\\)，兩組數據均值差 \\(|\\bar{y}_2-\\bar{y}_1|\\) 除以其合併後的標準誤 \\(\\sqrt{\\frac{\\hat\\sigma_1^2}{n_1}+\\frac{\\hat\\sigma_2^2}{n_2}}\\)。利用公式 (24.3) 和 (24.4)，把已知的兩組數據各自的方差用樣本方差取代之後即可用於計算信賴區間，實施假設檢驗求 \\(p\\) 值。 但是，當兩組觀察數據的樣本量不大時 \\((&lt; 30)\\)，根據 Welch–Satterthwaite 建議的，估計均值差除以估計標準誤服從一個自由度爲 \\(n^*\\) 的 \\(t\\) 分佈。值得注意的是，這個自由度並非正整數： \\[ n^*=\\frac{(\\frac{\\hat\\sigma_1^2}{n_1}+\\frac{\\hat\\sigma_2^2}{n_2})^2}{[\\frac{(\\hat\\sigma_1^2/n_1)^2}{n_1-1}] + [\\frac{(\\hat\\sigma_2^2/n_2)^2}{n_2-1}]} \\] 在 R 裏可以指定 var.equal = TRUE 進行 \\(t\\) 檢驗： t.test(Walk$Age ~ Walk$Group, var.equal = FALSE) ## ## Welch Two Sample t-test ## ## data: Walk$Age by Walk$Group ## t = -3, df = 8.7, p-value = 0.01 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -3.8879 -0.5621 ## sample estimates: ## mean in group exercise mean in group control ## 10.12 12.35 值得注意的是在 R 裏面，\\(t\\) 檢驗是默認組間方差不齊的，如果你沒有指定 var.equal = TRUE，R 就會默認進行上面的方差不齊的 \\(t\\) 檢驗。 24.2 兩個人羣的方差比較 24.2.1 方差比值檢驗 variance ratio test 前一節介紹的樣本均值比較中一個重要的前提是方差齊不齊的問題，所以本節我們就來討論如何比較兩個人羣的方差是否相同，進而爲均值比較時是選用方差齊的檢驗方法 (two sample \\(t\\) test) 還是方差不齊的方法 (Welch Two Sample \\(t\\) test) 提供有價值的參考信息。 比較方差是否相同，最簡單的是利用 \\(F\\) 檢驗，也就是標題的方差比值檢驗 variance ratio test。和大多數檢驗方法一樣，多數情況下進行的也是雙側檢驗，零假設是方差齊，替代假設是方差不齊。 同前例，我們用 \\(Y_{1i} (i=1,2,\\cdots, n_1), Y_{2i} (i=1,2,\\cdots,n_2)\\) 標記兩組從兩個不同人羣中隨機觀察的獨立樣本數據。兩個數據服從正態分佈。檢驗統計量是兩個方差之比 \\(F=\\frac{\\hat\\sigma_1^2}{\\hat\\sigma_2^2}\\)。這個比值距離零假設條件下的 1 越遠，證明兩個方差不相同的證據越強。 此時需要有 \\(F\\) 分佈的知識，具體的推導和證明需要參考統計推斷部分 (Section 17.2)，此處直接使用其結論。如果兩個獨立變量，各自服從相應自由度的卡方分佈，那麼他們各自除以自由度後的商，服從 \\(F\\) 分佈。正式的數學定義描述如下： \\[ \\begin{aligned} &amp; \\text{If } A\\sim \\chi_a^2 \\text{ and } B \\sim \\chi_b^2 \\text{ independently} \\\\ &amp; \\text{then } F = \\frac{A/a}{B/b} \\sim F_{a,b} \\end{aligned} \\] 在應用方差比值檢驗時，零假設條件下 (方差相等)，兩方差自由度分別是 \\(n_1-1, n_2-1\\)，故 \\(F=\\frac{\\hat\\sigma_1^2}{\\hat\\sigma_2^2} \\sim F_{n_1-1, n_2-1}\\)，即服從自由度爲 \\(n_1-1, n_2-1\\) 的 \\(F\\) 分佈。所以需要比較計算所得的統計量 \\(F\\) 值的大小和相應自由度的 \\(F\\) 分佈。 比較方差大小時，習慣上先計算兩樣本的方差，然後把較大的那個當作分子除以較小的那個，由此計算的檢驗統計量就會總是大於 \\(1\\)。此時我們查閱統計表格獲得的 \\(p\\) 值是單側的，你可以將之乘以 \\(2\\)，或者計算另一半 \\(p\\) 值相加即可。\\(F\\) 檢驗高度依賴數據服從正態分佈這一前提。在 R 裏面 var.test() 是進行 \\(F\\) 檢驗的代碼，另外包 car 裏還有 leveneTest() 是一種更加穩健的比較方差的方法，適用於數據不服從正態分佈時： var.test(Walk$Age~Walk$Group) ## ## F test to compare two variances ## ## data: Walk$Age by Walk$Group ## F = 2.3, num df = 5, denom df = 4, p-value = 0.4 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.2417 16.7226 ## sample estimates: ## ratio of variances ## 2.264 leveneTest(Age ~ Group, data = Walk, center = median) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 0 0.95 ## 9 24.2.2 信賴區間 類比章節 21.6，可以容易地推導出方差比值 \\(\\frac{\\sigma_1^2}{\\sigma_2^2}\\) 的 \\(95\\%\\) 信賴區間公式爲： \\[ \\begin{equation} (\\frac{F}{F_{n_1-1,n_2-1, 0.975}} , \\frac{F}{F_{n_1-1,n_2-1,0.025}}) \\end{equation} \\tag{24.6} \\] 上面的式子會需要計算檢驗統計量 \\(F\\) 值左側的 \\(p\\) 值，一般的檢驗統計表個不提供。但是利用 \\(F\\) 分佈的性質如果 \\(F\\sim F_{a,b}\\) 那麼 \\(\\frac{1}{F} \\sim F_{b,a}\\) ，所以下面的公式在查閱表格時更加實用： \\[ (\\frac{F}{F_{n_1-1,n_2-1, 0.975}} , F\\times F_{n_2-1,n_1-1,0.975}) \\] 24.3 比較兩個百分比 24.3.1 兩個百分比差是否爲零的推斷 Risk difference 令 \\(R_1, R_2\\) 爲兩種不同實驗的成功次數，每種實驗進行的次數分別是 \\(n_1, n_2\\)。類似地，令 \\(P_1, P_2\\) 表示兩種實驗的觀察勝率。所以 \\(R_1, R_2\\) 服從二項分佈：\\(R_k \\sim \\text{Bin}(n_k, \\pi_k) \\text{ for } k=1,2\\)。所以有： \\[ \\begin{aligned} &amp; E(P_k) = \\pi_k \\text{ and Var}(P_k) = \\frac{\\pi_k(1-\\pi_k)}{n_k} \\\\ &amp; \\text{For } k = 1,2 \\text{ and } P_1, P_2 \\text{ independent } \\end{aligned} \\] 當 \\(n_k\\) 足夠大，每個百分比都可以根據中心極限定理用下面的正態分佈來近似： \\[ P_k \\sim N(\\pi_k, \\frac{\\pi_k(1-\\pi_k)}{n_k}) \\text{ for } k= 1,2 \\] 由於兩樣本是獨立的，所以百分比差也是服從下面的正態分佈的： \\[ \\begin{equation} P_2-P_1 \\sim N(\\pi_2-\\pi_1, \\frac{\\pi_1(1-\\pi_1)}{n_1}+\\frac{\\pi_2(1-\\pi_2)}{n_2}) \\end{equation} \\tag{24.7} \\] 所以，作大樣本的百分比比較時，百分比差 \\(\\pi_2-\\pi_1\\) 的 \\(100(1-\\alpha)\\%\\) 信賴區間公式爲： \\[ (P_2-P_1) \\pm z_{1-\\alpha/2}\\sqrt{\\frac{P_1(1-P_1)}{n_1}+\\frac{P_2(1-P_2)}{n_2}} \\] 進行的百分比差的假設檢驗爲： \\(\\text{H}_0: \\pi_2-\\pi_1 = 0 \\text{ v.s. H}_1: \\pi_2-\\pi_1 \\neq 0\\) 檢驗統計量 \\(Z\\) 爲： \\[ \\begin{aligned} &amp; Z=\\frac{P_2-P_1}{\\sqrt{P(1-P)(\\frac{1}{n_2}+\\frac{1}{n_1})}} \\sim N(0,1) \\\\ &amp; \\text{Where } P=\\frac{R_1+R_2}{n_1+n_2} \\text{ is the marginal probability of success} \\\\ &amp; p\\text{-value} = 2\\times(1-\\Phi\\{ \\frac{|P_2-P_1|}{\\sqrt{P(1-P)(\\frac{1}{n_2}+\\frac{1}{n_1})}} \\}) \\end{aligned} \\] 24.3.2 兩個百分比商是否爲 1 的推斷 relative risk/risk ratio 兩個百分比商，在流行病學中通常使用相對危險度 (relative risk) 或者危險度比 (risk ratio) 來表示。從樣本數據中獲得的相對危險度比的估計爲 \\(RR=\\frac{P_2}{P_1}\\)。樣本量大時，百分比近似服從正態分佈，所以百分比差也近似服從正態分佈，然而百分比商則不然。此時用到數據的轉換，將百分比商求對數以後 \\(\\text{log}\\frac{P_2}{P_1}\\) ，得到近似正態分佈的對數樣本分佈進而進行假設檢驗，計算信賴區間。 下一章會着重介紹數據的轉換 (transformation)，本章暫且先用其結論，當 \\(Y_k=\\text{log}(P_k)\\) ，其方差爲 \\(\\text{Var}(Y_k) = \\frac{1-\\pi_k}{n_k\\pi_k}\\)，所以此方差的估計量爲 \\(\\frac{1-P_k}{R_k}\\)。 由此可得 \\(\\text{log}\\frac{\\pi_2}{\\pi_1}\\) 的 \\(95\\%\\) 信賴區間公式爲： \\[ \\text{log} \\frac{P_2}{P_1} \\pm 1.96\\times\\sqrt{\\frac{1-P_1}{R_1}+\\frac{1-P_2}{R_2}} \\] 如果把上面式子計算的 \\(\\text{log}\\frac{\\pi_2}{\\pi_1}\\) 的 \\(95\\%\\) 信賴區間標記爲 \\((L,U)\\)，那麼相對危險度 \\(\\frac{\\pi_2}{\\pi_1}\\) 的 \\(95\\%\\) 信賴區間爲 \\((exp(L), exp(U))\\)。 "],
["-assumptions-and-transformations.html", "第 25 章 前提和數據轉換 Assumptions and transformations 25.1 穩健性 25.2 正態性 25.3 總結連續型變量不服從正態分佈時的處理方案 25.4 數學冪轉換 power transformations", " 第 25 章 前提和數據轉換 Assumptions and transformations 幾乎所有的統計分析手法都有自己的前提條件，所以重要的問題來了： 在多大的程度上分析結果引導的結論會依賴於這些前提？ 有沒有方法檢驗，至少檢查數據是否滿足前提條件？ 如果數據無法滿足相應的前提條件，該怎麼辦？ 目前爲止，分析方法中接觸到的簡單統計檢驗法中典型的前提舉例如下： 單樣本 \\(t\\) 檢驗 (Section 22.6) 需要的前提條件是所有的觀察數據 相互獨立 independent； 服從正態分佈 normally distributed。 事件發生率的信賴區間計算 (Section 21.9) 需要的前提條件是 事件發生的件數服從泊松分佈 Poisson distributed。 兩個百分比的卡方檢驗 (Section 23.3.3 and Section 24.3.1) 需要的前提條件是 兩組數據中成功次數的數據服從二項分佈 Binomial distributed。 當觀察數據可能不滿足上述前提條件時，一個最爲常用的手段是對原始數據進行數學轉換 (transformation)。然而，數學轉換會對推斷的結果意義產生影響： 數學轉換以後的數據可能更加滿足前提條件，不好的數學轉換則可能使轉換後的數據更加偏離前提條件； 數學轉換以後，改變了統計結果的現實意義，change the ease of interpretation of the results。 比方說，一組採樣獲得的血壓數據，你發現把原始數據開根號之後的結果可以符合正態分佈的前提，但是此種轉換最大的缺點是，轉換後的數據使用 two sample \\(t\\) test 時比較的不再是均值差，而是開根號之後的差。這就導致了無法良好的解釋這樣的差異在實際生活中有什麼意義 (臨牀上的意義)，換句話說，醫生和患者是無法理解什麼是根號血壓差的 \\(\\sqrt{\\text{mmHg}}\\)。 25.1 穩健性 其實應用統計學方法時真實數據多多少少會偏離一些前提條件，在某些前提條件不能滿足的情況下，分析結果是否穩健 (robustness) 有如下不太精確但是廣泛被接受的定義： A statistical procedure is robust if it performs well when the needed assumptions are not violated “too badly”, or if the procedure performs well for a large family of probabilty distributions. — van Belle et al. (p253) (Belle et al. 2004) 那麼什麼情況下可以說一個統計方法是表現良好的呢，performing well？ 我們說一個統計方法表現良好，是指該方法用於定義是否有意義的臨界值，或者叫名義顯著性水平 (nominal signficance level)，和實際上計算的檢驗統計量在所有的可能中達到或超過該臨界值的概率 (actual probability the test statistic exceeds the cut-off)。用 \\(t\\) 檢驗舉例如下： \\[ \\text{Prob}(|T| &gt; t_{df,0.975} | \\text{H}_0 \\text{true}) = 0.05 \\] 類似地，我們說一個信賴區間的計算方法表現良好，是指該方法計算獲得的 \\(95\\%\\) 信賴區間包含真實參數值的概率真的可以無限接近 \\(95\\%\\)： \\[ \\text{Prob}(\\mu \\in (L, U) | \\mu) = 0.95 \\] 一些常見方法的穩健性列舉： 樣本量小且分佈偏度越大時，依賴正態分佈前提的信賴區間計算和其他的檢驗手段就變得不再可靠； 兩個方差比較時使用的 \\(F\\) 檢驗 (Section 24.2.1) 常常由於數據不服從正態分佈缺乏穩健性，即使樣本量較大也不能改善； 根據中心極限定理，樣本量足夠大時，單樣本 \\(t\\) 檢驗 (Section 22.6) 具有良好的穩健性。 一般地，基於均值的檢驗方法都相對其他統計量較爲穩健。 25.2 正態性 大多數情況下，正如我們在這個部分最開頭的章節提到的，拿到數據以後先用圖形手段探索，並熟悉該數據。從圖形來判斷一組數據是否接近正態分佈或者偏離正態分佈。常用的探索連續型變量是否服從正態分佈的圖形方法是： 箱形圖，box and whisker plot，如圖 20.5； 柱狀圖，histogram，如圖 25.1； 正態分佈圖，normal plots，如圖 25.2。 set.seed(1234) Normal &lt;- rnorm(2500, mean = 120, sd = 8) h &lt;- hist(Normal,breaks = 20, col = &quot;lightblue&quot;, xlab = &quot;some value&quot; , ylim = c(0,300)) xfit&lt;-seq(min(Normal),max(Normal),length=40) yfit&lt;-dnorm(xfit,mean=mean(Normal),sd=sd(Normal)) yfit &lt;- yfit*diff(h$mids[1:2])*length(Normal) lines(xfit, yfit, col=&quot;blue&quot;, lwd=2) 圖 25.1: Appearance of histogram with normal curve qqnorm(Normal,frame=F); qqline(Normal) 圖 25.2: Appearance of normal plot for a normally distributed variable 25.2.1 正態分佈圖 normal plot 其實光看柱狀圖和箱形圖，有時候很難判斷數據正態性與否，當數據和正態分佈有些微妙的不同時可能就沒辦法從柱狀圖覺察出來。此時需要借用正態分布圖的威力。正態分布圖的原理就是，把原始數據 (Y軸) 和理論上服從正態分佈的期待數據 (X軸) 從小到大排序一一對應以後繪製散點圖。所以理論上，如果原始數據服從正態分佈，那麼正態分佈中第10百分位的點，我們期望和原始數據中第10百分位的點十分接近，那麼繪成的散點圖應該接近於完美的貼在 \\(y=x\\) 這條直線上。如果正態分布圖的點越偏離 \\(y=x\\) 的直線，覺說明原始數據越偏離正態分佈。 下面的系列圖25.3，25.4，25.5，25.5展示了各種非正態分佈時會出現的柱狀圖，和正態分布圖的特徵： 圖 25.3: Appearance of histogram and normal plot for a variable with outlying values 圖 25.4: Appearance of histogram and normal plot for a variable exhibiting right-skewness 圖 25.5: Appearance of histogram and normal plot for a variable exhibiting left-skewness 圖 25.6: Appearance of histogram and normal plot for a heavy tailed variable 如果對數據是否服從正態分佈實在沒有信心，統計學家也很少使用那些檢驗是否服從正態分佈的所謂檢驗方法 (Sharpiro-Wilk test 或者 Kolmogorov-Smirnov test)，而是傾向用直接改用穩健統計學分析法 (Robust Statistical Methods)。 25.3 總結連續型變量不服從正態分佈時的處理方案 根據中心極限定理，樣本量足夠大時，即使原始樣本數據不服從正態分佈，仍然可以用一般的參數估計技巧來分析類似均值這樣較爲穩健的參數。 用非參數檢驗法，會在穩健統計學方法中介紹，但是這些方法的缺點很明顯，例如無法進行精確的參數估計，且容易失去較大的統計學檢驗力 (loss of power)，增加一類錯誤概率 (錯誤的拒絕掉可能存在有意義差異的檢驗)。更重要的是，沒有一種非參數檢驗法是可以和多重線性迴歸等較爲複雜，高級的技巧等價的。 用一些穩健統計學方法 (bootstrap，“sandwich” estimators of variance)，可行但是對電腦的計算需求較高。 數據轉換法。但是沒有人能保證一定能找到合適的數學轉換法來滿足前提條件 (下節討論)。 25.4 數學冪轉換 power transformations 數據轉換家族： \\[ \\cdots,x^{-2},x^{-1},x^{-\\frac{1}{2}},\\text{log}(x),x^{\\frac{1}{2}},x^1,x^2,\\cdots \\] 上面舉例的數學冪轉換方法，都是常見的手段用於降低原始數據的偏度 (skewness)，相反地，冪轉換卻不一定能夠改變數據的峯度 (kurtosis)。下面的方程，(非常的羅嗦的方程 sorry)，用於實施類似 ladder 在 Stata 中的效果，即對數據進行各種轉換，然後輸出每種冪轉換後的數據是否爲正態分佈的檢驗結果 (使用 shapiro.test())： Ladder.x &lt;- function(x){ data &lt;- data.frame(x^3,x^2,x,sqrt(x),log(x),1/sqrt(x),1/x,1/(x^2),1/(x^3)) names(data) &lt;- c(&quot;cubic&quot;,&quot;square&quot;,&quot;identity&quot;,&quot;square root&quot;,&quot;log&quot;,&quot;1/(square root)&quot;, &quot;inverse&quot;,&quot;1/square&quot;,&quot;1/cubic&quot;) # options(scipen=5) test1 &lt;- shapiro.test(data$cubic) test2 &lt;- shapiro.test(data$square) test3 &lt;- shapiro.test(data$identity) test4 &lt;- shapiro.test(data$`square root`) test5 &lt;- shapiro.test(data$log) test6 &lt;- shapiro.test(data$`1/(square root)`) test7 &lt;- shapiro.test(data$inverse) test8 &lt;- shapiro.test(data$`1/square`) test9 &lt;- shapiro.test(data$`1/cubic`) W.statistic &lt;- c(test1$statistic, test2$statistic, test3$statistic, test4$statistic, test5$statistic, test6$statistic, test7$statistic, test8$statistic, test9$statistic) p.value &lt;- c(test1$p.value, test2$p.value, test3$p.value, test4$p.value, test5$p.value, test6$p.value, test7$p.value, test8$p.value, test9$p.value) Hmisc::format.pval(p.value ,digits=5, eps = 0.00001, scientific = FALSE) Transformation &lt;- c(&quot;cubic&quot;,&quot;square&quot;,&quot;identity&quot;,&quot;square root&quot;,&quot;log&quot;,&quot;1/(square root)&quot;, &quot;inverse&quot;,&quot;1/square&quot;,&quot;1/cubic&quot;) Formula &lt;- c(&quot;x^3&quot;,&quot;x^2&quot;,&quot;x&quot;,&quot;sqrt(x)&quot;,&quot;log(x)&quot;,&quot;1/sqrt(x)&quot;,&quot;1/x&quot;,&quot;1/(x^2)&quot;,&quot;1/(x^3)&quot;) (results &lt;- data.frame(Transformation, Formula, W.statistic, p.value)) } Normal &lt;- rnorm(2500, mean = 120, sd = 8) Ladder.x(Normal) ## Transformation Formula W.statistic p.value ## 1 cubic x^3 0.9901 3.906e-12 ## 2 square x^2 0.9968 4.283e-05 ## 3 identity x 0.9994 5.835e-01 ## 4 square root sqrt(x) 0.9990 2.039e-01 ## 5 log log(x) 0.9977 8.750e-04 ## 6 1/(square root) 1/sqrt(x) 0.9952 3.370e-07 ## 7 inverse 1/x 0.9917 8.896e-11 ## 8 1/square 1/(x^2) 0.9816 1.735e-17 ## 9 1/cubic 1/(x^3) 0.9674 2.175e-23 25.4.1 對數轉換 logarithmic Transformation 在衆多冪轉換中，對數轉換是最常用的，因爲對數轉換之後，再通過逆運算轉換回原單位數據的方法，被發現是相較於其他冪轉換較爲容易解釋和應用在臨牀醫學中。假如現在在分析男女之間收縮期血壓的均值差別。下面是對數轉換前後的檢驗方法步驟，試作一個對比： 轉換前： 計算收縮期血壓在男性女性中各自的均值 \\(\\bar{Y}_j, j=1,2\\)； 計算男女間均值差 \\(D=\\bar{Y}_2 - \\bar{Y}_1\\)； 所以均值差就被解釋爲男女減血壓的平均差距 (difference of mmHg)； 例如，均值差爲 10 mmHg，就可以被解讀爲女性血壓平均值比男性低 10 mmHg。 對數轉換後： 計算觀察值的對數值 \\(t_{ij} = \\text{log}_e(y_{ij})\\)； 計算男女對數收縮期血壓的算數平均值 \\(\\bar{T}_j, j=1,2\\)； 計算對數血壓均值差 \\(D=\\bar{T}_2-\\bar{T}_1\\)； 由於 \\(exp(\\bar{T}_j) = G_j\\) 是男女收縮期血壓的幾何平均值，所以 \\(exp(D)=exp(\\text{log}_eG_2 - \\text{log}_eG_1) = \\frac{G_2}{G_1}\\)，就可以解釋爲男女收縮期血壓的幾何平均值之比； 例如，\\(D=-0.05\\)，那麼男女收縮期血壓的幾何平均值之比爲 \\(exp(-0.05)=0.951\\)，就可以被解讀爲女性收縮期血壓平均比男性低 \\(4.9\\%\\)。 25.4.2 逆轉換信賴區間 back-transformation of CIs 當使用轉換後數據計算信賴區間以後，需要再把數據逆轉換回原始數據的單位才能順利被解讀。但是逆轉換回去以後的信賴區間就不再左右對稱了 (no way)。 25.4.3 對數正態分佈 log-normal distribution 一個隨機變量的對數轉換如果服從正態分佈，我們說這個數據服從對數正態分佈。 25.4.4 百分比的轉換 百分比被侷限在 \\([0,1]\\) 的範圍內，所以爲了打破這個取值範圍的限制，百分比常用的數學轉換有： 把百分比 \\(\\pi\\) 轉換成 Odds \\(\\frac{\\pi}{1-\\pi}\\)。如此 Odds 的取值範圍就可以變成 \\([0, \\infty)\\)； Odds \\(\\frac{\\pi}{1-\\pi}\\) 又常被轉換成 log-odds \\(\\text{log}(\\frac{\\pi}{1-\\pi})\\)。這樣的轉換方程 \\(f(\\pi)=\\text{log}(\\frac{\\pi}{1-\\pi})\\) 又被命名爲邏輯轉換 (logit transformation)； 百分比的商 (危險度比，risk ratio) \\(\\pi_1/\\pi_2\\) 可以轉換成 \\(\\text{log}(\\pi_1/\\pi_2)\\)； 比值比 (odds ratio) \\(\\frac{\\pi_1(1-\\pi_2)}{\\pi_2(1-\\pi_1)}\\) 可以轉換成對數比值比 (log odds ratio) \\(\\text{log}[\\frac{\\pi_1(1-\\pi_2)}{\\pi_2(1-\\pi_1)}] = \\text{log}[\\pi_1(1-\\pi_1)] - \\text{log}[\\pi_2(1-\\pi_2)]\\)。 表25.1： Common Transformation and their range Transformation Formula Range Odds \\(\\frac{\\pi}{1-\\pi}\\) \\([0,\\infty)\\) Log Odds \\(\\text{log}(\\frac{\\pi}{1-\\pi})\\) \\((-\\infty,+\\infty)\\) Risk Ratio \\(\\frac{\\pi_1}{\\pi_2}\\) \\([0,\\infty)\\) Log Risk Ratio \\(\\text{log}(\\frac{\\pi_1}{\\pi_2})\\) \\((-\\infty,+\\infty)\\) Odds Ratio \\(\\frac{\\pi_1(1-\\pi_2)}{\\pi_2(1-\\pi_1)}\\) \\([0,\\infty)\\) Log Odds Ratio \\(\\text{log}[\\frac{\\pi_1(1-\\pi_2)}{\\pi_2(1-\\pi_1)}]\\) \\((-\\infty,+\\infty)\\) References "],
["lm.html", "第 26 章 簡單線性迴歸 Simple Linear Regression 26.1 一些背景和術語 26.2 簡單線性迴歸模型 simple linear regression model 26.3 區分因變量和預測變量 26.4 參數的估計 estimation of parameters 26.5 殘差方差的估計 Estimation of the residual variance \\((\\sigma^2)\\) 26.6 R 演示 例 1： 圖 26.1 數據 26.7 R 演示 例 2： 表26.1 數據 26.8 練習", " 第 26 章 簡單線性迴歸 Simple Linear Regression Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong questions, which can always be made precise. —- John Tukey 26.1 一些背景和術語 思考下面這些問題： 脂肪攝入量增加，會導致體重增加嗎？ 兒童成年時的身高，可以用父母親的身高來預測嗎？ 如果其他條件都沒有變化，飲食習慣的改變，是否能影響血清膽固醇的水平？ 上面的問題中，自變量 (預測變量)，和因變量 (反應量) 分別是什麼？ 你可能還會碰到像下面這些稱呼，他們都是一個意思： 因變量 Dependent variable = 反應量 response variable = 結果變量 outcome variable; 自變量 independent variable = 預測變量 predictor variable = 解釋變量 explanatory variable = 共變量 covariate. 所有的非簡單統計模型 (non-trivial statistical models) 都包括以下三個部分： 隨機變量 random variables： 因變量永遠都是隨機變量； 預測變量不一定是隨機變量； 在相對簡單的模型中，我們討論的因變量和預測變量幾乎都來自於從人羣中抽取觀察樣本收集來的數據。 人羣參數 population parameters： 人羣參數，是我們希望通過收集樣本獲得的數據來估計 (estimate) 的參數。 對不確定性的描述 representation of uncertainty： 不確定性，意爲因變量的變動中，沒有被預測變量解釋的部分。 其他的術語問題： 單一因變量的統計模型：univariate model; 多個因變量的統計模型： multivariate model; 單一因變量，含有多個預測變量的統計模型：multivariable model； 在線性迴歸中，單一因變量，單一預測變量的統計模型：simple linear regression (簡單線性迴歸)； 在線性迴歸中，單一因變量，多個預測變量的統計模型：multiple linear regression (多重線性迴歸)； 儘量避免將預測變量 (predictor variable) 寫作自變量 (independent variable)，因爲 “independent” 有自己的統計學含義 (獨立)。然而我們在線性迴歸中使用的預測變量，不一定都互相獨立，所以容易讓人混淆其意義。 26.2 簡單線性迴歸模型 simple linear regression model 即：單一因變量，單一預測變量的統計模型。 26.2.1 數據 A 下面的散點圖 26.1 展示的是一項橫斷面調查的結果，調查的是一些兒童的年齡 (月)，和他們的體重 (千克) 之間的關係。 圖 26.1: Age and weight of children in a cross-sectional survey 26.2.2 數據 B 表 26.1 羅列的是11名兒童能夠自己獨立行走時的年齡。這些兒童在剛出生時被隨機分配到兩個組中 (積極鍛鍊走路，和對照組)。如果你熟悉均數比較，這樣的數據可以通過簡單 \\(t\\) 檢驗來分析其均值的不同。但是實際上後面你會看到簡單 \\(t\\) 檢驗和簡單線性迴歸是同一回事。 表 26.1: Childen’s ages at time of first walking aline by randomisation group Age in months for walking alone Active Exercise (n=6) Eight Week Control (n=5) 9.00 13.25 9.50 11.5 9.75 12 10.00 13.5 13.00 11.5 9.50 – 26.3 區分因變量和預測變量 在簡單兩樣本 \\(t\\) 檢驗中，我們不區分那兩個要比較的數據 \\((X, Y)\\)。所以 \\(X\\) 和 \\(Y\\) 的關係，同分析 \\(Y\\) 和 \\(X\\) 的關係是一樣的。表 26.1 的例子中，視“直立行走的年齡”這一變量爲因變量十分直觀且自然。圖 26.1 的例子中我們顯然可以關心是否可以用兒童的年齡來推測他/她的體重。所以年齡被視爲預測變量 \\((X)\\)，體重被視爲因變量或者叫結果變量 \\((Y)\\)。 26.3.1 均值 (期待值) 公式 圖 26.1 的例子中，當我們決定考察體重變化 \\((Y)\\) 和年齡的關係 \\((X)\\) 後，我們需要提出一個模型，來描述二者之間的關係。這個模型中，最重要的信息，是均值，或者叫期待值： \\[ E(Y|X=x), \\text{ the expected value of } Y \\text{ when } X \\text{ takes the value } x \\] 在簡單線性迴歸模型中，我們認爲這個均值方程是線性關係： \\[ E(Y|X=x) = \\alpha +\\beta x \\] 所以這個線性關係中，有兩個參數 (parameters) 是我們關心的 \\(\\alpha, \\beta\\)。 \\(\\alpha\\) 是截距 intecept。意爲當 \\(X\\) 取 \\(0\\)時， \\(Y\\) 的期待值大小； \\(\\beta\\) 是方程的斜率 slope。意爲當 \\(X\\) 上升一個單位時，\\(Y\\) 上升的期待值大小。 需要強調的是，這樣的線性模型，是我們提出，用來模擬真實數據時使用的。你如果作死當然還可以提出更加複雜的模型。如下面圖 26.2 顯示的是線性迴歸直線， 而圖 26.3 顯示的是較爲複雜的迴歸曲線。曲線方程可能更加擬合我們收集到的數據，然而這樣的連續的斜率變化很可能僅僅只解釋了這個樣本量數據，而不能解釋在人羣中年齡和體重的關係。 圖 26.2: Linear mean function for age and weight of children in a cross-sectional survey 圖 26.3: Non-linear mean function for age and weight of children in a cross-sectional survey 26.3.2 條件分佈和方差 the conditional distribution and the variance function 如果要完全明確一個統計模型，另一個重要的點在於，提出的模型能否準確描述因變量在預測變量的條件下的分佈 (conditional distribution) it is necessary to describe the distribution of the dependent variable conditional on the predictor variable。使用簡單線性迴歸模型有幾個前提假設： 因變量對預測變量的條件分佈的方差是保持不變的 the variance of the dependent variable (conditional on the predictor variable) is constant。 該條件分佈是一個正態分佈。 有時候，這些假設條件並不能得到滿足。上面的散點圖 26.1看上去還算符合這兩個假設前提：在每一個年齡階段，體重的分佈沒有發生歪斜 (skew)，分散分佈 (方差) 也相對穩定。但是圖 26.4 中的價格-克拉數據很明顯無法滿足上面的前提假設。在線性迴歸模型中，我們使用 \\(\\sigma^2\\) 表示殘差的方差 (residual variance)。 圖 26.4: Relationship between diamond carat and price 26.3.3 定義簡單線性迴歸模型 用來描述一個隨機變量 \\((Y)\\) 和另一個變量 \\((X)\\) 之間關係的簡單線性迴歸模型，被定義爲： \\[ (Y|X=x) \\sim N(\\alpha+\\beta x, \\sigma^2) \\] 上面這個模型，同時還描述了我們對數據的分佈的假設。同樣的模型，你可能更多得看到被寫成如下的方式： \\[ y=\\alpha+\\beta x+ \\varepsilon \\text{, where } \\varepsilon\\sim N(0,\\sigma^2) \\] 假如，我們有一組樣本量爲 \\(n\\) 的數據 \\(\\underline{x}\\)。我們就可以把通過上面的迴歸模型實現的 \\(Y_i\\) 和它對應的 \\(X_i (i=1,\\cdots, n)\\)。描述爲如下的形式： \\[ \\begin{equation} (Y_i|X_i=x_i) \\sim \\text{NID}(\\alpha+\\beta x, \\sigma^2) \\text{ where } i=1,\\cdots,n \\end{equation} \\tag{26.1} \\] 此處的 \\(\\text{NID}\\) 意爲獨立且服從正態分佈 (normally and independently distributed)。這裏默認的一個重要前提是所有的觀察值 \\(X_i\\) 是相互獨立互不影響的。例如上面圖 26.1 所示兒童的年齡和體重數據，就必須假設這些兒童都來自沒有血緣關係的獨立家庭。如果這以數據中的兒童，有些是兄弟姐妹的話，觀察數據互相獨立的前提就無法得到滿足。不滿足相互獨立前提的數據，其分析方法會在 “Analysis of hierarchical and other dependent data (Term 2)” 中詳盡介紹。 公式 (26.1) 常被記爲： \\[ \\begin{equation} (Y_i|X_i=x_i) = \\alpha + \\beta x_i + \\varepsilon_i, \\text{ where } \\varepsilon_i\\sim \\text{NID}(0,\\sigma^2) \\end{equation} \\tag{26.2} \\] 或者爲了簡潔表述寫成： \\[ \\begin{equation} y_i = \\alpha + \\beta x_i + \\varepsilon_i, \\text{ where } \\varepsilon_i\\sim \\text{NID}(0,\\sigma^2) \\end{equation} \\tag{26.3} \\] 26.3.4 殘差 residuals 公式 (26.2) 和 (26.3) 其實已經包含了殘差的表達式： \\[ \\varepsilon_i = y_i - (\\alpha + \\beta x_i) \\] 所以 \\(\\varepsilon_i\\) 的意義是第 \\(i\\) 個觀察對象的隨機(偶然)誤差 (random error)，或者叫真實殘差 (true residual)。其實就是從線性迴歸模型計算獲得的映射值 \\(\\alpha+\\beta x_i\\)，和實際觀察值 \\(y_i\\) 之間的差距。而且從其公式可見，殘差本身也是由人羣的參數 \\((\\alpha, \\beta)\\) 決定的。殘差也被定義爲迴歸模型的偏差值。當我們用樣本數據獲得的參數估計 \\((\\hat\\alpha, \\hat\\beta)\\) 來取代掉參數 \\((\\alpha, \\beta)\\) 時，這時的模型變成了估計模型，殘差也成了估計殘差或者叫觀察模型和觀察殘差。須和真實殘差加以區分。 26.4 參數的估計 estimation of parameters 簡單線性迴歸模型中有三個人羣參數 \\((\\alpha, \\beta, \\sigma^2)\\)。統計分析的目標，就是使用樣本數據 \\(Y_i, X_i, (i=1, \\cdots, n)\\) 來對總體參數做出推斷 (inference)。在線性迴歸中主要使用普通最小二乘法 (ordinary least squares, OLS) 作爲推斷的工具。在統計學中，我們習慣給希臘字母戴上“帽子”，作爲該參數的估計值，例如 \\(\\hat\\alpha, \\hat\\beta\\) 是參數 \\(\\alpha, \\beta\\) 的估計值。通過線性迴歸模型，給第 \\(i\\) 個觀察值擬合的預測值，被叫做因變量的估計期望值 (estimated expectation)。用下面的式子來表示: \\[ \\hat{y}_i=\\hat\\alpha+\\hat\\beta x_i \\] 此時，第 \\(i\\) 名對象的觀察殘差 (observed or fitted or estimated residuals) 用下面的式子來表示： \\[ \\hat{\\varepsilon}_i = y_i-\\hat{y}_i=y_i-(\\hat\\alpha+\\hat\\beta x_i) \\] 26.4.1 普通最小二乘法估計 \\(\\alpha, \\beta\\) 普通最小二乘法估計的 \\(\\alpha, \\beta\\) 會最小化擬合迴歸直線的偏差 minimize the sum of squared deviations from the fitted regression line。其正式的定義爲：OLS估計值，指的是能夠使殘差平方和 (residual sum of squares, \\(SS_{RES}\\))取最小值的 \\(\\hat\\alpha, \\hat\\beta\\)。 \\[ \\begin{equation} SS_{RES} = \\sum_{i=1}^n \\hat{\\varepsilon}^2_i = \\sum_{i=1}^n (y_i-\\hat\\alpha-\\hat\\beta x_i)^2 \\end{equation} \\tag{26.4} \\] 可以證明的是，OLS的 \\(\\alpha, \\beta\\) 估計值的計算公式爲： \\[ \\begin{equation} \\hat\\alpha=\\bar{y}-\\hat\\beta\\bar{x} \\tag{26.5} \\end{equation} \\] \\[ \\begin{equation} \\hat\\beta=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2} \\tag{26.6} \\end{equation} \\] 其中 \\(\\bar{y}=\\frac{\\sum_{i=1}^ny_i}{n}, \\bar{x}=\\frac{\\sum_{i=1}^nx_i}{n}\\) 證明 求能最小化 \\(SS_{RES}\\) 的 \\(\\alpha\\)， 我們需要把公式 (26.4) 對 \\(\\hat\\alpha\\) 求導，然後將求導之後的式子等於 \\(0\\) 之後求根即可： \\[ \\begin{aligned} &amp; \\frac{\\text{d}SS_{RES}}{\\text{d}\\hat\\alpha} =\\sum_{i=1}^n -2(y_i-\\hat\\alpha-\\hat\\beta x_i) = 0\\\\ &amp; \\text{Since } \\sum_{i=1}^n(y_i) = n\\bar{y}; \\sum_{i=1}^n (x_i) =n\\bar{x} \\\\ &amp; \\Rightarrow -n\\bar{y}+n\\hat\\alpha+n\\hat\\beta\\bar{x} = 0 \\\\ &amp; \\Rightarrow \\hat\\alpha = \\bar{y}-\\hat\\beta\\bar{x} \\end{aligned} \\] 求能最小化 \\(SS_{RES}\\) 的 \\(\\beta\\)，求導之前我們先把公式 (26.4) 中含有 \\(\\hat\\alpha\\) 的部分替換掉： \\[ \\begin{equation} \\begin{split} SS_{RES} &amp;= \\sum_{i=1}^n\\hat\\varepsilon_i^2=\\sum_{i=1}^n(y_i-(\\bar{y}-\\hat\\beta\\bar{x})-\\hat\\beta x_i)^2\\\\ &amp;= \\sum_{i=1}^n((y_i-\\bar{y})-\\hat\\beta(x_i-\\bar{x}))^2 \\\\ \\end{split} \\tag{26.7} \\end{equation} \\] 接下來對上式 (26.7) 求導之後，用相同辦法求根： \\[ \\begin{aligned} &amp;\\frac{\\mathrm{d} SS_{RES}}{\\mathrm{d} \\hat\\beta} = \\sum_{i=1}^n -2(x_i-\\bar{x})(y_i-\\bar{y}) + 2\\hat\\beta(x_i-\\bar{x})^2 = 0\\\\ &amp; \\Rightarrow \\hat\\beta\\sum_{i=1}^n(x_i-\\bar{x})^2 = \\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y}) \\\\ &amp; \\hat\\beta=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2} \\end{aligned} \\] 這兩個式子 (26.5) (26.6) 同時也是參數 \\(\\alpha, \\beta\\) 的極大似然估計 (MLE)。 26.5 殘差方差的估計 Estimation of the residual variance \\((\\sigma^2)\\) 殘差方差等於殘差平方和除以樣本量。所以我們會把殘差方差的估計用下面的式子表示： \\[ \\begin{equation} \\hat\\sigma^2=\\sum_{i=1}^n \\frac{\\hat\\varepsilon^2}{n} = \\sum_{i=1}^n \\frac{(y_i-\\hat\\alpha-\\hat\\beta x_i)^2}{n} \\end{equation} \\tag{26.8} \\] 這的確是 \\(\\sigma^2\\) 的極大似然估計 (MLE)。然而我們知道，公式 (26.8) 並不是殘差方差的無偏估計。類似與樣本方差低估了總體方差 (Section 10.3)，那樣，這裏殘差方差的觀察值也是低估了總體殘差方差的。所以，殘差方差的無偏估計需要用下面的式子來校正： \\[ \\begin{equation} \\hat\\sigma^2=\\sum_{i=1}^n \\frac{\\hat\\varepsilon^2}{n-2} = \\sum_{i=1}^n \\frac{(y_i-\\hat\\alpha-\\hat\\beta x_i)^2}{n-2} \\end{equation} \\tag{26.9} \\] 公式 (26.9) 被叫做殘差均方 (Residual Mean Squares, RMS)，常常被標記爲 \\(\\text{MS}_{RES}\\)。分母的 \\(n-2\\)，表示進行殘差方差估計時用掉了兩個信息量 \\(\\alpha, \\beta\\) (自由度減少了 2)， 26.6 R 演示 例 1： 圖 26.1 數據 library(haven) growgam1 &lt;- read_dta(&quot;backupfiles/growgam1.dta&quot;) slm &lt;- lm(wt~age, data=growgam1) summary(slm) # basic default output of the summary ## ## Call: ## lm(formula = wt ~ age, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.924 -0.785 0.007 0.797 4.068 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.8376 0.2101 32.5 &lt;2e-16 *** ## age 0.1653 0.0111 14.9 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.27 on 188 degrees of freedom ## Multiple R-squared: 0.541, Adjusted R-squared: 0.538 ## F-statistic: 221 on 1 and 188 DF, p-value: &lt;2e-16 print(anova(slm), digits = 8) # show the sum of squares for the fitted model and residuals ## Analysis of Variance Table ## ## Response: wt ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## age 1 359.06320 359.06320 221.39203 &lt; 2.22e-16 *** ## Residuals 188 304.90655 1.62184 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 也可以用 stargazer 包輸出很酷的表格報告： library(stargazer) stargazer(slm, type = &quot;html&quot;) Dependent variable: wt age 0.165*** (0.011) Constant 6.838*** (0.210) Observations 190 R2 0.541 Adjusted R2 0.538 Residual Std. Error 1.274 (df = 188) F Statistic 221.400*** (df = 1; 188) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 其實結果都一樣。我們這裏詳細來看 \\(\\alpha, \\beta, \\sigma^2\\)： \\(\\hat\\alpha = 6.84\\)：當年齡爲 \\(0\\) 時，體重爲 \\(6.84 kg\\)。本數據 26.1 中並沒有 \\(0\\) 歲的兒童，所以這裏的截距的解釋需要非常小心是否合理。 \\(\\hat\\beta = 0.165\\)：這數據中兒童的體重估計隨着年齡升高 \\(1\\) 個月增長 \\(0.165 kg\\)。所以使用這兩個估計值我們就可以來估計任意年齡時兒童的體重。圖 26.2 就是擬合數據以後的簡單線性迴歸曲線。 \\(\\hat\\sigma^2 = 1.62, \\hat\\sigma=1.27\\) 就是默認輸出中最下面的 Residual standard error: 1.274 和 ANOVA 表格中 Residuals 的 Mean Sq=1.62184 部分。含義是，沿着擬合的直線，在每一個給定的年齡上兒童體重的分佈的標準差是 \\(1.27 kg\\)。 26.7 R 演示 例 2： 表26.1 數據 如果在 Stata 聽說你還需要自己生成啞變量 (dummy variables) (應該是計算時，在想要變成啞變量的變量名前面加上 i.)。在 R 裏面，分類變量被設置成因子 “factor” 時，你就完全可以忽略生成啞變量的過程。下圖 26.5 顯示了兩組兒童直立行走時的年齡。 圖 26.5: Age at walking by group 擬合簡單線性迴歸也是小菜一碟： wk_age &lt;- lm(Age ~ Group, data=Walk) summary(wk_age) ## ## Call: ## lm(formula = Age ~ Group, data = Walk) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.125 -0.738 -0.375 0.388 2.875 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.125 0.512 19.77 1e-08 *** ## Groupcontrol 2.225 0.760 2.93 0.017 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.25 on 9 degrees of freedom ## (1 observation deleted due to missingness) ## Multiple R-squared: 0.488, Adjusted R-squared: 0.431 ## F-statistic: 8.58 on 1 and 9 DF, p-value: 0.0168 anova(wk_age) ## Analysis of Variance Table ## ## Response: Age ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Group 1 13.5 13.50 8.58 0.017 * ## Residuals 9 14.2 1.57 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 這裏的 \\(\\hat\\alpha=10.125\\)，意爲參照組 (此處，“exercise” 被默認設定爲參照組，而 “control” 被默認拿來和參照組相比較) 的兒童也就是，積極練習走路的小朋友這組能夠獨立行走的平均年齡是 \\(10.125\\) 個月。 \\(\\hat\\beta=2.225\\)，意爲和參照組 (積極練習組) 相比，對照組兒童能夠自己行走的年齡平均要晚 \\(2.225\\) 個月。所以對照組兒童能夠直立行走的平均年齡就是 \\(10.125+2.225=12.35\\) 個月。 上述結果，你如果拿來和下面的兩樣本 \\(t\\) 檢驗的結果相比就知道，是完全一致的。其中統計量 \\(t^2=2.9285^2=F_{1,9}=8.58\\)。 t.test(Age~Group, data=Walk, var.equal=TRUE) ## ## Two Sample t-test ## ## data: Age by Group ## t = -2.9, df = 9, p-value = 0.02 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -3.9437 -0.5063 ## sample estimates: ## mean in group exercise mean in group control ## 10.12 12.35 26.8 練習 使用的數據內容爲：兩次調查同一樣本，99 名健康男性的血清膽固醇水平，間隔一年。 # 數據讀入 Chol &lt;- read_dta(&quot;backupfiles/chol.dta&quot;) summary(Chol) ## id chol1 chol2 ## Min. : 1.0 Min. :152 Min. :170 ## 1st Qu.:25.5 1st Qu.:235 1st Qu.:240 ## Median :50.0 Median :265 Median :260 ## Mean :50.0 Mean :265 Mean :264 ## 3rd Qu.:74.5 3rd Qu.:290 3rd Qu.:290 ## Max. :99.0 Max. :360 Max. :355 # Alternative Descriptive Statistics using psych package describe(Chol) ## Chol ## ## 3 Variables 99 Observations ## ---------------------------------------------------------------------------------------------------- ## id Format:%9.0g ## n missing distinct Info Mean Gmd .05 .10 .25 .50 .75 ## 99 0 99 1 50 33.33 5.9 10.8 25.5 50.0 74.5 ## .90 .95 ## 89.2 94.1 ## ## lowest : 1 2 3 4 5, highest: 95 96 97 98 99 ## ---------------------------------------------------------------------------------------------------- ## chol1 Format:%9.0g ## n missing distinct Info Mean Gmd .05 .10 .25 .50 .75 ## 99 0 51 0.999 264.6 46.11 204.5 210.0 235.0 265.0 290.0 ## .90 .95 ## 320.0 330.3 ## ## lowest : 152 170 190 200 205, highest: 333 340 350 355 360 ## ---------------------------------------------------------------------------------------------------- ## chol2 Format:%9.0g ## n missing distinct Info Mean Gmd .05 .10 .25 .50 .75 ## 99 0 30 0.997 263.5 43.28 200 215 240 260 290 ## .90 .95 ## 311 330 ## ## lowest : 170 190 195 200 205, highest: 320 330 345 350 355 ## ---------------------------------------------------------------------------------------------------- # 兩次膽固醇水平的直方圖 Distribution of the two measures par(mfrow=c(1,2)) hist(Chol$chol1) hist(Chol$chol2) # 對兩次膽固醇水平作散點圖 ggplot(Chol, aes(x=chol1, y=chol2)) + geom_point(shape=20) + scale_x_continuous(breaks=seq(150, 400, 50),limits = c(150, 355))+ scale_y_continuous(breaks=seq(150, 400, 50),limits = c(150, 355)) + theme_stata() +labs(x = &quot;Cholesterol at visit 1 (mg/100ml)&quot;, y = &quot;Cholesterol at visit 2 (mg/100ml)&quot;) 26.8.1 兩次測量的膽固醇水平分別用 \\(C_1, C_2\\) 來標記的話，考慮這樣的簡單線性迴歸模型：\\(C_2=\\alpha+\\beta C_2 + \\varepsilon\\)。我們進行這樣迴歸的前提假設有哪些？ 每個觀察對象互相獨立。 前後兩次測量的膽固醇水平呈線性相關。 殘差值，在每一個給定的 \\(C_1\\) 值處呈現正態分佈，且方差不變。 從散點圖來看這些假設應該都能得到滿足。 # 計算兩次膽固醇水平的 均值，方差，以及二者的協方差 mean(Chol$chol1); mean(Chol$chol2) ## [1] 264.6 ## [1] 263.5 var(Chol$chol1); var(Chol$chol2) ## [1] 1661 ## [1] 1457 cov(Chol$chol1, Chol$chol2) ## [1] 961.2 26.8.2 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 \\(\\hat\\alpha, \\hat\\beta\\) \\[ \\begin{aligned} \\hat\\beta &amp;= \\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\\\ &amp;=\\frac{\\text{Cov}(C_1,C_2)}{\\text{Var}(C_1)}\\\\ &amp;=\\frac{1661.061}{961.224}=0.578 \\end{aligned} \\] cov(Chol$chol1, Chol$chol2)/var(Chol$chol1) ## [1] 0.5787 \\[\\hat\\alpha=\\bar{y}-\\hat\\beta\\bar{x}=263.54-0.578\\times264.59=110.425\\] mean(Chol$chol2)-mean(Chol$chol1)*cov(Chol$chol1, Chol$chol2)/var(Chol$chol1) ## [1] 110.4 26.8.3 和迴歸模型計算的結果作比較，解釋這些估計值的含義 summary(lm(chol2~chol1, data=Chol)) ## ## Call: ## lm(formula = chol2 ~ chol1, data = Chol) ## ## Residuals: ## Min 1Q Median 3Q Max ## -56.88 -22.06 1.85 16.63 84.12 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 110.4247 20.0113 5.52 2.8e-07 *** ## chol1 0.5787 0.0748 7.74 9.5e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 30.2 on 97 degrees of freedom ## Multiple R-squared: 0.382, Adjusted R-squared: 0.375 ## F-statistic: 59.9 on 1 and 97 DF, p-value: 9.51e-12 截距的估計值是 110.4 mg/100ml: 意爲這組樣本，第一次採集數據時，膽固醇水平的平均值是 110.4。 斜率的估計值是 0.58：意爲第一次採集的膽固醇水平每高 1 mg/100ml，那麼第二次採集的膽固醇相應提高的值的期待量爲 0.58. 26.8.4 加上計算的估計值直線 (即迴歸直線) ggplot(Chol, aes(x=chol1, y=chol2)) + geom_point(shape=20, colour=&quot;grey40&quot;) + stat_smooth(method = lm, se=FALSE, size=0.5) + scale_x_continuous(breaks=seq(150, 400, 50),limits = c(150, 355))+ scale_y_continuous(breaks=seq(150, 400, 50),limits = c(150, 355)) + theme_stata() +labs(x = &quot;Cholesterol at visit 1 (mg/100ml)&quot;, y = &quot;Cholesterol at visit 2 (mg/100ml)&quot;) 可以注意到，第一次訪問時膽固醇水平高的人，第二次被測量時膽固醇值高於平均值，但是卻沒有第一次高出平均值的部分多。 相似的，第一次膽固醇水平低的人，第二次膽固醇水平低於平均值，但是卻沒有第一次低於平均值的部分多。這一現象被叫做 “向均數迴歸-regression to the mean” 26.8.5 下面的代碼用於模型的假設診斷 M &lt;- lm(chol2~chol1, data=Chol) par(mfrow = c(2, 2)) # Split the plotting panel into a 2 x 2 grid plot(M) 好心人在 github 上共享了 Check_assumption.R 的代碼，可以使用 ggplot2 來獲取高逼格的模型診斷圖： source(&quot;checkassumptions.R&quot;) check_assumptions(M) "],
["-ordinary-least-squares-estimators-and-inference.html", "第 27 章 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference 27.1 OLS 估計量的性質 27.2 \\(\\hat\\beta\\) 的性質 27.3 截距和迴歸係數的方差，協方差 27.4 \\(\\alpha, \\beta\\) 的推斷 27.5 線性迴歸模型和 Pearson 相關係數 27.6 Pearson 相關係數和模型迴歸係數的檢驗統計量 \\(t\\) 之間的關係 27.7 練習", " 第 27 章 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference 前一章介紹了簡單線性迴歸模型中對總體參數 \\(\\alpha, \\beta, \\sigma^2\\) 的估計公式，分別是 (26.5) (26.6) (26.9)。本章繼續介紹他們的統計學性質。下面的標記和統計量也會被用到： \\(\\bar{y}=\\frac{\\sum_{i=1}^n y_i}{n}\\)，因變量 \\(y\\) 的樣本均值； \\(\\bar{x}=\\frac{\\sum_{i=1}^n x_i}{n}\\)，預測變量 \\(x\\) 的樣本均值； \\(SS_{yy}=\\sum_{i=1}^n(y_i-\\bar{y})^2\\)，因變量 \\(y\\) 的校正平方和； \\(SS_{xx}=\\sum_{i=1}^n(x_i-\\bar{x})^2\\)，預測變量 \\(x\\) 的校正平方和； \\(SD_y^2=\\frac{\\sum_{i=1}(y_i-\\bar{y})^2}{n-1}=\\frac{SS_{yy}}{n-1}\\)，因變量 \\(y\\) 的樣本方差； \\(SD_x^2=\\frac{\\sum_{i=1}(x_i-\\bar{x})^2}{n-1}=\\frac{SS_{xx}}{n-1}\\)，因變量 \\(y\\) 的樣本方差； \\(S_{xy}=\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})\\)，\\(x,y\\) 的交叉乘積； \\(CV_{xy}=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{n-1}=\\frac{S_{xy}}{n-1}\\)，樣本協方差； \\(r_{xy}=\\frac{CV_{xy}}{SD_xSD_y}\\)，\\(x,y\\) 的樣本相關係數； \\(SS_{RES}=\\sum_{i=1}^n\\hat\\varepsilon^2=\\sum_{i=1}^n(y_i-\\hat\\alpha-\\hat\\beta x_i)^2\\)，殘差的估計平方和。 27.1 OLS 估計量的性質 樣本估計的迴歸直線必定穿過數據的中心 \\((\\bar{x},\\bar{y})\\)。 證明 由於樣本估計的截距和斜率公式 (26.5) (26.6) 可知： \\[ \\begin{aligned} \\hat\\alpha &amp;= \\bar{y} - \\hat\\beta\\bar{x} \\\\ \\hat y_i &amp;= \\hat\\alpha + \\hat\\beta x_i \\\\ \\Rightarrow \\hat y_i &amp;= \\bar{y}+\\hat\\beta(x_i-\\bar{x}) \\end{aligned} \\tag{27.1} \\] 所以，當 \\(\\hat x_i=\\bar{x}\\) 時 \\(\\hat y_i=\\bar{y}\\)。即迴歸直線必然穿過中心點。 如果擬合模型是正確無誤的， \\(\\hat\\alpha,\\hat\\beta,\\hat\\sigma^2\\) 分別是各自的無偏估計。 \\(\\hat\\alpha, \\hat\\beta\\) 是極大似然估計， \\(\\hat\\sigma^2\\) 不是MLE。 \\(\\hat\\alpha, \\hat\\beta\\) 是 \\(\\alpha, \\beta\\) 最有效的估計量。 27.2 \\(\\hat\\beta\\) 的性質 \\[ \\begin{equation} \\hat\\beta=\\frac{S_{xy}}{SS_{xx}}=\\frac{CV_{xy}}{SD_x^2} \\end{equation} \\tag{27.2} \\] 27.2.1 \\(Y\\) 對 \\(X\\) 迴歸， 和 \\(X\\) 對 \\(Y\\) 迴歸 如果我們使用 \\(\\hat\\beta_{y|x}\\) 表示預測變量 \\(x\\)，因變量 \\(y\\) 的簡單線性迴歸係數，那麼我們就有： \\[ \\begin{equation} \\hat\\beta_{y|x} = \\frac{CV_{xy}}{SD_x^2} \\text{ and } \\hat\\beta_{x|y} = \\frac{CV_{xy}}{SD_y^2} \\\\ \\text{Hence, } \\hat\\beta_{y|x}\\hat\\beta_{x|y} = r^2_{xy} \\end{equation} \\tag{27.3} \\] 公式 (27.3) 也證明了：如果兩個變量相關係數爲 \\(1\\) (100% 相關)， \\(Y\\) 對 \\(X\\) 迴歸的迴歸係數，是 \\(X\\) 對 \\(Y\\) 迴歸的迴歸係數的倒數。 27.2.2 例 1： 還是圖 26.1 數據 library(haven) growgam1 &lt;- read_dta(&quot;backupfiles/growgam1.dta&quot;) # regress wt on age summary(lm(wt~age, data=growgam1)) ## ## Call: ## lm(formula = wt ~ age, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.924 -0.785 0.007 0.797 4.068 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.8376 0.2101 32.5 &lt;2e-16 *** ## age 0.1653 0.0111 14.9 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.27 on 188 degrees of freedom ## Multiple R-squared: 0.541, Adjusted R-squared: 0.538 ## F-statistic: 221 on 1 and 188 DF, p-value: &lt;2e-16 print(anova(lm(wt~age, data=growgam1)), digits = 8) ## Analysis of Variance Table ## ## Response: wt ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## age 1 359.06320 359.06320 221.39203 &lt; 2.22e-16 *** ## Residuals 188 304.90655 1.62184 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # regress age on wt summary(lm(age~wt, data=growgam1)) ## ## Call: ## lm(formula = age ~ wt, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -16.010 -4.239 0.083 3.130 21.111 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -14.57 2.16 -6.75 1.8e-10 *** ## wt 3.27 0.22 14.88 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.66 on 188 degrees of freedom ## Multiple R-squared: 0.541, Adjusted R-squared: 0.538 ## F-statistic: 221 on 1 and 188 DF, p-value: &lt;2e-16 print(anova(lm(age~wt, data=growgam1)), digits = 8) ## Analysis of Variance Table ## ## Response: age ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## wt 1 7103.6730 7103.6730 221.39203 &lt; 2.22e-16 *** ## Residuals 188 6032.2428 32.0864 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 可以看到二者的輸出結果中統計檢驗量一樣，但是一個是將體重針對年齡迴歸，另一個則是反過來，所以迴歸係數和截距都不同。迴歸方程的含義也就發生了變化。如果把兩條迴歸曲線同時作圖可以更加直觀： 圖 27.1: Simple linear regression model line relating weight to age 圖 27.2: Simple linear regression model line relating age to weight 27.3 截距和迴歸係數的方差，協方差 假如簡單線性迴歸模型是正確的，那麼截距 \\(\\hat\\alpha\\) 和迴歸係數 \\(\\hat\\beta\\) 的方差分別是： \\[ \\begin{equation} V(\\hat\\alpha) = \\sigma^2(\\frac{1}{n}+\\frac{\\bar{x}^2}{SS_{xx}}) = \\frac{\\sigma^2}{(n-1)} (1-\\frac{1}{n}+\\frac{\\bar{x}^2}{SD_x^2}) \\end{equation} \\tag{27.4} \\] \\[ \\begin{equation} V(\\hat\\beta) = \\frac{\\sigma^2}{SS_{xx}}=\\frac{\\sigma^2}{(n-1)SD_x^2} \\end{equation} \\tag{27.5} \\] 從公式 (27.4) 和 (27.5) 也可以看出，兩個估計量的方差隨着殘差方差的增加而增加 (估計不精確)，隨着樣本量的增加而減少 (估計更精確)。截距 \\(\\hat\\alpha\\) 的方差會隨着樣本均值的增加而增加。 通常來說，截距和迴歸係數二者之間並非相互獨立。他們的協方差爲： \\[ \\begin{equation} Cov(\\hat\\alpha,\\hat\\beta) = -\\frac{\\sigma^2\\bar{x}}{SS_{xx}} \\end{equation} \\tag{27.6} \\] 上面的公式 (27.4) (27.5) (27.6) 都包含了真實的殘差方差 \\(\\sigma^2\\)。這個量對於我們“人類”來說是未知的。 27.3.1 中心化 centring 簡單線性迴歸模型常用的一個技巧是將預測變量中心化。即，求預測變量的均值，然後將每個觀測值減去均值之後再用這個新的預測變量擬合簡單線性迴歸模型。這樣做其實完全不影響回顧係數，卻會影響截距的大小。此時新的迴歸直線的截距，就等於因變量 (體重) 的均值。 用圖 26.1 數據來解釋： # mean value of age mean(growgam1$age) ## [1] 16.98 growgam1$age_cen &lt;- growgam1$age-mean(growgam1$age) # regress wt on age print(summary(lm(wt~age, data=growgam1)), digit=5) ## ## Call: ## lm(formula = wt ~ age, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.92418 -0.78489 0.00710 0.79747 4.06781 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.837584 0.210070 32.549 &lt; 2.2e-16 *** ## age 0.165331 0.011112 14.879 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.274 on 188 degrees of freedom ## Multiple R-squared: 0.54078, Adjusted R-squared: 0.53834 ## F-statistic: 221.39 on 1 and 188 DF, p-value: &lt; 2.22e-16 print(summary(lm(wt~age_cen, data=growgam1)), digit=5) ## ## Call: ## lm(formula = wt ~ age_cen, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.92418 -0.78489 0.00710 0.79747 4.06781 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.644737 0.092391 104.391 &lt; 2.2e-16 *** ## age_cen 0.165331 0.011112 14.879 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.274 on 188 degrees of freedom ## Multiple R-squared: 0.54078, Adjusted R-squared: 0.53834 ## F-statistic: 221.39 on 1 and 188 DF, p-value: &lt; 2.22e-16 很明顯，結果顯示中心化不會改變迴歸係數，也不會改變它的方差。但是“新”的截距，其實就等於因變量 (體重) 的均值。而且很多數據都集中在這個均值附近，因而，截距的方差比沒有中心化的迴歸方程要小。 27.4 \\(\\alpha, \\beta\\) 的推斷 \\(\\hat\\alpha, \\hat\\beta\\) 都可以被改寫成關於因變量 \\(Y\\) 的方程，因此同時也是隨機誤差的方程式： \\[ \\begin{aligned} \\hat\\beta &amp;= \\sum_{i=1}^n[\\frac{(x_i-\\bar{x})}{SS_{xx}}(y_i-\\bar{y})] \\\\ \\text{Substituting } &amp;(y_i-\\bar{y}) = \\beta(x_i-\\bar{x})+(\\varepsilon_i-\\bar{\\varepsilon}) \\\\ &amp;= \\beta + \\sum_{i=1}^n[\\frac{x_i-\\bar{x}}{SS_{xx}}(\\varepsilon_i-\\bar{\\varepsilon})] \\end{aligned} \\] 又因爲，\\(\\varepsilon_i \\sim NID(0,\\sigma^2)\\)，估計量 \\(\\hat\\alpha, \\hat\\beta\\) 均爲 \\(\\varepsilon_i\\) 的線性轉換，所以他們也都是服從正態分佈的。 27.4.1 對迴歸係數進行假設檢驗 對於迴歸係數 \\(\\beta\\)，我們可以使用 Wald statistic (Section 16.4) 進行零假設爲 \\(\\text{H}_0: \\beta=0\\) 的假設檢驗。此時，替代假設爲 \\(\\text{H}_1: \\beta\\neq0\\)。最佳檢驗統計量爲： \\[ \\begin{equation} t = \\frac{\\hat\\beta-0}{SE(\\hat\\beta)} \\\\ \\end{equation} \\tag{27.7} \\] 根據公式 (27.5) \\(SE(\\hat\\beta) = \\sqrt{V(\\hat\\beta)} = \\frac{\\hat\\sigma}{\\sqrt{SS_{xx}}}\\)。用 \\(\\hat\\sigma^2\\) 替換掉公式 (27.5) 中的 \\(\\sigma^2\\)，意味着迴歸係數的檢驗統計量 \\(t\\) 服從自由度爲 \\(n-2\\) 的 \\(t\\) 分佈。之後就可以根據 \\(t\\) 分佈的性質求相應的 \\(p\\) 值了，對相關係數是否爲 \\(0\\) 進行檢驗。之所以我們可以在這裏使用 Wald 檢驗，是因爲前提條件：隨機誤差服從正態分佈，於是 \\(\\beta\\) 的對數似然比也是左右對稱的，當對數似然比的圖形左右對稱時，就可以使用二次方程來近似 (Wald 檢驗的實質)。 27.4.2 迴歸係數，截距的信賴區間 估計量 \\(\\beta\\) 的 \\(95\\%\\) 信賴區間的計算公式如下： \\[ \\begin{equation} \\hat\\beta \\pm t_{n-2,0.975}SE(\\hat\\beta) \\end{equation} \\tag{27.8} \\] 其中，\\(t_{n-2, 0.975}\\) 表示自由度爲 \\(n-2\\) 的 \\(t\\) 分佈的 \\(97.5\\%\\) 位點的值。繼續使用之前的實例，圖 26.1 中的數據。體重對年齡進行簡單線性迴歸之後，年齡的估計回顧係數 \\(\\hat\\beta=0.165, SE(\\hat\\beta)=0.0111\\), 此例中 \\(n=190\\)，所以 \\(t_{188, 0.975}=1.973\\)。所以迴歸係數的 \\(95\\%\\) 信賴區間可以如此計算：\\(0.165\\pm1.973\\times0.0111=(0.143, 0.187)\\)。 類似的，估計截距 \\(\\hat\\alpha\\) 的 \\(95\\%\\) 信賴區間的計算式便是： \\(\\hat\\alpha \\pm t_{n-2, 0.975}SE(\\hat\\alpha)\\)。同樣的例子裏，\\(\\hat\\alpha=6.838, SE(\\hat\\beta) = 0.210, t_{188, 0.975}=1.973\\)。所以截距的 \\(95\\%\\) 信賴區間的計算方法就是： \\(6.838\\pm1.973\\times0.210=(6.42, 7.25)\\) 跟下面 R 計算的完全一樣： confint(lm(wt~age, data=growgam1)) ## 2.5 % 97.5 % ## (Intercept) 6.4232 7.2520 ## age 0.1434 0.1873 27.4.3 預測值的信賴區間 (置信帶) - 測量迴歸曲線本身的不確定性 這裏所謂的“預測值”其實並沒有拿來預測什麼新的數值，而是說我們希望通過線性迴歸找到因變量真實值的存在區間 (信賴區間)。所以這個預測值的真實含義其實應該是在預測變量取 \\(X=x\\) 時，因變量的期待值，\\(E(Y|X=x)\\)。 這個預測值的方差公式如下： \\[ \\begin{equation} V(\\hat y_{x}) = \\sigma^2[\\frac{1}{n}+\\frac{(x_i-\\bar{x})^2}{SS_{xx}}] \\end{equation} \\tag{27.9} \\] 於是可以計算它的 \\(95\\%\\) 信賴區間公式是： \\[ \\begin{equation} \\hat y_x \\pm t_{n-2, 0.975} \\hat\\sigma \\sqrt{[\\frac{1}{n}+\\frac{(x-\\bar{x})^2}{SS_{xx}}]} \\end{equation} \\tag{27.10} \\] 其實在之前的圖 (圖 26.2) 我們也已經展示過這個信賴區間的範圍。 27.4.4 預測帶 Reference range - 包含了 95% 觀察值的區間 此處的 \\(95\\%\\) 預測帶，其實是包含了 \\(95\\%\\) 觀察數據的區間。所以預測帶要比置信帶更寬。它的方差計算公式爲： \\[ \\begin{equation} V(\\hat y_x)+\\sigma^2 = \\sigma^2[1+\\frac{1}{n}+\\frac{(x-\\bar{x})^2}{SS_{xx}}] \\end{equation} \\tag{27.11} \\] 區間計算公式爲： \\[ \\begin{equation} \\hat{y}_x \\pm t_{n-2, 0.975} \\sqrt{1+\\frac{1}{n}+\\frac{(x-\\bar{x})^2}{SS_{xx}}} \\end{equation} \\tag{27.12} \\] 將置信帶和預測帶同時展現則如下圖： growgam1 &lt;- read_dta(&quot;backupfiles/growgam1.dta&quot;) Model &lt;- lm(wt~age, data=growgam1) temp_var &lt;- predict(Model, interval=&quot;prediction&quot;) new_df &lt;- cbind(growgam1, temp_var) ggplot(new_df, aes(x=age, y=wt)) + geom_point(shape=20, colour=&quot;grey40&quot;) + stat_smooth(method = lm, se=TRUE, size = 0.3) + geom_line(aes(y=lwr), color = &quot;red&quot;, linetype = &quot;dashed&quot;)+ geom_line(aes(y=upr), color = &quot;red&quot;, linetype = &quot;dashed&quot;)+ scale_x_continuous(breaks=seq(0, 38, 4),limits = c(0,36.5))+ scale_y_continuous(breaks = seq(0, 20, 5),limits = c(0,20.5)) + theme_stata() +labs(x = &quot;Age (Months)&quot;, y = &quot;Weight (kg)&quot;) 圖 27.3: Simple linear regression for age and weight of children in a cross-sectional survey with 95% CI of predicted values and 95% reference range 27.5 線性迴歸模型和 Pearson 相關係數 前面也推導過線性迴歸係數和 Pearson 相關係數之間的關係 (Section 27.2.1)，這裏詳細再展開討論它們之間關係的另外兩個重要結論。 27.5.1 \\(r^2\\) 可以理解爲因變量平方和被模型解釋的比例 Pearson 相關係數，因變量的平方和，模型的殘差平方和之間有如下的關係： \\[ \\begin{equation} r^2 = \\frac{SS_{yy}-SS_{RES}}{SS_{yy}} = 1-\\frac{SS_{RES}}{SS_{yy}} \\end{equation} \\tag{27.13} \\] 證明 \\[ \\frac{SS_{RES}}{SS_{yy}} = \\frac{\\sum_{i=1}^n(y_i-\\hat\\alpha-\\hat\\beta x_i)^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2} \\] 因爲 (26.5) : \\(\\hat\\alpha=\\bar{y}-\\hat{\\beta}\\bar{x}\\) \\[ \\begin{aligned} \\frac{SS_{RES}}{SS_{yy}} &amp;= \\frac{\\sum_{i=1}^n[(y_i-\\bar{y})-\\hat\\beta(x_i-\\bar{x})]^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2} \\\\ &amp;=\\frac{\\sum_{i=1}^n(y_i-\\bar{y})^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2}-\\frac{2\\hat\\beta\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n(y_i-\\bar{y})^2}+\\frac{\\hat\\beta^2\\sum_{i=1}^n(x_i-\\bar{x})^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2}\\\\ &amp;=1-\\frac{2\\hat\\beta S_{xy}}{SS_{yy}} + \\frac{\\hat\\beta^2SS_{xx}}{SS_{yy}} \\end{aligned} \\] 又因爲 \\(\\hat\\beta=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2}=\\frac{S_{xy}}{SS_{xx}}, r^2=\\frac{S_{xy}^2}{SS_{xx}SS_{yy}}\\)。 \\[ \\begin{aligned} \\frac{SS_{RES}}{SS_{yy}} &amp;= 1-\\frac{2S_{xy}^2}{SS_{yy}SS_{xx}}+\\frac{S_{xy}^2}{SS_{xx}SS_{yy}}\\\\ &amp;=1-2r^2+r^2\\\\ &amp;=1-r^2\\\\ \\Rightarrow r^2&amp;=1-\\frac{SS_{RES}}{SS_{yy}} \\end{aligned} \\] 因此，這裏就引出了非常重要的一個結論，Pearson 相關係數的平方 \\(r^2\\) 的統計學含義是，因變量的平方和 \\(SS_{yy}\\) 中，模型的預測變量能夠解釋的部分 \\(1-SS_{RES}\\) 的百分比。 統計學結果的報告中，爲了和一般相關係數的意義區分，會用大寫的 \\(R^2\\) 來表示這個模型解釋了因變量的百分比。(Section 28.2.3) 27.6 Pearson 相關係數和模型迴歸係數的檢驗統計量 \\(t\\) 之間的關係 \\[ \\begin{equation} t=r\\sqrt{\\frac{n-2}{1-r^2}} \\end{equation} \\tag{27.14} \\] 證明 由於前面推導的 \\(r^2\\) 公式 (27.13)，而且 \\(r^2=\\frac{S_{xy}^2}{SS_{xx}SS_{yy}}\\)： \\[ \\begin{aligned} \\frac{r^2}{1-r^2} &amp; = \\frac{\\frac{S_{xy}^2}{SS_{xx}SS_{yy}}}{\\frac{SS_{RES}}{SS_{yy}}} \\\\ &amp; = \\frac{S_{xy}^2}{SS_{xx}SS_{RES}} \\\\ &amp; = \\frac{S_{xy}^2}{SS_{xx}(n-2)\\hat\\sigma^2} \\end{aligned} \\] 由於公式 (27.5)，所以 \\(\\hat\\sigma^2=V(\\hat\\beta)SS_{xx}\\) \\[ \\begin{aligned} \\frac{r^2}{1-r^2} &amp; = \\frac{S_{xy}^2}{SS^2_{xx}(n-2)V(\\hat\\beta)} \\\\ &amp; = \\frac{\\hat\\beta^2}{(n-2)V(\\hat\\beta)} \\\\ \\Rightarrow t=r\\sqrt{\\frac{n-2}{1-r^2}} \\end{aligned} \\] 這個結論也被用於相關係數的假設檢驗。而且也正如 Section 27.2.1 證明過的那樣，在簡單線性迴歸裏因變量和預測變量的位置對調以後，對於回顧係數是否爲零的檢驗統計量不受影響。 27.7 練習 數據同前一章練習部分數據相同 26.8： # 數據讀入 Chol &lt;- read_dta(&quot;backupfiles/chol.dta&quot;) Model &lt;- lm(chol2~chol1, data=Chol) print(summary(Model), digit=6) ## ## Call: ## lm(formula = chol2 ~ chol1, data = Chol) ## ## Residuals: ## Min 1Q Median 3Q Max ## -56.87654 -22.06181 1.84937 16.63107 84.11839 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 110.4246582 20.0113279 5.51811 2.8499e-07 *** ## chol1 0.5786806 0.0747598 7.74053 9.5114e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 30.16 on 97 degrees of freedom ## Multiple R-squared: 0.381834, Adjusted R-squared: 0.375462 ## F-statistic: 59.9159 on 1 and 97 DF, p-value: 9.51139e-12 print(anova(Model), digit=6) ## Analysis of Variance Table ## ## Response: chol2 ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## chol1 1 54511.7 54511.7 59.9159 9.5114e-12 *** ## Residuals 97 88250.9 909.8 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # 計算截距和迴歸係數的 P 值 HAND CALCULATIONS twosided p-value in R can be obtained by pt(t, df) function ## p value for intercept: 110.42466/20.01133 #=5.518107 ## [1] 5.518 2*pt(5.518107, 97, lower.tail = FALSE) ## [1] 2.85e-07 ## p value for beta: 0.57868/0.07476 #= 7.740503 ## [1] 7.741 2*pt(7.740503, 97, lower.tail = FALSE) ## [1] 9.513e-12 # add fitted regression lines 95% CIs and reference range temp_var &lt;- predict(Model, interval=&quot;prediction&quot;) new_df &lt;- cbind(Chol, temp_var) ggplot(new_df, aes(x=chol1, y=chol2)) + geom_point(shape=20, colour=&quot;grey40&quot;) + stat_smooth(method = lm, se=TRUE, size=0.5) + geom_line(aes(y=lwr), color = &quot;red&quot;, linetype = &quot;dashed&quot;)+ geom_line(aes(y=upr), color = &quot;red&quot;, linetype = &quot;dashed&quot;)+ scale_x_continuous(breaks=seq(150, 400, 50),limits = c(150, 355))+ scale_y_continuous(breaks=seq(150, 400, 50),limits = c(150, 355)) + theme_stata() +labs(x = &quot;Cholesterol at visit 1 (mg/100ml)&quot;, y = &quot;Cholesterol at visit 2 (mg/100ml)&quot;) 圖中可見，95% 置信帶變化顯著，距離均值越遠的地方，置信帶越寬。然而預測帶基本是平行的沒有變化。因爲預測帶的涵義是，95%的觀察數據都在這個區間範圍內。 "],
["ANOVA.html", "第 28 章 方差分析 Introduction to Analysis of Variance 28.1 背景 28.2 簡單線性迴歸模型的方差分析 28.3 分類變量用作預測變量時的 ANOVA", " 第 28 章 方差分析 Introduction to Analysis of Variance 28.1 背景 當我們用統計模型模擬真實數據的時候，我們常常會被問到這樣的問題：“兩個模型哪個能更好的擬合這個數據？” 本章我們先考慮簡單的情況，兩個模型互相比較時，其中一個稍微簡單些的模型使用的預測變量，同時也是另一個較複雜的模型的預測變量 (nested models)。所以，複雜模型的預測變量較多，而其中一個或者幾個預測變量又構成了新的較爲簡單的模型。這兩個模型之間的比較，就需要用到方差分析 Analysis of Variance (ANOVA)。 此處方差分析的原則是：如果複雜模型能夠更好的擬合真實實驗數據，那我們會認爲簡單模型無法解釋的大量殘差平方和，有效地被複雜模型解釋了。所以，這一原則下，可以推理，複雜模型計算獲得的殘差平方和，會顯著地小於簡單模型計算獲得的殘差平方和。ANOVA 就提供了這個殘差平方和變化的定量比較方法。 28.2 簡單線性迴歸模型的方差分析 其實從線性迴歸的第一章節開始，我們都在使用方差分析的思想。圖 26.1 數據的迴歸模型中，我們其實比較了以下兩個模型： 零假設模型：null model, 即認爲年齡和體重之間沒有任何關係 (水平直線)； 替代模型： alternative model, 認爲年齡和體重之間有一定的線性關係 (擬合後的直線)。 圖 28.1: NULL (red) and Alternative models (blue) for the data 28.2.1 兩個模型的參數估計 無論是零假設模型，還是替代假設模型，都需要通過最小化殘差來獲得其參數估計： \\[ SS_{RES} = \\sum_{i=1}^n \\hat\\varepsilon^2= \\sum_{i=1}^n(y_i-\\hat y_i)^2 \\] 替代假設模型，在線性迴歸第一部分 (Section 26.3.1) 已經提到過，均值方程是 \\(E(Y|X=x) = \\alpha+\\beta x\\)，且這個方程的參數 \\(\\alpha, \\beta\\) 以及殘差方差 \\(\\sigma^2\\) 的估計值計算公式也已經推導完成 (26.5) (26.6) (26.9)。 零假設模型，它的均值方程是 \\(E(Y|X=x)=\\alpha\\)。所以需要將它的殘差最小化： \\[ SS_{RES} = \\sum_{i=1}^n(y_i-\\hat\\alpha)^2 \\] 由於 (26.5) ：\\(\\hat\\alpha=\\bar{y}-\\hat\\beta\\)，所以 \\(\\hat\\alpha = \\bar{y}\\)。 所以對於零假設模型來說： \\[ SS_{RES} = \\sum_{i=1}^n(y_i-\\bar{y})^2 =SS_{yy} \\] 因此，沒有預測變量的零假設模型，它的殘差平方和，就等於因變量的平方和。 28.2.2 分割零假設模型的殘差平方和 ANOVA，方差分析的原則，其實就是將較簡單模型 (零假設模型) 的殘差平方和 \\((SS_{RES_{NULL}})\\)，分割成下面兩個部分： 替代假設的複雜模型能夠說明的模型平方和 \\((SS_{REG})\\)； 替代假設的複雜模型的殘差平方和 \\((SS_{RES_{ALT}})\\)。 用數學表達式表示爲： \\[ \\begin{equation} \\sum_{i=1}^n(y_i-\\bar{y})^2 = \\sum_{i=1}^n(\\hat{y}-\\bar{y})^2 + \\sum_{i=1}^n(y_i-\\hat{y}_i)^2 \\\\ SS_{RES_{NULL}}(SS_{yy}) = SS_{REG} + SS_{RES_{ALT}} \\end{equation} \\tag{28.1} \\] 證明 \\[ \\begin{aligned} \\sum_{i=1}^n(y_i-\\bar{y})^2 &amp;= \\sum_{i=1}^n[(\\hat{y}-\\bar{y})+(y_i-\\hat{y})]^2\\\\ &amp;= \\sum_{i=1}^n(\\hat{y}-\\bar{y})^2+\\sum_{i=1}^n(y_i-\\hat{y})^2+2\\sum_{i=1}^n(\\hat{y}_i-\\bar{y})(y_i-\\hat{y}) \\\\ &amp;= SS_{REG} + SS_{RES_{ALT}} + 2\\sum_{i=1}^n(\\hat{y}_i-\\bar{y})(y_i-\\hat{y}) \\end{aligned} \\] 接下來就是要證明 \\(\\sum_{i=1}^n(\\hat{y}_i-\\bar{y})(y_i-\\hat{y})=0\\) 因爲公式 (27.1) \\(\\hat{y}_i=\\bar{y}+\\hat{\\beta}(x_i-\\bar{x})\\) 所以公式變形如下： \\[ \\begin{aligned} \\sum_{i=1}^n(\\hat{y}_i-\\bar{y})(y_i-\\hat{y}) &amp;= \\sum_{i=1}^n(\\bar{y}+\\hat\\beta(x_i-\\bar{x})-\\bar{y})(y_i-\\bar{y}-\\hat\\beta(x_i-\\bar{x})) \\\\ &amp;= \\sum_{i=1}^n\\hat\\beta(x_i-\\bar{x})[y_i-\\bar{y}-\\hat\\beta(x_i-\\bar{x})] \\\\ &amp;= \\hat\\beta\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y}) - \\hat\\beta^2\\sum_{i=1}^n(x_i-\\bar{x}) \\\\ &amp;= \\frac{S_{xy}}{S_{xx}}S_{xy} - (\\frac{S_{xy}}{S_{xx}})^2SS_{xx}\\\\ &amp;= 0 \\\\ \\Rightarrow SS_{RES_{NULL}}(SS_{yy}) &amp;= SS_{REG} + SS_{RES_{ALT}} \\end{aligned} \\] 28.2.3 \\(R^2\\) – 我的名字叫決定係數 coefficient of determination 在公式 (28.1) 中，因變量的平方和被分割成了兩個部分：\\(SS_{REG}\\) 迴歸模型能說明的部分，和 \\(SS_{RES_{ALT}}\\) 迴歸模型的殘差平方和。所以，我們定義迴歸模型能說明的部分，佔因變量平方和的百分比 \\(\\frac{SS_{REG}}{SS_{yy}}\\)，爲決定係數 \\(R^2\\)。 這個決定係數之前 (Section 27.5) 也出現過： \\[ \\begin{equation} R^2 = \\frac{SS_{REG}}{SS_{yy}} = \\frac{\\sum_{i=1}^n(\\hat{y}_i-\\bar{y})^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2} = 1-\\frac{\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2} \\end{equation} \\tag{28.2} \\] 再一次回到數據 (26.1) 的線性迴歸來看： growgam1 &lt;- read_dta(&quot;backupfiles/growgam1.dta&quot;) Model &lt;- lm(wt~age, data=growgam1) print(summary(Model), digit=6) ## ## Call: ## lm(formula = wt ~ age, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.924182 -0.784889 0.007099 0.797468 4.067806 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.8375842 0.2100701 32.5491 &lt; 2.22e-16 *** ## age 0.1653314 0.0111115 14.8793 &lt; 2.22e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.274 on 188 degrees of freedom ## Multiple R-squared: 0.540782, Adjusted R-squared: 0.53834 ## F-statistic: 221.392 on 1 and 188 DF, p-value: &lt; 2.22e-16 R 輸出的結果中最下面的部分 Multiple R-squared: 0.5408。我們就可以用“人話”來解釋其意義：假定年齡和體重成直線關係，那麼年齡解釋了這組數據中兒童體重變化 (平方和) 的 54%。 28.2.4 方差分析表格 the ANOVA table 一般情況下一個簡單線性迴歸，通過 ANOVA 對因變量平方和的分割，會被彙總成下面這樣的表格： 表 28.1: Analysis of Variance table for a simple liear regression model Source of Variation Sum of Squares Degrees of Freedom Mean Sum of Squares Regression (model) \\(SS_{reg}\\) \\(1\\) \\(MS_{reg} = \\frac{SS_{reg}}{1}\\) Residual \\(SS_{res}\\) \\(n-2\\) \\(MS_{res} = \\frac{SS_{res}}{(n-2)}\\) Total \\(SS_{yy}\\) \\(n-1\\) \\(\\frac{SS_{yy}}{(n-1)}\\) 表格中最右邊一列是平均平方和 (mean sum of squares)。它的定義是將平方和除以各自的自由度。其中殘差的平均平方和 \\(MS_{RES}=\\frac{SS_{RES}}{(n-2)}\\) 是替代模型下殘差方差的無偏估計。總體平均平方和 (total mean sum of squares)，則是零假設模型時的殘差方差估計。在 R 裏面也已經演示過多次 anova(model) 是調取方差分析表格的代碼： Model &lt;- lm(wt~age, data=growgam1) print(anova(Model), digit=8) ## Analysis of Variance Table ## ## Response: wt ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## age 1 359.06320 359.06320 221.39203 &lt; 2.22e-16 *** ## Residuals 188 304.90655 1.62184 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 注意到 R 省略掉第三行總體平方和的部分，不過其實也不太需要。檢驗統計量 F 的計算也很簡單，就是359.06320/1.62184=221.39。 28.2.5 用 ANOVA 進行假設檢驗 在 ANOVA 中使用的檢驗手段是 \\(F\\) 檢驗。這裏用 \\(F\\) 檢驗來比較模型解釋的因變量平方和部分 \\((SS_{REG})\\) 和這個模型不能解釋的殘差平方和部分 \\(SS_{RES}\\) 經過自由度校正以後比值的大小。 此時我們需要知道零假設和替代假設 \\(\\text{H}_0: \\beta=0 \\text{ v.s. H}_1: \\beta\\neq0\\) 時，\\(SS_{REG}, SS_{RES}\\) 的分佈。 零假設和替代假設時，\\(SS_{RES}\\) 均服從自由度爲 \\(n-2\\) 的卡方分佈： \\[ \\begin{equation} \\text{Because } SS_{RES} = \\sum_{i=1}^n \\varepsilon \\sim N(0, \\sigma^2)\\\\ \\frac{SS_{RES}}{\\sigma^2} \\sim \\chi^2_{n-2} \\end{equation} \\tag{28.3} \\] 零假設時， \\(SS_{REG}\\) 服從自由度爲 \\(1\\) 的卡方分佈，且與 \\(SS_{RES}\\) 相互獨立： \\[ \\begin{equation} \\frac{SS_{REG}}{\\sigma^2} \\sim \\chi^2_1 \\end{equation} \\tag{28.4} \\] 替代假設時，\\(SS_{REG}\\) 服從一個非中心化的卡方檢驗，且與 \\(SS_{RES}\\) 相互獨立： \\[ \\begin{equation} SS_{REG} = \\beta^2 SS_{xx} + U \\text{ where }\\frac{U}{\\sigma^2} \\sim \\chi_1^2 \\end{equation} \\tag{28.5} \\] 28.2.6 簡單線性迴歸時的 \\(F\\) 檢驗 如果兩個隨機變量各自服從相應自由度的卡方分佈，他們的每個元素的比值服從 \\(F\\) 分佈： \\[ A\\sim \\chi_a^2 \\text{ and } B\\sim \\chi_b^2\\\\ \\Rightarrow \\frac{A/a}{B/b} \\sim F_{a,b} \\] 因此，目前爲止的推導過程我們也可以看到，在零假設條件下，\\(MS_{REG}\\) 和 \\(MS_{RES}\\) 的比值會服從 \\(F\\) 分佈，自由度爲 \\((1, n-2)\\)： \\[ \\begin{equation} F=\\frac{SS_{REG}/1}{SS_{RES}/(n-2)} = \\frac{MS_{REG}}{MS_{RES}} \\sim F_{1,n-2} \\end{equation} \\tag{28.6} \\] 在替代假設條件下 \\((\\text{H}_1: \\beta\\neq0)\\)，\\(SS_{REG}\\) 的期望值是 \\(\\sigma^2+\\beta^2SS_{xx}\\)，所以替代假設條件下的 \\(F\\) 檢驗量總是會大於零假設時的 \\(F\\)。因此你可以看到，這是一個雙側檢驗 (\\(\\text{H}_0: \\beta=0 \\text{ v.s. H}_1: \\beta\\neq0\\))，但是由於替代假設的 \\(F\\) 總是較大，所以只需要 \\(F\\) 的右半部分的概率密度積分 (單側 \\(p\\) 值)。 28.2.7 簡單線性迴歸時 \\(F\\) 檢驗和 \\(t\\) 檢驗的一致性 證明 \\[ \\begin{aligned} &amp;F=\\frac{SS_{REG}/1}{SS_{RES}/(n-2)} = \\frac{SS_{REG}}{(SS_{yy}-SS_{REG})/(n-2)} \\\\ &amp;\\text{Since } r^2 = \\frac{SS_{REG}}{SS_{yy}} \\\\ &amp;F=(n-2)\\frac{SS_{yy}r^2}{SS_{yy}-SS_{yy}r^2}=(n-2)(\\frac{r^2}{1-r^2})=t^2 \\end{aligned} \\] 最後一步用到 (Section 27.6) 證明過的，迴歸係數檢驗統計量 \\(t\\)，和 Pearson 相關係數 \\(r\\) 之間的關係。 28.3 分類變量用作預測變量時的 ANOVA 方差分析的應用是如此的廣泛，你可以在多重迴歸中使用，也可以在模型中有分類變量時使用，甚至是同時有連續性變量和分類變量的迴歸模型中得到應用。 之前也遇到過二分類變量的簡單線性迴歸模型，當時我們的做法是使用一個啞變量來表示一個二分類變量。同樣的方法也可以用到多組分類變量上來，然後繼續使用線性迴歸。 28.3.1 一個二分類預測變量 在前面的例子 (Section 26.7) 中也已經展示過，可以通過線性迴歸來分析一個二分類變量 (實驗組對照組)，和一個連續型變量 (能直立行走時的兒童年齡)兩個變量之間的關係。而且其結果同兩樣本 \\(t\\) 檢驗的結果完全一致。 繼續回到之前用過的這個兒童行走數據 (表 26.1)： ## ## Call: ## lm(formula = Age ~ Group, data = Walk) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.1250 -0.7375 -0.3750 0.3875 2.8750 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.12500 0.51223 19.7663 1.007e-08 *** ## Groupcontrol 2.22500 0.75977 2.9285 0.0168 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.255 on 9 degrees of freedom ## (1 observation deleted due to missingness) ## Multiple R-squared: 0.48795, Adjusted R-squared: 0.43105 ## F-statistic: 8.5763 on 1 and 9 DF, p-value: 0.016797 ## Analysis of Variance Table ## ## Response: Age ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Group 1 13.502 13.5017 8.5763 0.0168 * ## Residuals 9 14.169 1.5743 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 之前分析這個數據的時候也說明過了，這裏的迴歸係數 \\(2.225\\) 的含義是兩組之間均值的差異。而且注意看，這個迴歸係數是否爲零的檢驗統計量\\((t-test)\\)獲得的 \\(p\\) 值和 ANOVA 的檢驗結果 \\((F-test)\\) 也是一致的。正驗證了我們前面證明的結果。(Section 28.2.7) 28.3.2 一個模型，兩種表述 上面這個例子中，一個二分類的預測變量和一個因變量之間的關係，實際上可以用兩種數學模型來表達： 令 \\(y_i, x_i\\) 分別是第 \\(i\\) 名觀察對象的因變量 (“直立行走的年齡”)，和預測變量 (“實驗組或者對照組”) \\((i=1,\\cdots,n)\\)。那麼迴歸模型可以寫作： \\[ \\begin{equation} y_i = \\alpha+\\beta x_i + \\varepsilon_i, \\text{ where } \\varepsilon_i \\sim NID(0, \\sigma^2) \\end{equation} \\tag{28.7} \\] 其中， \\(x_i=0\\) 時，表示第 \\(i\\) 名觀察對象在實驗組； \\(x_i=1\\) 時，表示第 \\(i\\) 名觀察對象在對照組。 在這樣的迴歸模型標記下，零假設和替代假設分別是 \\(\\text{H}_0: \\beta=0 \\text{ v.s. H}_1: \\beta\\neq0\\) 另一種模型的表達方式，被叫做 ANOVA 表達方式。是如此描述上面的關係的：令 \\(y_{ki}\\) 表示第 \\(i\\) 名觀察對象，他在第 \\(k\\) 組 \\((i=1,\\cdots, n_k; k=1,2)\\)，此時的模型被寫作： \\[ \\begin{equation} y_{ki} = \\mu_k + \\varepsilon_{ki}, \\text{ where } \\varepsilon_{ki} \\sim NID(0, \\sigma^2) \\end{equation} \\tag{28.8} \\] 此時，\\(\\mu_k\\) 表示第 \\(k\\) 組因變量的均值。零假設和替代假設分別是 \\(\\text{H}_0: \\mu_k=\\mu \\text{ v.s. H}_1: \\mu_k\\neq\\mu\\)。這裏的 \\(\\mu\\) 表示，每個組的平均值等於一個共同的均值 \\(\\mu\\)。 28.3.3 分組變量的平方和 對於預測變量只有一個分組變量的模型，擬合後的數值就是兩組的因變量均值 \\((\\bar{y}_k)\\)。在零假設條件下，兩組均值相等，均等於總體均值 \\(\\bar{y}\\)。這就導致了，殘差平方和，模型平方和在分組變量的 ANOVA 分析時要使用與連續型變量不同的術語。 殘差平方和表示爲： \\[ \\begin{equation} SS_{RES} = \\sum_{k=1}^k\\sum_{i=1}^{n_k} (y_{ki}-\\bar{y}_k)^2 \\end{equation} \\tag{28.9} \\] 其實這就是組內平方和 (within group sum of squares)。 模型平方和表示爲： \\[ \\begin{equation} SS_{REG} = \\sum_{k=1}^k\\sum_{i=1}^{n_k}(\\bar{y}_k-\\bar{y})^2=\\sum_{k=1}^kn_k(\\bar{y}_k-\\bar{y})^2 \\end{equation} \\tag{28.10} \\] 其實這就是組間平方和 (between group sum of squares) Mdl0 &lt;- aov(Age ~ Group, data = Walk) # fit a one-way ANOVA print(summary(Mdl0), digits = 6) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Group 1 13.5017 13.50170 8.57629 0.016797 * ## Residuals 9 14.1687 1.57431 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## 1 observation deleted due to missingness 其實這跟之前的 anova(Model) 給出的結果完全一致。 bartlett.test(Age ~ Group, data=Walk) ## ## Bartlett test of homogeneity of variances ## ## data: Age by Group ## Bartlett&#39;s K-squared = 0.63, df = 1, p-value = 0.4 FYI. 上面的代碼 bartlett.test() 利用的是另外一個叫做 Bartlett 檢驗法的方差比較公式。(在 STATA 的 oneway 命令中也會默認給出 Bartlett 檢驗的方差是否一致的檢驗結果) 28.3.4 簡單模型的分組變量大於兩組的情況 公式 (28.8), (28.9), 和 (28.10) 在兩組以上分組變量作預測變量時也是適用的。但是當組數爲 \\(K\\) 時，組內平方和 (殘差平方和 \\(SS_{RES}\\)) 的自由度需要修改成 \\(n-K\\) (這是因爲模型中使用了 \\(K\\) 個參數)。此時方差分析 ANOVA 的彙總表格就變爲了下面這樣： 表 28.2: One-way ANOVA table Source of variation Sum of Squares Degrees of Freedom Mean Sum of Squares Between groups \\(SS_{between}\\) \\(K-1\\) \\(\\frac{SS_{between}}{(K-1)}\\) Within groups \\(SS_{within}\\) \\(n-K\\) \\(\\frac{SS_{within}}{(n-K)}\\) Total \\(SS_{yy}\\) \\(n-1\\) \\(\\frac{SS_{yy}}{(n-1)}\\) 此時，檢驗統計量 \\(F\\) 的計算公式爲： \\[ \\begin{equation} F=\\frac{SS_{between}/(K-1)}{SS_{within}/(n-K)} \\sim F_{(K-1),(n-K)} \\end{equation} \\tag{28.11} \\] 在解釋兩組以上分組變量的分析結果時，要注意的是如果 \\(p\\) 值很小，檢驗結果告訴我們的是，各組中因變量的均值不全相等，而不是全部都不相等。其實就是，即使做了這個檢驗，我們也不知道到底那兩組之間是有差異的。如果此時我們發現結果提示均值不全相等，通常我們還會再作進一步的分析，使用類似成對比較法等等 (以後再繼續詳述)。不過提前要記住，如果使用成對比較法時 (pair-wise comparisons)，多重比較的問題 (multiple comparisons)會凸顯出來，主要的結果是增加統計檢驗的假陽性 (false-positive) 概率，此時再繼續使用 \\(p&lt;0.05\\) 作爲統計學意義的標準則是不妥當的。 "],
["-multivariable-models.html", "第 29 章 多元模型分析 Multivariable Models 29.1 兩個預測變量的線性迴歸模型 29.2 線性回歸模型中使用分組變量 29.3 協方差分析模型 the Analysis of Covariance (ANCOVA) Model 29.4 偏回歸係數的變化 29.5 混雜 confounding", " 第 29 章 多元模型分析 Multivariable Models 簡單線性迴歸描述的是一個連續型的因變量 \\((y)\\)，和一個單一的預測變量 \\((x)\\) 之間的關係。我們考慮把這個模型擴展成包含多個預測變量，單一因變量的模型。例如，我們可以考慮建立一個模型使用生活習慣 (包括“年齡，性別，運動，飲食習慣等”) 來預測收縮期血壓。此時多重迴歸的思想就可以幫我們理解一些我們更加關心的因子，與因變量之間的關係，同時控制或者叫調整了其他的混雜因子 (control or adjust confounders)。有時候這樣的模型也可以直接應用到生活中去，比如上面的例子，我們可以通過瞭解一個人的生活習慣，用建立好的模型來估計這個人的收縮期血壓。 建立模型之前，必須明確研究的目的是什麼。例如我們關心一個新發現的因子可能與高血壓有關係，那麼模型中我們放進去調整的其他因子 (如年齡，性別，運動) 等和因變量 (血壓) 之間的關係就變得不那麼重要。 多重線性迴歸，或者叫多元模型分析 (multiple linear regression or multivariable linear regression) 是研究一個連續型因變量和多個預測變量之間關係的重要模型。本章還會着重討論混雜 (confounding)的概念。 29.1 兩個預測變量的線性迴歸模型 29.1.1 數學標記法和解釋 這裏假設我們研究一個因變量 \\(Y\\)，和兩個預測變量 \\((X_1,X_2)\\) 的模型。那麼此時兩個預測變量的線性迴歸模型可以記爲： \\[ \\begin{equation} y_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i, \\text{ where } \\varepsilon_i \\sim \\text {NID}(0, \\sigma^2) \\end{equation} \\tag{29.1} \\] 其中， \\(y_i\\) 是第 \\(i\\) 名研究對象的因變量數據 (例如體重)； \\(x_{1i}\\) 是第 \\(i\\) 名研究對象的第一個預測變量數據 (例如年齡)， \\(X_1\\)； \\(x_{2i}\\) 是第 \\(i\\) 名研究對象的第二個預測變量數據 (例如身高)， \\(X_1\\)； \\(\\alpha\\) 的涵義是，當兩個預測變量均爲 \\(0\\) 時，因變量的期望值； \\(\\beta_1\\) 的涵義是，當 \\(X_2\\) 不變時，\\(X_1\\) 每升高一個單位，因變量的期望值； \\(\\beta_2\\) 的涵義是，當 \\(X_1\\) 不變時，\\(X_2\\) 每升高一個單位，因變量的期望值。 \\(\\beta_1, \\beta_2\\) 叫做偏迴歸係數 (partial regression coefficient)。它們測量的是兩個預測變量中，當一個被控制 (保持不變) 時，另一個對因變量的影響。 這個模型也可以用矩陣的形式來表示： \\[ \\begin{equation} \\textbf{Y} = \\textbf{X}\\beta+\\varepsilon, \\text{ where } \\varepsilon \\sim N(0, \\textbf{I}\\sigma^2) \\\\ \\left( \\begin{array}{c} y_1\\\\ y_2\\\\ \\vdots\\\\ y_n \\end{array} \\right) = \\left( \\begin{array}{c} 1&amp; x_{11} &amp; x_{21} \\\\ 1&amp; x_{12} &amp; x_{22} \\\\ \\vdots &amp; \\vdots&amp; \\vdots \\\\ 1&amp; x_{1n}&amp; x_{2n} \\\\ \\end{array} \\right)\\left( \\begin{array}{c} \\alpha \\\\ \\beta_1\\\\ \\beta_2 \\end{array} \\right)+\\left( \\begin{array}{c} \\varepsilon_1\\\\ \\varepsilon_2\\\\ \\vdots\\\\ \\varepsilon_n\\\\ \\end{array} \\right) \\end{equation} \\tag{29.2} \\] 此時上面的表達式中，\\(\\textbf{X}\\) 是一個矩陣，\\(\\textbf{Y, \\beta, \\varepsilon}\\) 均為向量。殘差被認為服從多變量正態分佈 (Multivariate normal distribution) ，這個多變量正態分佈的協方差矩陣為 \\(\\sigma^2\\) 和單位矩陣 \\(\\textbf{I}\\) 的乘積來描述。這等價於假設殘差是獨立同分佈且方差 \\(\\sigma^2\\) 不變。 29.1.2 最小平方和估計 Least Squares Estimation 跟簡單線性回歸相似地，我們需要通過對殘差平方和最小化，來獲得此時多重線性回歸的各項參數估計： \\[ \\begin{equation} SS_{RES} = \\sum_{i=1}^n \\hat\\varepsilon_{i}^2 = \\sum_{i=1}^n(y_i-\\hat{y})^2=\\sum_{i=1}^n(y_i-\\hat\\alpha-\\hat\\beta_1x_{1i}-\\hat\\beta_2x_{2i})^2 \\end{equation} \\tag{29.3} \\] 求能讓這個殘差平方和取最小值的參數估計 \\(\\hat\\alpha,\\hat\\beta_1,\\hat\\beta_2\\) 我們會在下一章用矩陣標記法來解釋。此處要強調的是，這些估計量都是無偏估計量，且可以被證明的是殘差方差可以用下面的式子來定義： \\[ \\begin{equation} \\hat\\sigma^2=\\sum_{i=1}^n\\frac{\\hat\\varepsilon_i^2}{(n-3)}=\\frac{\\sum_{i=1}^n(y_i-\\hat\\alpha-\\hat\\beta_1x_{1i}-\\hat\\beta_2x_{2i})^2}{(n-3)} \\end{equation} \\tag{29.4} \\] 29.2 線性回歸模型中使用分組變量 之前我們已展示過，分組變量可以使用啞變量來表示。分組變量多於兩組時，可用多個啞變量來同時表示。現在假設變量 \\(X\\) 有三個分組分別用 \\(1,2,3\\) 來表示。那麼用啞變量來描述含有這個分組變量的數學方法可以標記為： \\[ \\begin{equation} y_i = \\alpha+\\beta_1u_{1i}+\\beta_2u_{2i}+\\varepsilon_i, \\text{ where } \\varepsilon_i \\sim \\text{NID} (0,\\sigma^2) \\end{equation} \\tag{29.5} \\] 其中 \\[ \\begin{aligned} u_{1i}=\\left\\{ \\begin{array}{ll} 1 \\text{ if } x_i=2 \\\\ 0 \\text{ if } x_i\\neq2 \\\\ \\end{array} \\right. ; u_{2i}=\\left\\{ \\begin{array}{ll} 1 \\text{ if } x_i=3 \\\\ 0 \\text{ if } x_i\\neq3 \\\\ \\end{array} \\right. \\end{aligned} \\] 其實如果你願意，你也可以把公式 (29.5) 寫成下面這樣： \\[ \\begin{aligned} \\begin{array}{ll} y_i = \\alpha + \\varepsilon_i &amp; \\text{if } x_i=1 \\\\ y_i = \\alpha +\\beta_1+ \\varepsilon_i &amp; \\text{if } x_i=2 \\\\ y_i = \\alpha +\\beta_2+ \\varepsilon_i &amp; \\text{if } x_i=3 \\\\ \\end{array} \\end{aligned} \\] 所以， \\(\\alpha\\) 是 \\(X=1\\) 時因變量的期待值； \\(\\alpha+\\beta_1\\) 是 \\(X=2\\) 時因變量的期待值，所以 \\(\\beta_1\\) 是分組變量 \\(X\\) 前兩組之間因變量的期待值的差； \\(\\alpha+\\beta_2\\) 是 \\(X=3\\) 時因變量的期待值，所以 \\(\\beta_2\\) 是分組變量 \\(X\\) 前兩組之間因變量的期待值的差。 此時的 \\(X=1\\) 這個組通常被當作是分組變量中的基準組，也就是參照組 (reference group)。實際情況下你可能可以改變這個參照組為其他組的任意一個。 29.3 協方差分析模型 the Analysis of Covariance (ANCOVA) Model 協方差分析模型用來分析一個連續型的因變量 \\(Y\\) ，與一個連續型的預測變量 \\((X_1)\\)和一個二分類的預測變量 \\((X_2= 1,2)\\)，模型被標記為： \\[ \\begin{equation} y_i=\\alpha+\\beta_1x_{1i}+\\beta_2u_{2i}+\\varepsilon_i, \\text{ where } \\varepsilon_i \\sim \\text{NID}(0,\\sigma^2) \\end{equation} \\tag{29.6} \\] 其中， \\(y_{i}\\) 為第 \\(i\\) 名研究對象的因變量數據 (連續型)； \\(x_{1i}\\) 為第 \\(i\\) 名研究對象的第一個預測變量 (也是連續型)； \\(u_i =\\left\\{ \\begin{array}{ll} 1 \\text{ if } x_{2i}=2 \\\\ 0 \\text{ if } x_{2i}=1 \\\\ \\end{array}\\right.\\) 此模型中用到的參數有： \\(\\alpha\\) 是截距，意為當 \\(X_1=0\\) 且 \\(X_2=1 \\; (u=0)\\) 時的因變量期待值； \\(\\beta_1\\) 是當 \\(X_2\\) 保持不變時，\\(X_1\\) 每升高一個單位時，因變量 \\(Y\\) 的期待值； \\(\\beta_2\\) 是當 \\(X_1\\) 保持不變時，分組變量 \\(X_2\\) 的兩組之間因變量 \\(Y\\) 的期待值差異大小。 所以理解了上面的解釋之後，就可以將表達式 (29.6) 描述為： \\[ \\begin{array}{ll} y_i=\\alpha+\\beta_1x_{1i}+\\varepsilon_i &amp; \\text{ if } x_{2i}=1 \\\\ y_i=\\alpha+\\beta_2+\\beta_1x_{1i}+\\varepsilon_i &amp; \\text{ if } x_{2i} = 2 \\end{array} \\] 所以，在一個二維圖形中繪製這兩條回歸直線，你會發現他們之間是平行的。因為他們之間相差的只有截距，決定直線斜率的回歸係數，都是 \\(\\beta_1\\)。再用之前用過的數據，兒童的體重和年齡，如果此時考慮了性別因素的話，多重線性回歸的輸出結果和圖形分別應該是： growgam1 &lt;- read_dta(&quot;backupfiles/growgam1.dta&quot;) growgam1$sex &lt;- as.factor(growgam1$sex) Model1 &lt;- lm(wt ~ age + sex, data=growgam1) print(summary(Model1), digits = 5) ## ## Call: ## lm(formula = wt ~ age + sex, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.19236 -0.76268 -0.00696 0.75675 3.79163 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.152414 0.234254 30.5327 &lt; 2.2e-16 *** ## age 0.163998 0.010919 15.0189 &lt; 2.2e-16 *** ## sex2 -0.518854 0.183053 -2.8344 0.005095 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.25 on 187 degrees of freedom ## Multiple R-squared: 0.5597, Adjusted R-squared: 0.55499 ## F-statistic: 118.85 on 2 and 187 DF, p-value: &lt; 2.22e-16 print(anova(Model1), digits = 5) ## Analysis of Variance Table ## ## Response: wt ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## age 1 359.06 359.06 229.6755 &lt; 2.2e-16 *** ## sex 1 12.56 12.56 8.0341 0.005095 ** ## Residuals 187 292.35 1.56 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 圖 29.1: Data and fitted values from a regression model relating age and gender to data from a cross-sectional survey. For male children data points shown as circles and fitted values linked by a solid line. For female children data points shown as triangles and fitted values linked by a dashed line. 29.4 偏回歸係數的變化 在增加不同的預測變量進入線性回歸模型中時，原先在方程中的預測變量的偏回歸係數發生了怎樣的變化？ 我們先從最簡單的開始入手。先只考慮一個簡單先行回歸模型的情況。當我們新加入一個預測變量，模型發生了什麼變化？ \\[ \\begin{aligned} &amp; \\text{Model 1: } y_i = \\alpha^*+\\beta_1^*x_{1i}+\\varepsilon^*_i \\\\ &amp; \\text{Model 2: } y_i = \\alpha + \\beta_1x_{1i} + \\beta_2 x_{2i}+\\varepsilon_i \\end{aligned} \\] \\(\\beta_1, \\beta_1^*\\) 表示的其實是完全不同的含義。\\(\\beta_1^*\\) 被稱為粗回歸係數 (crude coefficient)，或者叫做調整前回歸係數，\\(\\beta_1\\) 被稱為調整後回歸係數 (adjusted coefficient)。二者之間的差異，其實是可以通過對這兩個變量進行簡單線性回歸來度量的： \\[ \\text{Model 3: } x_{2i} = \\gamma+\\delta_1x_{1i}+\\omega_i \\] 將 Model 2 中的 \\(x_{2i}\\) 用 Model 3 來替換掉： \\[ \\begin{aligned} \\text{Model 2: }y_i &amp;= \\alpha + \\beta_1 x_{1i} + \\beta_2(\\gamma + \\delta_1x_{1i}+\\omega_i) +\\varepsilon_i \\\\ &amp;= \\alpha + \\beta_2\\gamma+(\\beta_1+\\beta_2\\delta_1)x_{1i}+\\beta_2\\omega_i + \\varepsilon_i \\end{aligned} \\] 比較 Model 1 和變形過後的 Model 2 中 \\(x_{1i}\\) 的係數就不難發現： \\[ \\beta_1^* = \\beta_1 + \\beta_2\\delta_1 \\] 由此可見，調整前後 \\(x_{1i}\\) 的回歸係數的變化 \\(\\beta_1^*, \\beta_1\\) 之間的差異，取決於兩個部分的大小： \\(\\beta_2\\) 的大小和它的符號； \\(X_1, X_2\\) 這兩個預測變量之間有多大關聯，用 Model 3 的 \\(\\delta_1\\) 來度量。 所以，當調整後的 \\(\\beta_1 &gt; 0\\) 時，要分三種情況來討論 29.4.1 情況1： \\(\\beta_1 &gt; \\beta_1^*\\) 此時，\\(\\beta_2\\delta_1&lt;0\\) 所以，二者之間一正一負。如下圖所示： 按圖所示，當 \\(X_2\\) 保持不變，\\(X_1\\) 與因變量 \\(Y\\) 正相關 (\\(\\beta_1&gt;0\\))。但是，兩個預測變量之間 \\(X_1, X_2\\) 也呈正相關關係 \\(\\delta_1 &gt;0\\)。而同時，\\(X_2\\) 的升高會導致因變量 \\(Y\\) 的下降 ($_2 &lt;0 $)。這種情況就意味著，如果，我們不調整 \\(X_2\\) (使之保持不變)，那麼 \\(X_1\\) 每升高一個單位，\\(Y\\) 的變化會低於調整 \\(X_2\\) 時，\\(X_1\\) 的變化所引起的 \\(Y\\) 的變化。如果這時候 \\(\\beta_2,\\delta_1\\) 較大，那麼對於 \\(X_1\\) 來說，調整 \\(X_2\\) 前後，回歸係數的變化較大，如果大到一定程度，甚至調整前後的回歸係數的方向 (正負) 都會發生變化。 29.4.2 情況2：\\(\\beta_1&lt;\\beta_1^*\\) 本情況下，\\(\\beta_2\\delta_1&gt;0\\) 是正的。所以二者要麼同時爲正，要麼同時爲負。如下圖所示： 當 \\(X_2\\) 保持不變時， \\(X_1\\) 同 \\(Y\\) 呈正關係。但是，\\(X_1\\) 的升高也會引起 \\(X_2\\) 的升高，同時通過 \\(X_2\\) 和 \\(Y\\) 之間的正關係升高 \\(Y\\)。所以假設在模型裏我們不對 \\(X_2\\) 進行控制 (controld or adjust)，那麼 \\(X_1\\) 和 \\(Y\\) 之間的關係就被誇大了。 所以，當 \\(X_1\\rightarrow X_2\\rightarrow Y\\) 的這條通路大大超過 \\(X_1\\rightarrow Y\\) 的話，調整後的迴歸係數 \\(\\beta_1\\) 就會變得很小。 29.4.3 情況3： \\(\\beta_1 = \\beta_1^*\\) 這種情況只有當 \\(\\beta_2\\delta_1=0\\) 時才會出現。所以，二者至少有一個是 \\(0\\)。 如下圖所示： \\(X_1\\) 與 \\(Y\\) 呈正關係，\\(X_1\\) 與 \\(X_2\\) 呈正關係。但是 \\(X_2\\) 與 \\(Y\\) 無關聯。所以此時無論模型是否調整了 \\(X_2\\) 都不會影響 \\(X_1\\) 和 \\(Y\\) 之間關係的計算。 29.5 混雜 confounding 流行病學家最喜歡的詞彙恐怕要屬混雜 (confounding) 了 (interaction, 交互作用也要算一個 (Section 32，(笑))。他們常用混雜來解釋爲什麼調整其他因子前後迴歸係數發生了變化。當有其他因子 (測量了或者甚至是未知的) 對我們關心的預測變量和因變量之間的關係產生了影響 (加強或是減弱) 時，就叫做發生了混雜。 對於一個預測變量是否夠格被叫做混雜因子，它必須滿足下面的條件： 與關心的預測變量相關 (i.e. \\(\\delta_1 \\neq 0\\))； 與因變量相關 (當關心的預測變量不變時，\\(\\beta_2\\neq0\\) )； 不在預測變量和因變量的因果關係 (如果有的話) 中作媒介。Not be on the causal pathway between the predictor of interest and the dependent variable. 有時，判斷一個因子是否對我們關心的預測變量和因變量之間的關係構成了混雜並不容易，也不直觀。所以，有太多太多的情況下，我們無法準確地 100% 地確定我們關心的關係是否被別的因子混雜。所以，莫要用 “混雜” 一詞簡單糊弄人。 29.5.1 作為媒介 mediation effect 多數情況下，我們也無法從數據判斷一個變量是否在我們關心的預測變量和因變量之間關係的通路上。此時要做的是離開你的電腦，去學習他們之間的生物學知識，看是否真的有關係。 但是有些例子就很簡單啦。比如說，服用降血壓藥物可以預防發生中風。那麼此時血壓的降低，就處在了這二者因果關係的通路上。因爲藥物通過降低了血壓，從而預防了中風的發生。這一關係中，我們不能說血壓是混雜因子，它是一個媒介 (mediator)。但是多數的橫斷面研究 (cross-sectional study) 中我們無法是很難下結論的。 29.5.2 兩個預測變量之間的關係 如果另一個變量不是媒介，且它和我們關心的預測變量，因變量之間如果都有相關關係，那它的確有可能成為混雜因子。但是僅僅通過統計學模型來考察混雜是絕對不夠的。例如樣本量較小的數據中，我們可能無法檢驗出一個變量對模型的混雜影響是不是有統計學意義的，但是這不能提供證據否認它不是混雜因子。同樣的，更多的混雜因子是我們沒有測量沒有觀察到收集到的未知因素。所以，任何數據都無法提供完全去除混雜因子影響的模型。 29.5.3 RCT臨床實驗是個特例 因為隨機對照臨床實驗，在設計階段就已經把治療組對照組之間的差異最小化了，理想的隨機對照實驗，其治療組和對照組之間理論上除了治療藥物的差別之外完全相同。當然這是理想狀況，且所有的臨床實驗都必須向這個方向努力設計和實施。偶然出現的治療組和對照組在某些特徵上的不平衡，不能被認為是混雜因子。只能說這樣的臨床實驗是不理想的，提供的證據水平也就較弱。 "],
["section-30.html", "第 30 章 多元模型分析：矩陣標記與其意義 30.1 線性回歸模型的矩陣/非矩陣標記法 30.2 解讀參數 30.3 方差分析一般化和 \\(F\\) 檢驗 30.4 添加新變量對迴歸模型的影響 30.5 實戰演習", " 第 30 章 多元模型分析：矩陣標記與其意義 在線性回歸目前為止介紹的內容中，我們最多只談到了預測變量為兩個的情況。本章，我們要把這些概念推廣到三個或者三個以上預測變量的情況。同時，多重線性回歸時採用的假設檢驗也會被談及。其實最常見的就是 \\(F\\) 檢驗。而且我們也見識過了，當預測變量只有一個的時候，\\(F\\) 檢驗和 \\(t\\) 檢驗是等價的。 重要的概念我們都已經介紹完畢。前一章的多重回歸模型中也強調了，我們之所以希望把多個預測變量放進模型，最大的目的就是想了解這些預測變量之間的相互關係，當他們得到調整 (adjustment) 之後，彼此之間的關係是怎樣的。這樣的關係我們稱之為條件關係 (conditional relationships)。當我們使用條件關係的稱呼時，需要同時指明我們說的是哪個變量，在那個變量不變的條件下，與因變量的關係是如何如何。 本章節最後的部分將會著重關注共線性 (collinearity) 的問題。 30.1 線性回歸模型的矩陣/非矩陣標記法 30.1.1 模型標記： 假如，因變量用 \\(Y\\) 表示，預測變量有 \\(p\\) 個之多 \\((X_1,\\cdots, X_p)\\)。該模型的非矩陣標記法如下： \\[ \\begin{equation} y_i = \\alpha + \\beta_1 x_{1i}+ \\beta_2 x_{2i} + \\cdots + \\beta_p x_{pi} + \\varepsilon_i \\text{ with } \\varepsilon_i \\sim \\text{NID}(0, \\sigma^2) \\end{equation} \\tag{30.1} \\] 其中， \\(y_i =\\) 第 \\(i\\) 名觀察對象的因變量數據； \\(x_{pi} =\\) 第 \\(i\\) 名觀察對象的第 \\(p\\) 個預測變量的觀察數據。 上面的非矩陣標記法，等同於如下的矩陣標記法： \\[ \\begin{equation} \\textbf{Y} = \\textbf{X}\\beta+\\varepsilon, \\text{ where } \\varepsilon \\sim N(0, \\textbf{I}\\sigma^2) \\\\ \\left( \\begin{array}{c} y_1\\\\ y_2\\\\ \\vdots\\\\ y_n \\end{array} \\right) = \\left( \\begin{array}{c} 1&amp; x_{11} &amp; \\cdots &amp; x_{p1} \\\\ 1&amp; x_{12} &amp; \\cdots &amp; x_{p2} \\\\ \\vdots &amp; \\vdots&amp; \\vdots &amp; \\vdots \\\\ 1&amp; x_{1n}&amp; \\cdots &amp;x_{pn} \\\\ \\end{array} \\right)\\left( \\begin{array}{c} \\alpha \\\\ \\beta_1\\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_p \\end{array} \\right)+\\left( \\begin{array}{c} \\varepsilon_1\\\\ \\varepsilon_2\\\\ \\vdots\\\\ \\varepsilon_n\\\\ \\end{array} \\right) \\end{equation} \\tag{30.2} \\] 此公式 (30.2) 中 \\(\\textbf{X}\\) 是一個 \\(n\\times(p+1)\\) 的矩陣； \\(\\textbf{Y}\\) 和 \\(\\varepsilon\\) 分別是長度為 \\(n\\) 的列向量； \\(\\beta\\) 是長度為 \\(p+1\\) 的列向量，且第一個元素是 \\(\\alpha\\)，偶爾被人誤寫成 \\(\\beta_0\\)。 殘差被認為服從多元正態分佈 (multivariate normal distribution)，這個多元正態分佈的方差協方差矩陣等於 \\(\\sigma^2\\) 與單位矩陣相乘獲得的矩陣。這其實等價於認為殘差服從獨立正態且方差為 \\(\\sigma^2\\) 的分佈， 30.2 解讀參數 模型中的參數的涵義為： \\(\\alpha\\) 是截距，所有的預測變量都是零的時候，因變量 \\(Y\\) 的期待值大小； \\(\\beta_j\\) 是預測變量 \\(X_j\\) 升高一個單位，且其他變量保持不變的同時，因變量 \\(Y\\) 的期待值的變化； \\(\\beta_j\\) 都是偏回歸係數，每個偏回歸係數，測量的都是該預測變量調整了其他預測變量之後對於因變量期待值的影響。 30.2.1 最小二乘估計 還是同之前一樣，我們對殘差的平方和最小化，來獲取我們關心的預測變量的回歸變量。 \\[ \\begin{aligned} SS_{RES} &amp; = \\sum_{i=1}^n \\hat\\varepsilon_i^2 = \\sum_{i=1}^n(y_i-\\hat{y})^2 \\\\ &amp; = \\sum_{i=1}^n (y_i-\\hat\\alpha-\\hat\\beta_1x_{1i}-\\hat\\beta_2x_{2i}-\\cdots-\\hat\\beta_px_{pi})^2 \\end{aligned} \\tag{30.3} \\] 下面用矩陣標記法計算 \\(\\hat\\beta\\)： \\[ \\begin{aligned} \\text{Because } \\mathbf{Y} &amp; = \\mathbf{X\\hat\\beta + \\varepsilon} \\\\ \\Rightarrow \\mathbf{\\varepsilon} &amp; = \\mathbf{Y - X\\hat\\beta}\\\\ \\Rightarrow \\mathbf{SS_{RES}} &amp; = \\varepsilon_1\\times \\varepsilon_1 + \\varepsilon_2\\times \\varepsilon_2 + \\cdots + \\varepsilon_n\\times \\varepsilon_n \\\\ &amp; = (\\varepsilon_1, \\varepsilon_2, \\cdots, \\varepsilon_n)\\left( \\begin{array}{c} \\varepsilon_1\\\\ \\varepsilon_2\\\\ \\vdots\\\\ \\varepsilon_n \\end{array} \\right) \\\\ &amp; = \\mathbf{\\varepsilon^\\prime} \\mathbf{\\varepsilon} \\\\ &amp; = \\mathbf{(Y-X\\hat\\beta)^\\prime(Y-X\\hat\\beta)} \\\\ &amp; = \\mathbf{Y^\\prime Y - X^\\prime\\hat\\beta^\\prime Y - Y^\\prime X\\hat\\beta + X^\\prime\\hat\\beta^\\prime X \\hat\\beta} \\\\ \\text{Because} &amp;\\text{ transpose of a scalar is a scalar:} \\\\ \\mathbf{Y^\\prime X\\hat\\beta} &amp; = \\mathbf{(Y^\\prime X\\hat\\beta)^\\prime = X^\\prime\\hat\\beta^\\prime Y} \\\\ \\Rightarrow \\mathbf{SS_{RES}} &amp; = \\mathbf{Y^\\prime Y - 2X^\\prime\\hat\\beta^\\prime Y + X^\\prime\\hat\\beta^\\prime X \\hat\\beta}\\\\ \\Rightarrow \\mathbf{\\frac{\\partial SS_{RES}}{\\partial \\hat\\beta}} &amp; = \\mathbf{-2X^\\prime Y + 2 X^\\prime X \\hat\\beta} = 0 \\\\ \\Rightarrow \\mathbf{\\hat\\beta} &amp; = \\mathbf{(X^\\prime X)^{-1}X^\\prime Y} \\end{aligned} \\tag{30.4} \\] 公式 (30.4) 是參數矩陣 \\(\\mathbf{\\beta}\\) 的無偏估計，且服從方差協方差矩陣爲 \\(\\mathbf{(X^\\prime X)^{-1}\\sigma^2}\\) 的多元正態分佈： \\[ \\begin{equation} \\mathbf{\\hat\\beta} \\sim N(\\mathbf{\\beta, (X^\\prime X)^{-1}\\sigma^2}) \\end{equation} \\tag{30.5} \\] 另外可以被證明的是，多元線性迴歸模型的殘差方差的估計量計算公式爲： \\[ \\begin{aligned} \\hat\\sigma^2 &amp; = \\sum^n_{i=1}\\frac{\\hat\\varepsilon^2_i}{[n-(p+1)]} \\\\ &amp; = \\sum^n_{i=1}\\frac{\\sum_{i=1}^n (y_i-\\hat\\alpha-\\hat\\beta_1x_{1i}-\\hat\\beta_2x_{2i}-\\cdots-\\hat\\beta_px_{pi})^2}{[n-(p+1)]} \\\\ \\text{Where } &amp; p \\text{ is the number of predictors} \\end{aligned} \\tag{30.6} \\] 30.2.2 因變量的期待值 \\(\\mathbf{\\hat Y}\\) 因變量的期待值矩陣 \\(\\mathbf{\\hat Y}\\) 根據公式 (30.4) 推導： \\[ \\begin{aligned} \\mathbf{\\hat Y} &amp; = \\mathbf{X\\hat\\beta} \\\\ &amp; = \\mathbf{X(X^\\prime X)^{-1}X^\\prime Y}= \\mathbf{PY} \\\\ \\text{Where } \\mathbf{P} &amp;= \\mathbf{X(X^\\prime X)^{-1}X^\\prime} \\end{aligned} \\tag{30.7} \\] 這裏的 \\(n\\times n\\) 的正方形矩陣 \\(\\mathbf{P}\\) 在多元線性迴歸中是一個極爲重要的矩陣。 它常被叫做“帽子/映射 (hat/projection)”矩陣，因爲它把觀察值 \\(\\mathbf{Y}\\) 和觀察值的擬合值一一映射； 帽子矩陣的第 \\(i\\) 個對角元素，是第 \\(i\\) 名觀察值的影響值 (leverage)，會用在下章節的模型診斷中； 擬合值矩陣的方差協方差矩陣被定義爲： \\[ \\begin{equation} \\text{Var}(\\mathbf{\\hat Y}) = \\mathbf{P}\\sigma^2 \\end{equation} \\tag{30.8} \\] 30.2.3 殘差 殘差的觀察值 \\(\\mathbf{\\hat\\varepsilon}\\) 被定義爲觀察值和擬合值的差。根據前節 (30.8) 推導： \\[ \\begin{equation} \\mathbf{\\hat\\varepsilon} = \\mathbf{Y - \\hat Y} = \\mathbf{Y - PY} = \\mathbf{(I - P)Y} \\end{equation} \\tag{30.9} \\] 這個觀察殘差的方差被定義爲： \\[ \\begin{equation} \\text{Var}(\\mathbf{\\hat\\varepsilon}) = \\mathbf{(I - P)}\\sigma^2 \\end{equation} \\tag{30.10} \\] 一般地，\\(\\mathbf{P}\\) 不是一個對角矩陣，意思是觀察殘差之間無法保證是獨立的； \\(\\mathbf{P}\\) 的對角元素也不全都相等，意思是觀察殘差的方差無法保證是恆定不變的。 30.3 方差分析一般化和 \\(F\\) 檢驗 30.3.1 多元線性迴歸時的決定係數和殘差方差 和簡單線性迴歸一樣，因變量的校正平方和可以被分割成兩部分：迴歸模型能夠解釋的平方和；模型無法解釋的殘差平方和。類比方差分析章節 (Section 28) 的公式 (28.1)： \\[ \\begin{aligned} \\sum_{i=1}^n(y_i-\\bar{y})^2 &amp; = \\sum_{i=1}^n(\\hat{y}_i - \\bar{y})^2 + \\sum_{i=1}^n(y_i - \\hat{y}_i)^2 \\\\ SS_{yy} &amp; = SS_{REG} + SS_{RES} \\end{aligned} \\tag{30.11} \\] 和簡單線性迴歸也一樣，多元線性迴歸時的模型決定係數 (coefficient of determination) 的定義爲： \\[ \\begin{aligned} R^2 &amp; = \\frac{SS_{yy}-SS_{RES}}{SS_{yy}} = 1- \\frac{SS_{RES}}{SS_{yy}} \\\\ &amp; = 1 - \\frac{\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \\end{aligned} \\tag{30.12} \\] 這裏的 \\(R^2\\) 也一樣可以被解釋爲模型能夠解釋的因變量變動部分的百分比 (proportion of the variability in the dependent variable explained by the model)。值得注意的是，當模型中預測變量不減少，每加入一個新的預測變量，決定係數也會增加，相反殘差平方和卻絕不會增加。 30.3.2 方差分析表格 下表和簡單線性迴歸的方差分析表格很類似，也可以用來作假設檢驗 (迴歸方程的顯著性檢驗 Global \\(F-\\text{test}\\)，和偏 \\(F\\) 檢驗 Partial \\(F-\\text{test}\\))。 表 30.1: Analysis of Variance table for a liear regression model with \\(p\\) predictor variables Source of Variation Sum of Squares Degrees of Freedom Mean Sum of Squares Regression (model) \\(SS_{REG}\\) \\(p\\) \\(MS_{REG} = \\frac{SS_{REG}}{p}\\) Residual \\(SS_{RES}\\) \\(n-(p+1)\\) \\(MS_{RES} = \\frac{SS_{RES}}{[n-(p+1)]}\\) Total \\(SS_{yy}\\) \\(n-1\\) \\(\\frac{SS_{yy}}{(n-1)}\\) 30.3.3 迴歸方程的顯著性檢驗 整個方程的顯著性檢驗，檢驗的是所有的迴歸係數都等於零的零假設，其對應的替代假設則是：“迴歸係數不全爲零”。就是至少有一個不等於零。 在零假設條件下，檢驗統計量的計算公式爲： \\[ \\begin{equation} F = \\frac{MS_{REG}}{MS_{RES}} \\sim F_{p, [n-(p+1)]} \\end{equation} \\tag{30.13} \\] 在零假設條件下，\\(F\\) 的期望值接近 \\(1\\)，而替代假設條件下的 \\(F\\) 總是會大於此，所以和 \\(F\\) 分佈比較特徵值時只需要比較單側的 (右側的) 值，即可獲得雙側 \\(p\\) 值。 在 R 裏面，迴歸方程的結果的最底下會出現統計量 \\(F\\) 的大小，但是 \\(MS_{REG}, MS_{RES}\\) 要用 anova() 代碼獲得： growgam1 &lt;- read_dta(&quot;backupfiles/growgam1.dta&quot;) growgam1$sex &lt;- as.factor(growgam1$sex) Model1 &lt;- lm(wt ~ age + len, data=growgam1) print(summary(Model1), digits = 5) ## ## Call: ## lm(formula = wt ~ age + len, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.20525 -0.64402 -0.00303 0.55967 2.86277 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -8.351244 1.259968 -6.6281 3.531e-10 *** ## age -0.011260 0.016751 -0.6722 0.5023 ## len 0.237129 0.019516 12.1502 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9546 on 187 degrees of freedom ## Multiple R-squared: 0.74337, Adjusted R-squared: 0.74063 ## F-statistic: 270.84 on 2 and 187 DF, p-value: &lt; 2.22e-16 print(anova(Model1), digits = 5) ## Analysis of Variance Table ## ## Response: wt ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## age 1 359.06 359.06 394.06 &lt; 2.2e-16 *** ## len 1 134.52 134.52 147.63 &lt; 2.2e-16 *** ## Residuals 187 170.39 0.91 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 可以看到 summary() 輸出結果的最後一行是關於迴歸方程整體的 \\(F\\) 檢驗結果 F-statistic: 270.84 on 2 and 187 DF, p-value: &lt; 2.22e-16，從 anova() 結果中可以獲得 \\(MS_{REG} = \\frac{359.0632 + 134.5153}{2} = 246.7892\\)。\\(F_{2,187} = \\frac{246.7892}{0.9111833} = 270.84\\)。這個檢驗結果證明了，兩個預測變量 “體重” 和 “身長” 至少有一個的迴歸係數不等於零。 30.3.4 \\(\\text{partial }F\\) 檢驗 如果我們建立兩個模型，一個稍微複雜一些 \\((B)\\)，比起略簡單的模型 \\((A)\\)，增加了 \\(k\\) 個預測變量。兩個模型放在一起的方差分析表格可以歸納成： 表 30.2: Analysis of Variance table comparing the fit of a model \\((B)\\) with \\(p\\) predictor variables with that of one (model \\(A\\)) with \\(p-k\\) predictor variables Source of Variation Sum of Squares Degrees of Freedom Mean Sum of Squares Explained by model \\(A\\) \\(SS_{REG_A}\\) \\(p-k\\) \\(MS_{REG_A} = \\frac{SS_{REG_A}}{p-k}\\) Extra Explained by model \\(B\\) \\(SS_{REG_B}-SS_{REG_A}\\) \\(k\\) \\(\\frac{SS_{REG_B}-SS_{REG_A}}{k}\\) Residual from model \\(B\\) \\(SS_{RES_B}\\) \\(n-(p+1)\\) \\(MS_{RES_B} = \\frac{SS_{RES_B}}{[n-(p+1)]}\\) Total \\(SS_{yy}\\) \\(n-1\\) \\(\\frac{SS_{yy}}{(n-1)}\\) 那麼偏 \\(F\\) 檢驗的零假設就是：\\(B\\) 模型中包含，\\(A\\) 模型中不包含的 \\(k\\) 個預測變量的迴歸係數都等於零。 \\[ \\begin{equation} F=\\frac{(SS_{REG-B}-SS_{REG-A})/k}{MS_{RES-B}} \\sim F_{k, [n-(p+1)]} \\end{equation} \\tag{30.14} \\] 在 R 裏建立兩個模型： Model1 &lt;- lm(wt ~ len, data=growgam1) print(summary(Model1), digits = 5) ## ## Call: ## lm(formula = wt ~ len, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.155217 -0.629239 0.014555 0.544783 2.928738 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -7.6694406 0.7463556 -10.276 &lt; 2.2e-16 *** ## len 0.2257467 0.0096893 23.299 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9532 on 188 degrees of freedom ## Multiple R-squared: 0.74275, Adjusted R-squared: 0.74139 ## F-statistic: 542.82 on 1 and 188 DF, p-value: &lt; 2.22e-16 print(anova(Model1), digits = 5) ## Analysis of Variance Table ## ## Response: wt ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## len 1 493.17 493.17 542.82 &lt; 2.2e-16 *** ## Residuals 188 170.80 0.91 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Model2 &lt;- lm(wt ~ len + age + sex, data = growgam1) print(summary(Model2), digits = 5) ## ## Call: ## lm(formula = wt ~ len + age + sex, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.110422 -0.648401 0.026103 0.560621 2.768583 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -7.8906758 1.3003091 -6.0683 7.091e-09 *** ## len 0.2317997 0.0198470 11.6793 &lt; 2.2e-16 *** ## age -0.0077959 0.0168974 -0.4614 0.6451 ## sex2 -0.1964758 0.1421171 -1.3825 0.1685 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9522 on 186 degrees of freedom ## Multiple R-squared: 0.74599, Adjusted R-squared: 0.74189 ## F-statistic: 182.08 on 3 and 186 DF, p-value: &lt; 2.22e-16 print(anova(Model2), digits = 5) ## Analysis of Variance Table ## ## Response: wt ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## len 1 493.17 493.17 543.8753 &lt;2e-16 *** ## age 1 0.41 0.41 0.4540 0.5013 ## sex 1 1.73 1.73 1.9113 0.1685 ## Residuals 186 168.66 0.91 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 根據公式 (30.14)，\\(F=\\frac{0.4116944+1.7330862}{2\\times0.9067645} = 1.18\\)。\\(p\\) 值可以在 R 裏面這樣計算： 1 - pf(df1 = 2,df2 = 186,q = (0.4116944+1.7330862)/(2*0.9067645)) ## [1] 0.3088 更方便的是直接用 anova() 進行偏 \\(F\\) 檢驗： print(anova(Model1, Model2), digits = 5) ## Analysis of Variance Table ## ## Model 1: wt ~ len ## Model 2: wt ~ len + age + sex ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 188 170.80 ## 2 186 168.66 2 2.1448 1.1827 0.3088 30.4 添加新變量對迴歸模型的影響 當你決定給建立的模型 \\(\\mathbf{A}\\) 增加新的預測變量時，輸出的結果改變的有： 模型 \\(\\mathbf{A}\\) 原先的預測變量的偏迴歸係數會改變； 模型 \\(\\mathbf{A}\\) 原先的預測變量的偏迴歸係數的方差會改變； 模型 \\(\\mathbf{A}\\) 原先的預測變量的偏迴歸係數的檢驗結果會改變； 模型 \\(\\mathbf{A}\\) 原先的 擬合值 (predicted values/fitted values)會改變； 決定係數 \\(R^2\\) 會改變。 30.4.1 偏迴歸係數方差的改變 偏迴歸係數矩陣 \\(\\mathbf{\\hat\\beta}\\) 的方差 \\(\\mathbf{(X^\\prime X)^{-1}\\sigma^2}\\) (30.5)，取決於 殘差方差 (residual variance) \\(\\sigma^2\\)； 樣本量大小 (sample size) \\(n\\)； 預測變量之間的協方差 (covariance between the predictor variable in question and the others)。 在簡單線性迴歸中，預測變量的變化性 (variability，用方差或標準差衡量) 越大，迴歸係數的估計就越精確。類似地，多元線性迴歸中，預測變量之間的協方差之所以重要，因爲它決定了其他預測變量保持不變時，該預測變量的變化性。如果某兩個預測變量之間高度相關 (high covariance)，那麼當一個預測變量保持不變時，另一個的變化性就很小。 所以當給一個模型加入新的預測變量時，可能觀察的現象是原先模型中已有的預測變量的偏迴歸係數的方差可能升高，也可能降低。 如果新加入的變量能解釋很大比例的殘差方差，那麼其他原有變量的偏迴歸係數會降低 (變精確)； 如果新加入的變量和原模型中的某個變量高度相關，那麼加入新變量後，原模型中與之高度相關的預測變量的方差會升高 (不精確)，這個現象會在共線性 (collinearity) 中繼續討論。 30.4.2 偏迴歸係數檢驗結果的改變 加入新預測變量時，原有的偏迴歸係數的檢驗結果發生的改變可以歸類成兩種情況： 估計的偏迴歸係數本身發生了改變； 偏迴歸係數的方差改變，導致了檢驗結果發生變化。 30.4.3 擬合值的改變 很明顯，當模型中加入新的變量，觀察對象的擬合值會發生改變，但是通常這樣的影響要遠遠小於對偏迴歸係數估計 (和其方差) 的影響。 30.4.4 決定係數的改變 模型中增加新的預測變量，那麼模型的決定係數不會減少，只會增加。 30.4.5 共線性 collinearity 當預測變量 \\(X_1\\) 和另一個預測變量 \\(X_2\\) 之間呈高度線性關係時被定義爲共線性現象。如果這兩個變量的關係是完全線性 (exact linear)，那麼多元迴歸其實是無法進行的，因爲這兩個變量中的一個隨着另一個改變，無法像我們設想的那樣把其中一個變量保持不變，從而估計另一個變量的迴歸係數。用矩陣表示多元預測變量時 \\(\\mathbf{X}\\) 是奇異矩陣 singular matrix，\\(\\mathbf{(X^\\prime X)^{-1}}\\) 是不存在的。 完全線性的最佳例子是我們在對分類變量使用啞變量的情況下。每個啞變量之間都是完全線性的關係，因而我們只能用 \\(0,1\\) 來編碼啞變量，當某個啞變量存在時，其餘的啞變量取 \\(0\\) 從模型中消失。否則模型將無法擬合。 如果某兩個變量之間高度相關，那麼他們的預測變量矩陣接近 奇異矩陣，把這兩個變量同時作爲預測變量放入模型中會引起共線性現象，表現出來的形式有： 偏迴歸係數的方差變得很大； 偏迴歸係數本身的絕對值變得異常大； 某些已知的重要預測變量的偏迴歸係數變得過小且不再有意義； 雖然會有 1-3 描述的異常現象出現，但是擬合值的變化卻可能微不足道。 所以擬合多元線性迴歸模型時，極爲重要的一點是要避免共線性。如果有些變量高度相關，必須考慮改變他們放入模型的形式： 收縮期血壓，舒張期血壓兩個變量是高度相關的，不能一起放入模型中。如果需要同時考慮兩個變量，可以用其中一個，另一個預測變量用二者之差； 身高，體重常常是高度相關的，儘量不要一起放入模型中，可以使用他們的結合形式體質指數 (BMI, \\(\\text{kg/m}^2\\))； 當使用二次方程進行模型擬合的時候，用 \\((x_i - \\bar{x})^2\\) 取代 \\(x_i^2\\)。 30.5 實戰演習 30.5.1 血清維生素 C 濃度的預測變量 數據來自與某個橫斷面研究，其目的是找出與血清維生素 C 濃度相關的預測變量。 數據中個變量含義如下表所示。 表 30.3: Data set of serum vitamin C level explained Variable name content serial Patient identifier age Age of subjects in years height Height in metres cigs Smoking status (0=non-smoker; 1=smoker) weight Weight in kg sex Gender (0=men; 1=women) seruvitc Serum Vitamin C level (\\(\\mu\\text{mol/L}\\)) ctakers Vitamin C supplements taken (1=yes, 0=no) 在 R 裏讀入數據，並對數據內容總結，對維生素C濃度和其他連續性變量作散點圖，對分類變量如性別，吸菸狀況，和維生素C補充劑服用與否之間的維生素 C 濃度作初步的分析表格。 library(haven) vitC &lt;- read_dta(&quot;backupfiles/vitC.dta&quot;) ########################################## # Recoding the categorical variables # ########################################## vitC$sex[vitC$sex == 0] &lt;- &quot;Men&quot; vitC$sex[vitC$sex == 1] &lt;- &quot;Women&quot; vitC$sex &lt;- as.factor(vitC$sex) vitC$cigs[vitC$cigs == 0] &lt;- &quot;Non-smoker&quot; vitC$cigs[vitC$cigs == 1] &lt;- &quot;Smoker&quot; vitC$cigs &lt;- as.factor(vitC$cigs) vitC$ctakers[vitC$ctakers == 0] &lt;- &quot;No&quot; vitC$ctakers[vitC$ctakers == 1] &lt;- &quot;Yes&quot; vitC$ctakers &lt;- as.factor(vitC$ctakers) ############################################ # End of recoding the categorical variables# ############################################ summary(vitC) #Basic summary without any package ## serial age height cigs weight sex ## Min. : 1.0 Min. :65.0 Min. :1.48 Non-smoker:80 Min. : 44.0 Men :44 ## 1st Qu.: 23.8 1st Qu.:67.0 1st Qu.:1.58 Smoker :12 1st Qu.: 57.8 Women:48 ## Median : 49.0 Median :69.0 Median :1.64 Median : 67.0 ## Mean : 49.2 Mean :69.3 Mean :1.65 Mean : 68.6 ## 3rd Qu.: 73.2 3rd Qu.:71.0 3rd Qu.:1.72 3rd Qu.: 76.5 ## Max. :100.0 Max. :74.0 Max. :1.89 Max. :103.0 ## NA&#39;s :1 NA&#39;s :1 ## seruvitc ctakers ## Min. : 8.0 No :73 ## 1st Qu.: 34.8 Yes:19 ## Median : 58.0 ## Mean : 53.2 ## 3rd Qu.: 71.0 ## Max. :100.0 ## head(vitC) #See the first 6 observations ## # A tibble: 6 x 8 ## serial age height cigs weight sex seruvitc ctakers ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 1.00 71.0 1.72 Smoker 68.8 Men 9.00 No ## 2 2.00 70.0 1.63 Non-smoker 58.2 Women 19.0 No ## 3 3.00 69.0 1.65 Non-smoker 94.3 Women 69.0 Yes ## 4 4.00 67.0 1.62 Non-smoker 87.6 Women 71.0 No ## 5 5.00 68.0 1.53 Non-smoker 66.3 Women 87.0 Yes ## 6 6.00 71.0 1.64 Non-smoker 72.2 Women 96.0 Yes library(psych) #some detailed summary function from this package describe(vitC) ## vitC ## ## 8 Variables 92 Observations ## ---------------------------------------------------------------------------------------------------- ## serial : subject number Format:%3.0f ## n missing distinct Info Mean Gmd .05 .10 .25 .50 .75 ## 92 0 92 1 49.25 33.74 5.55 10.10 23.75 49.00 73.25 ## .90 .95 ## 88.90 95.45 ## ## lowest : 1 2 3 4 5, highest: 96 97 98 99 100 ## ---------------------------------------------------------------------------------------------------- ## age : age on study entry Format:%2.0f ## n missing distinct Info Mean Gmd .05 .10 .25 .50 .75 ## 92 0 10 0.988 69.32 3.353 65.0 65.1 67.0 69.0 71.0 ## .90 .95 ## 74.0 74.0 ## ## Value 65 66 67 68 69 70 71 72 73 74 ## Frequency 10 9 12 8 10 10 11 3 8 11 ## Proportion 0.109 0.098 0.130 0.087 0.109 0.109 0.120 0.033 0.087 0.120 ## ---------------------------------------------------------------------------------------------------- ## height Format:%4.1f ## n missing distinct Info Mean Gmd .05 .10 .25 .50 .75 ## 91 1 34 0.999 1.647 0.1128 1.50 1.52 1.58 1.64 1.72 ## .90 .95 ## 1.79 1.81 ## ## lowest : 1.48 1.49 1.51 1.52 1.53, highest: 1.80 1.81 1.82 1.86 1.89 ## ---------------------------------------------------------------------------------------------------- ## cigs ## n missing distinct ## 92 0 2 ## ## Value Non-smoker Smoker ## Frequency 80 12 ## Proportion 0.87 0.13 ## ---------------------------------------------------------------------------------------------------- ## weight : Clothed weight Format:%5.1f ## n missing distinct Info Mean Gmd .05 .10 .25 .50 .75 ## 91 1 79 1 68.57 15.35 48.85 50.40 57.80 67.00 76.55 ## .90 .95 ## 88.30 91.60 ## ## lowest : 44.0 46.7 48.1 48.4 48.5, highest: 92.0 94.3 97.5 102.4 103.0 ## ---------------------------------------------------------------------------------------------------- ## sex ## n missing distinct ## 92 0 2 ## ## Value Men Women ## Frequency 44 48 ## Proportion 0.478 0.522 ## ---------------------------------------------------------------------------------------------------- ## seruvitc : Serum ascorbate Format:%3.0f ## n missing distinct Info Mean Gmd .05 .10 .25 .50 .75 ## 92 0 60 1 53.21 27.12 11.55 17.00 34.75 58.00 71.00 ## .90 .95 ## 80.90 84.45 ## ## lowest : 8 9 10 11 12, highest: 85 86 87 96 100 ## ---------------------------------------------------------------------------------------------------- ## ctakers ## n missing distinct ## 92 0 2 ## ## Value No Yes ## Frequency 73 19 ## Proportion 0.793 0.207 ## ---------------------------------------------------------------------------------------------------- library(epiDisplay) #some STATA-like simple summary function summ(vitC) ## ## No. of observations = 92 ## ## Var. name obs. mean median s.d. min. max. ## 1 serial 92 49.25 49 29.07 1 100 ## 2 age 92 69.32 69 2.91 65 74 ## 3 height 91 1.65 1.64 0.1 1.48 1.89 ## 4 cigs ## 5 weight 91 68.57 67 13.48 44 103 ## 6 sex ## 7 seruvitc 92 53.21 58 23.83 8 100 ## 8 ctakers vitC$serial[which(is.na(vitC$height))] ## [1] 24 vitC$serial[which(is.na(vitC$weight))] ## [1] 24 從初步的熟悉數據結構和歸納結果可以看出，身高體重兩個數據有出現缺損值 (編號 24 的患者)。 summ(vitC$seruvitc, by=vitC$sex, graph = FALSE) # From package &quot;epiDisplay&quot; ## For vitC$sex = Men ## obs. mean median s.d. min. max. ## 44 46.091 52.5 24.877 8 100 ## ## For vitC$sex = Women ## obs. mean median s.d. min. max. ## 48 59.729 66.5 21.043 15 96 summ(vitC$seruvitc, by=vitC$cigs, graph = FALSE) ## For vitC$cigs = Non-smoker ## obs. mean median s.d. min. max. ## 80 55.138 58 23.323 8 100 ## ## For vitC$cigs = Smoker ## obs. mean median s.d. min. max. ## 12 40.333 49.5 24.186 9 68 summ(vitC$seruvitc, by=vitC$ctakers, graph = FALSE) ## For vitC$ctakers = No ## obs. mean median s.d. min. max. ## 73 48.644 55 22.795 8 84 ## ## For vitC$ctakers = Yes ## obs. mean median s.d. min. max. ## 19 70.737 72 19.612 13 100 # You can also get similar detailed descriptive statistics by groups from package &quot;psych&quot; describeBy(vitC$seruvitc, group = vitC$sex) ## ## Descriptive statistics by group ## group: Men ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 44 46.09 24.88 52.5 45.61 25.95 8 100 92 -0.06 -1.12 3.75 ## --------------------------------------------------------------------------- ## group: Women ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 48 59.73 21.04 66.5 61.15 15.57 15 96 81 -0.65 -0.62 3.04 describeBy(vitC$seruvitc, group = vitC$cigs) ## ## Descriptive statistics by group ## group: Non-smoker ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 80 55.14 23.32 58 56.3 22.24 8 100 92 -0.43 -0.85 2.61 ## --------------------------------------------------------------------------- ## group: Smoker ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 12 40.33 24.19 49.5 40.7 25.2 9 68 59 -0.19 -1.93 6.98 describeBy(vitC$seruvitc, group = vitC$ctakers) ## ## Descriptive statistics by group ## group: No ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 73 48.64 22.79 55 49.47 25.2 8 84 76 -0.33 -1.24 2.67 ## --------------------------------------------------------------------------- ## group: Yes ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 19 70.74 19.61 72 72.41 19.27 13 100 87 -1.07 1.52 4.5 所以，血清維生素水平在女性，非吸菸者，和服用補充劑(廢話) 的人中較高。 par(mfrow=c(2,2)) plot(vitC$age, vitC$seruvitc, pch = 20, xlab = &quot;age on study entry&quot;, ylab = &quot;Serum ascorbate&quot;) plot(vitC$weight, vitC$seruvitc, pch = 20, xlab = &quot;Clothed weight&quot;, ylab = &quot;Serum ascorbate&quot;) plot(vitC$height, vitC$seruvitc, pch = 20, xlab = &quot;Height&quot;, ylab = &quot;Serum ascorbate&quot;) 圖 30.1: Scatter plots between serum ascorbate and age/weight/height 散點圖似乎沒有證據提示血清維生素 C 濃度和連續型變量，年齡，身高，體重之間有什麼相關性。 建立維生素 C 和其他預測變量的簡單線性迴歸模型，你有什麼結論？ summary(lm(seruvitc ~ age, data = vitC)) ## ## Call: ## lm(formula = seruvitc ~ age, data = vitC) ## ## Residuals: ## Min 1Q Median 3Q Max ## -44.94 -18.98 5.82 16.67 46.52 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 113.104 59.511 1.90 0.061 . ## age -0.864 0.858 -1.01 0.316 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 23.8 on 90 degrees of freedom ## Multiple R-squared: 0.0111, Adjusted R-squared: 0.000163 ## F-statistic: 1.01 on 1 and 90 DF, p-value: 0.316 confint(lm(seruvitc ~ age, data = vitC)) ## 2.5 % 97.5 % ## (Intercept) -5.125 231.3335 ## age -2.568 0.8401 血清維生素 C 濃度隨着年齡增加遞減，但是迴歸係數不具有統計學意義 (\\(p=0.32\\))。年齡每增加 1 歲，血清維生素平均下降 \\(0.864 \\:\\mu\\text{mol/L， 95% CI:} (-2.57, 0.840)\\)， summary(lm(seruvitc ~ height, data = vitC)) ## ## Call: ## lm(formula = seruvitc ~ height, data = vitC) ## ## Residuals: ## Min 1Q Median 3Q Max ## -45.11 -19.81 5.76 17.94 48.29 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 115.9 41.2 2.81 0.006 ** ## height -37.8 25.0 -1.51 0.134 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 23.3 on 89 degrees of freedom ## (1 observation deleted due to missingness) ## Multiple R-squared: 0.0251, Adjusted R-squared: 0.0141 ## F-statistic: 2.29 on 1 and 89 DF, p-value: 0.134 confint(lm(seruvitc ~ height, data = vitC)) ## 2.5 % 97.5 % ## (Intercept) 34.05 197.75 ## height -87.37 11.84 血清維生素 C 濃度隨着身高增加遞減，但是迴歸係數不具有統計學意義 (\\(p=0.134\\))。身高每增加 1cm，血清維生素平均下降 \\(0.378 \\:\\mu\\text{mol/L， 95% CI:} (-0.874, 0.118)\\)， summary(lm(seruvitc ~ cigs, data = vitC)) ## ## Call: ## lm(formula = seruvitc ~ cigs, data = vitC) ## ## Residuals: ## Min 1Q Median 3Q Max ## -47.14 -19.53 3.26 17.86 44.86 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 55.14 2.62 21.05 &lt;2e-16 *** ## cigsSmoker -14.80 7.25 -2.04 0.044 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 23.4 on 90 degrees of freedom ## Multiple R-squared: 0.0442, Adjusted R-squared: 0.0336 ## F-statistic: 4.17 on 1 and 90 DF, p-value: 0.0442 confint(lm(seruvitc ~ cigs, data = vitC)) ## 2.5 % 97.5 % ## (Intercept) 49.93 60.3417 ## cigsSmoker -29.21 -0.3945 血清維生素 C 濃度與在吸菸人羣中較低，與不吸菸人羣相比，吸菸人羣的血清維生素 C 濃度平均低 \\(14.8 \\:\\mu\\text{mol/L， 95% CI:} (0.394, 29.2)\\)，這個濃度差具有臨界統計學意義 \\((p=0.044)\\)。 summary(lm(seruvitc ~ weight, data = vitC)) ## ## Call: ## lm(formula = seruvitc ~ weight, data = vitC) ## ## Residuals: ## Min 1Q Median 3Q Max ## -44.71 -18.39 4.41 17.21 46.28 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 53.04017 12.90016 4.11 8.7e-05 *** ## weight 0.00967 0.18463 0.05 0.96 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 23.6 on 89 degrees of freedom ## (1 observation deleted due to missingness) ## Multiple R-squared: 3.08e-05, Adjusted R-squared: -0.0112 ## F-statistic: 0.00274 on 1 and 89 DF, p-value: 0.958 confint(lm(seruvitc ~ weight, data = vitC)) ## 2.5 % 97.5 % ## (Intercept) 27.4078 78.6725 ## weight -0.3572 0.3765 維生素濃度和體重關係幾乎可以忽略 \\((p=0.96)\\)。 summary(lm(seruvitc ~ sex, data = vitC)) ## ## Call: ## lm(formula = seruvitc ~ sex, data = vitC) ## ## Residuals: ## Min 1Q Median 3Q Max ## -44.73 -20.23 6.59 17.27 53.91 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 46.09 3.46 13.32 &lt;2e-16 *** ## sexWomen 13.64 4.79 2.85 0.0055 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 23 on 90 degrees of freedom ## Multiple R-squared: 0.0826, Adjusted R-squared: 0.0724 ## F-statistic: 8.1 on 1 and 90 DF, p-value: 0.00547 confint(lm(seruvitc ~ sex, data = vitC)) ## 2.5 % 97.5 % ## (Intercept) 39.22 52.97 ## sexWomen 4.12 23.16 血清維生素 C 濃度與在女性中較高，與男性相比，女性的血清維生素 C 濃度平均高 \\(13.6 \\:\\mu\\text{mol/L， 95% CI:} (4.12, 23.2)\\)，這個濃度差具有顯著統計學意義 \\((p=0.005)\\)。 summary(lm(seruvitc ~ ctakers, data = vitC)) ## ## Call: ## lm(formula = seruvitc ~ ctakers, data = vitC) ## ## Residuals: ## Min 1Q Median 3Q Max ## -57.74 -15.42 5.81 18.61 35.36 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 48.64 2.60 18.73 &lt; 2e-16 *** ## ctakersYes 22.09 5.72 3.87 0.00021 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 22.2 on 90 degrees of freedom ## Multiple R-squared: 0.142, Adjusted R-squared: 0.133 ## F-statistic: 14.9 on 1 and 90 DF, p-value: 0.000209 confint(lm(seruvitc ~ ctakers, data = vitC)) ## 2.5 % 97.5 % ## (Intercept) 43.48 53.80 ## ctakersYes 10.74 33.45 血清維生素 C 濃度與在服用補充劑的人中較高，與不服用補充劑的人相比，服用者的血清維生素 C 濃度平均高 \\(22.1 \\:\\mu\\text{mol/L， 95% CI:} (10.7, 33.4)\\)，這個濃度差具有顯著統計學意義 \\((p=0.00021)\\)。 擬合一個多元線性迴歸模型，因變量爲血清維生素 C 濃度，預測變量使用 性別，吸菸狀態，和 是否服用維生素補充劑。解釋輸出結果的數字的含義。跟這些預測變量單獨和血清維生素 C 濃度建立的簡單線性迴歸模型作比較。說明哪些結果發生了改變，爲什麼。 summary(lm(seruvitc ~ sex + cigs + ctakers, data = vitC)) ## ## Call: ## lm(formula = seruvitc ~ sex + cigs + ctakers, data = vitC) ## ## Residuals: ## Min 1Q Median 3Q Max ## -40.66 -19.07 2.24 17.62 38.03 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 44.97 3.55 12.69 &lt; 2e-16 *** ## sexWomen 10.66 4.51 2.36 0.02044 * ## cigsSmoker -11.57 6.66 -1.74 0.08586 . ## ctakersYes 20.25 5.51 3.67 0.00041 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 21.3 on 88 degrees of freedom ## Multiple R-squared: 0.23, Adjusted R-squared: 0.203 ## F-statistic: 8.74 on 3 and 88 DF, p-value: 3.88e-05 print(anova(lm(seruvitc ~ sex + cigs + ctakers, data = vitC)), digits = 5) ## Analysis of Variance Table ## ## Response: seruvitc ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## sex 1 4270 4270.0 9.4354 0.0028320 ** ## cigs 1 1497 1497.0 3.3080 0.0723454 . ## ctakers 1 6102 6101.8 13.4831 0.0004125 *** ## Residuals 88 39824 452.5 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 confint(lm(seruvitc ~ sex + cigs + ctakers, data = vitC)) ## 2.5 % 97.5 % ## (Intercept) 37.927 52.017 ## sexWomen 1.687 19.630 ## cigsSmoker -24.799 1.666 ## ctakersYes 9.291 31.211 從這個多元線性迴歸的輸出報告來看，血清維生素 C 濃度 在吸菸者中較低 \\(-11.6 \\:\\mu\\text{mol/L， 95% CI:} (-24.8, +1.67), p = 0.086\\)； 在女性中較高 \\(+10.7 \\:\\mu\\text{mol/L， 95% CI:} (1.69, 19.6), p = 0.020\\)； 在服用維生素補充劑的人中較高 \\(+20.3 \\:\\mu\\text{mol/L， 95% CI:} (9.29, 31.2), p = 0.0004\\)。 故，本次數據告訴我們，服用維生素補充劑是最強的預測變量。在多元線性迴歸模型的結果中可以看到： 性別之間維生素 C 濃度差變小了 (\\(+13.6 \\rightarrow +10.7\\)) 這是因爲女性中有較多人服用維生素補充劑。即便如此，性別差在多元線性迴歸模型中仍然是有意義的。 a &lt;- Epi::stat.table(list(&quot;Vitamin C taker&quot;=ctakers, &quot;Gender&quot; = sex), list(count(),percent(ctakers)), data = vitC, margins = TRUE) print(a, digits = c(percent = 2)) ## ---------------------------------- ## ---------Gender---------- ## Vitamin Men Women Total ## C taker ## ---------------------------------- ## No 37 36 73 ## 84.09 75.00 79.35 ## ## Yes 7 12 19 ## 15.91 25.00 20.65 ## ## ## Total 44 48 92 ## 100.00 100.00 100.00 ## ---------------------------------- 吸菸與非吸菸者之間的維生素 C 濃度差也變小了 (\\(-14.8 \\rightarrow -11.6\\))，因爲儘管吸菸與非吸菸者的維生素補充劑服用比例差不不大，但是吸菸者中大部分是男性。(詳見下表) 吸菸者和非吸菸者之間維生素 C 濃度差經過多元線性迴歸調整後變得不再有統計學意義 \\((p=0.086)\\)。 a &lt;- Epi::stat.table(list(&quot;Vitamin C taker&quot;=ctakers, &quot;Smoker&quot; = cigs), list(count(),percent(ctakers)), data = vitC, margins = TRUE) print(a, digits = c(percent = 2)) ## ------------------------------------- ## -----------Smoker----------- ## Vitamin Non-smoker Smoker Total ## C taker ## ------------------------------------- ## No 63 10 73 ## 78.75 83.33 79.35 ## ## Yes 17 2 19 ## 21.25 16.67 20.65 ## ## ## Total 80 12 92 ## 100.00 100.00 100.00 ## ------------------------------------- a &lt;- Epi::stat.table(list(&quot;Gender&quot; = sex, &quot;Smoker&quot; = cigs), list(count(),percent(sex)), data = vitC, margins = TRUE) print(a, digits = c(percent = 2)) ## ------------------------------------ ## -----------Smoker----------- ## Gender Non-smoker Smoker Total ## ------------------------------------ ## Men 36 8 44 ## 45.00 66.67 47.83 ## ## Women 44 4 48 ## 55.00 33.33 52.17 ## ## ## Total 80 12 92 ## 100.00 100.00 100.00 ## ------------------------------------ 在前一個模型中加入年齡，身高，體重作爲新的預測變量。先解釋新的模型中報告的個數值的意義，利用方差分析表格比較兩個模型的差別 (先手計算，再用 R 計算確認你的答案)。 由於身高體重有缺損值(serial=24)，所以要比較預測變量增加前後的模型，需要先把之前的模型中 serial=24 的觀察對象刪除掉才公平。 Model1 &lt;- lm(seruvitc ~ sex + cigs + ctakers, data = vitC[-24,]) summary(Model1);anova(Model1) ## ## Call: ## lm(formula = seruvitc ~ sex + cigs + ctakers, data = vitC[-24, ## ]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -40.79 -18.21 2.21 17.59 36.97 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 46.03 3.55 12.96 &lt; 2e-16 *** ## sexWomen 9.76 4.49 2.18 0.03228 * ## cigsSmoker -12.26 6.59 -1.86 0.06627 . ## ctakersYes 19.83 5.45 3.64 0.00047 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 21 on 87 degrees of freedom ## Multiple R-squared: 0.226, Adjusted R-squared: 0.199 ## F-statistic: 8.46 on 3 and 87 DF, p-value: 5.39e-05 ## Analysis of Variance Table ## ## Response: seruvitc ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## sex 1 3689 3689 8.35 0.00486 ** ## cigs 1 1679 1679 3.80 0.05440 . ## ctakers 1 5841 5841 13.23 0.00047 *** ## Residuals 87 38418 442 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Model2 &lt;- lm(seruvitc ~ sex + cigs + ctakers + age + weight + height, data = vitC[-24,]) summary(Model2);anova(Model2) ## ## Call: ## lm(formula = seruvitc ~ sex + cigs + ctakers + age + weight + ## height, data = vitC[-24, ]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -40.56 -17.72 4.23 18.75 35.58 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 65.352 89.482 0.73 0.46722 ## sexWomen 10.367 7.285 1.42 0.15843 ## cigsSmoker -11.800 6.757 -1.75 0.08444 . ## ctakersYes 19.859 5.547 3.58 0.00057 *** ## age -0.353 0.840 -0.42 0.67499 ## weight 0.107 0.223 0.48 0.63174 ## height -1.573 42.259 -0.04 0.97040 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 21.3 on 84 degrees of freedom ## Multiple R-squared: 0.233, Adjusted R-squared: 0.178 ## F-statistic: 4.25 on 6 and 84 DF, p-value: 0.00088 ## Analysis of Variance Table ## ## Response: seruvitc ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## sex 1 3689 3689 8.14 0.00546 ** ## cigs 1 1679 1679 3.70 0.05767 . ## ctakers 1 5841 5841 12.88 0.00056 *** ## age 1 205 205 0.45 0.50283 ## weight 1 133 133 0.29 0.58951 ## height 1 1 1 0.00 0.97040 ## Residuals 84 38079 453 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 利用偏 \\(F\\) 檢驗的公式 \\[ F=\\frac{(205.2889295+132.9899543+0.6280691)/3}{38079.42/84} = 0.2492713 \\] anova(Model1, Model2) ## Analysis of Variance Table ## ## Model 1: seruvitc ~ sex + cigs + ctakers ## Model 2: seruvitc ~ sex + cigs + ctakers + age + weight + height ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 87 38418 ## 2 84 38079 3 339 0.25 0.86 所以檢驗統計量對應的 \\(p=0.86\\) 告訴我們沒有證明據證明調整了性別，吸菸狀況，服用補充劑與否之後，增加的年齡，體重，身高作爲預測變量和觀察對象的血清維生素 C 濃度有關係。模型 2 比模型 1 不能解釋更多的模型殘差 (不比模型 1 更加擬合數據)。 30.5.2 紅細胞容積與血紅蛋白 表 30.4: Data set of haemoglobin and PCV explained Variable name content hb Haemoglobin (gm/dl) pcv Pack cell volume % age Age (years) 把數據導入 R，並且建立因變量爲血紅蛋白，預測變量爲 PCV 和 年齡的多元線性迴歸模型 library(haven) haem &lt;- read_dta(&quot;backupfiles/haem.dta&quot;) psych::describe(haem) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## hb 1 12 12.53 1.70 12.8 12.56 1.70 9.6 15.1 5.5 -0.26 -1.39 0.49 ## pcv 2 12 38.58 8.14 37.5 38.80 11.12 25.0 50.0 25.0 -0.10 -1.59 2.35 ## age 3 12 32.75 8.98 31.5 32.40 9.64 20.0 49.0 29.0 0.31 -1.20 2.59 Model3 &lt;- lm(hb ~ pcv + age, data = haem) summary(Model3) ## ## Call: ## lm(formula = hb ~ pcv + age, data = haem) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.413 -1.002 0.302 0.662 1.867 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.0606 1.9680 2.57 0.030 * ## pcv 0.1056 0.0429 2.46 0.036 * ## age 0.1036 0.0389 2.66 0.026 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.15 on 9 degrees of freedom ## Multiple R-squared: 0.63, Adjusted R-squared: 0.548 ## F-statistic: 7.65 on 2 and 9 DF, p-value: 0.0114 haem$e_hat &lt;- Model3$residuals haem$y_hat &lt;- Model3$fitted.values print(haem) ## # A tibble: 12 x 5 ## hb pcv age e_hat y_hat ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 11.1 35.0 20.0 0.274 10.8 ## 2 10.7 45.0 22.0 -1.39 12.1 ## 3 12.4 47.0 25.0 -0.211 12.6 ## 4 14.0 50.0 28.0 0.762 13.2 ## 5 13.1 31.0 28.0 1.87 11.2 ## 6 10.5 30.0 31.0 -0.938 11.4 ## 7 9.60 25.0 32.0 -1.41 11.0 ## 8 12.5 33.0 35.0 0.331 12.2 ## 9 13.5 35.0 38.0 0.810 12.7 ## 10 13.9 40.0 40.0 0.475 13.4 ## 11 15.1 45.0 45.0 0.629 14.5 ## 12 13.9 47.0 49.0 -1.20 15.1 利用 R 的矩陣計算重現迴歸模型的計算結果 計算因變量和兩個預測變量各自的和 sumy &lt;- sum(haem$hb) sumx1 &lt;- sum(haem$pcv) sumx2 &lt;- sum(haem$age) 計算因變量和兩個預測變量各自的平方和 sumy2 &lt;- sum((haem$hb)^2) sumx1y &lt;- sum(haem$hb*haem$pcv) sumx2y &lt;- sum(haem$hb*haem$age) sumx12 &lt;- sum((haem$pcv)^2) sumx22 &lt;- sum((haem$age)^2) sumx1x2 &lt;- sum(haem$pcv*haem$age) 生成一個數值爲 1 的變量，名爲 one one &lt;- rep(1,12) 用 matrix() 命令生成矩陣 Rownames &lt;- NULL for(i in 1:12) { a &lt;- paste(&quot;row&quot;, i, sep = &quot;&quot;) Rownames &lt;- c(Rownames,a); rm(a) } Y &lt;- matrix(haem$hb ,dimnames = list(Rownames, &quot;hb&quot;)) Y ## hb ## row1 11.1 ## row2 10.7 ## row3 12.4 ## row4 14.0 ## row5 13.1 ## row6 10.5 ## row7 9.6 ## row8 12.5 ## row9 13.5 ## row10 13.9 ## row11 15.1 ## row12 13.9 X &lt;- matrix(c(one, haem$pcv, haem$age), nrow = 12, dimnames = list(Rownames, c(&quot;one&quot;, &quot;pcv&quot;, &quot;age&quot;))) X ## one pcv age ## row1 1 35 20 ## row2 1 45 22 ## row3 1 47 25 ## row4 1 50 28 ## row5 1 31 28 ## row6 1 30 31 ## row7 1 25 32 ## row8 1 33 35 ## row9 1 35 38 ## row10 1 40 40 ## row11 1 45 45 ## row12 1 47 49 用公式 (30.4) 計算估計 \\(\\mathbf{\\hat\\beta}\\) 矩陣 XX &lt;- t(X) %*% X # these are the sum of squares of each variable and the sum of the cross products of the pairs of variables XX ## one pcv age ## one 12 463 393 ## pcv 463 18593 15276 ## age 393 15276 13757 (data.frame(sumx1,sumx12,sumx2,sumx22, sumx1x2)) ## sumx1 sumx12 sumx2 sumx22 sumx1x2 ## 1 463 18593 393 13757 15276 XY &lt;- t(X) %*% Y # this is the cross-product matrix of predictors against outcome XY ## hb ## one 150.3 ## pcv 5887.7 ## age 5026.0 (data.frame(sumy, sumx1y, sumx2y)) ## sumy sumx1y sumx2y ## 1 150.3 5888 5026 betahat &lt;- solve( t(X) %*% X ) %*% t(X) %*% Y betahat ## hb ## one 5.0606 ## pcv 0.1056 ## age 0.1036 ###or equivalently you can use betahat &lt;- solve( crossprod(X) ) %*% crossprod( X, Y ) betahat ## hb ## one 5.0606 ## pcv 0.1056 ## age 0.1036 可以看到 betahat 的結果和多元迴歸模型輸出的迴歸係數估計是一致的。 計算擬合值 Fitted &lt;- X%*%betahat Fitted ## hb ## row1 10.83 ## row2 12.09 ## row3 12.61 ## row4 13.24 ## row5 11.23 ## row6 11.44 ## row7 11.01 ## row8 12.17 ## row9 12.69 ## row10 13.43 ## row11 14.47 ## row12 15.10 估計迴歸係數的方差協方差矩陣 e_hat &lt;- Y-Fitted # residuals e_hat ## hb ## row1 0.2736 ## row2 -1.3892 ## row3 -0.2110 ## row4 0.7616 ## row5 1.8674 ## row6 -0.9377 ## row7 -1.4134 ## row8 0.3314 ## row9 0.8096 ## row10 0.4747 ## row11 0.6291 ## row12 -1.1962 SSres &lt;- t(e_hat) %*% e_hat # residual sum of squares SSres ## hb ## hb 11.81 Sigma2 &lt;- SSres %*% (1/(12-(2+1))) # residual variance Sigma2 ## [,1] ## hb 1.312 # multiply the inverse of the cross-product matrix for the predictors # by the residual variance to get the variance-covariance matrix of # the coefficients V &lt;- solve( crossprod(X) ) * as.numeric(Sigma2) V ## one pcv age ## one 3.87296 -0.0632072 -0.0404537 ## pcv -0.06321 0.0018365 -0.0002336 ## age -0.04045 -0.0002336 0.0015105 # the square root of the diagonal terms in the above matrix are the standard errors shown in the regression output sqrt(diag(V)) ## one pcv age ## 1.96798 0.04285 0.03887 "],
["section-31.html", "第 31 章 線性迴歸的模型診斷 31.1 線性迴歸模型的前提條件 31.2 用圖形來視覺診斷 31.3 殘差圖 31.4 殘差正態圖 normal plot of residuals 31.5 前提條件的統計學檢驗 31.6 異常值，槓桿值，和庫克距離 31.7 在統計忍者包裏面對模型診斷作圖", " 第 31 章 線性迴歸的模型診斷 和其他的統計學模型一樣，線性迴歸也有自己的前提條件，而且從模型結果作出的各種推斷都依賴這些前提條件的成立。所以，我們需要有一些統計學的手段來檢查線性迴歸模型中這些前提是否得到滿足。然而理想總是很豐滿，現實通常又太骨感。你不大可能找到一組真實的數據能夠 100% 完美的滿足所需要的前提條件。當然不是說不能滿足模型的前提條件，我們就無法進行統計推斷了。而且我們也有不少結果穩健 (robust) 的統計學手段，讓我們可以不必考慮太多前提條件。檢查數據，瞭解數據內容，理解數據本身的結構永遠都是有助於數據分析的。 還要記得一點就是，根據中心極限定理，(即使有一些前提假設不能成立) 大型數據分析結果的穩健性/可靠性，要高於小型數據的分析。 31.1 線性迴歸模型的前提條件 因變量和各個預測變量之間的關係都是線性 linear relationship 的； 因變量之間相互獨立； 真實 true 殘差的方差是恆定不變的 constant。這裏的含義是在真實迴歸直線上下散佈的因變量的點，在任意一個預測變量值的位置的方差 (分散) 要保持恆定不變。這個特性被描述成方差齊性 homoscedasticity (殘差方差的一致性 homogeneity of the residual variance)，與之相對的定義是異方差性 heteroscedasticity (殘差方差的不同質性，heterogeneity of the residual variance)。 真實殘差服從正態分佈。(儘管你發現統計忍者包裏丟入隨便什麼數據都能給你個線性迴歸的報告來，但是，如果你真想用其結果做統計推斷，p CI 的話，這條前提必須滿足。) 本章着重討論第 1，3，4 前提條件的診斷法。因爲觀測數據之間是否獨立性 (第 2 條) 並不是你光盯着數據看就能知道的。你要去問給你數據的 (沒良心的) 人。 31.2 用圖形來視覺診斷 圖 31.1: Illustration the usefullness of scatter plots of the dependent variable against the predictor variable in simple linear regression 圖 31.1 中展示了四種實例。把預測變量和因變量做散點圖，這常常是甄別出異方差性 (Example C)，非線性 (Example A)，異常值 (Example D) 的最好方法。其中右上角的 Example B 是良好的迴歸模型的散點圖應該有的樣子。 建議進行視覺判斷的時候把擬合曲線去掉再作一次，看看有迴歸直線和沒有迴歸直線前後的散點圖差別，更容易看出數據的分佈特徵。但是光看散點圖作判斷的方法，在多元線性迴歸模型中只能看看能否找到一些異常值，對輔助判斷方差齊性和線性關係就沒有太大的用處。殘差點圖就更加實用。 31.3 殘差圖 如果線性迴歸模型的前提條件能夠得到滿足，那麼擬合模型後的殘差，一定會服從正態分佈且方差均勻一致。所以另一個診斷異方差性的辦法可以通過作觀察殘差和擬合值之間的散點圖來輔助判斷。下圖 31.2 是各個簡單線性迴歸擬合後的殘差和擬合值之間的散點圖。可以看出左下角的 Example C 的異方差性展現得更加明顯了。同樣此圖也能幫助判斷線性關係，如左上角的 Example A 所示，如果預測變量和因變量之間不是線性關係，那麼殘差就不可能均勻的分佈在 \\(0\\) 的兩側。 圖 31.2: Plots of residuals agianst fitted values for the examples in the previous figure 對於一個簡單線性迴歸模型來說，擬合值僅僅只是預測變量的一個線性數學轉換，所以上面圖中的殘差和擬合值的散點圖，其實等價於殘差和預測變量的散點圖。所以圖 31.1 和圖 31.2 兩圖展現的信息量此時是一樣的。 但是，多元線性迴歸時，殘差和擬合值的散點圖會比殘差和預測變量散點圖更適合判斷異方差性，和線性關係的假設。 31.4 殘差正態圖 normal plot of residuals 正態圖在分析技巧的章節也有介紹 (Section 25.2.1)。這是最佳的判斷數據是否服從正態分佈的視覺圖。所以用它來繪製線性迴歸擬合後的殘差，是個很好的辦法。可惜的是殘差正態圖無法用於判斷異方差性，和線性關係兩個假設。 圖 31.3: Normal plots of residuals for the examples in the previous figure 有時後觀察殘差 (observed residuals) 可能不能滿足齊方差性質而真實殘差 (true residuals) 反而滿足。所以一些統計學家建議把計算的殘差標準化 (standardised residuals) 以後再作正態圖。 31.4.1 模型診斷實例 前面建立過的兒童體重和年齡，身長之間的多元迴歸模型的診斷 (Section 30.3.3) 見下圖。所有四個圖都沒有證據證明非線性關係和異方差性。看不見顯著的異常值。正態圖看出殘差有那麼一點點不太正態分佈，但是不嚴重到讓人懷疑模型給出的推斷是否受到重大影響。 圖 31.4: Residual plots for the linear regression relating a child’s weight to their age and length 31.5 前提條件的統計學檢驗 31.5.1 二次方程迴歸法檢驗非線性 二次方程迴歸法是一種多元迴歸模型，它包含了兩個預測變量，一個是另一個的平方。數學模型可以標記成爲： \\[ \\begin{aligned} y_i &amp; = \\alpha + \\beta_1 x_i + \\beta_2 x_i^2 + \\varepsilon_i \\\\ \\text{Where } &amp; \\varepsilon_i \\sim \\text{NID}(0, \\sigma^2) \\end{aligned} \\tag{31.1} \\] 儘管你看到了二次方程在這裏，但是這仍然是一個線性迴歸模型。但是二次方程的迴歸模型描述的是 \\(Y, X\\) 兩個變量之間的非線性關係。如果你把方程 \\(\\hat{y}_i = \\hat\\alpha + \\hat\\beta_1x_i + \\hat\\beta_2x^2_i\\) 對 \\(x_i\\) 求微分，你會得到 \\(\\hat\\beta_1+2\\hat\\beta_2 x_i\\)。這是二次方程的曲率方程。所以如果結果中報告 \\(\\hat\\beta_2\\) 是有統計學意義的，就等於是有證據證明這兩個變量之間的關係不是線性的。 growgam1$age2 &lt;- (growgam1$age)^2 Model2 &lt;- lm(wt ~ len + age + age2, data=growgam1) print(summary(Model1), digits = 5) ## ## Call: ## lm(formula = wt ~ age + len, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.20525 -0.64402 -0.00303 0.55967 2.86277 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -8.351244 1.259968 -6.6281 3.531e-10 *** ## age -0.011260 0.016751 -0.6722 0.5023 ## len 0.237129 0.019516 12.1502 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9546 on 187 degrees of freedom ## Multiple R-squared: 0.74337, Adjusted R-squared: 0.74063 ## F-statistic: 270.84 on 2 and 187 DF, p-value: &lt; 2.22e-16 print(summary(Model2), digits = 5) ## ## Call: ## lm(formula = wt ~ len + age + age2, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.30561 -0.64811 -0.01615 0.54829 2.74233 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -8.5918429 1.2537775 -6.8528 1.031e-10 *** ## len 0.2514685 0.0205039 12.2644 &lt; 2.2e-16 *** ## age -0.1110198 0.0502050 -2.2113 0.02823 * ## age2 0.0023351 0.0011091 2.1055 0.03659 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9459 on 186 degrees of freedom ## Multiple R-squared: 0.74935, Adjusted R-squared: 0.74531 ## F-statistic: 185.36 on 3 and 186 DF, p-value: &lt; 2.22e-16 正如上面的二次方程模型輸出結果所示，年齡和體重之間，當調整了身高以後，有證據 (但是較弱) 證明不呈現線性關係 \\((p=0.037)\\)。 31.5.2 非線性關係模型 二次方程的迴歸模型的應用在非線性模型中的應用其實有許許多多的缺陷。例如二次方程迴歸只能默認有一個極致點。也就是在二次方程模型中，預測變量和因變量的關係要麼是先下降後升高，要麼是先升高再下降。不光如此，二次方程迴歸還默認二者之間的關係在極致點是左右對稱的。這無論如何在現實中都很難有成這樣關係的兩個變量。所以，假如你使用二次方程模型迴歸之後發現非線性的證據是有意義的，那麼更好的辦法是接下來擬合一個更加符合實際情況的非線性模型-多項式曲線迴歸模型。 二次方程回顧模型是多項式曲線迴歸模型的最簡單形式，其次是三次方程模型 (其實就是在公式 (31.1) 裏面加一個 \\(+\\beta_3 x_i^3\\))。另一種更加靈活的模型是擬合一個精確的分段式多項式模型，即允許在不同範圍 (被描述爲 “結點 knots”) 的預測變量 \\(X\\) 內擬合不同的模型。其中一種叫做 限制性立方曲線模型 restricted cubic spline model (點這裏看我用了這種方法的論文)： 默認第一個節點之前和最後一個節點以後爲直線模型； 其餘節點之間默認用三次方迴歸模型擬合數據； 在節點處的兩個方程之間用平滑的曲線連接 (強制兩個方程的一階二階導數相等即可 constraining the first and second derivatives of adjacent functions to agree when they meet at the knot point) 31.6 異常值，槓桿值，和庫克距離 觀測值中的異常值很顯然對模型的擬合會有較大的影響。如果某個觀測值對應的擬合值是異常值的話，那麼這樣的值被認爲槓桿值很大。庫克距離 (Cook’s Distance) 是另一種用來衡量異常值的手段。 31.6.1 異常值和標準化殘差 異常值指的是那些通過模型擬合過後，觀測值和擬合值差異很大的那些觀察對象。這些值需要被甄別出來因爲它們 可能是數據錄入階段造成的人爲失誤，或者是有什麼別的原因導致的系統性異常需要讓輸入數據的人員進行進一步的調查； 異常值可能較大的影響迴歸係數的方差估計，造成不精確甚至錯誤的結果； 異常值也會影響迴歸係數本身的估計。 觀測值和擬合值之間的差，被命名爲觀測殘差 (observed residuals)。線性迴歸模型的前提之一是 真實殘差 獨立且方差維持恆定不變。但是觀測殘差卻無可能做到獨立且方差恆定不變。 之所以說觀測殘差不是獨立的，可以這樣來理解：假如擬合某個線性迴歸模型，預測變量是二分類的，且其中一個分類只有兩個觀測值，那麼擬合的直線會通過這兩個觀測值的中心點 (均值)，那麼這兩個觀測值的觀測殘差就恰好分佈在迴歸直線的兩側 (相加之和爲零，呈完美負相關)，它們是相關的！！！ 觀測殘差的方差不可能恆定的理由，可以這樣來理解：同樣假如擬合某個預測變量是二分類的線性迴歸模型，其中一個分類只有一個觀測值，那麼迴歸直線在這個觀測值處的殘差方差是零。 標準化殘差 (standardized residuals) \\((r_i)\\)，被定義爲每個觀測值的殘差和模型估計的殘差標準誤相除獲得的數據。所以符合前提條件的線性模型擬合後，計算的標準化殘差會服從標準正態分佈。從標準正態分佈的知識你也應該知道，\\(95\\%\\) 的觀測值的標準化殘差必須分佈在數值 \\(-2, 2\\) 範圍內。另外一種標準化殘差的方法叫做內學生化殘差 (studentised residual)。內學生化殘差是把觀測值的殘差除以每一個觀測值各自的估計標準誤。在 R 裏面可以通過 rstandard() 命令計算迴歸模型每個觀測值的內學生化殘差。內學生化殘差也是服從標準正態分佈的。 31.6.2 槓桿值 Leverage 如果一個觀測值的擬合值十分極端，那麼該觀測值本身可能對迴歸模型的參數估計影響很大。這個影響程度大小用槓桿值衡量。簡單線性迴歸時，每個觀測值的槓桿值計算公式爲： \\[ \\begin{aligned} l_i = \\frac{1}{n} + \\frac{x_i-\\bar{x}}{SS_{xx}} \\end{aligned} \\tag{31.2} \\] 多元線性迴歸時的槓桿值計算公式和 (30.7) 中的帽子矩陣 \\(\\mathbf{P}\\) 有關： \\[ \\begin{aligned} &amp; l_i = \\mathbf{P}_{ii} \\text{ The } i\\text{ th diagonal element of } \\\\ &amp; \\mathbf{X(X^\\prime X)^{-1}X^\\prime} \\end{aligned} \\tag{31.3} \\] 槓桿值的範圍是 \\(\\frac{1}{n}, 1\\) 之間。槓桿值越大，該觀測值就有越大的可能性對模型擬合造成影響。如果槓桿值大到等於 \\(1\\)，那麼槓桿效應造成的影響極大，觀測值和擬合值就完全一致。意味着在這個觀測值附近，只有它自己，沒有其他觀測值。 31.6.3 庫克距離 Cook’s Distance 當通過計算觀測值的槓桿值之後，發現具有較大槓桿值的那些觀測點，應該被視爲對模型的穩定性有“潛在威脅”。此時就輪到庫克距離的登場。庫克距離可以用來衡量一個觀測值對模型的影響大小 (比較把觀測值移除出模型前後的模型變化)。 對於一個有 \\(p\\) 個預測變量的迴歸模型來說，如果殘差方差的估計值爲 \\(\\hat\\sigma^2\\)，那麼第 \\(i\\) 個觀測值的庫克距離的計算過程就是把該觀測值移除，重新擬合相同的模型，計算獲得該點的新的擬合值 \\(\\hat y_{j(i)}\\)： \\[ \\begin{aligned} D_i = \\frac{\\sum^n_{j=1}(\\hat y_{j(i)} - \\hat y_j)^2}{(p+1)\\hat\\sigma^2} \\end{aligned} \\tag{31.4} \\] 可以被證明的是，庫克距離其實是結合標準化殘差值 \\((r_i)\\)，和槓桿值 \\((l_i)\\) 的一個綜合量： \\[ \\begin{aligned} D_i &amp; = \\frac{\\sum^n_{j=1}(\\hat y_{j(i)} - \\hat y_j)^2}{(p+1)\\hat\\sigma^2} \\\\ &amp; = \\frac{r^2_il_i}{(p+1)(1-l_i)} \\end{aligned} \\tag{31.5} \\] 所以從庫克距離和標準化殘差，以及槓桿值之間的關係公式 (31.5) 也可以看出，當槓桿值大同時標準化殘差值的絕對值也大的觀測值，庫克距離就會很大。用線性迴歸時，把每個觀測值得庫克距離和擬合值作散點圖，或者把槓桿值和標準化殘差作散點圖是常用的判斷異常值的手段。 31.7 在統計忍者包裏面對模型診斷作圖 擬合好了一個線性迴歸模型以後，plot(Modelname) 即可看到四個診斷圖 (Section 26.8.5)。 "],
["interaction.html", "第 32 章 交互作用 Interactions 32.1 兩個預測變量之間的線性模型交互作用", " 第 32 章 交互作用 Interactions 線性迴歸部分目前爲止我們討論過如何用多元迴歸模型來控制 (或調整) 特定的預測變量 \\((X)\\) 之外的變量。多元迴歸的目的之一是爲了估計預測變量和因變量之間的迴歸係數的同時，保持其他 (想要被調整的) 變量不變。如此一來，其實等於是假定了無論其餘的調整變量取值如何，\\(X,Y\\) 之間的迴歸係數總是相同 (繪製的迴歸線是一組平行線)。本章討論的交互作用，就是探討其中某個變量改變了 \\(X,Y\\) 之間的關係 (modification effect) 的情況。放寬了之前強制所有直線都平行的限制，探討兩個變量之間的線性關係是否因爲某個變量而發生了質的改變。這樣的關係，在流行病學中被定義爲 交互作用 interaction。 本站會探討如何利用線性迴歸模型分析交互作用，如何理解並解釋統計忍者包輸出的報告結果的意義。具體涉及的例子爲：兩個連續型變量，兩個分類型變量，以及一個連續型，一個分類型變量之間的關係的交互作用。 32.1 兩個預測變量之間的線性模型交互作用 32.1.1 交互作用線性模型的一般表達式 假如準備擬合的模型是一個因變量 \\(Y\\)，兩個預測變量 \\(X_1, X_2\\)。同時模型考慮根據 \\(X_2\\) 的值，\\(X_1, Y\\) 之間關係的迴歸係數可以不相等 (直線的斜率不同，即會出現兩條相交的迴歸直線)。這樣的模型其實只要在原有的兩個預測變量的迴歸線性模型中增加一個新的預測變量，新的預測變量是 \\(X_1, X_2\\) 的乘積即可。很簡單，不是麼？ \\[ \\begin{aligned} y_i &amp; = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{3i} + \\varepsilon_i \\\\ \\text{Where, } &amp; \\varepsilon_i \\sim \\text{NID}(0,\\sigma^2) \\\\ y_i &amp; = \\text{value of the dependent variable} \\\\ x_{1i} &amp; = \\text{value of the first predictor variable} \\\\ x_{2i} &amp; = \\text{value of the second predictor variable} \\\\ x_{3i} &amp; = x_{1i} \\times x_{2i} \\\\ \\end{aligned} \\tag{32.1} \\] 爲什麼增加一個 \\(X_1\\times X_2\\) 就能夠分析交互作用呢 (不同直線的斜率)？ 要理解其中的奧妙，我們可以這樣來理解：當像普通的線性迴歸模型那樣調整了 \\(X_2\\) 之後，也就是當 \\(X_2\\) 固定不變時 \\((X_2=k)\\)，迴歸方程 (32.1)，就變成了： \\[ \\begin{equation} y_i = (\\alpha + \\beta_2 k) + (\\beta_1 + \\beta_3 k)x_{1i} + \\varepsilon_i \\end{equation} \\tag{32.2} \\] 此時的 \\(X_1\\) 的斜率從 \\(\\beta_1\\) 變成了 \\((\\beta_1 + \\beta_3 k)\\)，截距從 \\(\\alpha\\) 變成了 \\((\\alpha + \\beta_2 k)\\)。 32.1.2 連續型變量和二分類變量之間的交互作用 一個連續型變臉一個二分類變量的交互作用迴歸方程十分容易理解 (利用啞變量建立模型)： \\[ \\begin{array}{ll} y_i = \\alpha + \\beta_1 x_1i + \\varepsilon_i &amp; \\text{ when } X_2 = 0 \\\\ y_i = (\\alpha + \\beta_2) + (\\beta_1+\\beta_3)x_{1i} + \\varepsilon_i &amp; \\text{ when } X_2 =1 \\end{array} \\tag{32.3} \\] 所以，\\(X_2\\) 取零 或者 取 \\(1\\) 代表了不同的分組，上面的迴歸方程就可以擬合 \\(Y, X_1\\) 在 \\(X_2\\) 的兩組中不同截距，不同斜率的兩條直線。其中各個參數估計，用人話來解釋就是： \\(\\alpha\\) 是當 \\(X_2 = 0\\) 時的截距； \\(\\alpha + \\beta_2\\) 是當 \\(X_2 = 1\\) 時的截距，所以 \\(\\beta_2\\) 就是二分類預測變量 \\(X_2\\) 的兩組之間截距的差； \\(\\beta_1\\) 是當 \\(X_2 = 0\\) 時的斜率； \\((\\beta_1+\\beta_3)\\) 是當 \\(X_2 = 1\\) 時的截距，所以 \\(\\beta_3\\) 就是二分類預測變量 \\(X_2\\) 的兩組之間斜率的差。 32.1.3 兩個二分類變量之間的交互作用 當兩個預測變量都是二分類變量時，可以用兩個啞變量來編碼各自的分組，擬合下面的迴歸模型： \\[ \\begin{array}{lll} y_i = \\alpha + \\varepsilon_i &amp; \\text{ when } X_1 = 0 \\&amp; X_2 = 0 &amp; \\mu_{00} \\\\ y_i = \\alpha + \\beta_1 + \\varepsilon_i &amp; \\text{ when } X_1 = 1 \\&amp; X_2 =0 &amp; \\mu_{10} \\\\ y_i = \\alpha + \\beta_2 + \\varepsilon_i &amp; \\text{ when } X_1 = 0 \\&amp; X_2 =1 &amp; \\mu_{01} \\\\ y_i = \\alpha + \\beta_1 + \\beta_2+ \\beta_3 + \\varepsilon_i &amp; \\text{ when } X_1 = 1 \\&amp; X_2 = 1 &amp; \\mu_{11} \\end{array} \\tag{32.4} \\] 如果用 \\(\\mu_{ij}\\) 表示 \\(X_1 = i, X_2 = j\\) 時的總體均值 (population mean)，那麼模型 (32.4) 各個參數估計及其意義爲： \\(\\alpha\\) 是當 \\(X_1 = 0, \\&amp; X_2 = 0\\) 時 \\(Y\\) 的均值估計 \\((\\mu_{00})\\)； \\(\\alpha+\\beta_1\\) 是當 \\(X_1 = 1 \\&amp; X_2 = 0\\) 時 \\(Y\\) 的均值估計 \\(\\mu_{10}\\)，所以 \\(\\beta_1\\) 是 \\(X_2 = 0\\) 時 \\(X_1\\) 的兩組之間 \\(Y\\) 的均值差，\\(\\mu_{10}-\\mu_{00}\\)； \\(\\alpha+\\beta_2\\) 是當 \\(X_1 = 0 \\&amp; X_2 = 1\\) 時 \\(Y\\) 的均值估計 \\(\\mu_{01}\\)，所以 \\(\\beta_2\\) 是 \\(X_1 = 0\\) 時 \\(X_2\\) 的兩組之間 \\(Y\\) 的均值差，\\(\\mu_{01}-\\mu_{00}\\)； \\(\\alpha + \\beta_1 + \\beta_2 + \\beta_3\\) 是當 \\(X_1 = 1 \\&amp; X_2 = 1\\) 時的均值估計 \\(\\mu_{11}\\)，所以 \\(\\beta_3\\) 是 \\(X_1 = 1\\) 時，\\(X_2\\) 的兩組之間 \\(Y\\) 的均值差 \\(\\mu_{11}-\\mu_{10}\\) 減去 \\(X_2 = 0\\) 時，\\(X_1\\) 的兩組之間的均值差 \\(\\mu_{01}-\\mu_{00}\\)：\\((\\mu_{11}-\\mu_{10}) - (\\mu_{01}-\\mu_{00})\\)。 當 \\(X_1\\) 是連續型變量時，交互作用項的迴歸係數 \\(\\beta_3\\) 的幾何意義是兩個迴歸直線斜率的差。但是本例中，兩個預測變量都是二分類變量的情況下，\\(\\beta_3\\) 的實際意義就變成了，被 \\(X_2\\) 定義的兩組 \\(X_1\\) 之間因變量差的差，\\((\\mu_{11}-\\mu_{10}) - (\\mu_{01}-\\mu_{00})\\)。 32.1.4 兩個連續變量之間的交互作用 前面 (Section 32.1.2) 已經討論過，一個是連續型變量 \\(X_1\\)，另一個是分類變量時 \\(X_2\\)，線性迴歸的交互作用項迴歸係數的含義是因變量 \\(Y\\) 和連續性變量 \\(X_1\\) 在不同的 \\(X_2\\) 組中的迴歸係數之差(斜率之差)。但是，當兩個預測變量 \\(X_1, X_2\\) 都是連續型變量時，交互作用項的迴歸係數該如何解釋呢？直觀的說，此時的交互作用項迴歸係數應該被理解爲：預測變量 \\(X_2\\) 每增加一個單位時，\\(Y, X_1\\) 之間關係的迴歸方程的斜率變化。爲了更好地解釋這個概念，我們沿用前面兒童年齡和身長預測其身高的模型 (Section 30.3.3)，加入年齡和身高的交互作用項結果如下： growgam1 &lt;- read_dta(&quot;backupfiles/growgam1.dta&quot;) growgam1$sex &lt;- as.factor(growgam1$sex) Model1 &lt;- lm(wt ~ age + len + age*len, data=growgam1) # or equivalently use lm(wt ~ age*len, data=growgam1) summary(Model1) ## ## Call: ## lm(formula = wt ~ age + len + age * len, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.200 -0.651 0.003 0.522 2.895 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4.51956 1.90918 -2.37 0.0189 * ## age -0.28490 0.10496 -2.71 0.0073 ** ## len 0.18777 0.02681 7.00 4.4e-11 *** ## age:len 0.00340 0.00129 2.64 0.0090 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.94 on 186 degrees of freedom ## Multiple R-squared: 0.753, Adjusted R-squared: 0.749 ## F-statistic: 189 on 3 and 186 DF, p-value: &lt;2e-16 confint(Model1) ## 2.5 % 97.5 % ## (Intercept) -8.2859887 -0.753130 ## age -0.4919562 -0.077844 ## len 0.1348837 0.240657 ## age:len 0.0008588 0.005937 這裏的模型中，兒童的身長和年齡相乘的部分構成了一個交互作用項。我們用這個擬合的迴歸方程寫出當兒童年齡爲 12 個月時，身長預測體重的方程： \\[ \\begin{aligned} E(\\text{weight|age}=12) &amp; = (-4.5196 - 0.2849\\times12) \\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\;+ (0.1878 + 0.0034\\times12)\\times\\text{Length} \\\\ &amp; = -7.9384 + 0.2286\\times \\text{Length} \\end{aligned} \\] 類似地，年齡 13 個月時， 預測體重的方程是： \\[ \\begin{aligned} E(\\text{weight|age}=13) &amp; = (-4.5196 - 0.2849\\times13) \\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\;+ (0.1878 + 0.0034\\times13)\\times\\text{Length} \\\\ &amp; = -8.2233 + 0.2320\\times \\text{Length} \\end{aligned} \\] 年齡 13 個月時， 預測體重的方程是： \\[ \\begin{aligned} E(\\text{weight|age}=14) &amp; = (-4.5196 - 0.2849\\times14) \\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\;+ (0.1878 + 0.0034\\times14)\\times\\text{Length} \\\\ &amp; = -8.5082 + 0.2354\\times \\text{Length} \\end{aligned} \\] 所以你會看到每個給定的兒童年齡時的方程身長預測體重的方程都是線性方程，截距和斜率都在變化。兒童的年齡每增加 \\(1\\) 個月，身長和體重的相關係數增加 \\(0.0034 \\text{kg/cm}\\)。除了迴歸係數，其餘的數字都是不能用正常的數據來理解的 (沒有兒童身長 或者 體重會等於零)。如果非要解釋，那麼需要把數據全部中心化 (Section 27.3.1)。 epiDisplay::summ(growgam1$age, graph=FALSE); epiDisplay::summ(growgam1$len, graph=FALSE) ## obs. mean median s.d. min. max. ## 190 16.979 16 8.337 5 36 ## obs. mean median s.d. min. max. ## 190 76.697 76.05 7.156 60.1 95.5 growgam1$age_c &lt;- growgam1$age-mean(growgam1$age) growgam1$len_c &lt;- growgam1$len-mean(growgam1$len) Model2 &lt;- lm(wt ~ age_c + len_c + age_c*len_c, data=growgam1) # or equivalently use lm(wt ~ age_c*len_c, data=growgam1) summary(Model2) ## ## Call: ## lm(formula = wt ~ age_c + len_c + age_c * len_c, data = growgam1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.200 -0.651 0.003 0.522 2.895 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.46978 0.09507 99.60 &lt;2e-16 *** ## age_c -0.02427 0.01721 -1.41 0.160 ## len_c 0.24547 0.01947 12.61 &lt;2e-16 *** ## age_c:len_c 0.00340 0.00129 2.64 0.009 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.94 on 186 degrees of freedom ## Multiple R-squared: 0.753, Adjusted R-squared: 0.749 ## F-statistic: 189 on 3 and 186 DF, p-value: &lt;2e-16 confint(Model2) ## 2.5 % 97.5 % ## (Intercept) 9.2822177 9.657345 ## age_c -0.0582290 0.009680 ## len_c 0.2070560 0.283877 ## age_c:len_c 0.0008588 0.005937 你會解釋上面中心化數據以後擬合的迴歸方程的結果，和各個參數估計的意義嗎？ "],
["sample-size.html", "第 33 章 樣本量計算問題 33.1 背景 33.2 決定所需樣本量大小的統計學因素 33.3 第一類和第二類錯誤 Type I and type II errors 33.4 比較兩組之間的百分比 (percentages or proportions) 33.5 比較兩組之間的均值 33.6 樣本量計算的調整", " 第 33 章 樣本量計算問題 33.1 背景 計劃臨牀實驗的時候，爲了避免偏倚和帶有偏見的結論，應當將注意力放在 如何將實驗對象隨機分配 (randomisation) 設計對照組 (control group) 合適（且必須）的貫徹盲法 (blinding) 另外一個同樣重要的問題是–“我到底需要多少樣本?” 一項臨牀實驗，應該提供足夠的證據來證明新藥物（新治療方法）是否有效，是否安全。影響一個實驗設計的樣本量的因素可能有如下幾種： 統計學方案。 從統計學上可以推算出，需要多少樣本來獲得一個堅實可信的證據來證明藥物的實際有效性。 經濟上的因素。 然而實際上可能還有經濟上，時間上，人力物力資源上的現實因素，會制約到底一個實驗能夠收集到多少樣本量。 倫理道德上的因素。 許多臨牀實驗還必須受制於醫學倫理因素。在倫理上一個實驗到底可以維持多久。或者說，要考慮當實驗中一些受試者的結果不理想，或者是有副作用的時候，我們何時該及時停止該實驗？ 實驗本身的可信度。 如果一個臨牀實驗的規模在設計上就很小，可能它本身的可信度就很低。 這裏我們只考慮沒有其他任何因素的影響下，1. 統計學方案上該如何計算準確的所需樣本量的大小。 比較下列兩個同樣比較了溶栓酶和安慰劑在預防心肌梗塞患者死亡的臨牀實驗： 表 33.1: Results from the 1st Australian and ISIS-2 trials for reducing mortality from post-MI 治療組 溶栓酶 安慰劑 p.values 1st Australian n=264 n=253 死亡人數 26 (9.8%) 32 (12.6%) p = 0.32 評價指標 Risk ratio 0.78 (95% CI: 0.48 to 1.27) ISIS-2 n=8592 n=8595 死亡人數 791 (9.2%) 1029 (12.0%) p &lt; 0.001 評價指標 Risk ratio 0.77 (95% CI: 0.70 to 0.84) 這兩個臨牀實驗獲得的治療效果 (treatment effect)，在數字的百分比上幾乎十分接近。然而由於樣本量巨大的差距，可以看到第一個實驗的信賴區間十分的大，使得實驗結果是無意義的。而第二個大樣本的實驗結果就告訴我們，溶栓酶的治療效果是有效降低了心肌梗死患者死亡概率（降低了23%）。第一個實驗收集了近500個病例，卻仍然不能提供確實有效的證據證明溶栓酶的治療效果（提供了強的關聯結果，卻是極弱的證據。strong correlation, but weak evidence) 。 33.2 決定所需樣本量大小的統計學因素 實驗主要結果的測量/比較方法是什麼？ What is the principal outcome measure of the trial? 一項臨牀實驗的主要結果，應該是切合該實驗的主要目的的。並且應當能夠客觀評價。(如死亡率的改善，治癒率的提高等等) 實驗數據準備分析的方案是什麼？ How will the data be analysed to detect a treatment difference? 實驗結果獲得的數據是連續型的 (血壓，血糖值，BMI)？還是分類的離散變量 (死亡的發生與否，疾病的治癒與否)？統計學上認爲的，治療結果提示有意義的差別時的概率。通常定爲 5%。(p &lt; 0.05) 對照組的試驗期望結果是怎樣的？ What results are expected in the control group? 當然我們不可能事先預知實驗對照組可能出現的結果。此處只討論我們的預期結果。大多數情況下，我們可以從已經進行過的類似臨牀試驗報告中獲得，或者是從非臨牀干預型研究（觀察型研究）報告中獲得對照組的期望結果。 如果實驗藥物在治療上確實有差異，當這個差異最小爲多少時希望能從設計的實驗中被檢測到？ How small a treatment difference, if it exists, is important to detect? 這一條恐怕是每個臨牀實驗在設計階段最重要，最敏感也是最難做出決定的。如果我們已知這個藥物療效和對照相比差別很大，那麼樣本量不用很大，就足以提供值得信賴的證據。不過臨牀上常常會認爲療效差距不必非常的顯著，但是在臨牀意義上也是十分重要的。 常常在這個問題上會引起衆多討論，因爲醫生和患者可能認爲任何一點差異都是有臨牀意義的。但是如果我們想檢測出較小的差距，會需要非常巨大的樣本量，這將會是十分不切合實際的。What needs to be decided upon is the smallest clinically relevant difference that would be important to detect if it were true. 在上面第 4 條被決定了以後，還要確定的是我們需要多大的把握來相信這個被檢測出來的療效差別？ With what degree of certainty is needed to be able to detect the treatment difference in 4? 在實際臨牀實驗中，結論是從觀察數據中得來的，而不是從我們預想的那個“未知的實驗效果”。觀察獲得的療效差別，可能比預想的大（有效），也很可能比預想的小（無效）。設計較好的臨牀實驗應該有足夠機率觀察到有意義的療效差別，即使觀察得到的結果不如預期的大。當然要增加我們觀察到有意義的療效差別，最簡單的辦法是增加樣本量。這個條件的含義是，當療效真差別真實存在，我們要有足夠大的把握把它通過實驗觀察到。 33.3 第一類和第二類錯誤 Type I and type II errors 下面羅列一下我們在進行實驗設計時要用到的概念和相應的標記，注意雖然我們無法知道真正的人羣裏真實參數 (parameter) 的大小，但是我們需要用一些估計 (estimator) 來代替： \\(p_1=\\) the observed percentage in those on standard treatment 意爲施行標準治療法時觀察到的（治癒/有效）百分比 \\(p_2=\\) the observed percentage in those on “new” treatment 意爲施行“新療法”時觀察到的（治癒/有效）的百分比 \\(\\Rightarrow p_1-p_2=\\) observed treatment effect 意爲可以觀察到的治療效果。 \\(\\pi_1=\\) the anticipated percentage in those on standard treatment 意爲施行標準治療法時，我們預期的（治癒/有效）百分比 \\(\\pi_2=\\) the anticipated percentage in those on “new” treatment 意爲施行“新療法”時，我們預期的（治療/有效）百分比 \\(\\Rightarrow \\pi_1-\\pi_2=\\) is the true difference which has been decided it is important to detect 意爲上面第 4 條中我們設定好的希望通過實驗證實的真實的療效差別。 其餘的數學標記包括： \\(\\alpha=\\) 有意義的療效差異，在統計學上的水平 (概率水平，通常設定爲 0.05 or 5%) \\(1-\\beta=\\) Degree of certainty that a true difference of \\(\\pi_1 - \\pi_2\\) would be detected. 效能, power。意爲有多大的把握能通過實驗檢測出療效差別。（通常將目標值設定爲 \\(1-\\beta=90\\%\\)） Table 33.2: Observed trial results compared to the truth of 1) no difference; 2) a true \\(\\pi_1-\\pi_2\\) diffrence 真實情況 Truth 無差別 真實差別存在 \\(\\pi_1-\\pi_2\\) 觀察到不存在有意義差別 \\(1−\\alpha\\) \\(\\beta\\) Type II error 觀察到存在有意義差別 \\(\\alpha\\) Type I error \\(1-\\beta\\) Power 考慮上面這個表格，可以很容易想到，一個理想的實驗設計，我們希望這個臨牀實驗獲得的結果儘可能地落在上表中的 左上角：即如果真實情況是無差別的，實驗結果也應該觀察到不存在有意義的差別。 右下角：即如果真實情況是是存在真實差別 \\(\\pi_1-\\pi_2\\) 的，試驗結果也應該觀察到有意義的差別。 然而，我們在獲得臨牀實驗結果之後常常犯的兩類錯誤，同樣在上面的表格中顯示： Type I error: A type I error is when a treatment difference is claimed based on a statistically significant observed result when in truth no such difference exists, i.e. a false positive result. 左下角爲一類錯誤，即實驗結果觀察到有顯著的療效差異，然而，真實情況是並沒有差異的話，被認爲是假陽性判斷。\\(\\alpha\\) 表示一類錯誤發生的概率。 Type II error: A type II error is when in truth there exists a difference of \\(\\pi_1-\\pi_2\\) but the observed results fail to reach statistical significance, i.e. a false negative result. 右上角爲二類錯誤，即實驗結果觀察到沒有顯著的療效差異，然而，真實情況是有差異的話，被認爲是假陰性判斷。\\(\\beta\\) 表示二類錯誤發生的概率。 Alternative ways of describing \\(\\alpha\\) and \\(\\beta\\) are as follows: \\(\\alpha\\) is the risk of a Type I error; \\(\\alpha\\) 也被叫做檢驗的顯著水平, significant level。 \\(\\beta\\) is the risk of a Type II error. \\(1-\\beta\\) is termed statistical power. 其中 \\(1-\\beta\\) 被叫做檢驗效能。 \\(\\alpha, 1-\\beta\\) 的水平需要事先被確定，否則無法進行進一步的樣本量的計算。 33.4 比較兩組之間的百分比 (percentages or proportions) 33.4.1 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%) \\[n=10.5\\times\\frac{[\\pi_1\\times(100-\\pi_1)+\\pi_2\\times(100-\\pi_2)]}{(\\pi_1-\\pi_2)^2}\\times2\\] 注意： 上面的公式後面有 \\(\\times2\\) 是因爲前一半公式計算的只是一組（治療或對照組）所需的樣本量。 這裏使用的是百分比。所以當使用比例的時候，要把 \\(100\\) 改成 \\(1\\)。 使用公式計算的所需樣本量，並不是說我們需要的病例數就是計算出來的結果。上面的公式獲得的結果只是對所需樣本量的估算。 33.4.2 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下) \\[n=f(\\alpha, \\beta)\\times\\frac{[\\pi_1\\times(100-\\pi_1)+\\pi_2\\times(100-\\pi_2)]}{(\\pi_1-\\pi_2)^2}\\times2\\] 其中， \\(f(\\alpha, \\beta)\\) 指的是關於檢驗顯著水平 \\(\\alpha\\) 和檢驗效能 \\(\\beta\\) 的函數。 可以參考下面的表格： Table 33.2: Values of \\(f(\\alpha, \\beta)\\) for different levels of \\(\\alpha\\) and \\(\\beta\\) \\(\\alpha\\) \\(\\beta\\) 0.05 0.1 0.2 0.5 (\\(95\\%\\) power) (\\(90\\%\\) power) (\\(80\\%\\) power) (\\(50\\%\\) power) 0.05 13.0 10.5 7.85 3.84 0.01 17.8 14.9 11.7 6.63 要注意的是，除了上面表格中提供的 \\(f(\\alpha, \\beta)\\) 數值，可以通過以下公式計算得出： \\[f(\\alpha, \\beta)=(Z_{1-\\frac{\\alpha}{2}}+Z_{1-\\beta})^2\\] 例如： \\(\\alpha=0.05, \\beta=0.1\\) 時：\\(f(\\alpha, \\beta)=(1.96+1.282)^2=10.5\\); \\(\\alpha=0.05, \\beta=0.2\\) 時：\\(f(\\alpha, \\beta)=(1.96+0.84)^2=7.85\\)。 33.5 比較兩組之間的均值 許多臨牀實驗不光關心患者是否被治癒或者死亡，另外還有許多實驗的主要結果是連續變量：例如，腎功能（腎小球濾過率），或收縮期血壓。然而背後的原理其實還是一樣的。 33.5.1 樣本量計算公式 然而，另外一個必須考慮的因素：治療組對照組測量結果的標準差 (standard deviation, \\(sd, \\sigma\\))。這裏先考慮兩者標準差相同的情況。標準差的數據通常來自與先行研究的科學文獻，有些（土豪）實驗會先進行預實驗獲得想要的實驗數據–標準差。通常，建議像比較百分比那樣，調整改變一下不同的檢驗顯著水品和檢驗效能，計算多個所需樣本量來互相比較參考。 比較兩組均值時需要用到的數學標記： \\(\\mu_1=\\) 標準治療法（對照組）的期待平均值； \\(\\mu_2=\\) 新治療法（治療組）的期待平均值； \\(\\sigma=\\) 兩組的標準差（假設兩組標準差相同）； \\(\\alpha=\\) 一類錯誤發生的概率，檢驗顯著水平； \\(\\beta=\\) 二類錯誤發生的概率，\\(1-\\beta\\) 是檢驗效能。 用上面標記表示的公式如下： \\[n=f(\\alpha, \\beta)\\times\\frac{2\\sigma^2}{(\\mu_1-\\mu_2)^2}\\times2\\] 可以認爲，上面的公式中 \\(\\mu_1-\\mu_2\\) ，各組的平均值本身並不重要，兩組之間均值的差是我們關心的。如果用 \\(\\delta\\) 表示兩組之間均值差的期待值，那麼公式可以改寫爲： \\[n=f(\\alpha, \\beta)\\times\\frac{2\\sigma^2}{\\delta^2}\\times2\\] 33.6 樣本量計算的調整 如果我們無法成功隨訪部分患者，那麼這部分人的數據就無法獲得，實驗數據的說服力就會下降。如果我們預估計有 \\(Q\\%\\) 的人會失去隨訪，那麼我們可以將之前步驟中計算獲得的數字乘以 \\(\\frac{1}{1-Q\\%}\\)。 如果實驗設計是我們會在某個時間點允許治療組或對照組中的部分人變更自己的實驗方案（即治療組的參與者改進入對照組，反之亦然）。那麼所需樣本量的計算調整的方法爲： 令 \\(Q_1=\\) 第一組中改成第二組治療方案的人數比例； 令 \\(Q_2=\\) 第二組中改成第一組治療方案的人數比例； 將之前步驟中計算獲得的樣本量數字乘以 \\(\\frac{1}{(1-Q_1-Q_2)^2}\\)。 如果預期參與實驗治療組（而不是對照組）的人中有部分人（比例爲 \\(Q\\)）會中斷實驗進程，那麼調整公式爲：\\(\\frac{1}{(1-Q)^2}\\)。 還有的實驗會使用大於 \\(1:1\\) 的比例設計對照組和實驗組的人數。假設這一比例爲 \\(r:1\\) 那麼調整的樣本量數字還要乘以：\\(\\frac{(r+1)^2}{4r}\\)。 "],
["baseline-adjustment-using-ancova.html", "第 34 章 Baseline Adjustment using ANCOVA", " 第 34 章 Baseline Adjustment using ANCOVA "],
["section-35.html", "第 35 章 穩健統計方法入門", " 第 35 章 穩健統計方法入門 "],
["section-36.html", "第 36 章 基於秩次的非參數檢驗 36.1 符號檢驗 the Sign test 36.2 Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test 36.3 Wilcoxon-Mann-Whitney (WMW) 檢驗 36.4 秩相關，Spearman’s Rank Correlation Coefficient 36.5 基於秩次的非參數檢驗的優缺點", " 第 36 章 基於秩次的非參數檢驗 基於秩次的統計學方法不像其他參數檢驗那樣需要太多的假設和前提 (比如服從正態分佈或者其它假設)。這類方法其實放棄了數據的部分信息 – 那就是數據之間值的差距。通過給數據排序列，我們僅僅知道數據的排序。所以我們可以下結論說 \\(A\\) 大於 \\(B\\)，或者 \\(B\\) 大於 \\(C\\) (因此 \\(A\\) 也大於 \\(C\\))，但是他們之間數值的差距被忽略掉了 (所以我們不能比較 \\(A-B\\) 和 \\(B-C\\) 的大小)。 所以，基於秩次的統計學方法完全只依賴數據的大小排序，觀察獲得數據的真實大小被忽視了。 36.1 符號檢驗 the Sign test 我們以下列一組空腹血糖測量值的數據爲例： 表 36.1: Fasting Glucose Level (mmol/L) n=24 Diabetics 10.3 8.8 5.3 9.5 6.7 6.7 12.2 12.5 5.2 15.1 4.2 13.3 10.8 15.3 7.5 19.0 7.2 4.9 16.1 9.3 19.5 8.1 8.6 11.1 我們如果想要對這組數據的中位數做出假設檢驗，\\(H_0: \\theta = 10; \\text{ v.s. } H_1: \\theta\\neq10\\)。 該選擇哪種檢驗方法來回答這個假設檢驗提出的問題：中位數是否等於 \\(10\\)? 符號檢驗 (the sign test)，可以用來輔助我們對數據的中位數 (median \\(\\theta\\)) 作出推斷 (inference)。雖然往下看你會發現嚴格說來這並不算是基於秩次的檢驗方法。使用符號檢驗時我們需要的唯一假設：數據來自連續分佈 (continuous distribution)。 這種類型的檢驗方法常用的假設檢驗如下： \\[ H_0: \\theta=\\theta_0 \\\\ H_1: \\theta\\neq\\theta_0 \\] 其中，\\(\\theta_0\\) 就是我們想要檢驗的中位數的大小，在上面的例子中，\\(\\theta_0=10\\)。 此時我們用到的檢驗統計量，\\(X\\) 的定義是：樣本數據中比 \\(\\theta_0\\) 大的數據個數，和比 \\(\\theta_0\\) 小的數據個數，兩個個數中較小的那一個。因爲在零假設的條件下，如果觀察數據的中位數等於 \\(\\theta_0\\) 的話，數據中比 \\(\\theta_0\\) 大或者小的數據個數應該是相等的。可以用一個二項分佈，概率爲 \\(0.5\\) 的模型來模擬： \\[X\\sim Bin(n, 0.5)\\] 在本例中，觀察數據有 13 個小於 \\(\\theta_0=10\\)，有 11 個大於 \\(\\theta_0=10\\)。因此 \\(X=11, n=24\\)。假如 \\(\\pi\\) 是一個觀察數據大於 \\(\\theta_0\\) 的概率的話，在零假設的條件下，\\(H_0: \\pi=0.5\\)。檢驗這個假設的雙側概率的計算公式爲： \\[2\\times P(X\\leqslant x|\\pi=0.5)\\] 在本例中， \\(X=11\\)。如果（像在考試的時候沒有電腦輔助）要用查表的方式判斷 \\(p\\) 值大小。可以先下載 一份統計數據的表格。下載好了找到 “Statistical Table 7.1 Critical one- and two-tailed values of x for a Sign test” 在第185頁：(下面只是截圖) \\[\\cdots\\cdots\\cdots\\] 圖 36.1: Critical Values for a Sign test 找到 \\(n=24\\) 這一行，發現顯著性水平是 \\(20\\%\\) 的拒絕域都要小於 \\(8\\)， 所以本例的 \\(p&gt;20\\%\\)。 如果你很幸運沒有在考場上，那麼可以找出自己的電腦下載好 R 之後執行下面的命令： 2*pbinom(11,24, 0.5) ## [1] 0.8388 或者可以使用命令 binom.test 來做一個二項分佈的概率檢驗： options(scipen = 1, digits = 8) # just to show the p values are exactly the same binom.test(11,24,0.5) ## ## Exact binomial test ## ## data: 11 and 24 ## number of successes = 11, number of trials = 24, p-value = 0.83882 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.25553020 0.67179192 ## sample estimates: ## probability of success ## 0.45833333 或者你也可以使用 BSDA 中的 SIGN.test 命令來進行一場轟轟烈烈的符號檢驗： options(scipen = 1, digits = 8) # input the data dt &lt;- c(10.3,9.5,12.2,15.1,10.8,19.0,16.1, 8.1, 8.8, 6.7,12.5, 4.2,15.3, 7.2, 9.3, 8.6, 5.3,6.7 ,5.2,13.3, 7.5, 4.9,19.5,11.1) BSDA::SIGN.test(dt, md=10, alternative=&quot;two.sided&quot;, conf.level=0.95) ## ## One-sample Sign-Test ## ## data: dt ## s = 11, p-value = 0.83882 ## alternative hypothesis: true median is not equal to 10 ## 95 percent confidence interval: ## 7.3988241 12.3011759 ## sample estimates: ## median of x ## 9.4 ## ## Achieved and Interpolated Confidence Intervals: ## ## Conf.Level L.E.pt U.E.pt ## Lower Achieved CI 0.9361 7.5000 12.2000 ## Interpolated CI 0.9500 7.3988 12.3012 ## Upper Achieved CI 0.9773 7.2000 12.5000 “據說”如果你用 Stata 的話還會給你一個絢麗的表格： 圖 36.2: The Stata output of a Sign Test 總而言之無論你用的是哪個方法，查 (水) 表法或是統計武俠包，結果都是一樣的：數據無法提供足夠的證據拒絕零假設，即無證據證明中位數不等於10。 需要注意的是，如果觀察數據中有的值恰好等於 \\(\\theta_0\\) 那麼這些觀察數據就會被剔除之後再進行檢驗，相應的樣本量 (\\(n\\)) 也就變小了。如果觀察數據樣本量足夠大，我們可以使用二項分佈的正態分佈近似 (Section 8.4) 法計算。近似法計算時記得要進行校正 (Section 8.6)： \\[ z=\\frac{\\frac{x}{n}-\\pi}{\\sqrt{\\pi(1-\\pi)/n}}=\\frac{\\frac{x}{n}-0.5}{\\sqrt{0.5(1-0.5)/n}}=\\frac{2x}{\\sqrt{n}}-\\sqrt{n}\\\\ \\text{With the continuity correction, this becomes: }\\\\ z=\\lvert\\frac{2x}{\\sqrt{n}}-\\sqrt{n}\\rvert-\\frac{1}{\\sqrt{n}} \\] 在本例中： \\[z=\\lvert\\frac{2\\times11}{\\sqrt{24}}-\\sqrt{24}\\rvert-\\frac{1}{\\sqrt{24}}=0.204\\] 標準正態分佈的 \\(z\\) 爲 \\(0.204\\) 時的雙側 \\(p\\) 值爲： (1-pnorm(0.204))*2 ## [1] 0.8383535 和前面的直接計算法的結果還算是十分接近滴。 36.1.1 符號檢驗的特點 符號檢驗十分的穩健 (Robust)，因爲我們除了數據連續性的假設之外沒有其他任何假設。但是穩健檢驗是有代價的。因爲進行符號檢驗的同時意味着我們要放棄一個個數據本身能提供的信息。結果導致這類檢驗敏感度較低，檢驗效能 (Power) 較差，以及獲得的信賴區間也就很寬 (不精確)。 36.2 Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test Wilcoxon 符號秩和檢驗也可以用來檢驗一組數據的中位數是否和某個已知數字相等。進行本方法時除了像符號檢驗那樣要假設數據是連續的以外，還要假設數據的分佈是左右對稱的。因此，由於假定了左右對稱的前提，中位數也就等於均數，所以它也可以被用於檢驗均數是否等於某個已知的值。 Wilcoxon 符號秩和檢驗的前提可以被認爲是介於符號檢驗和單一樣本 \\(t\\) 檢驗 (還假設數據來自於正態分佈) 之間的一種檢驗。 當一組隨機觀察數據 \\(x_1,\\cdots,x_n\\) 來自於對稱的連續分佈數據。如果它的中位數是 \\(\\theta\\)，在零假設：\\(H_0: \\theta=\\theta_0\\) 的條件下： 將全部觀察數據一一和 \\(\\theta_0\\) 相減，那麼每一個 \\(d_i=x_i-\\theta_0, i=1,2,\\cdots,n\\) 的正負符號概率是相等的； 任何一個和 \\(\\theta_0\\) 相減之後的差 \\(\\lvert d_i \\lvert\\) ，取正負符號的概率是相等的。 這裏我們使用另一個例子來說明 Wilcoxon 檢驗法。下列數據爲，12名女性從平躺姿勢改成直立時心跳次數的變化 (次/分)。 -2, -5, 12, 4, 16, 17, 8, 3, 20, 25, 1, 9 下面來使用 Wilcoxon 符號秩和檢驗法來檢驗中位數 \\(\\theta=15\\)。 首先，先計算每個數據和 \\(15\\) 之間的差值： data &lt;- c(-2, -5, 12, 4, 16, 17, 8, 3, 20, 25, 1, 9) newdata &lt;- data-15 newdata ## [1] -17 -20 -3 -11 1 2 -7 -12 5 10 -14 -6 下一步，計算這些差值的絕對值： abs_newdata &lt;- abs(newdata) abs_newdata ## [1] 17 20 3 11 1 2 7 12 5 10 14 6 Dt &lt;- data.frame(data, newdata, abs_newdata) Dt &lt;- Dt[order(newdata), ] # sort the data by newdata Dt ## data newdata abs_newdata ## 2 -5 -20 20 ## 1 -2 -17 17 ## 11 1 -14 14 ## 8 3 -12 12 ## 4 4 -11 11 ## 7 8 -7 7 ## 12 9 -6 6 ## 3 12 -3 3 ## 5 16 1 1 ## 6 17 2 2 ## 9 20 5 5 ## 10 25 10 10 之後，給絕對值排序： Dt$ranks &lt;- rank(Dt$abs_newdata) Dt ## data newdata abs_newdata ranks ## 2 -5 -20 20 12 ## 1 -2 -17 17 11 ## 11 1 -14 14 10 ## 8 3 -12 12 9 ## 4 4 -11 11 8 ## 7 8 -7 7 6 ## 12 9 -6 6 5 ## 3 12 -3 3 3 ## 5 16 1 1 1 ## 6 17 2 2 2 ## 9 20 5 5 4 ## 10 25 10 10 7 接下來，給小於 \\(15\\) 的數據的排序加上負號： Dt$signed_ranks &lt;- ifelse(Dt$newdata &lt; 0, Dt$ranks*(-1), Dt$ranks) Dt &lt;- Dt[order(Dt$ranks),] Dt ## data newdata abs_newdata ranks signed_ranks ## 5 16 1 1 1 1 ## 6 17 2 2 2 2 ## 3 12 -3 3 3 -3 ## 9 20 5 5 4 4 ## 12 9 -6 6 5 -5 ## 7 8 -7 7 6 -6 ## 10 25 10 10 7 7 ## 4 4 -11 11 8 -8 ## 8 3 -12 12 9 -9 ## 11 1 -14 14 10 -10 ## 1 -2 -17 17 11 -11 ## 2 -5 -20 20 12 -12 對正的負的 signed_ranks 分別求和，絕對值較小的那個就是 Wilcoxon 檢驗的統計量。本例中：\\(S^+=\\) 14，\\(S^-=\\) -64，所以本例中的檢驗統計量等於 \\(14\\)。如果要繼續查表的話，可以找到 \\(0.05&lt;p&lt;0.1\\)： \\[\\cdots\\cdots\\cdots\\] 圖 36.3: Critical Values for a Wilcoxon Signed-Ranks test 精確的 Wilcoxon 符號秩和檢驗可以通過下列代碼在 R 裏完成： wilcox.test(Dt$data, mu=15, paired = FALSE) ## ## Wilcoxon signed rank test ## ## data: Dt$data ## V = 14, p-value = 0.052246 ## alternative hypothesis: true location is not equal to 15 如果數據中有觀察值和我們希望比較的數值完全相等的話，和符號檢驗類似的，這些觀察值需要被剔除之後再進行上面的個步驟檢驗。記得還要將樣本量減去相應個數再去查表尋找 \\(p\\) 值。 另外，下面的代碼可以計算正態分佈近似的 Wilcoxon 秩和檢驗，結果十分接近： wilcox.test(Dt$data, mu=15, paired = FALSE, exact = FALSE, correct = FALSE) ## ## Wilcoxon signed rank test ## ## data: Dt$data ## V = 14, p-value = 0.04986 ## alternative hypothesis: true location is not equal to 15 值得注意的是，精確計算時，我們需要剔除那些和比較數值完全一致的觀察值。然而在正態分佈近似法的 Wilcoxon 檢驗中，這些數值並不會被剔除，而是保留下來，並且用於對方差進行調整。Wilcoxon 秩和檢驗可以在我們能夠假設數據左右對稱分佈，且明顯不服從正態分佈時使用 (即概率密度分布圖左右兩端的尾部較厚的時候)。如果數據左右完全對稱，本檢驗方法不太推薦採用。 36.3 Wilcoxon-Mann-Whitney (WMW) 檢驗 本方法用於比較兩組獨立樣本的分佈是否只是左右位移 (或者叫平移)。此檢驗需要的假設前提爲：兩組獨立樣本來自連續型分佈，且僅僅只存在整體的左右位移 (或者叫平移) (location shift)。 例如說，兩組數據各自的累積概率方程分別是 \\(F(\\cdot), G(\\cdot)\\) 時，由上面的假設可知： \\[G(y)=F(y-\\Delta), \\text{ where } -\\infty&lt;\\Delta&lt;\\infty\\] 上面式子中的 \\(\\Delta\\) 就是所謂的 “左右位移 (或者叫平移)”。因此本檢驗的零假設和替代假設爲： \\[H_0: \\Delta=0\\\\ H_1: \\Delta\\neq0\\] 在零假設的條件下，我們可以認爲兩個樣本來自相同的人羣分佈。假如，\\(F, G\\) 都是正態分佈，且同方差。那麼 \\(\\Delta\\) 就等於兩個分佈的均值差。在這種情況下就可以使用兩樣本 \\(t\\) 檢驗。所以說，WMW 檢驗其實就是把假設前提放寬了的 (免去了正態分佈假設) 兩樣本 \\(t\\) 檢驗。 如果兩個獨立樣本分別有樣本量 \\(n, m, \\text{ and } n&lt;m\\)：\\(X_1,\\cdots,X_n\\) 和 \\(Y_1, \\cdots, Y_m\\)。在零假設的條件下，將這兩個樣本合併之後的大樣本 (\\(m+n\\) 個樣本量) ：\\(X_1,\\cdots,X_n,Y_1, \\cdots, Y_m\\) 可以視爲來自同一分佈。那麼在合併後的樣本中，我們給每一個元素賦予它們的合併後數據中的排序 (\\(\\text{Rank}_i: i= 1,2,\\cdots,n, n+1, \\cdots, n+m\\))。那麼我們感興趣的 Wilcoxon 秩和統計量 (Wilcoxon rank sum statistic) \\(W_1\\) 是樣本量較小的那些數字在合併後數據中的排序之和。 \\[W_1=\\sum_{i=1}^n R_i\\] 對於大小相同的數據，排序取他們的排序的平均值。 之後再計算 ： \\[U_1=W_1+\\frac{n(n+1)}{2}\\] 最後拿來判斷的檢驗統計量是 \\(U_1\\) 和 \\(n\\times m -U_1\\) 兩者中較小的數字。(注：如果我們一開始計算樣本量較多的部分的秩和 \\(W_2=\\sum_{i=1}^m R_i\\) 時，將計算的 \\(U_2=W_2-\\frac{m(m+1)}{2}\\)，跟 \\(n\\times m - U_2\\) 中較小的數字作爲檢驗統計量的話，我們會在數學上獲得完全一樣的檢驗統計量。) 其實兩個統計量 \\(W, U\\) 均可以用來作相同的統計推斷，當然各自的 \\(p\\) 值表格不同。但是 \\(U\\) 有另外一種統計學含義：\\(U\\) 是 \\(X_i&gt;Y_j\\)， 也就是所有的 \\((X_i, Y_j)\\) 配對中 \\(X_i\\) 較大的對的個數。 這裏使用下面的例子來解釋如何操作 WMW 檢驗： 採集16名甲亢兒童的血清甲狀腺素濃度值列表如下， 表 36.2: Serum thyroxine levels n=16 hypothyroid children thyr group 34 Slight or no symptoms 45 Slight or no symptoms 49 Slight or no symptoms 55 Slight or no symptoms 58 Slight or no symptoms 59 Slight or no symptoms 60 Slight or no symptoms 62 Slight or no symptoms 86 Slight or no symptoms 5 Marked symptoms 8 Marked symptoms 18 Marked symptoms 24 Marked symptoms 60 Marked symptoms 84 Marked symptoms 96 Marked symptoms 這裏我們需要比較輕微症狀組和嚴重症狀組的血清甲狀腺濃度的分佈是否只是左右位移，\\(H_0: \\Delta=0\\)。 首先，我們要給兩組合併後的濃度排序： dt$rank &lt;- rank(dt$thyr) dt &lt;- dt[order(dt$rank),] dt ## thyr group rank ## 10 5 Marked symptoms 1.0 ## 11 8 Marked symptoms 2.0 ## 12 18 Marked symptoms 3.0 ## 13 24 Marked symptoms 4.0 ## 1 34 Slight or no symptoms 5.0 ## 2 45 Slight or no symptoms 6.0 ## 3 49 Slight or no symptoms 7.0 ## 4 55 Slight or no symptoms 8.0 ## 5 58 Slight or no symptoms 9.0 ## 6 59 Slight or no symptoms 10.0 ## 7 60 Slight or no symptoms 11.5 ## 14 60 Marked symptoms 11.5 ## 8 62 Slight or no symptoms 13.0 ## 15 84 Marked symptoms 14.0 ## 9 86 Slight or no symptoms 15.0 ## 16 96 Marked symptoms 16.0 Wilcoxon 統計量 \\(W_1\\) 是人數少的組的排序之數值和。本樣本中 7 人有嚴重症狀，9人有輕微或無症狀。所以 \\(W_1\\) 就是嚴重症狀組的秩和： \\[W_1=1+2+3+4+11.5+14+16=51.5\\] 再計算統計量 \\(U_1\\)： \\[U_1=W_1-\\frac{n(n+1)}{2}=51.5-\\frac{7\\times(7+1)}{2}=23.5\\] 所以 \\(n\\times m-U_1=7\\times9-23.5=39.5\\)，顯然這兩個數值中小的 \\(23.5\\) 就是我們尋找的 WMW 統計量。繼續查水錶： 圖 36.4: Critical Values of U for a Wilcoxon-Mann-Whitney test 可知 \\(n_1=7, n_2=9\\) 時，統計量要低於 \\(15\\) \\(p\\) 值才會小於 \\(0.01\\)。所以數據給出的 \\(p&gt;0.1\\)。 在 R 裏面用下面的代碼進行 WHW 檢驗： wilcox.test(dt$thyr~dt$group, correct=FALSE) # without continuity correction ## ## Wilcoxon rank sum test ## ## data: dt$thyr by dt$group ## W = 23.5, p-value = 0.39675 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(dt$thyr~dt$group) # with continuity correction i.e. normal appriximation ## ## Wilcoxon rank sum test with continuity correction ## ## data: dt$thyr by dt$group ## W = 23.5, p-value = 0.42692 ## alternative hypothesis: true location shift is not equal to 0 36.4 秩相關，Spearman’s Rank Correlation Coefficient Spearman 的秩相關 (通常用 \\(\\rho\\))，是一種基於數據排序的相關係數算法。和傳統的 Pearson 相關係數類比，是當數據無法被認定是線性相關時的另一種相關關係檢驗方法。所以秩相關不假定兩組數據之間是線性相關 (linear association)。秩相關只關心一個數據遞增時，另一個數據是否單調遞增。所以可以用於傾向性檢驗。 具體的操作是，在兩組數據中先各自排序，像所有的排序檢驗一樣遇到相同大小的數值將排序取均值。之後使用一般的求相關係數的方法。本法中只用到了數值在各自組中的排序，並沒有使用他們的真實大小。近似法的秩相關計算公式爲： \\[\\hat\\tau=\\frac{\\hat\\rho}{\\sqrt{(1-\\hat\\rho^2)/(n-2)}}\\] 在零假設條件下 \\(H_0: \\rho=0\\)，上面的近似法秩相關服從 \\(t_{n-2}\\) 分佈。 下面用某血友病患者調查數據獲得的血液 \\(T_4, T_8\\) 淋巴球計數 \\((\\times10^9/\\ell)\\) 來詳細解釋計算過程： 表 36.3: Lymphocyte counts n=28 haemophiliacs th4 th8 0.20 0.17 0.27 0.52 0.28 0.25 0.37 0.34 0.38 0.14 0.48 0.10 0.49 0.58 0.56 0.23 0.60 0.24 0.64 0.67 0.64 0.90 0.66 0.26 0.70 0.61 0.77 0.18 0.88 0.74 0.88 0.54 0.88 0.76 0.90 0.62 1.02 0.48 1.10 0.58 1.10 0.34 1.18 0.84 1.20 0.63 1.30 0.46 1.40 0.84 1.60 1.20 1.64 0.59 2.40 1.30 給這組數據繪製散點圖： 圖 36.5: Scatter plot of T4 and T8 counts 可以看見圖中右上角的兩個點幾乎可以認爲是異常值 (outliers)。 分別給 th4, th8 求各自的排序： dt$rank4 &lt;- rank(dt$th4) dt$rank8 &lt;- rank(dt$th8) kable(dt, &quot;html&quot;, align = &quot;c&quot;,caption = &quot;Lymphocyte counts&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;bordered&quot;)) %&gt;% # collapse_rows(columns = c(1)) %&gt;% add_header_above(c(&quot;n=28 haemophiliacs with ranks&quot; = 4)) %&gt;% scroll_box(width = &quot;400px&quot;, height = &quot;500px&quot;, extra_css=&quot;margin-left: auto; margin-right: auto;&quot;) 表 36.4: Lymphocyte counts n=28 haemophiliacs with ranks th4 th8 rank4 rank8 0.20 0.17 1.0 3.0 0.27 0.52 2.0 13.0 0.28 0.25 3.0 7.0 0.37 0.34 4.0 9.5 0.38 0.14 5.0 2.0 0.48 0.10 6.0 1.0 0.49 0.58 7.0 15.5 0.56 0.23 8.0 5.0 0.60 0.24 9.0 6.0 0.64 0.67 10.5 21.0 0.64 0.90 10.5 26.0 0.66 0.26 12.0 8.0 0.70 0.61 13.0 18.0 0.77 0.18 14.0 4.0 0.88 0.74 16.0 22.0 0.88 0.54 16.0 14.0 0.88 0.76 16.0 23.0 0.90 0.62 18.0 19.0 1.02 0.48 19.0 12.0 1.10 0.58 20.5 15.5 1.10 0.34 20.5 9.5 1.18 0.84 22.0 24.5 1.20 0.63 23.0 20.0 1.30 0.46 24.0 11.0 1.40 0.84 25.0 24.5 1.60 1.20 26.0 27.0 1.64 0.59 27.0 17.0 2.40 1.30 28.0 28.0 接下來再給 th4, th8 的排序做散點圖： 圖 36.6: Scatter plot of T4 and T8 ranks 此時也就沒有了異常值的存在。對二者的排序計算相關係數： cor.test(dt$rank4, dt$rank8) ## ## Pearson&#39;s product-moment correlation ## ## data: dt$rank4 and dt$rank8 ## t = 4.11513, df = 26, p-value = 0.00034606 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.33297073 0.81107104 ## sample estimates: ## cor ## 0.62803129 cor.test(dt$th4, dt$th8) ## ## Pearson&#39;s product-moment correlation ## ## data: dt$th4 and dt$th8 ## t = 5.28031, df = 26, p-value = 0.000016061 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.47328797 0.86128090 ## sample estimates: ## cor ## 0.71934766 秩相關的相關係數爲 \\(0.628\\)。而原始數據的相關係數爲 \\(0.719\\)。 36.5 基於秩次的非參數檢驗的優缺點 優點： 可以讓我們拋棄很多 (正態分佈等的) 前提假設，許多真實數據本身並不能滿足這些條件，這些情況下，基於秩次的非參數檢驗能提供更高的統計效能 (power)。 缺點： 如果數據本身能夠滿足如正態分佈之類的假設，那麼相比較與一般的參數檢驗，基於秩次的非參數檢驗法效能就偏低。 基於秩次的非參數檢驗較難推廣到更加複雜的情況。 這些檢驗法僅僅只能幫助我們進行假設檢驗。但是多數情況下，我們更加希望能使用觀察數據對總體進行點估計 (point estimates) 並且給出信賴區間 (CIs)。通常情況下，基於秩次的非參數檢驗法就很難給出這樣的估計。 "],
["-permutation-procedures.html", "第 37 章 排列置換法 Permutation procedures 37.1 背景介紹 37.2 直接上實例 37.3 排列置換法三板斧 37.4 基於排序置換檢驗法計算信賴區間 37.5 排序置換法的優缺點", " 第 37 章 排列置換法 Permutation procedures 37.1 背景介紹 Good(Good 2006) 曾經提出假設檢驗構建的步驟，這裡引用如下： 分析問題，確認零假設 (null hypothesis)，和可能的替代假設 (alternative hypothesis)。確認這兩種假設決定以後可能伴隨的錯誤 (The potential risk associated with a decision)； 選擇一個檢驗統計量； 計算數據給出的檢驗統計量； 確定檢驗統計量，在零假設時的樣本分佈； 用確定好的樣本分佈，以及數據給出的統計量大小，做出決策！ 本章要介紹的排列置換法 (permutation)，和下一章會介紹的自助重抽法 (bootstrap) ，需要大量的計算機的計算，和較強的電腦性能。這兩種方法有一個共同的特徵，它們都利用手頭獲得的樣本數據輔助生成樣本分佈，同時對該數據的分佈或者特質不進行假設。也就是用在上面羅列步驟的第4步。其餘的步驟則與一般的參數假設檢驗完全相同。 37.2 直接上實例 之前用過的甲亢數據： 表 37.1: Serum thyroxine levels n=16 hypothyroid children thyr group 34 Slight or no symptoms 45 Slight or no symptoms 49 Slight or no symptoms 55 Slight or no symptoms 58 Slight or no symptoms 59 Slight or no symptoms 60 Slight or no symptoms 62 Slight or no symptoms 86 Slight or no symptoms 5 Marked symptoms 8 Marked symptoms 18 Marked symptoms 24 Marked symptoms 60 Marked symptoms 84 Marked symptoms 96 Marked symptoms 我們來計算這個數據中不同組的甲狀腺素的平均值，標準差，中位數等特徵描述量； epiDisplay::summ(dt$thyr, by=dt$group, graph=FALSE) ## For dt$group = Marked symptoms ## obs. mean median s.d. min. max. ## 7 42.143 24 37.481 5 96 ## ## For dt$group = Slight or no symptoms ## obs. mean median s.d. min. max. ## 9 56.444 58 14.222 34 86 這個例子中我們關心的是，兩組之間的甲狀腺素水平是否相同。所以，我們的檢驗統計量在這裡就可以定義為兩組之間均值差，或者中位數差，我們先考慮用均值時的情況。 \\[ T=\\bar{Y}_1 - \\bar{Y}_2 \\] 接下來我們需要這個統計量 \\(T\\) 的樣本分佈，同時我們不對數據進行任何分佈的假設 (數據不被認為是正態分佈或者服從其他任何已知的分佈)。 在排列置換法中，我們利用的原則是，在零假設的條件下，所有觀察值的分組可以隨機改變。也就是說，我們認為，零假設時，所有的觀察數據，均來自於一個相同且未知的分佈，每一個觀察值的分組標籤對平均值沒有影響。故，此例中我們可以這樣認為： 每個人的甲狀腺激素水平相同，不受分組情況影響； 輕微或無症狀組的人如果也在顯著症狀組，他們的甲狀腺激素水平不會改變； 改變任何一個人的組別信息，對均值沒有影響。 利用上述原則，檢驗統計量 \\(T\\) 的樣本分佈，就是所有16個人的組別信息的排列組合的情況下，觀察值的均值差異大小。所以，我們可以對16個觀察對象的組別信息隨機分配，計算每一次分組情況下的觀察值均值差，獲得零假設條件下，檢驗統計量的樣本分佈。 這裡使用 R 進行組別的隨機分配： #用 -sample- 對組別信息重新隨機排列 set.seed(1234) g1 &lt;- sample(dt$group, length(dt$group), FALSE) # FALSE means replace = FALSE g2 &lt;- sample(dt$group, length(dt$group), FALSE) g3 &lt;- sample(dt$group, length(dt$group), FALSE) g4 &lt;- sample(dt$group, length(dt$group), FALSE) g5 &lt;- sample(dt$group, length(dt$group), FALSE) dt &lt;- cbind(dt, g1, g2, g3, g4, g5) kable(dt, &quot;html&quot;, align = &quot;c&quot;,caption = &quot;Serum thyroxine levels with permuted groups&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;bordered&quot;)) %&gt;% scroll_box(width = &quot;780px&quot;, height = &quot;500px&quot;, extra_css=&quot;margin-left: auto; margin-right: auto;&quot;) 表 37.2: Serum thyroxine levels with permuted groups thyr group g1 g2 g3 g4 g5 34 Slight or no symptoms Slight or no symptoms Slight or no symptoms Slight or no symptoms Slight or no symptoms Slight or no symptoms 45 Slight or no symptoms Marked symptoms Marked symptoms Slight or no symptoms Marked symptoms Marked symptoms 49 Slight or no symptoms Slight or no symptoms Slight or no symptoms Slight or no symptoms Slight or no symptoms Slight or no symptoms 55 Slight or no symptoms Marked symptoms Slight or no symptoms Marked symptoms Slight or no symptoms Slight or no symptoms 58 Slight or no symptoms Marked symptoms Marked symptoms Marked symptoms Slight or no symptoms Slight or no symptoms 59 Slight or no symptoms Slight or no symptoms Marked symptoms Marked symptoms Slight or no symptoms Marked symptoms 60 Slight or no symptoms Slight or no symptoms Slight or no symptoms Marked symptoms Marked symptoms Slight or no symptoms 62 Slight or no symptoms Slight or no symptoms Slight or no symptoms Marked symptoms Marked symptoms Slight or no symptoms 86 Slight or no symptoms Slight or no symptoms Marked symptoms Marked symptoms Marked symptoms Marked symptoms 5 Marked symptoms Slight or no symptoms Slight or no symptoms Slight or no symptoms Marked symptoms Slight or no symptoms 8 Marked symptoms Slight or no symptoms Marked symptoms Slight or no symptoms Marked symptoms Slight or no symptoms 18 Marked symptoms Marked symptoms Marked symptoms Slight or no symptoms Marked symptoms Slight or no symptoms 24 Marked symptoms Marked symptoms Slight or no symptoms Slight or no symptoms Slight or no symptoms Marked symptoms 60 Marked symptoms Marked symptoms Slight or no symptoms Slight or no symptoms Slight or no symptoms Marked symptoms 84 Marked symptoms Marked symptoms Marked symptoms Marked symptoms Slight or no symptoms Marked symptoms 96 Marked symptoms Slight or no symptoms Slight or no symptoms Slight or no symptoms Slight or no symptoms Marked symptoms 接下來我們就可以計算當觀察對象的組別信息不同時，檢驗統計量 \\(T\\) 的分佈： mean(dt$thyr[dt$group==&quot;Slight or no symptoms&quot;]) - mean(dt$thyr[dt$group==&quot;Marked symptoms&quot;]) ## [1] 14.301587 mean(dt$thyr[dt$g1==&quot;Slight or no symptoms&quot;]) - mean(dt$thyr[dt$g1==&quot;Marked symptoms&quot;]) ## [1] 1.8571429 mean(dt$thyr[dt$g2==&quot;Slight or no symptoms&quot;]) - mean(dt$thyr[dt$g2==&quot;Marked symptoms&quot;]) ## [1] -1.6984127 mean(dt$thyr[dt$g3==&quot;Slight or no symptoms&quot;]) - mean(dt$thyr[dt$g3==&quot;Marked symptoms&quot;]) ## [1] -28.619048 mean(dt$thyr[dt$g4==&quot;Slight or no symptoms&quot;]) - mean(dt$thyr[dt$g4==&quot;Marked symptoms&quot;]) ## [1] 17.095238 mean(dt$thyr[dt$g5==&quot;Slight or no symptoms&quot;]) - mean(dt$thyr[dt$g5==&quot;Marked symptoms&quot;]) ## [1] -26.079365 所以理論上，我們可以把16人中任意7人陪分配到“輕微或無症狀”組的所有排列組合窮舉出來 (有 \\(\\binom{16}{7} = 11,440\\) 不同的分組法)，計算出所有情況下的均值差，組成我們感興趣的統計量的樣本分佈。所以你會看到，當我們的樣本量只有16個人的時候，兩組分配已經達到上萬種之多，樣本量增加之後，計算量是成幾何級倍數在增加的。例如20人中兩組各10人的分組種類有：\\(\\binom{20}{10} = 184,756\\) 種，30人中兩組個15人的分組種類有：\\(\\binom{30}{15} = 1.55\\times10^8\\) 種之多。所以實際情況下，我們通常的解決辦法是，隨機從所有可能的分組法中抽出足夠多的配列組合。下面以這個甲狀腺數據為例，我們對11,440種可能的排列組合隨機抽出10000種排列計算這10000個不同的均值差： set.seed(1) dist &lt;- replicate(10000, t.test(sample(dt$thyr, length(dt$thyr), FALSE) ~ dt$group, var.equal = TRUE)$statistic) 上面的代碼的涵義是從樣本對觀察值進行10000次排列組合，對每個組合進行 \\(t\\) 檢驗，獲取 \\(t\\) 檢驗的統計量。下面把觀察值原本的統計量的位置標記在所有10000次組合給出的統計量的柱狀圖中。 圖 37.1: The sampling distribution of the difference 可以看出來，觀察值的統計量在這10000個新樣本中，並不那麼“極端”。觀察數據的排列置換法 \\(p\\) 值為： #Use the distribution to obtain a p-value for the mean-difference by counting how many permuted mean-differences are more extreme than the one we observed in our actual data: sum(abs(dist) &gt; abs(t.test(dt$thyr ~ dt$group, var.equal = TRUE)$statistic))/10000 ## [1] 0.3072 跟下面用參數檢驗法的 \\(p\\) 值結果做一下對比，就會發現，其實二者的 \\(p\\) 值結果十分接近。 t.test(dt$thyr ~ dt$group, var.equal = TRUE) ## ## Two Sample t-test ## ## data: dt$thyr by dt$group ## t = -1.05935, df = 14, p-value = 0.30738 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -43.256997 14.653823 ## sample estimates: ## mean in group Marked symptoms mean in group Slight or no symptoms ## 42.142857 56.444444 37.3 排列置換法三板斧 標題黨會不服，其實排列置換法的步驟不止三步 (笑)。 在零假設的前提下，確認觀察數據所屬的組別，是可以任意對調的。(exchangeability) 有時候我們可能對數據進行一些轉換 (transforming)，以滿足這個要求。 確認檢驗統計量 \\(T\\)，用 \\(T_{NULL}\\) 標記。並且確定零假設時，檢驗統計量的期待值。(通常會用 \\(T_{NULL}=0\\)) 計算觀察數據獲得的統計量 \\(T_0\\)。 對觀察對象的組別進行 \\(N\\) 次隨機排列組合。計算每次排列組合情況下的統計量 \\((T_1, T_2, \\cdots, T_N)\\)。 計算 \\((T_1, T_2, \\cdots, T_N)\\) 中比 \\(T_0\\) 更極端的值所佔的比例 (\\(&gt;|T_0|\\))，作為觀察值 \\(T_0\\) 的雙側 \\(p\\) 值。 37.3.1 該如何選用合適的檢驗統計量 \\(T\\)？ 在排列置換法中選用合適的檢驗統計量是一個需要仔細思考的過程。選用的 \\(T\\) 必須要能反映組間的差異，並且要與話題相關。也希望能夠盡量和另假設時的統計量有一定的距離\\(T_{NULL}\\)。然而，選擇了不同的檢驗統計量並不意味著統計結果會有天差地別。最終常常是殊途同歸。另外，檢驗統計量並不一定要是一般參數檢驗時用到的統計量 (\\(t\\) 或者其他的似然比檢驗)，因為我們不需要對統計量的精確度 (標準差標準誤等統統不要) 作判斷，本法的統計學推斷是通過排列置換的過程實現的。 37.3.2 可以在排列置換法中對其他變量進行統計學調整 (adjustment) 嗎？ 用隨機對照試驗做例子。假如在實驗開始前的某個測量變量需要作為共變量被調整 (也就是要用 ANCOVA)，以獲得調整後的 \\(Y\\) 差異。在零假設條件下，\\(Y_i\\) 就不滿足可置換原則 (exchangeable)，因為那個需要被調整的測量變量可能決定了他們之間組別是有差異的。 此時，零假設條件 (沒有組間差異) 下，滿足可置換原則的其實是不考慮組別的情況下對需要校正的變量進行線性回歸後獲得的殘差 \\(R_i\\)： \\[ R_i = Y_i - \\hat{Y}_i = Y_i - \\hat\\alpha - \\hat\\beta X_i \\] 另假設條件下，只有殘差 \\(R_i\\) 才滿足可置換原則，可以用在排列置換法中。當需要調整的變量個數增加時，同樣適用。 37.3.3 排列置換法，基於秩次的非參數檢驗之間的關係 如果你注意到，當我們把原始觀察數據排序之後進行的排序檢驗其實就是我們本章介紹的排列置換法。它在前面的秩次非參數檢驗中以特殊的形式展現。Good (Good 2006) 曾經說的好，“99% of common non-parametric tests are permutation tests in which the observations have been replaced by ranks. The sign is one notable exception.” 所以符號檢驗是非排序檢驗的特例。 37.3.4 排列置換檢驗法，是一種精確檢驗 複合型假設，指的是假設中只提及了所有分佈情況中的一種的例如： \\[\\text{The mean of X is equal to } 0\\] 相反，一個簡單假設，則是對參數分佈進行了詳細描述的假設： \\[X\\sim N(0,4)\\] 所以，對複合型假設進行的統計檢驗法，被稱作精確檢驗法。精確檢驗法的特點是，複合型假設中包含的所有假設發生的概率之和等於該檢驗法的第一類錯誤概率 \\(\\alpha\\)。 A test is said to be exact with respect to a compound hypothesis if the probability of making a type I error is exactly \\(\\alpha\\) for each and every one of the simple hypotheses that are subsumed within the compound hypothesis. 一個大家都聽說過的精確檢驗的例子就是 Fisher 精確檢驗法 (也是一種排列置換檢驗)。所有的排列置換檢驗法都是精確檢驗法。 37.4 基於排序置換檢驗法計算信賴區間 基於排序置換檢驗法的信賴區間計算，是一個有些許繁瑣的過程。我們可以設定多個不同的 \\(N_{NULL}\\) ，但是樣本分佈相同的零假設時的統計量。計算相應的 \\(p\\) 值，95% 信賴區間就是 \\(p\\) 值保持大於等於 \\(0.05\\)的 \\(N_{NULL}\\) 取值範圍。計算量將會是很大的。 用前面的例子來解釋就是，我們可以假設兩組之間甲狀腺素的差異是 \\(T_{NULL} = 10\\)，然後將第二組的觀察值全部加上10 (或者將第一組的觀察值全部減去10)，然後用前面描述的方法來檢驗兩組之間的差是否等於零，獲取 \\(p\\) 值。然後用不同的 \\(T_{NULL}\\) 取值，重複這個過程，直到找到上限和下限的 \\(T_{NULL}\\) 值，他們的檢驗 \\(p\\) 值都是0.05。 37.5 排序置換法的優缺點 優點： 數據如果大大偏離了參數檢驗法的假設 (完全不是正態分佈)，本法則十分適用，且結果穩健 Robust； 所有的排序置換法計算的 \\(p\\) 值都是精確不需要近似的； 排序置換法十分可靠，結果不會偏離對應的參數檢驗法，但是當你的數據樣本量很小，無法使用參數檢驗進行理想的統計分析時，排序置換法是極佳的選擇。 缺點： 可置換原則必須得到滿足； 消耗極大的運算能力，當數據量大時，計算過程將會很緩慢；(Windows的話可能直接就死機了，笑) 用排序置換法計算信賴區間的過程比檢驗本身還好耗時費力。 References "],
["-the-bootstrap.html", "第 38 章 自助重抽法 The bootstrap 38.1 定義", " 第 38 章 自助重抽法 The bootstrap 38.1 定義 自助重抽，bootstrap 法是另一種對運算能力有較高要求的非參數檢驗常用手段。 "],
["the-sandwich-estimator.html", "第 39 章 The sandwich estimator", " 第 39 章 The sandwich estimator "],
["section-40.html", "第 40 章 貝葉斯統計入門 40.1 概率論推斷的複習 40.2 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability 40.3 貝葉斯推理的統計學實現 40.4 練習題", " 第 40 章 貝葉斯統計入門 A Bayesian statistician is one who, vaguely expecting a horse and catching a glimpse of a donkey, strongly concludes he has seen a mule. — Guernsey McPearson’s Drug Development Dictionary3 本章節之目的： 介紹 (啓發) 貝葉斯推斷 Bayesian inference 的基本概念。並且與概率論 frequentist inference 推斷實例作比較。 介紹共軛分佈的概念 conjugate distributions。用單一參數家族 (single parameter family) ，特別是二項分佈的圖形來描述共軛分佈；用方差已知的正態分佈均值來描述共軛分佈。 介紹貝葉斯預測分佈 Bayesian prediction distribution。 推薦書目： “Principles of Statistical Inference” by D.R. Cox (D. Cox 2006) “Bayesian Data Analysis” by Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin (Gelman et al. 2013), website for the book “Bayesian Biostatistics” by Vehtari and Rubin (Lesaffre and Lawson 2012) 貝葉斯統計推斷，提供了不同於概率論推斷的另一種考察和解決問題的思路。所有的思考，都源於貝葉斯定理 Bayes’ Theorem (Section 2)。起源於英國統計學家托馬斯貝葉斯 (Thomas Bayes) 死後被好友 Richard Price 整理發表的論文: “An essay towards solving a problem in the doctrine of chances.” 概率論推斷與貝葉斯推斷的中心都圍繞似然 likelihood (Section 12) 的概念。然而二者對似然提供的信息之理解和解釋完全不同。即在對於觀察數據提供的信息的理解，和如何應用已有信息來影響未來決策（或提供預測）的問題上常常被認爲是統計學中形成鮮明對比的兩種哲學理念。過去幾個世紀二者之間孰優孰劣的爭論相當激烈。但是，從實際應用的角度來看，我們目前更關心哪種思維能更加實用地描述和模擬真實世界。幸運地是，多數情況下，二者的差距不大。所以無法簡單地從一個實驗或者一次爭論中得出誰更出色的結論。現在的統計學家們通常不再如同信仰之爭那樣的互相水火不容，而是從實用性角度來判斷一些實際情況下，採用哪種思想能使計算過程更加簡便或者計算結果更加接近真實情況。 請思考如下的問題： 什麼是概率？ What is probability? 概率論思想下的定義：某事件在多次重複觀察實驗結果中發生次數所佔的比例。 The probability of an event is the limit of its relative frequency in a large number of trials.&quot; 貝葉斯思想下的定義：概率是你相信某事件會發生的可能性。 Probability is a measure of the degree of belief about an event. 40.1 概率論推斷的複習 思考不同場景： 場景 A：假如我們在監測一個製造鐵絲的工廠，需要測量該工廠生產的鐵絲的強度。 場景 B：假如我們正在進行一個大型隊列研究，該研究是關於心臟病和與之相關的某個危險因子的評價。數據來源是家庭醫生的診療數據庫。 場景 C：假如一名警察凌晨三點在空無一人的街頭巡邏時，突然聽見防盜自動警鈴的報警聲。他立刻循聲望去，對面街上的珠寶店玻璃碎了一地。一個戴着巴拉克拉瓦頭套的人正揹着一個大包從破碎玻璃窗中爬出。該警察毫不猶豫地判定該人就是劫匪，立刻將其逮捕。 在這些場景下，請用概率論思想思考如下幾個問題： 事件是什麼？ 如何解讀總體參數？ 如何使用參數進行概率推斷？ 用經典概率論時，有什麼缺點嗎？ 場景 A： 事件：該工廠製造的鐵絲，長期以來的強度大小是多少。 總體參數：鐵絲的真實強度，或者與鐵絲強度相關的特性。 概率推斷：我們進行鐵絲的強度實驗，即從該工廠已經生產的鐵絲中大量抽取樣本逐一進行強度檢測。用相應的概率模型來模擬抽取的樣本數據，並且使用極大似然估計找到最能體現抽樣數據的參數估計，然後對獲得的極大似然估計進行95%信賴區間的計算。然後如果我們重複這樣相同的實驗無數次，那麼我們計算的所有的信賴區間中，有95%包含了真實的鐵絲強度大小。 在鐵絲強度測量的場景中，經典概率論顯得十分自然，因爲我們真的可以重複這樣的實驗很多很多次以獲得想要的參數的精確估計。 場景 B： 事件：由於我們用的是整個隊列研究的數據。所以從概率論的角度來看，本事件就是假定我們可以在人數無限多的人羣中重複同樣的隊列研究。 總體參數：我們感興趣的心臟病相關危險因子，在抽取該隊列作爲樣本的人羣中的真實值大小。 概率推斷：我們用泊松分佈的概率模型來模擬人羣中從開始觀察時起，至心臟病發病這段時間內和該危險因子之間的關係大小。然後用傳統的極大似然估計法計算獲得 HR, OR 等值來表示危險因素和心臟病的關係。 缺點：實際情況是，經費時間和人力資源的限制下，我們無法“重複相同的隊列研究”。而且該對列本身可能就是十分獨特的，比如只有男性，或者有年齡限制，或者其他的特性使隊列本身在理論上就是不可能被重複的。所以，在這樣的場景下，用經典的概率論思想作統計推斷常常會被認爲是不自然不妥當的。 場景 C： 事件：警察無數次在同樣的時間同樣的地點巡邏時，聽見防盜自動警鈴的報警聲，他看見頭戴巴拉克拉瓦頭套的人從破碎的玻璃窗中爬出…… 總體參數：在無數次上面描述的場景時，發生盜竊案的真實概率。 概率推斷：使用某種可以描述該事件（巡邏時。。。發生盜竊案的概率）的數學模型，我們用極大似然估計來計算發生盜竊案概率的估計和95%信賴區間，然後警察同志再來決定是否要去抓眼前這個頭戴巴拉克拉瓦頭套的人。 缺點：經典概率論在如此場景下很明顯是完全不適用的。1) 這裏經典概率論思維下的概率實際上無法準確定義，充其量是一種發生盜竊案可能性的估計。2) 在如此場景下，警察會根據已經觀察到的現象（已知信息），來判斷一場盜竊案發生的概率是多少。 通過上面不同場景的下的思考，應該能看到傳統概率論中始終假設我們可以重複相同的實驗多次，然後從長遠來估測相關事件發生的概率。許多場景下，即使事件概率能被準確定義，我們是很難知道我們關心的參數的分佈的，從而導致我們常常要用到漸進法估算 (asymptotic approximation)。 40.2 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability 首先，不得不承認的一個事實是，所有的概率都是條件概率。 要麼是根據已知的信息。 要麼是一般性大家都接受的某種假設條件。 其次，概率，並不是“長遠”地重複觀察獲得的事件發生頻率。相反地，概率的大小取決與你自己和你感興趣的話題（事件）。思考下列例子： 明天會下雨嗎？ 阿森納下一場比賽會贏還是會輸？ 你的期末考試能不能過？ 40.2.1 演繹推理 deductive reasoning 和 三段論 weak syllogisms 數學要用到邏輯，假設我們用 \\(A,B,C\\) 標記不同的事件。 如果 \\(A\\Rightarrow B\\) (事件 A 可以推導出事件 B) 那麼當我們知道“事件 B 爲真”時，雖然B不一定能倒推回 A，但是我們會相信事件 A 很可能發生了。 例如，A 表示“正在下雨”這件事，B 表示 “天上有烏雲”。那麼從邏輯學上來說，\\(A\\Rightarrow B\\) 。然而有烏雲本身不一定會下雨。但是會讓我們覺得下雨的可能性增加了。 再來思考警察巡邏的例子。A 表示 “在珠寶店正在發生盜竊案”，B 表示 “一個頭戴巴拉克拉瓦頭套的人正在從玻璃窗中爬出”。也是一樣的道理。 所以警察薯熟在做判斷的時候，需要判斷 Pr(A|B)。他需要如下的信息： 珠寶店發生盜竊案的前提下，有個人從碎玻璃窗中爬出來的概率。 該警察薯熟正處於的環境（半夜三點無人的街頭，等場景） 所以，看到這裏是不是覺得貝葉斯使用的是我們的“常識”在思考決斷問題？因爲我們的先驗概率 (prior) 至關重要。這是我們的背景知識和解釋參數似然（推斷）的依據。 40.2.2 如何給可能性定量 Quantifying plausibility 進行可能性定量之前，R.T. Cox 制定了如下的規則(R. T. Cox 1946)： \\(\\text{plausibility}(A)\\) 是一個有邊界的實數； 傳遞性，transitivity：如果 \\(\\text{plaus}(C)&gt;\\text{plaus}(B)\\) and \\(\\text{plaus}(B)&gt;\\text{plaus}(A)\\) then \\(\\text{plaus}(C)&gt;\\text{plaus}(A)\\) 一致性，consistency：事件 \\(A\\) 發生的可能性只取決於所有與 \\(A\\) 直接相關的信息，而不包括那些推理到與 \\(A\\) 相關信息之前的信息。 The plausibility of proposition \\(A\\) depends only on the relevant information on \\(A\\) and not on the path of reasoning followed to arrive at \\(A\\). R.T. Cox 證明了他提出的這些規則可以完全適用於所有的可能性計算，而且可能性 (plausibility) 的這些規則和概率 (probability) 的微積分計算完全一致。 所以利用上面的可能性規則，我們可以對條件概率進行更深層次的定義： \\[\\text{Pr}(A|B)=\\frac{\\text{Pr}(B|A)\\text{Pr}(A)}{\\text{Pr}(B)}\\propto \\text{Pr}(B|A)\\text{Pr}(A)\\] 用文字表述爲： 事後概率 \\(\\propto\\) 似然 \\(\\times\\) 先驗概率 其中： 事後概率，posterior probability：\\(B\\) 發生的條件下, \\(A\\) 發生的概率； \\(\\propto\\) ：與…成正比； 似然，likelihood：\\(A\\) 發生的條件下，\\(B\\) 發生的概率； 先驗概率，prior probability：事件 \\(A\\) 發生的概率。 這就是貝葉斯定理。這個定理也告訴我們爲什麼貝葉斯論證在18，19世紀時被叫做“逆概率推理, inverse probability reasoning”。因爲似然 (\\(A\\) 發生的條件下，\\(B\\) 發生的概率) 在與先驗概率相乘以後，概率發生了逆轉–事後概率 (\\(B\\) 發生的條件下, \\(A\\) 發生的概率)。 回頭再來看之前的珠寶店盜竊案： 事件 \\(A\\)：珠寶店正在發生盜竊案； 事件 \\(B\\)：一個頭戴巴拉克拉瓦頭套的人正在從玻璃窗中爬出。 所以： \\(\\text{Pr}(A)=\\) 珠寶店發生盜竊案的概率 – 先驗概率 (prior probability); \\(\\text{Pr}(B|A)=\\) 當珠寶店發生盜竊案時，觀察到“一個頭戴巴拉克拉瓦頭套的人正在從玻璃窗中爬出”事件的可能性 – 似然 (likelihood); \\(\\text{Pr}(A|B)\\) 當觀察到“一個頭戴巴拉克拉瓦頭套的人正在從玻璃窗中爬出”事件時，倒推珠寶店發生了盜竊案的概率 – 事後概率 (posterior probability)。 用例子來解釋貝葉斯推理之後你會發現，其實貝葉斯思想也是純粹的概率理論。與經典概率論不同的是，我們沒有必要認爲某些事件發生的概率需要被重複實驗驗證。貝葉斯對整個世界的理解源於我們每個人自己認爲的事件發生概率 (personalisitic probability)，或者叫信念度（degree of belief）（不需要大量的实验）。 40.3 貝葉斯推理的統計學實現 在經典概率論中，概率分佈的標記 \\(f_X(x;\\theta)\\) 的涵義爲： 對於一個隨機變量 \\(X\\)，它在我們假設的某種固定的真實（上帝才知道是多少的）參數 \\(\\theta\\) 的分佈框架下，不斷重複相同的實驗之後獲得的概率分佈。 在貝葉斯統計推理中，一切都被看作是一個服從概率分佈的隨機變量。利用貝葉斯定理，我們將先驗隨機概率分佈 (prior probability distribution)，和觀察數據作條件概率 (condition on the observed data)，從而獲得事後概率分佈 (posterior probability distribution)。 40.3.1 醫學診斷測試 diagnostic testing 貝葉斯推理最常用的實例是在診斷測試中，即當一個人拿着陽性的檢驗報告結果來找你，你如何判斷這個人有多大的概率真的患有該疾病。 用 \\(D\\) 標記患病， \\(\\bar{D}\\) 標記不患病；\\(T\\) 標記檢查結果爲陽性，\\(\\bar{T}\\) 標記檢查結果爲陰性。那麼，陽性檢查結果時，真的患病的概率 \\(\\text{Pr}(D|T)\\)： \\[ \\begin{aligned} \\text{Pr}(D|T) &amp;= \\frac{\\text{Pr}(T|D)\\text{Pr}(D)}{\\text{Pr}(T)}\\\\ &amp;=\\frac{\\text{Pr}(T|D)\\text{Pr}(D)}{\\text{Pr}(T|D)\\text{Pr}(D)+\\text{Pr}(T|\\bar{D})\\text{Pr}(\\bar{D})} \\end{aligned} \\] 其中分母的轉換用到了 Law of Total Probability (L.T.P): \\[ \\begin{aligned} \\text{Pr}(T) &amp;= \\text{Pr}(T \\cap D) + \\text{Pr}(T \\cap \\bar{D}) \\\\ &amp;= \\text{Pr}(T|D)\\text{Pr}(D)+\\text{Pr}(T|\\bar{D})\\text{Pr}(\\bar{D}) \\end{aligned} \\] 所以說，貝葉斯定理在這裏告訴我們，要計算 \\(\\text{Pr}(D|T)\\) 我們只需要下列幾個信息： 患病率： \\(\\text{Pr}(D)\\) 檢測手段的敏感度 (sensitivity)： \\(\\text{Pr}(T|D)\\) 檢測手段的 1 - 特異度 (specificity)： \\(\\text{Pr}(T|\\bar{D})=1-\\text{Pr}(\\bar{T}|\\bar{D})\\) 40.3.2 HIV 檢查時的應用 假設人羣中患病率爲 \\(1/1000\\)，所用的 HIV 檢測手段的敏感度爲 \\(0.99\\)， 特異度爲 \\(0.98\\)。試計算該檢測HIV手段的事後概率（即拿到陽性結果時，患病的概率 \\(\\text{Pr}(D|T)\\)）。 解 令 \\(D=\\text{HIV positive}, \\bar{D}=\\text{HIV negative}\\\\ T=\\text{test postive}, \\bar{T}=\\text{test negative}\\) \\[ \\begin{aligned} \\text{Pr}(D|T) &amp;= \\frac{\\text{Pr}(T|D)\\text{Pr}(D)}{\\text{Pr}(T|D)\\text{Pr}(D)+\\text{Pr}(T|\\bar{D})\\text{Pr}(\\bar{D})} \\\\ &amp;= \\frac{0.99\\times0.001}{0.99\\times0.001+(1-0.98)\\times0.999} \\\\ &amp;= 0.0472 \\end{aligned} \\] 如果 特異度能達到 \\(0.99\\) \\[ \\begin{aligned} \\text{Pr}(D|T) &amp;= \\frac{\\text{Pr}(T|D)\\text{Pr}(D)}{\\text{Pr}(T|D)\\text{Pr}(D)+\\text{Pr}(T|\\bar{D})\\text{Pr}(\\bar{D})} \\\\ &amp;= \\frac{0.99\\times0.001}{0.99\\times0.001+(1-0.99)\\times0.999} \\\\ &amp;= 0.0901 \\end{aligned} \\] 如果特異度能達到 \\(0.999\\) \\[ \\begin{aligned} \\text{Pr}(D|T) &amp;= \\frac{\\text{Pr}(T|D)\\text{Pr}(D)}{\\text{Pr}(T|D)\\text{Pr}(D)+\\text{Pr}(T|\\bar{D})\\text{Pr}(\\bar{D})} \\\\ &amp;= \\frac{0.99\\times0.001}{0.99\\times0.001+(1-0.999)\\times0.999} \\\\ &amp;= 0.497 \\end{aligned} \\] 可見，對於像 HIV 這樣人羣中患病率較爲罕見的疾病，其檢驗手段的敏感度，特異度都要達到極高才能讓檢驗結果可靠，即拿到陽性結果的人的確患有該疾病。其中當敏感度爲 \\(0.99\\)，特異度爲 \\(0.999\\) 時，才能讓這樣的檢驗手段達到接近一半的可靠程度 (即只有接近一半的陽性結果是真陽性)。 注意本例爲貝葉斯理論的特例，即我們使用的是一個固定的先驗概率 (prior) 和似然 (likelihood)。一般情況下，先驗概率和似然會有自己的概率分佈 (probability distribution)，而不會是一個固定的值， 其相應的事後概率 (posterior) 也擁有概率分佈，並且使用它本身的均值和方差來描述。 40.3.3 說點小歷史 圖 40.1: Sir Ronald Fisher Ronald Aylmer Fisher (1890-1962) 推動了統計學在20世紀前半頁的重大發展。他鞏固了概率論統計學堅實的基礎，並且積極提倡這一套理論(R. A. Fisher 1922)。但是 Fisher 本人對於統計學的“統計學意義, level of significance” 的認識卻是隨着時間和他年齡的變化而變化的： 表 40.1: Fisher’s interpretation of ‘level of significance’ and the Neyman-Pearson interpretation 早期 Fisher (1935) 晚期 Fisher (1956) Neyman and Pearson 統計學有意義的水平（傳統上使用 \\(\\alpha=5\\%\\)），必須在實施統計檢驗之前就被決定。因此，統計學意義的水平是相應統計學檢驗本身的性質之一。 Thus, the level of significance is a property of the test. 統計學意義的水平，應該被精確計算並且在報告中明確 \\(p\\) 值的大小，故統計學意義的水平本身是在實施了統計檢驗之後計算的。它應該是屬於觀察數據的固有性質。 Here the level of significance is a property of the data. \\(\\alpha\\) 和 \\(\\beta\\) 作爲統計檢驗的第一類錯誤和第二類錯誤指標，應該在實施統計檢驗之前被決定。所以 \\(\\alpha, \\beta\\) 是屬於統計檢驗的性質。 Yet, to determine \\(\\alpha, \\beta\\) no convention is required, but rather a cost-benefit estimation of the severity of the two kinds of error. 隨着马尔科夫蒙特卡洛 (Markov-Chain Monte Carlo, MCMC) 法的廣泛應用，貝葉斯統計學在事後概率計算上（計算量超大的）棘手問題，得到了解決。 40.4 練習題 從經典概率論的角度，準確定義 \\(95\\%\\) 信賴區間。思考，在貝葉斯統計理論中，它會如何被定義。 解 概率論： 對於一個總體參數 \\(\\theta\\) 來說，\\(95\\%\\) 信賴區間是一個從觀察數據中計算得到的數值區間。如果重複相同的實驗無數次，我們從無數個觀察數據中計算這個區間，那麼這些無數多的信賴區間 (confidence interval, CI) 裏有 \\(95\\%\\) 包含了總體參數 \\(\\theta\\)。 貝葉斯： 對於一組觀察數據，它可以計算獲得可信區間 (credible interval, CI)。如果使用 \\(L, U\\) 分別表示下限和上限的值，\\(\\theta\\) 表示參數，\\(x\\) 表示觀察數據，\\(\\pi(\\theta|x)\\) 表示事後概率分佈的密度方程， posterior distribution。那麼有： \\[\\text{Pr}(\\theta \\in (L,U)) = \\int_L^U\\pi(\\theta|x)\\text{d}\\theta = 95\\%\\] 即，在貝葉斯理論下，95% 可信區間就是這一個區間包含了參數的概率是95%。 證明貝葉斯定理。 並且用二項分佈隨機變量的例子來證明：\\(\\text{posterior odds} = \\text{prior odds}\\times\\text{likelihood ratio}\\) 用前面提到的 HIV 的案例來說明這個公式的實際應用。 解 參照上面的標記法： \\(\\theta\\) 表示參數 \\(x\\) 表示觀察數據 \\(\\pi(\\theta|x)\\) 表示事後概率分佈的密度方程， posterior distribution \\(f(\\theta,x)\\) 表示參數和數據的聯合分佈， joint distribution \\(f(x)\\) 表示先驗概率分佈的密度方程， prior distribution \\[ \\begin{aligned} \\pi(\\theta|x) &amp;= \\frac{f(\\theta, x)}{f(x)} \\\\ &amp;=\\frac{f(\\theta, x)}{f(x)}\\cdot\\frac{1/\\pi(\\theta)}{1/\\pi(\\theta)} \\\\ &amp;=\\frac{\\frac{f(\\theta,x)}{\\pi(\\theta)}}{\\frac{f(x)}{\\pi(\\theta)}} \\end{aligned} \\] 其中分子部分 \\(\\frac{f(\\theta,x)}{\\pi(\\theta)}\\) 就是條件概率 \\(f(x|\\theta)\\)。 分母的 \\(f(x)\\) 部分 \\[ \\begin{aligned} f(x) &amp;= \\int f(x,\\theta) \\text{d}\\theta \\\\ &amp;= \\int \\frac{f(x,\\theta)}{\\pi(\\theta)} \\cdot \\pi(\\theta) \\text{d}\\theta \\\\ &amp;= \\int f(x|\\theta) \\cdot \\pi(\\theta) \\text{d}\\theta \\end{aligned} \\] 所以， \\[\\pi(\\theta|x)=\\frac{f(x|\\theta)\\pi(\\theta)}{\\int f(x|\\theta) \\cdot \\pi(\\theta) \\text{d}\\theta}\\] 用二項分佈隨機變量 (\\(\\theta=1, 0\\)) 來證明：\\(\\text{posterior odds} = \\text{prior odds}\\times\\text{likelihood ratio}\\) 解 假設 \\(\\theta\\) 是一個二項分佈的隨機變量，那麼 \\(f(\\theta|x)=\\text{Pr}(\\theta |x)\\)。 \\[ \\begin{aligned} \\text{posterior odds} &amp;= \\frac{\\text{Pr}(\\theta=1|x)}{\\text{Pr}(\\theta=0|x)} \\\\ &amp;= \\frac{\\frac{\\text{Pr}(x|\\theta=1)\\text{Pr}(\\theta=1)}{\\text{Pr}(x)}}{\\frac{\\text{Pr}(x|\\theta=0)\\text{Pr}(\\theta=0)}{\\text{Pr}(x)}}\\\\ &amp;=\\frac{\\text{Pr}(\\theta=1)}{\\text{Pr}(\\theta=0)}\\cdot\\frac{\\text{Pr}(x|\\theta=1)}{\\text{Pr}(x|\\theta=0)} \\\\ &amp;=\\text{prior odds}\\times\\text{likelihood ratio} \\end{aligned} \\] 用前面提到的 HIV 案例來驗證： HIV的患病率爲 \\(1/1000\\)，所以 \\(\\text{prior odds}=1:999\\)，似然比 \\(\\text{likelihood ratio}=0.99:(1-0.98)\\)。所以就有： \\[ \\begin{aligned} \\text{posterior odds} &amp;=\\text{prior odds}\\times\\text{likelihood} \\\\ &amp;= \\frac{1}{999}\\times\\frac{0.99}{1-0.98} \\\\ &amp;= \\frac{0.99}{19.98} \\\\ &amp;= \\frac{1}{20.18182} \\end{aligned} \\] 所以事後概率（陽性結果患病的概率）爲 \\(1/(1+20.18182)=0.0472\\)。 史密斯先生有2個孩子，其中之一是男孩。另一個孩子是女孩的概率是多少？ 如下前提默認成立： 男女比例爲: 50-50。 這個家庭中沒有對男孩或者女孩的偏好。 這兩個孩子不是同胞雙胞胎。 一個家庭有兩個孩子的性別組合的所有可能性： 第一個孩子性別 第二個孩子性別 男孩 男孩 男孩 女孩 女孩 男孩 女孩 女孩 所以根據已知條件，其中之一是男孩，所以最後一種情況：“兩個女孩” 是不可能的。故另一孩子是女孩的概率就是 \\(\\frac{2}{3}\\)。 如果用貝葉斯理論來正式計算的話： \\[ \\begin{aligned} &amp; \\text{Pr (1 girl in family of 2 | family does not have 2 girls)} \\\\ &amp;= \\frac{\\text{Pr(family doesn&#39;t have 2 girls|1 girl in a family of 2)}\\times \\\\ \\text{Pr(1 girl in a family of 2 )}}{\\sum_{j=0,1,2}\\text{Pr(family doesn&#39;t have 2 girls|j girl in a family of 2)}\\times\\\\\\text{Pr(j girl in a family of 2)}} \\\\ &amp;= \\frac{1\\times\\frac{1}{2}}{1\\times\\frac{1}{4}+1\\times\\frac{1}{2}+0\\times\\frac{1}{4}} \\\\ &amp;= \\frac{\\frac{1}{2}}{\\frac{3}{4}}=\\frac{2}{3} \\end{aligned} \\] 也是一樣的結論。 下表是全國普查以後得出的家庭有兩個孩子，且至少一個是男孩的數據分佈： 第一個孩子性別 第二個孩子性別 家庭數量 男孩 男孩 657 男孩 女孩 591 女孩 男孩 610 女孩 女孩 0 求同樣的概率問題： 解 另一個孩子是女孩的概率是：\\(\\frac{610+591}{610+591+657}=0.646\\) References "],
["section-41.html", "第 41 章 貝葉斯定理的應用：單一參數模型 41.1 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions 41.2 \\(\\theta\\) 的先驗概率 41.3 練習題", " 第 41 章 貝葉斯定理的應用：單一參數模型 從前一章節我們可以深切體會到，貝葉斯統計是如何讓我們的先驗概率，在觀察到數據之後，更新信息，獲得事後概率 (這是一個通過數據自我學習，進化的過程)。(How a prior belief about an event can be updated, given data, to a posterior belief.) 所以說，在貝葉斯模型中，我們期待使用觀察數據來學習，以增加現有的對相關參數的知識和信息。本章我們把重點放在二項分佈，用二項分佈作爲單一參數模型來瞭解怎樣推導事後分佈。 41.1 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions \\(R\\) 用來表示服從一個二項分佈的隨機變量， \\(R\\sim Bin(n, \\theta)\\)。 \\(r\\) 表示觀察到 \\(r\\) 次成功實驗，實驗次數爲 \\(n\\)。 先驗概率分佈： \\(\\pi_\\Theta(\\theta)\\) 應用貝葉斯定理： \\[ \\begin{aligned} \\pi_{\\Theta|R}(\\theta|r) &amp;= \\frac{f_R(r|\\theta)\\pi_\\Theta(\\theta)}{\\int_0^1f_R(r|\\theta)\\pi_\\Theta(\\theta)\\text{ d}\\theta}\\\\ &amp;= \\frac{f_R(r|\\theta)\\pi_\\Theta(\\theta)}{f_R(r)} \\end{aligned} \\] 如果我們的先驗概率分佈： \\[\\begin{equation} \\pi_\\Theta(\\theta)=\\begin{cases} 1 \\text{ if } \\theta=0.2\\\\ 0 \\text{ otherwise} \\end{cases} \\end{equation}\\] 意思就是，我們 100% 相信 \\(\\theta\\) 絕對就等於 0.2，不相信 \\(\\theta\\) 竟然還能取任何其他值（霸道自大又狂妄的我們）。 如果先驗概率分佈： \\[\\begin{equation} \\pi_\\Theta(\\theta)=\\begin{cases} 0.4 \\text{ if } \\theta=0.2\\\\ 0.6 \\text{ if } \\theta=0.7 \\end{cases} \\end{equation}\\] 意思就是，我們有 60% 的把握相信 \\(\\theta=0.7\\)，有 40% 的把握相信 \\(\\theta=0.2\\)，稍微傾向於 \\(\\theta=0.7\\)。 假設進行10次實驗，觀察到3次成功。當 \\(\\theta=0.2\\) 時，觀察數據的似然 (likelihood) 爲： \\[f_R(3|\\theta=0.2)=\\binom{10}{3}0.2^3(1-0.2)^7\\] 當 \\(\\theta=0.7\\) 時，觀察數據的似然爲： \\[f_R(3|\\theta=0.7)=\\binom{10}{3}0.7^3(1-0.7)^7\\] 應用貝葉斯定理計算事後概率分佈： \\[\\begin{equation} \\pi_{\\Theta|R}(\\theta|3)=\\begin{cases} \\frac{\\binom{10}{3}0.2^3(1-0.2)^7\\times0.4}{\\binom{10}{3}0.2^3(1-0.2)^7\\times0.4+\\binom{10}{3}0.7^3(1-0.7)^7\\times0.6}=0.937 \\text{ if } \\theta=0.2\\\\ \\frac{\\binom{10}{3}0.7^3(1-0.7)^7\\times0.6}{\\binom{10}{3}0.7^3(1-0.7)^7\\times0.6+\\binom{10}{3}0.2^3(1-0.2)^7\\times0.4}=0.063 \\text{ if }\\theta=0.7 \\end{cases} \\end{equation}\\] 所以，我們從一開始認爲只有40%的把握相信 \\(\\theta=0.2\\)，觀察數據告訴我們 10 次實驗，3次獲得了成功。所以我們現在有 93.7% 的把握相信 \\(\\theta=0.2\\)。也就是說，觀察數據讓我們對參數 \\(\\theta\\) 的取值可能性發生了質的變化，從原先的傾向於 \\(\\theta=0.7\\) 到現在幾乎接近 100% 的認爲 \\(\\theta=0.2\\)。也就是，觀察數據獲得的信息改變了我們的立場。 上面的例子很直觀，但是有下面幾個問題： 如果我們無法對參數 \\(\\theta\\) 賦予先驗概率的點估計時，該怎麼辦？ 如果事後概率不是一個離散的分佈時，該如何才能表達事後概率？ 41.2 \\(\\theta\\) 的先驗概率 一種選擇是，我們用均一分佈 (uniform distribution)，即我們對數據一無所知，認爲所有的 \\(\\theta\\) 的可能性都一樣，概率密度方程爲 \\(1\\)。在這一情況下，先驗概率爲 1： \\(\\pi_\\Theta(\\theta)=1\\)，其事後概率分佈爲： \\[ \\begin{equation} \\pi_{\\Theta|R}(\\theta|r)=\\frac{\\binom{n}{r}\\theta^r(1-\\theta)^{n-r}}{\\int_0^1\\binom{n}{r}\\theta^r(1-\\theta)^{n-r} \\text{ d}\\theta} \\tag{41.1} \\end{equation} \\] 看到即使在如此簡單的先驗概率下，我們還是要使用複雜的微積分進行計算。幸運的是，像 (41.1) 的分母這樣的積分公式其實是有跡可循的。這就是 beta (\\(\\beta\\)) 分佈。 41.2.1 beta 分佈 the beta distribution 圖 41.1: Beta distribution functions for various values of a, b 我們定義 \\(a&gt;0\\) 時伽馬方程爲 \\[\\Gamma(a)=\\int_0^\\infty x^{a-1}e^{-ax}\\text{ d}x\\] 當 \\(a\\) 取正整數時， \\(\\Gamma(a)\\) 是 \\((a-1)!\\)。例如，當 \\(a=4, \\Gamma(a)=3\\times2\\times1=6\\)。 對於 \\(\\theta\\in[0,1]\\) 時，beta 方程 \\(Beta(a,b)\\) 被定義爲： \\[ \\begin{aligned} \\pi\\Theta(\\theta|a,b) &amp;= \\theta^{a-1}(1-\\theta)^{b-1}\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\\\ &amp;= \\frac{\\theta^{a-1}(1-\\theta)^{b-1}}{B(a,b)} \\end{aligned} \\] 其中 \\[B(a,b)=\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\] 莫要混淆 B 方程和 Beta 方程。 利用 Beta 方程作爲前概率顯得十分便捷且靈活。圖 41.1 展示的是 6 種不同的 \\((a,b)\\) 取值下的先驗概率分佈示意圖。其實我們可以看到，包括均一分佈在內的各種可能性都可以通過 Beta 分佈實現。其中 \\((a,b)\\) 被叫做超參數 (hyperparameter)。\\((a,b)\\) 取值越大，先驗概率分佈的方差越小。 關於 Beta 分佈的幾個性質： 均值：\\(\\text{mean}=\\frac{a}{a+b}\\)； 衆數：\\(\\text{mode}=\\frac{a-1}{a+b-2}\\)； 方差：\\(\\text{variance}=\\frac{ab}{(a+b)^2(a+b+1)}\\)。 回到均一分佈的簡單例子 (41.1) 上： \\(\\pi_\\Theta(\\theta)=Beta(1,1)\\) 是 \\(\\theta\\in[0,1]\\) 上的均一分佈。所以事後概率 posterior 和下面的式子成正比： \\[\\theta^r(1-\\theta)^{n-r}\\] 換句話說，事後概率分佈服從 \\(Beta(r+1,n-r+1)\\)，均值爲 \\(\\frac{r+1}{n+2}\\)，方差爲 \\(\\frac{(1+r)(n-r+1)}{(n+2)^2(n+3)}\\)。 由此可見，在貝葉斯統計思維下，先驗概率爲均一分佈的二項分佈數據，其事後概率分佈的均值和方差，和經典概率論下的極大似然估計 \\(r/n\\) 不同，和它的漸進樣本方差 \\(r(n-r)/n^3\\) 也不同。但是，當 \\(n\\) 越來越大，獲得的觀察數據越多提供的信息越來越多以後，我們會發現事後概率分佈的均值和方差也會越來越趨近於經典概率論下的極大似然估計和它的方差。 於是這裏可以總結以下兩點： 即使先驗概率對參數毫無用處（不能提供有效信息，或者我們對所觀察的數據一無所知），也可能會對事後概率分佈結果提供一些意外的信息。 當樣本量增加，似然就主導了整個貝葉斯方程，在數學計算上，經典概率論和貝葉斯推理的估計結果將會十分接近。當然，其各自的意義還是截然不同的。 41.2.2 二項分佈數據事後概率分佈的一般化：共軛性 當 \\(r\\sim \\text{Binomial}(n,\\theta)\\) 時，如果先驗概率 \\(\\pi_\\Theta(\\theta)=\\text{Beta}(a,b)\\)。那麼參數 \\(\\theta\\) 的事後概率分佈的密度方程滿足： \\[\\pi_{\\Theta|r}(\\theta|r)=\\text{Beta}(a+r, b+n-r)\\] 它的事後概率分佈均值爲： \\[E[\\theta|r]=\\frac{a+r}{a+b+n}\\] 事後概率分佈的衆數爲： \\[\\text{Mode}[\\theta|r]=\\frac{a+r-1}{n+a+b-2}\\] 事後概率分佈方差爲： \\[\\text{Var}[\\theta|r]=\\frac{(a+r)(b+n-r)}{(a+b+n)^2(a+b+n+1)}\\] 因此，我們看到先驗概率服從 \\(\\text{Beta}(a,b)\\) 分佈，觀察數據爲二項分佈時，事後概率分佈還是服從 \\(\\text{Beta}\\) 分佈，僅僅只是超參數發生了轉變（更新）。這就是共軛分佈的實例。\\(\\text{Beta}\\) 分佈是二項分佈的共軛先驗概率分佈 (the \\(\\text{Beta}(a,b)\\) is the conjugate prior for the binomial likelihood)。 在經典概率論的框架下，參數 \\(\\theta\\) 的估計就是極大似然估計 (MLE)。在二項分佈的例子中， \\(\\text{MLE}=\\hat\\theta=r/n\\)，當樣本量 \\(n\\rightarrow\\infty\\) 時，事後概率分佈均值： \\[E[\\theta|r]=\\frac{a+r}{a+b+n}=\\frac{\\frac{r}{n}+\\frac{a}{n}}{1+\\frac{a+b}{n}}\\approx\\frac{r}{n}=\\text{MLE}\\] 事後概率分佈的衆數爲： \\[ \\begin{aligned} \\text{Mode}[\\theta|r] &amp;=\\frac{a+r-1}{n+a+b-2} \\\\ &amp;= \\frac{\\frac{r}{n}+\\frac{a-1}{n}}{1+\\frac{a+b-2}{n}}\\\\ &amp;\\approx \\frac{r}{n} \\end{aligned} \\] 事後概率分佈的方差爲： \\[\\frac{(a+r)(b+n+r)}{(a+b+n)^2(a+b+n+1)}\\approx0\\] 當 \\(n\\)，樣本越來越大時，我們獲得更多的來自數據的信息，所以來自數據的信息逐漸主導 (dominate) 了整個貝葉斯推斷的過程，事後均值等衆多統計結果都越來越趨近於概率論統計思想下的極大似然估計等結論。 我們也可以注意到，當 \\(a\\rightarrow0, b\\rightarrow0\\) 時，事後概率分佈的均值 \\(E[\\theta|r] = \\frac{a+r}{a+b+n} \\rightarrow \\frac{r}{n}\\)，方差也趨向於樣本漸進方差 (asymptotic sample variance)。但是當 \\(a\\rightarrow 0, b\\rightarrow0\\) 時，先驗概率是沒有被定義的，可是此例下事後概率卻可以正常被定義。所以當先驗概率分佈無法被定義，或者被定義的不恰當時，事後概率分佈依然不受太大影響。所以特別是對於均值（或迴歸係數，regression coefficients）等參數，我們常常會使用均一分佈這樣的無信息先驗概率。 41.3 練習題 41.3.1 Q1 當先驗概率分佈服從 \\(\\text{Beta}(0.5,0.5)\\)，觀察數據記錄到 \\(5\\) 個患者中 \\(3\\) 人死亡的事件。 試求： 死亡發生概率 \\(\\theta\\) 的 95% 可信區間 (credible intervals)。 解 根據 Section 41.2.2 的公式，當先驗概率爲 \\(\\pi_{\\Theta|r}(\\theta|r)=\\text{Beta}(a=0.5,b=0.5)\\) ，數據 \\(n=5, r=3\\)。參數 \\(\\theta\\) 的事後概率分佈 \\(\\pi_{\\Theta|r}(\\theta|r)=\\text{Beta}(a+r,b+n-r)=\\text{Beta}(3.5,2.5)\\)。 在 R 裏進行貝葉斯計算十分簡便： # 95% Credible Intervals L &lt;- qbeta(0.025, 3.5, 2.5) U &lt;- qbeta(0.975, 3.5, 2.5) print(c(L,U)) ## [1] 0.20941666 0.90560967 事後分佈 \\(\\pi_{\\Theta|r}(\\theta|r)=\\text{Beta}(3.5,2.5)\\) 的分佈圖形如下： post &lt;- Vectorize(function(theta) dbeta(theta, 3.5, 2.5)) # Illustration x &lt;- seq(0,1,length=10000) y &lt;- post(x) plot(x,y, type = &quot;l&quot;, xlab=~theta, ylab=&quot;Density&quot;, lwd=2, frame.plot = FALSE) polygon(c(L, x[x&gt;=L &amp; x&lt;= U], U), c(0, y[x&gt;=L &amp; x&lt;=U], 0), col=&quot;grey&quot;) 圖 41.2: Posterior distribution of Beta(3.5,2.5) 我們可以自己寫一個求可信區間的公式來計算： # Credible Interval function: # a, b : shape / super parameters # level: probability level (0,1) cred.int &lt;- function(a,b,level){ L &lt;- qbeta((1-level)/2, a, b) # Lower limit U &lt;- qbeta((1+level)/2, a, b) # Upper limit return(c(L,U)) } cred.int(3.5,2.5,0.95) ## [1] 0.20941666 0.90560967 95%可信區間 \\((0.2094, 0.9056)\\) 告訴我們，參數 \\(\\theta\\in(0.2094, 0.9056)\\) 的概率是 \\(0.95\\)。 下面我們嘗試寫 Beta 分佈的其他統計量：均值，衆數，方差等。 # a, b: shape / super parameters MeanBeta &lt;- function(a,b) a/(a+b) ModeBeta &lt;- function(a,b) { m &lt;- ifelse(a&gt;1 &amp; b&gt;1, (a-1)/(a+b-2), NA) return(m) } VarianceBeta &lt;- function(a,b) (a*b)/((a+b)^2*(a+b+1)) # mean MeanBeta(3.5,2.5) ## [1] 0.58333333 # mode ModeBeta(3.5,2.5) ## [1] 0.625 # Variance VarianceBeta(3.5, 2.5) ## [1] 0.034722222 # SD sqrt(VarianceBeta(3.5, 2.5)) ## [1] 0.186339 41.3.2 Q2 假如數據還是 Q1 的數據，然而先驗概率讓我們認爲可能在 5 名受試對象中觀察到 1 次事件。 試求超參數 \\((a,b)\\) 滿足先驗概率的 Beta 分佈。(不止一組) 解 我們認爲最有可能發生 “5 名受試對象中觀察到 1 次事件” 的情況，所以先驗概率的均值爲 \\(\\frac{a}{a+b}=0.2\\)。所以，在實數中有無數組超參數都可以用來模擬先驗概率分佈。例如 \\(a=1, b=4; a=10, b=40; a=100, b=400; a=0.317, b=1.268, \\cdots\\)。 假如觀察數據是 \\(n=5, r=1\\)，計算事後概率分佈及其均值，標準差。 解 先來嘗試寫一個計算貝葉斯二項分佈的方程： # binbayes function in R #------------------------------ # a, b: shape / super parameters # r : number of successes # n : number of trials binbayes &lt;- function(a, b, r, n) { prior &lt;- c(a, b, NA, MeanBeta(a,b), sqrt(VarianceBeta(a, b)), qbeta(0.025, a, b), qbeta(0.5, a, b), qbeta(0.975, a, b)) posterior &lt;- c(a+r, b+n-r, r/n, MeanBeta(a+r, b+n-r), sqrt(VarianceBeta(a+r, b+n-r)), qbeta(0.025, a+r, b+n-r), qbeta(0.5, a+r, b+n-r), qbeta(0.975, a+r, b+n-r)) out &lt;- rbind(prior, posterior) out &lt;- round(out, 4) colnames(out) &lt;- c(&quot;a&quot;,&quot;b&quot;,&quot;r/n&quot;,&quot;Mean&quot;, &quot;SD&quot;, &quot;2.5%&quot;, &quot;50%&quot;, &quot;97.5%&quot;) return(out) } # a=1, b=4, r=1, n=5 binbayes(1,4,1,5) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 1 4 NA 0.2 0.1633 0.0063 0.1591 0.6024 ## posterior 2 8 0.2 0.2 0.1206 0.0281 0.1796 0.4825 # a=10, b=40, r=1, n=5 binbayes(10,40,1,5) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 10 40 NA 0.2 0.0560 0.1024 0.1960 0.3202 ## posterior 11 44 0.2 0.2 0.0535 0.1063 0.1963 0.3143 通過繪製先驗概率分佈圖和事後概率分佈圖來比較二者的變化： # Prior vs posterior graphs # a,b : shape / super parameters # r : number of successes # n : number of trials graph.binbayes &lt;- function(a,b,r,n) { prior &lt;- Vectorize(function(theta) dbeta(theta, a,b)) posterior &lt;- Vectorize(function(theta) dbeta(theta, a+r, b+n-r)) YL &lt;- max(prior(seq(0.001,0.999,by=0.001)),posterior(seq(0.001,0.999,by=0.001))) curve(prior, xlab=~theta, ylab=&quot;Density&quot;, lwd=1, lty=2,n=10000,ylim=c(0,YL), frame.plot = FALSE) curve(posterior, xlab=~theta,lwd=2,lty = 1, add=T,n=10000) } graph.binbayes(1,4,1,5) 圖 41.3: Prior (dashed) Beta(1,4) vs. Posterior (cont.) Beta(2,8) graph.binbayes(10,40,1,5) 圖 41.4: Prior (dashed) Beta(10,40) vs. Posterior (cont.) Beta(11, 44) 我們可以很清楚的看見，先驗概率相同時，\\(\\text{Beta} (a,b)\\) 的超參數如果越大，先驗概率的分佈就越趨近與對稱圖形，且極大值也就越出現在均值的地方 (本例中是 \\(0.2\\))。而且也會使事後概率的 HPD (highest posterior density) 的區間更狹窄 (意爲對事後概率的預測越準確)，同時事後概率分佈也更加接近左右對稱。 41.3.3 Q3 我們事先估計某個事件在 \\(n=20\\) 名患者中發生的概率爲 \\(15\\%\\)。當實際觀察數據爲 \\(n=15,r=3\\) 時，計算相應的事後概率。 解 # because 15% events happened in 20 subjects, assuming prior Beta(a=3, b=17) # observed n=15, r=3 binbayes(3,17,3,15) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 3 17 NA 0.1500 0.0779 0.0338 0.1383 0.3314 ## posterior 6 29 0.2 0.1714 0.0628 0.0676 0.1651 0.3106 graph.binbayes(3,17,3,15) 圖 41.5: Prior (dashed) Beta(3,17) vs. Posterior (cont.) Beta(6,29) 試着繪製先驗概率服從 \\(\\text{Beta} (1,1)\\)，回憶之前本章開頭的圖 41.1，這個先驗概率的含義就是我們沒有任何背景知識，對數據完全陌生的情況： graph.binbayes(1,1,3,15) 圖 41.6: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(4,13) 41.3.4 Q4 試給出上面各題中參數 \\(\\theta\\) 落在 \\((0.1,0.25)\\) 之間的概率。 # function to calculate probabilities in a interval # a, b: super parameters # r : number of successes # n : number of trials # L : Lower limit of the probability interval # U : Upper limit of the probability interval prob.int &lt;- function(a,b,r,n,L,U){ prior0 &lt;- pbeta(U,a,b) - pbeta(L,a,b) posterior0 &lt;- pbeta(U,a+r,n-r+b) - pbeta(L,a+r,n-r+b) prob &lt;- as.matrix(c(prior0, posterior0)) prob &lt;- round(prob,4) colnames(prob) &lt;- paste(&quot;Probability of theta lies between the Interval&quot;, L, U) rownames(prob) &lt;- c(&quot;Prior&quot;,&quot;Posterior&quot;) return(prob) } # Prior Beta(0.317,1.286) n = 5, r=1 binbayes(0.317, 1.286, 1, 5) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 0.317 1.286 NA 0.1978 0.2469 0.000 0.0823 0.8516 ## posterior 1.317 5.286 0.2 0.1995 0.1449 0.013 0.1684 0.5493 prob.int(0.317, 1.286, 1, 5,0.1,0.25) ## Probability of theta lies between the Interval 0.1 0.25 ## Prior 0.1711 ## Posterior 0.3911 graph.binbayes(0.317, 1.286, 1, 5) 圖 41.7: Prior (dashed) Beta(0.317,1.286) vs. Posterior (cont.) Beta(1.317, 5.286) # Prior Beta(10,40) n = 5, r=1 binbayes(10, 40, 1, 5) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 10 40 NA 0.2 0.0560 0.1024 0.1960 0.3202 ## posterior 11 44 0.2 0.2 0.0535 0.1063 0.1963 0.3143 prob.int(10, 40, 1, 5,0.1,0.25) ## Probability of theta lies between the Interval 0.1 0.25 ## Prior 0.7951 ## Posterior 0.8099 所以在範圍固定的時候，事後概率分佈總是能夠比先驗概率分佈給出更高的累計概率。 41.3.5 Q5 一個臨牀試驗要進行兩個階段 (two phases)，第一階段我們觀察到 \\(10\\) 個患者中 \\(1\\) 個事件。第二階段，觀察到 \\(n=50, r=5\\)。 兩個階段都使用 \\(\\text{Beta}(1,1)\\) 作先驗概率。求兩個實驗階段參數 \\(\\theta&lt;0.1\\) 的概率。 # Phase I binbayes(1, 1, 1, 10) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 1 1 NA 0.5000 0.2887 0.0250 0.500 0.9750 ## posterior 2 10 0.1 0.1667 0.1034 0.0228 0.148 0.4128 prob.int(1,1,1,10,0,0.1) ## Probability of theta lies between the Interval 0 0.1 ## Prior 0.1000 ## Posterior 0.3026 graph.binbayes(1, 1, 1, 10) 圖 41.8: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(2, 10) # Phase II binbayes(1, 1, 5, 50) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 1 1 NA 0.5000 0.2887 0.0250 0.5000 0.9750 ## posterior 6 46 0.1 0.1154 0.0439 0.0444 0.1105 0.2141 prob.int(1,1,5,50,0,0.1) ## Probability of theta lies between the Interval 0 0.1 ## Prior 0.1000 ## Posterior 0.4024 graph.binbayes(1, 1, 5, 50) 圖 41.9: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(6, 46) 繼續使用先驗概率分佈 \\(\\text{Beta}(1,1)\\)，合併兩個實驗階段，求此時的事後概率分佈，以及參數 \\(\\theta&lt;0.1\\) 的概率。 # Combining both phases binbayes(1, 1, 6, 60) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 1 1 NA 0.5000 0.2887 0.0250 0.5000 0.9750 ## posterior 7 55 0.1 0.1129 0.0399 0.0474 0.1087 0.2019 prob.int(1,1,6,60,0,0.1) ## Probability of theta lies between the Interval 0 0.1 ## Prior 0.1000 ## Posterior 0.4105 graph.binbayes(1, 1, 6, 60) 圖 41.10: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(7, 55) 用第一階段的實驗結果做第二階段實驗的先驗概率分佈，再計算事後概率分佈，以及 \\(\\theta&lt;0.1\\) 的概率。 # Using Phase I results as a prior for Phase II binbayes(2, 10, 5, 50) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 2 10 NA 0.1667 0.1034 0.0228 0.1480 0.4128 ## posterior 7 55 0.1 0.1129 0.0399 0.0474 0.1087 0.2019 prob.int(2,10,5,50,0,0.1) ## Probability of theta lies between the Interval 0 0.1 ## Prior 0.3026 ## Posterior 0.4105 graph.binbayes(2, 10, 5, 50) 圖 41.11: Prior (dashed) Beta(2,10) vs. Posterior (cont.) Beta(7, 55) 第2，3兩個小問題提示我們，無論是將第一階段實驗結果作爲第二階段實驗的先驗假設還是將兩次實驗合併，最終的結果是不會改變的。Both approaches are equivalent. 41.3.6 Q6 藥物 A 和藥物 B 都被批准用於治療某種疾病。在 5000 例病例中使用藥物 A，發現有 3 人發生了不良副作用。在另外 7000 例病例中使用藥物 B，發現只有 1 例發生了副作用。 先使用單一分佈作爲先驗概率 (uniform prior: \\(\\text{Beta}(1,1)\\))。求藥物 A 和藥物 B 各自發生不良反應的事後概率。 藥物 A # Drug A binbayes(1,1, 3, 5000) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 1 1 NA 0.5000 0.2887 0.0250 0.5000 0.9750 ## posterior 4 4998 0.0006 0.0008 0.0004 0.0002 0.0007 0.0018 圖 41.12: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(4, 4998) 藥物 B # Drug B binbayes(1,1, 1, 7000) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 1 1 NA 0.5000 0.2887 0.025 0.5000 0.9750 ## posterior 2 7000 0.0001 0.0003 0.0002 0.000 0.0002 0.0008 圖 41.13: Prior (dashed) Beta(1,1) vs. Posterior (cont.) Beta(2, 7000) 使用 \\(\\text{Beta}(0.00001,0.00001)\\) 作爲先驗概率，重複上面的計算 藥物 A # Drug A binbayes(0.00001, 0.00001, 3, 5000) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 0 0 NA 0.5000 0.5000 0.0000 0.5000 1.0000 ## posterior 3 4997 0.0006 0.0006 0.0003 0.0001 0.0005 0.0014 圖 41.14: Prior (dashed) Beta(0.00001,0.00001) vs. Posterior (cont.) Beta(3, 4997) 藥物 B # Drug B binbayes(0.00001, 0.00001, 1, 7000) ## a b r/n Mean SD 2.5% 50% 97.5% ## prior 0 0 NA 0.5000 0.5000 0 0.5000 1.0000 ## posterior 1 6999 0.0001 0.0001 0.0001 0 0.0001 0.0005 圖 41.15: Prior (dashed) Beta(0.00001,0.00001) vs. Posterior (cont.) Beta(1, 6999) 現在使用概率論的計算信賴區間 (confidence intervals) 的方法，求上面數據的精確二項分佈 95% 信賴區間。之前兩問中使用的哪個先驗概率更加接近概率論算法？ #------------------------------------------------ # Binomial confidence intervals #------------------------------------------------ # r : number of successes # n : number of trials # level: confidence level binom.confint &lt;- function(r,n,level){ p &lt;- r/n conf &lt;- as.vector(binom.test(r,n,conf.level = 0.95)$conf.int) out &lt;- c(p,conf) out &lt;- as.matrix(t(round(out,8))) colnames(out) &lt;- c(&quot;MLE&quot;, &quot;L&quot;, &quot;U&quot;) return(out) } # Drug A binom.confint(3,5000,0.95) ## MLE L U ## [1,] 0.0006 0.00012375 0.00175244 # Drug B binom.confint(1,7000,0.95) ## MLE L U ## [1,] 0.00014286 3.62e-06 0.00079569 明顯可以看到，先驗概率使用 \\(\\text{Beta}(0.00001,0.00001)\\) 時，事後概率的均值和可信區間的下限值更接近概率論算法。使用先驗概率 \\(\\text{Beta}(1,1)\\) 時，事後概率的可信區間的上限值更接近概率論算法。 如果需要你來下結論說，藥物 B 和藥物 A 哪個更加安全？ 求 \\(\\text{Pr}(\\theta_B &lt; \\theta_A|data)\\)。 解 貝葉斯 在計算機的輔助下，這是一個十分簡單的計算。我們從各自的事後分佈中採集大量隨機樣本，然後求 \\(\\theta_B-\\theta_A\\) 然後看有多少比例這個數值是小於零的就可以得出結論： # Simulating from each posterior set.seed(1001) post.thetaA &lt;- rbeta(1000000, 3, 4997) post.thetaB &lt;- rbeta(1000000, 1, 6999) # Taking the differences theta.diff0 &lt;- post.thetaB - post.thetaA # Histogram of the differences hist(theta.diff0,probability = TRUE, breaks = 50, xlab=expression(theta[B] - theta[A]),main = &quot;&quot;) abline(v=0, col=&quot;red&quot;, lwd=2) box() 圖 41.16: Histogram of Drug B - Drug A 也可以不採用直方圖而是使用連續曲線： # Continuous version plot(density(theta.diff0), xlab=expression(theta[B] - theta[A]), lwd=2, main = &quot;&quot;, frame=FALSE) abline(v=0, col=&quot;red&quot;, lwd=2) box() 圖 41.17: Density of Drug B - Drug A 計算 \\(\\text{Pr}(\\theta_B &lt; \\theta_A|data)\\) 和可信區間： # P(theta[B] &lt; theta[A] | Data) mean(theta.diff0 &lt;0) ## [1] 0.927829 # Credible interval for theta[B] - theta[A] quantile(theta.diff0, c(0.05,0.95)) ## 5% 95% ## -0.001142862872 0.000052484912 quantile(theta.diff0, c(0.10,0.90)) ## 10% 90% ## -0.00094605885 -0.00004674857 # Simulating from each posterior set.seed(1001) post.thetaA &lt;- rbeta(1000000, 4, 4998) post.thetaB &lt;- rbeta(1000000, 2, 7000) # Taking the differences theta.diff1 &lt;- post.thetaB - post.thetaA hist(theta.diff1,probability = TRUE, breaks = 50, xlab=expression(theta[B] - theta[A]),main = &quot;&quot;) abline(v=0, col=&quot;red&quot;, lwd=2) box() 圖 41.18: Histogram of Drug B - Drug A # Continuous version plot(density(theta.diff1), xlab=expression(theta[B] - theta[A]), lwd=2,main = &quot;&quot;) abline(v=0, col=&quot;red&quot;, lwd=2) box() 圖 41.19: Density of Drug B - Drug A 計算 \\(\\text{Pr}(\\theta_B &lt; \\theta_A|data)\\) 和可信區間： # P(theta[B] &lt; theta[A] | Data) mean(theta.diff1 &lt;0) ## [1] 0.899677 # Credible interval for theta[B] - theta[A] quantile(theta.diff1, c(0.05,0.95)) ## 5% 95% ## -0.00131289334 0.00013423126 quantile(theta.diff1, c(0.10,0.90)) ## 10% 90% ## -1.0955252e-03 6.5146438e-07 概率論算法 # Normal Approximation diff_mle &lt;- (1/7000)-(3/5000) diff_se &lt;- sqrt( 1*6999/7000^3 + 3*4997/5000^3 ) U &lt;- diff_mle + 1.28*diff_se L &lt;- diff_mle - 1.28*diff_se print(c(U,L)) ## [1] 0.000022358961 -0.000936644675 norm.app &lt;- Vectorize(function(x) dnorm(x,diff_mle,diff_se)) # Comparison plot(density(theta.diff0), xlab=expression(theta[B] - theta[A]), xlim= c(-0.002,0.001), lwd=2, col=&quot;red&quot;,main = &quot;&quot;) points(density(theta.diff1), xlab=expression(theta[B] - theta[A]), type = &quot;l&quot;, col = &quot;blue&quot;, lwd=2) curve(norm.app,-0.0045,0.002,add=T,lwd=2,n=10000) legend(-0.0021, 1300, c(&quot;Posterior with B(0,0)&quot;,&quot;Posterior with B(1,1)&quot;,&quot;Frequentist Normal App&quot;), col=c(&quot;red&quot;,&quot;blue&quot;,&quot;black&quot;), text.col = &quot;black&quot;, lty = c(1, 1, 1), lwd = c(2,2,2), merge = TRUE, bg = &quot;gray90&quot;,cex=0.8) box() 圖 41.20: Comparison of different prior distribution and frequentist approximation "],
["normal-distribution-applying-bayes-theorem.html", "第 42 章 Normal distribution applying Bayes’ Theorem", " 第 42 章 Normal distribution applying Bayes’ Theorem "],
["section-43.html", "第 43 章 重要概念複習 43.1 概率論學派統計推斷要點複習 43.2 似然 43.3 極大似然估計 43.4 關於假設檢驗的複習 43.5 線性迴歸複習", " 第 43 章 重要概念複習 There are no routine statistical questions, only questionable statistical routines. — Sir David Cox 43.1 概率論學派統計推斷要點複習 下面我們一起用二項分佈的概念 (\\(n\\) 個對象中 \\(K\\) 個“事件”)，來複習概率論學派的統計推斷要點。 模型，the Model。一個統計模型，描述的不僅僅是我們研究的人羣的一些特徵，而且通常一個模型還可提供如何從人羣中收集該樣本的信息。 用二項分佈的概念來解釋，人羣是衆多個體的集合，他們中的一部分佔比 \\(\\pi\\) 的人身上發生了某個事件。從這個人羣的集合中，我們隨機抽取 \\(n\\) 個對象作爲研究樣本，該樣本中有 \\(K\\) 個人身上發生了事件。此時，我們說 \\(K\\) 服從人羣比例爲 \\(\\pi\\) 的二項分佈：\\(K \\sim \\text{Bin}(n,\\pi)\\)。 參數，parameters。模型中的參數反映了人羣的某些特徵。在實際應用中，從來沒有“人類”能知道人羣參數的真實值，渺小的我們從人羣中抽取樣本，用於推斷 “上帝才知道的” 這些代表了人羣特徵的參數。 在二項分佈的情境下，有且只有一個人羣參數，人羣中事件的比例 \\(\\pi\\)。 參數估計量，parameter estimators。估計量是樣本的統計量，被用來估計未知的總體參數。估計量 estimator，是一個隨機變量，是我們計算估計值的一般形式。估計值 estimate，是每個樣本通過統計模型計算獲得的估計量的真實值，每採樣一次，計算獲得的估計值理論上會略有不同。 二項分佈的上下文中，人羣事件比例 – 這一參數 \\(\\pi\\) 的天然估計量是 \\(\\hat\\pi = \\frac{K}{n}\\)，當一個樣本中發現 \\(K = k\\)，該樣本給出的估計值是 \\(\\frac{k}{n}\\)。 研究假設，hypotheses。研究假設是實驗前我們提出的要被檢驗的一些關於人羣某些特徵參數的 “陳述 statement”。可以是猜想參數等於某個特定值，或者多個參數大小相同。 二項分佈的數據裏，只有一個人羣參數，\\(\\pi\\)。可能提出的零假設和替代假設有很多，\\(\\pi = 0.5 \\text{ v.s. } \\pi \\neq 0.5\\) 是其中之一的複合型假設。 43.2 似然 如果一個模型只有一個參數 \\(\\theta\\)，樣本數據已知的話，該參數的似然爲： \\[\\text{L}(\\theta | \\text{data}) = \\text{Pr}(\\text{data}|\\theta)\\] 其中，\\(\\text{Pr}(\\text{data}|\\theta)\\) 對於離散型變量，是概率方程 probability function；對於連續型變量，則是概率密度方程 probability density function (PDF)。 對數似然，就是上面的似然方程取自然底數的對數方程： \\[\\ell(\\theta | \\text{data}) = \\text{ln}\\{ \\text{L}(\\theta | \\text{data}) \\}\\] 43.3 極大似然估計 當數據收集完畢，從獲得的數據中計算獲得的能夠使似然方程/或對數似然方程取得極大值的 \\(\\theta\\) 的大小，被叫做極大似然估計 \\(\\text{(MLE)}\\)，且通常數學標記會在參數上加一頂帽子： \\(\\hat\\theta\\)。收集不同的樣本，在相同的似然方程或對數似然方程下，極大似然估計不同。 許多問題，我們獲得極大似然估計的方法是先定義好模型的似然方程，然後求該方程的一階導數之後計算使之等於零的參數值大小就是 \\(\\text{MLE } \\hat\\theta\\)。此時，你還要記得再求一次二階導數，看是否小於零，以確保前一步計算獲得的值給出的似然方程是極大值。 更多的時候我們用對數似然方程以簡化計算過程： \\[ \\begin{aligned} \\left.\\frac{\\text{d}}{\\text{d } \\theta}\\ell (\\theta | \\text{data})\\right\\vert_{\\theta=\\hat{\\theta}} &amp;= \\ell^\\prime(\\hat\\theta) = 0 \\\\ \\left.\\frac{\\text{d}^2}{\\text{d } \\theta^2}\\ell (\\theta | \\text{data})\\right\\vert_{\\theta=\\hat{\\theta}} &amp;= \\ell^{\\prime\\prime}(\\hat\\theta) &lt; 0 \\end{aligned} \\] 我們只關心似然方程的形狀，所以方程中不包含參數的部分可全部忽略掉。 \\(\\text{MLE}\\) 的一些關鍵性質： 漸進無偏 asymptotically unbiased：當 \\(n\\rightarrow \\infty\\) 時，\\(E(\\hat\\theta) \\rightarrow \\theta\\)； 一致性 consistency：隨着樣本量的增加，\\(\\hat\\theta\\) 收斂於 (converges) 總體參數 \\(\\theta\\)； 漸進正態分佈 asymptotically normality：隨着樣本量增加，\\(\\hat\\theta\\) 的樣本分佈收斂於 (converges) 正態分佈，方差爲 \\[E[-\\ell^{\\prime\\prime}(\\theta)]^{-1}=[-\\ell^{\\prime\\prime}(\\hat\\theta)]^{-1}\\] 恆定性 invariance：如果 \\(\\hat\\theta\\) 是 \\(\\text{MLE}\\)，那麼 \\(\\theta\\) 被數學轉換以後 \\(g(\\theta)\\) 的方程的 \\(\\text{MLE}\\) 是 \\(g(\\hat\\theta)\\) 似然理論可以直接拓展到多個參數的情況。一般地，如果一個模型有 \\(p\\) 個參數 \\(\\mathbf{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_p)^T\\)，這些參數在給定數據的條件下的似然方程爲：\\[\\text{L}(\\mathbf{\\theta} | \\text{data}) = \\text{Pr}(\\text{data} | \\mathbf{\\theta})\\] 其中，概率 (密度) 方程在多個參數時變成聯合 (joint) 概率 (密度) 方程。似然，也是各個參數的聯合似然方程。此時，參數向量 \\(\\mathbf{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_p)^T\\) 的方差協方差矩陣的估計量爲： \\[ \\hat{\\text{Var}}(\\mathbf{\\hat\\theta}) = - \\left( \\begin{array}{c} \\frac{\\partial^2\\ell}{\\partial\\theta^2_1} &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_2\\partial\\theta_1} &amp; \\cdots &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_k\\partial\\theta_1} \\\\ \\frac{\\partial^2\\ell}{\\partial\\theta_1\\partial\\theta_2} &amp; \\frac{\\partial^2\\ell}{\\partial\\theta^2_2} &amp; \\cdots &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_k\\partial\\theta_2} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial^2\\ell}{\\partial\\theta_1\\partial\\theta_k} &amp; \\frac{\\partial^2\\ell}{\\partial\\theta_2\\partial\\theta_k} &amp; \\cdots &amp; \\frac{\\partial^2\\ell}{\\partial\\theta^2_k} \\\\ \\end{array} \\right)^{-1}_{\\theta=\\hat\\theta} \\] Tips: typing vcov(Modelname) command in R will display this estimated variance-covariance matrix for the parameter estimates. 回到二項分佈數據的例子： \\[ K \\sim \\text{Bin}(n, \\pi) \\] 如果我們樣本的觀測數據是 \\(K=k\\)，對數似然方程一次微分等於零以後求得的參數 \\(\\pi\\) 的 \\(\\text{MLE}\\) 是 \\(\\hat\\pi = \\frac{k}{n}\\)。所以參數 \\(\\pi\\) 的估計量是 \\(\\frac{K}{n}\\)。\\(\\hat\\pi\\) 的方差估計量是： \\[ \\hat{\\text{Var}} (\\hat\\pi) = \\frac{\\hat\\pi(1-\\hat\\pi)}{n} \\text{ for } \\hat\\pi = \\frac{k}{n} \\] 43.4 關於假設檢驗的複習 極大似然估計可以有三大類檢驗方法：似然比檢驗法 likelihood ratio test；Wald 檢驗 Wald test；Score 檢驗 Score test。 似然比檢驗法 likelihood ratio test (LRT) (Section 16.2)： \\[ -2llr(\\theta_0) = -2\\{ \\ell(\\theta_0) - \\ell(\\hat\\theta) \\} \\] 零假設條件下 (Under \\(\\text{H}_0\\):) \\[ -2llr(\\theta_0) \\sim \\chi_1^2 \\] 這個對數似然比的統計量可以和自由度爲 1 的卡方分佈作比較，計算反對零假設的證據的強度大小。如果顯著性水平是 \\(\\alpha\\)，那麼下面條件成立時，可以認爲反對零假設的證據強度大到足以拒絕零假設。 \\[ -2llr(\\theta_0) &gt; \\chi^2_{1, 1-\\alpha} \\] Wald 檢驗 (Section 16.4) 是一種利用二次方程近似法對似然比檢驗進行近似的手段。其檢驗統計量是 \\[ \\begin{aligned} (\\frac{M-\\theta_0}{S})^2 &amp; \\sim \\chi^2_1 \\\\ \\text{Where } M &amp; = \\hat\\theta \\\\ S^2 &amp; = \\frac{1}{-\\ell^{\\prime\\prime}(\\hat\\theta)} \\end{aligned} \\] Score 檢驗 (Section 16.5) 是另一種利用二次方程近似法對似然比檢驗進行近似的手段。其檢驗統計量是 \\[ \\begin{aligned} \\frac{U^2}{V} &amp; \\sim \\chi^2_1 \\\\ \\text{Where } U &amp; = \\ell^\\prime(\\theta_0) \\\\ V &amp; = -\\ell^{\\prime\\prime}(\\theta_0) \\end{aligned} \\] 如果對數似然方程本身就是一個二次方程 (數據服從完美正態分佈狀態，且總體方差已知時)，這三大類的檢驗法其實計算獲得完全一樣的 \\(p\\) 值，提供完全一致的證據。多數情況下，三大類檢驗法的結果是近似的。關於三種檢驗法的比較可以參考過去總結的章節 (Section 16.6) 43.4.1 子集似然函數 當統計模型中的部分參數是噪音參數 (nuisance parameters) 時，我們需要用到子集似然函數法 (Section 19) 來去除噪音參數的影響,，只檢驗我們感興趣的那部分參數。 43.5 線性迴歸複習 43.5.1 簡單線性迴歸 假設對於 \\(n\\) 名研究對象，我們測量個兩個觀測值 \\((y_i, x_i)\\)，那麼用線性迴歸模型來表示這兩個測量值估計的參數之間的關係就是： \\[ \\begin{aligned} y_i &amp; = \\alpha + \\beta x_i + \\varepsilon_i \\\\ \\text{Where } &amp; \\varepsilon_i \\sim \\text{NID}(0,1) \\end{aligned} \\] 或者用另一個標記法： \\[ Y_i | x_i \\sim N(\\alpha + \\beta x_i, \\sigma^2) \\] 43.5.2 多元線性迴歸 如果預測變量有兩個或者兩個以上 \\((x_i, \\;\\&amp;\\; z_i)\\)，那麼描述這兩個預測變量和因變量之間的多元線性迴歸模型可以寫作： \\[ y_i = \\alpha + \\beta x_i + \\gamma z_i + \\varepsilon_i \\] 此時， \\(\\beta\\) 的含義是，當保持 \\(z\\) 不變時，\\(x\\) 每增加一個單位，\\(y\\) 的變化量。用這個模型，我們默認 \\(z\\) 保持不變的同時無論取值爲多少， \\(x, y\\) 之間的關係是不會變化的，我們用這個模型來調整 (adjust) \\(z\\) 的混雜效應 (confounding effect) (Section 29.5)。 當然我們也可以考慮當 \\(z\\) 取值不同時， \\(x, y\\) 之間的關係發生改變，只要在上面的多元線性迴歸方程中加入一個交互作用項即可 (Section 32)。 \\[ y_i = \\alpha + \\beta x_i + \\gamma z_i + \\delta x_i z_i + \\varepsilon_i \\] 增加了交互作用項最大的變化是，\\(x_i\\) 的迴歸係數 \\(\\beta\\) 的含義發生了改變：當且僅當 \\(z = 0\\) 且保持不變時，\\(x\\) 每增加一個單位，\\(y\\) 的變化量。如果 \\(z = k \\neq 0\\) 且保持不變，那麼 \\(x\\) 每增加一個單位，\\(y\\) 的變化量則是 \\(\\beta + k\\delta\\)。 43.5.3 簡單線性迴歸的統計推斷 一個給定的樣本 \\((y_i, x_i), i = 1, \\cdots, n\\) ，其對數似然方程是 \\[ \\ell(\\alpha, \\beta, \\sigma^2 | \\mathbf{y, x}) = -\\frac{1}{2\\sigma^2}\\sum^n_{i=1}(y_i - \\alpha - \\beta x_i)^2 \\] 分別對 \\(\\alpha, \\beta\\) 求微分之後可以獲得他們各自的 \\(\\text{MLE}\\)： \\[ \\begin{aligned} U(\\alpha) &amp; = \\ell^\\prime(\\alpha) = \\frac{1}{\\sigma^2}\\sum_{i=1}^n (y_i - \\alpha - \\beta x_i) \\\\ U(\\beta) &amp; = \\ell^{\\prime}(\\beta) = \\frac{1}{\\sigma^2}\\sum_{i=1}^n x_i(y_i - \\alpha - \\beta x_i) \\\\ U(\\hat\\alpha) &amp; = 0 \\Rightarrow \\hat\\alpha = \\bar{y} - \\hat\\beta\\bar{x} \\\\ U(\\hat\\beta) &amp; = 0 \\Rightarrow \\hat\\beta=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2} = \\frac{\\sum x_iy_i - n\\bar{x}\\bar{y}}{\\sum x_i^2 - n\\bar{x}^2} \\end{aligned} \\] 注意到和線性迴歸章節中推導的過程不同 (Section 26.4.1)，當時我們用的是最小二乘法，這裏我們用的是光明正大的極大似然法，同時也證明了最小二乘法獲得的 \\(\\hat\\alpha,\\hat\\beta\\) 是他們各自的 \\(\\text{MLE}\\)。 另外，殘差方差的 \\(\\text{MLE}\\) 也可以用上面的方法推導出來，同樣和之前的方法 (Section 26.5) 做個對比吧： \\[ \\begin{aligned} U(\\sigma^2) &amp; = \\ell^\\prime(\\sigma^2) = -\\frac{n}{2\\sigma^2} + \\frac{1}{2\\sigma^4}\\sum_{i=1}^n(y_i - \\alpha - \\beta x_i)^2 \\\\ U(\\hat\\sigma^2) &amp; \\Rightarrow \\hat\\sigma^2 = \\frac{\\sum_{i=1}^n(y_i - \\hat\\alpha - \\hat\\beta x_i)^2}{n} \\end{aligned} \\] 這個殘差方差的 \\(\\text{MLE}\\) 其實不是一個無偏估計，它只是一個漸進無偏的估計 (需要除以 \\(\\frac{n-2}{n}\\))，所以，當一個線性迴歸模型中有 \\(p\\) 個參數時： \\[ \\hat\\sigma^2 = \\frac{\\sum_{i=1}^n(y_i - \\hat\\alpha - \\hat\\beta_1 x_{i1} - \\hat\\beta_2 x_{i2}\\cdots)^2}{n - p} \\] 線性迴歸時殘差方差的檢驗統計量服從 \\(F\\) 分佈 (Section 28.2.6)。 "],
["section-44.html", "第 44 章 廣義線性迴歸入門 44.1 指數分佈家族 44.2 廣義線性迴歸模型之定義 44.3 注意 44.4 如何在 R 裏擬合 “GLM”", " 第 44 章 廣義線性迴歸入門 線性迴歸方法是十分強大的建模工具，可惜的是它只能適用與因變量爲連續型變量的情況。廣義線性迴歸模型 (或者叫一般化線性迴歸模型 generalised linear models, GLM) 是一大類將線性迴歸模型拓展到因變量可以使用二分類，計數，分組型變量的建模工具。 44.1 指數分佈家族 一個服從正態分佈的隨機變量 \\(Y\\) 的概率密度方程 (probability density function, PDF) 可以寫作 \\[ f(y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(y-\\mu)^2}{2\\sigma^2}} \\] 給 PDF 的左右兩邊同時取自然底數的對數，方程變形爲 \\[ \\begin{aligned} \\text{ln}\\{f(y)\\} &amp; = -\\frac{y^2}{2\\sigma^2} + \\frac{y\\cdot\\mu}{\\sigma^2} - \\frac{\\mu^2}{2\\sigma^2} -\\frac{1}{2}\\text{ln}(2\\pi\\sigma^2) \\\\ &amp; = \\frac{y\\cdot\\mu - \\frac{\\mu^2}{2}}{\\sigma^2} - [\\frac{y^2}{2\\sigma^2} + \\frac{1}{2}\\text{ln}(2\\pi\\sigma^2) ] \\end{aligned} \\tag{44.1} \\] 如果令 \\[ \\begin{aligned} \\theta &amp; = \\mu \\\\ \\psi &amp; = \\sigma^2 \\\\ b(\\theta) &amp; = \\frac{\\mu^2}{2} \\\\ c(y, \\theta) &amp; = \\frac{y^2}{2\\sigma^2} + \\frac{1}{2}\\text{ln}(2\\pi\\sigma^2) \\end{aligned} \\] 那麼上面的式子 (44.1) 可以被整理爲： \\[ \\begin{equation} \\text{ln}\\{f(y)\\} = \\frac{y\\cdot\\theta - b(\\theta)}{\\psi} - c(y, \\theta) \\end{equation} \\tag{44.2} \\] 此處有重要結論： 凡是分佈的概率密度方程的對數方程能夠轉換整理成 (44.2) 形式的分佈，都隸屬於指數分佈家族 (the Exponential Family of distributions)。 44.1.1 泊松分佈和二項分佈的指數分佈家族屬性 泊松分佈 Poisson Distribution \\[ \\begin{aligned} f(y) &amp; = \\text{Pr}(Y = y) = \\frac{\\mu^y e^{-\\mu}}{y!}, y = 0,1,2,\\cdots \\\\ \\text{ln}\\{ f(y) \\} &amp; = y\\cdot\\text{ln}(\\mu) - \\mu - \\text{ln}(y!) \\\\ \\text{Let } &amp;\\color{red}{\\boxed{\\theta = \\text{ln}(\\mu), \\psi = 1, b(\\theta) = \\mu, c(y,\\psi) = \\text{ln}(y!)}} \\\\ \\Rightarrow \\text{ln}\\{f(y)\\} &amp; = \\frac{y\\cdot\\theta - b(\\theta)}{\\psi} - c(y, \\theta) \\\\ \\end{aligned} \\] 所以，泊松分佈屬於指數分佈家族成員。 二項分佈 Binommial Distribution \\[ \\begin{aligned} f(y) &amp; = \\text{Pr}(Y = y) = \\binom{n}{y}\\pi^y(1-\\pi)^{n-y}, y = 0,1,2,\\cdots\\\\ \\text{ln}\\{ f(y) \\} &amp; = y\\cdot \\text{ln}(\\pi) + (n - y)\\text{ln}(1-\\pi) + \\text{ln}\\{\\binom{n}{y}\\} \\\\ &amp; = y\\cdot \\text{ln}(\\frac{\\pi}{1-\\pi}) + n\\text{ln}(1-\\pi) + \\text{ln}\\{\\binom{n}{y}\\} \\\\ \\text{Let } &amp;\\color{red}{\\boxed{\\theta = \\text{ln}(\\frac{\\pi}{1-\\pi}), \\psi = 1,}} \\\\ &amp;\\color{red}{\\boxed{b(\\theta) = -n\\text{ln}(1-\\pi), c(y, \\psi) = -\\text{ln}\\{\\binom{n}{y}\\}}}\\\\ \\Rightarrow \\text{ln}\\{f(y)\\} &amp; = \\frac{y\\cdot\\theta - b(\\theta)}{\\psi} - c(y, \\theta) \\\\ \\end{aligned} \\] 所以，二項分佈也屬於指數分佈家族成員。 指數分佈家族成員的數學表達式 (44.2) 中， \\(\\theta\\) 被叫做標準 (或者叫自然) 參數 (canonical or natural parameter)，相關的函數被叫做標準鏈接函數 (canonical link function)，如上面所列舉的例子中：泊松分佈時用的對數函數 \\(\\text{ln}(\\mu)\\)，二項分佈時用的邏輯函數 (logit function) \\(\\text{ln}(\\frac{\\pi}{1-\\pi})\\)，鏈接函數可能還有別的選擇，(例如，二項分佈數據的另一種標準鏈接函數是概率函数 (probit function \\(\\Phi^{-1}(P)\\)))，同時它對於條件推斷 conditional inference 至關重要，因爲它還提示我們應該用什麼樣的算法去估計我們苦苦尋找的人羣參數。 \\(\\phi\\) 被命名爲尺度參數 (scale or dispersion parameter)，泊松分佈和二項分佈的尺度參數是 \\(1\\)。但是正態分佈的尺度參數是方差 \\(\\sigma^2\\)，且常常是未知的，需要從樣本數據中估計。尺度參數是否需要從樣本中獲取其估計值，對於實際統計推斷或者假設檢驗的過程有重大影響。 廣義線性迴歸就是這個指數分佈家族數據共通的一種統計建模過程，所以，在這一“屋檐”下，它衍生出衆多種類的統計模型。 44.1.2 Exercise. Exponential distribution 證明指數分佈本身也屬於指數分佈家族，定義其標準鏈接函數和標準參數。 證明 \\[ \\begin{aligned} Y \\sim \\text{exp}(\\lambda) &amp; \\rightarrow f(y) = \\lambda \\text{exp}(-y\\lambda), y &gt; 0\\\\ \\Rightarrow \\text{ln}\\{ f(y) \\} &amp; = - y \\lambda + \\text{ln}(\\lambda) \\\\ \\text{Let } &amp; \\color{red}{\\theta = -\\lambda, b(\\theta) = - \\text{ln}(\\lambda), \\phi = 1, c(y, \\phi) = 0} \\\\ \\Rightarrow \\text{ln}\\{f(y)\\} &amp; = \\frac{y\\cdot\\theta - b(\\theta)}{\\phi} - c(y, \\theta) \\\\ \\text{Because } E(Y) &amp; = \\frac{1}{\\lambda}, \\text{ the canonical link is } g(\\lambda) = -\\frac{1}{\\lambda}\\\\ \\end{aligned} \\] 44.2 廣義線性迴歸模型之定義 一個四肢健全的廣義線性模型包括三個部分： 因變量分佈 (或者叫響應變量分佈，response distribution)：\\(Y_i, i = 1,\\cdots,n\\) 可以被認爲是互相獨立且服從指數家族分佈，設其期望值 (均值) \\(E(Y_i) = \\mu_i\\)； 線性預測方程 (linear predictor)：預測變量及其各自的參數以線性迴歸形式進入模型，其中第 \\(i\\) 個觀測值的線性預測值爲： \\[\\eta_i = \\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}\\] 鏈接函數 (link function)：鏈接函數連接的是線性預測方程 \\(\\eta_i\\) 和其期待值 (均值) 之間 \\(\\mu_i\\) 的關係。 \\[g(\\mu_i) = \\eta_i\\] 簡單線性迴歸模型本身當然也數據廣義線性迴歸模型： 因變量分佈是正態分佈； 線性預測值也是線性迴歸形式； 鏈接函數是它因變量本身 (the identity function)。 44.3 注意 廣義線性迴歸的線性預測方程部分的意義，需要澄清的是它指的是 參數 parameter 之間呈線性關係，預測變量本身可以有二次方，三次方，多次方，因爲這些多項式線性迴歸本身仍然是線性的如： \\[\\eta_i = \\alpha + \\beta_1 x_i + \\beta_2 x_i^2 + \\cdots + \\beta_p x_i^p\\] 然而，這樣的形式 \\[\\eta_i = \\alpha (1- e^{\\beta_1 x_{i1}})\\] 就不能說是一個線性預測方程。 除了有很少的特例。廣義線性迴歸擬合後的參數估計，推斷，模型評價和比較時使用的原理都一樣，不同的只有各自的分佈和鏈接函數。 通常選用的鏈接方程，要能夠使線性預測方程的取值範圍達到所有實數 \\(-\\infty,+\\infty\\)。 “模型的似然函數 the log likelihood of the model”，只是我們偷懶縮短了原文 “在給定數據的前提下，當所有參數均爲 \\(\\text{MLE}\\) 時模型的對數似然函數 (the log likelihood function of the model for the given data evaluated at the MLE’s of the parameters)”，就是對數似然函數的極大值的意思 (i.e. the maximum of the log likelihood function)。 從本節開始往後的章節中 “模型，model”，“廣義線性模型，generalized linear model”，和 “GLM” 將被視爲同義詞。 44.4 如何在 R 裏擬合 “GLM” 這裏討論用極大似然法擬合 “GLM” 模型的方法。前面一章節的複習也是在告訴我們，利用極大似然法簡單說就是找到模型參數，使得似然函數能夠取到極大值。對於線性迴歸來說， \\(\\text{MLE}\\) 可以用一個封閉式函數來計算；但是廣義線性迴歸模型則必須使用迭代法計算 (iterative methods)。 在 R 裏面擬合廣義線性模型的命令及其格式是： glm(response variable ~ explanatory variables to form linear predictor, family=name of distribution(link=link function), data=dataset) Tips: See help(glm) for other modeling options. See help(family) for other allowable link functions for each family. 下面的數據來自一個心理學臨牀實驗，比較的是和安慰劑組相比，注射嗎啡組，注射海洛因組對象的精神病檢測指數的前後變化。 Mental &lt;- read.table(&quot;backupfiles/MENTAL.DAT&quot;, header = FALSE, sep =&quot;&quot;, col.names = c(&quot;treatment&quot;, &quot;Before&quot;, &quot;After&quot;)) Mental$treatment[Mental$treatment == 1] &lt;- &quot;placebo&quot; Mental$treatment[Mental$treatment == 2] &lt;- &quot;morphine&quot; Mental$treatment[Mental$treatment == 3] &lt;- &quot;heroin&quot; Mental$treatment &lt;- factor(Mental$treatment, levels = c(&quot;placebo&quot;, &quot;morphine&quot;, &quot;heroin&quot;)) head(Mental) ## treatment Before After ## 1 placebo 0 7 ## 2 placebo 2 1 ## 3 placebo 14 10 ## 4 placebo 5 10 ## 5 placebo 5 6 ## 6 placebo 4 2 我們來比較一下簡單線性迴歸的代碼輸出結果和廣義線性迴歸代碼輸出結果是否一致： 用 lm 命令，擬合因變量爲注射後精神病檢測指數，預測變量爲治療方式和注射錢精神病檢測指數，及兩者的交互作用項： Model1 &lt;- lm(After ~ treatment*Before, data = Mental) summary(Model1) ## ## Call: ## lm(formula = After ~ treatment * Before, data = Mental) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.82808 -1.93513 -0.51606 1.41607 11.36012 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.978030 1.294069 1.5285 0.131158 ## treatmentmorphine -1.211742 1.750342 -0.6923 0.491185 ## treatmentheroin -1.461968 1.771855 -0.8251 0.412284 ## Before 0.593939 0.183468 3.2373 0.001889 ** ## treatmentmorphine:Before -0.089526 0.248346 -0.3605 0.719633 ## treatmentheroin:Before -0.312985 0.250383 -1.2500 0.215704 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.3329 on 66 degrees of freedom ## Multiple R-squared: 0.34418, Adjusted R-squared: 0.29449 ## F-statistic: 6.9274 on 5 and 66 DF, p-value: 0.000029744 同樣的模型也可以用 glm 命令擬合： Model2 &lt;- glm(After ~ treatment*Before, family = gaussian(link = &quot;identity&quot;), data = Mental) summary(Model2) ## ## Call: ## glm(formula = After ~ treatment * Before, family = gaussian(link = &quot;identity&quot;), ## data = Mental) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -7.82808 -1.93513 -0.51606 1.41607 11.36012 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.978030 1.294069 1.5285 0.131158 ## treatmentmorphine -1.211742 1.750342 -0.6923 0.491185 ## treatmentheroin -1.461968 1.771855 -0.8251 0.412284 ## Before 0.593939 0.183468 3.2373 0.001889 ** ## treatmentmorphine:Before -0.089526 0.248346 -0.3605 0.719633 ## treatmentheroin:Before -0.312985 0.250383 -1.2500 0.215704 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 11.107994) ## ## Null deviance: 1117.875 on 71 degrees of freedom ## Residual deviance: 733.128 on 66 degrees of freedom ## AIC: 385.414 ## ## Number of Fisher Scoring iterations: 2 可以看到，glm 命令的輸出結果略多，但是參數估計的部分是完全相同的。但是如果你用的是坑爹的 STATA，那裏面的 glm 命令中的統計檢驗量和 \\(p\\) 值用的則是正態分佈近似法。所以在 STATA 裏面簡單線性迴歸模型最好不要使用 glm 命令： glm After i.treatt##c.Before, family(gaussian) link(identity) Iteration 0: log likelihood = -185.70711 Generalized linear models No. of obs = 72 Optimization : ML Residual df = 66 Scale parameter = 11.10799 Deviance = 733.1276068 (1/df) Deviance = 11.10799 Pearson = 733.1276068 (1/df) Pearson = 11.10799 Variance function: V(u) = 1 [Gaussian] Link function : g(u) = u [Identity] AIC = 5.325197 Log likelihood = -185.707106 BIC = 450.8676 ------------------------------------------------------------------------------ | OIM After| Coef. Std. Err. z P&gt;|z| [95% Conf. Interval] -------------+---------------------------------------------------------------- treat | 2 | -1.211742 1.750342 -0.69 0.489 -4.642349 2.218865 3 | -1.461968 1.771855 -0.83 0.409 -4.934741 2.010805 | Before | .5939394 .1834682 3.24 0.001 .2343483 .9535305 | treat#Before| 2 | -.0895258 .2483459 -0.36 0.718 -.5762749 .3972233 3 | -.3129855 .2503829 -1.25 0.211 -.803727 .1777561 | _cons | 1.97803 1.294069 1.53 0.126 -.5582981 4.514359 ------------------------------------------------------------------------------ 回到 R 來， 當儲存了一個 Model2 向量在 R 裏之後，你可以用下面的各種命令獲取你想要的各種有用的信息。 confint(Model2) # 95% CI for the coefficients ## 2.5 % 97.5 % ## (Intercept) -0.55829809 4.51435869 ## treatmentmorphine -4.64234925 2.21886536 ## treatmentheroin -4.93474055 2.01080452 ## Before 0.23434829 0.95353050 ## treatmentmorphine:Before -0.57627487 0.39722332 ## treatmentheroin:Before -0.80372697 0.17775605 exp(coef(Model2)) # exponentiated coefficients ## (Intercept) treatmentmorphine treatmentheroin Before ## 7.22849102 0.29767829 0.23177968 1.81110905 ## treatmentmorphine:Before treatmentheroin:Before ## 0.91436470 0.73126055 exp(confint(Model2)) # 95% CI for exponentiated coefficients ## 2.5 % 97.5 % ## (Intercept) 0.5721820406 91.3189836 ## treatmentmorphine 0.0096350359 9.1968898 ## treatmentheroin 0.0071923267 7.4693242 ## Before 1.2640846824 2.5948546 ## treatmentmorphine:Before 0.5619879499 1.4876881 ## treatmentheroin:Before 0.4476574460 1.1945339 head(predict(Model2, type=&quot;response&quot;)) # predicted values ## 1 2 3 4 5 6 ## 1.9780303 3.1659091 10.2931818 4.9477273 4.9477273 4.3537879 head(residuals(Model2, type=&quot;deviance&quot;)) # residuals ## 1 2 3 4 5 6 ## 5.02196970 -2.16590909 -0.29318182 5.05227273 1.05227273 -2.35378788 44.4.1 margins 命令 一個在 STATA 裏面十分有用的用於預測的命令 margins，在 R 裏，下載了 margins 包以後就可以調用和 STATA 的 margins 類似的命令。 假如我們用擬合的模型預測當注射前精神病檢測值分別是 0，6，12 分時三組之間的注射後精神病檢測值差，可以這樣求： summary(margins(Model2, at = list(Before=c(0,6,12)))) ## factor Before AME SE z p lower upper ## Before 0 0.4598 0.1004 4.5797 0.0000 0.2630 0.6565 ## Before 6 0.4598 0.1004 4.5797 0.0000 0.2630 0.6565 ## Before 12 0.4598 0.1004 4.5798 0.0000 0.2630 0.6565 ## treatmentheroin 0 -1.4620 1.7719 -0.8251 0.4093 -4.9347 2.0108 ## treatmentheroin 6 -3.3399 0.9624 -3.4705 0.0005 -5.2261 -1.4537 ## treatmentheroin 12 -5.2178 1.7963 -2.9048 0.0037 -8.7384 -1.6972 ## treatmentmorphine 0 -1.2117 1.7503 -0.6923 0.4888 -4.6423 2.2189 ## treatmentmorphine 6 -1.7489 0.9630 -1.8160 0.0694 -3.6364 0.1386 ## treatmentmorphine 12 -2.2861 1.7977 -1.2716 0.2035 -5.8095 1.2374 對比 STATA 裏的結果： margins, dydx(trt) at(pre = (0 6 12)) Conditional marginal effects Number of obs = 72 Model VCE : OIM Expression : Predicted mean post, predict() dy/dx w.r.t. : 2.trt 3.trt 1._at : pre = 0 2._at : pre = 6 3._at : pre = 12 ------------------------------------------------------------------------------ | Delta-method | dy/dx Std. Err. z P&gt;|z| [95% Conf. Interval] -------------+---------------------------------------------------------------- 1.trt | (base outcome) -------------+---------------------------------------------------------------- 2.trt | _at | 1 | -1.211742 1.750342 -0.69 0.489 -4.642349 2.218865 2 | -1.748897 .963025 -1.82 0.069 -3.636391 .1385977 3 | -2.286051 1.797717 -1.27 0.204 -5.809513 1.23741 -------------+---------------------------------------------------------------- 3.trt | _at | 1 | -1.461968 1.771855 -0.83 0.409 -4.934741 2.010805 2 | -3.339881 .9623512 -3.47 0.001 -5.226054 -1.453707 3 | -5.217794 1.796264 -2.90 0.004 -8.738406 -1.697181 ------------------------------------------------------------------------------ Note: dy/dx for factor levels is the discrete change from the base level. 44.4.2 ggplot2::geom_smooth(method = &quot;loess&quot;) 命令 類似 STATA 作散點圖時的 lowess 命令，在 R 裏，你可以用 ggplot2 包裏自帶的 geom_smooth(method = &quot;loess&quot;) 選項命令，給散點圖添加平滑曲線。把觀測數據中變量之間的關係視覺化，用於輔助判斷一個模型是否可以被擬合爲線性關係。全稱是 “locally weighted scatterplot smoothing”，縮寫成 “lowess/loess”。LOWESS 的原理簡略說是，通過把預測變量分成幾個部分，分別在各個小區間內擬合迴歸各自的迴歸曲線，如此便可以將每個觀測值都以各自不同的加權值放入整個模型中，然而正如我們在簡單線性模型中提到過的，這樣的曲線更加擬合觀測數據，而不能說明觀測值來自的人羣中，兩個變量之間的關係。此方法的靈活性在於，你可以選擇平滑的程度，該平滑程度用 bandwith(STATA) 或者 span(R) 表示，取值範圍是 \\(0 \\sim 1\\) 之間的任意值，越靠近 \\(1\\)，Lowess 曲線越接近簡單線性直線，越靠近 \\(0\\)，那麼每個觀測點本身的權重越大，擬合的 Lowess 曲線越接近觀測數據本身。下圖 44.1 提示，選用的平滑程度 \\(= 0.8\\) 時，精神病測量分數在 (安慰劑組中) 實驗前後的關係接近線性關係。當我們降低平滑程度，Lowess 曲線接近觀測數據本身，其實是太接近觀測數據本身，反而無法提供太多的信息。 ggplot(Mental, aes(Before, After)) + geom_point() + geom_smooth(method = &quot;loess&quot;, span = 0.8, se = FALSE) + facet_grid(treatment ~ .) + theme_bw() 圖 44.1: Lowess smoother, with bandwith/span set to 0.8, for the mental data ggplot(Mental, aes(Before, After)) + geom_point() + geom_smooth(method = &quot;loess&quot;, span = 0.4, se = FALSE) + facet_grid(treatment ~ .) + theme_bw() 圖 44.2: Lowess smoother, with bandwith/span set to 0.4, for the mental data "],
["-logistic-regression-model.html", "第 45 章 二項分佈數據的廣義線性迴歸模型 logistic regression model 45.1 分組/個人 (grouped / individual) 的二項分佈數據 45.2 二項分佈數據的廣義線性迴歸模型 45.3 注 45.4 邏輯迴歸模型迴歸係數的實際意義 45.5 邏輯迴歸實際案例", " 第 45 章 二項分佈數據的廣義線性迴歸模型 logistic regression model 二項分佈數據在醫學研究中很常見，例子有千千萬，下面這些只是作爲拋磚引玉： 心臟搭橋手術和血管成形術兩組病人比較療效時，結果變量可以是：死亡 (是/否)；心肌梗死發作 (是/否)； 機械心臟瓣膜手術結果：成功/失敗； 用小鼠作不同劑量二硫化碳暴露下的毒理學實驗，結果變量是：小鼠死亡 (是/否)； 隊列研究中追蹤對象中出現心肌梗死病例，結果變量是：心肌梗死發作 (是/否)。 45.1 分組/個人 (grouped / individual) 的二項分佈數據 下面的數據，來自某個毒理學實驗，不同劑量的二硫化碳暴露下小鼠的死亡數和總數的數據： ## dose n_deaths n_subjects ## 1 49.06 6 59 ## 2 52.99 13 60 ## 3 56.91 18 62 ## 4 60.84 28 56 ## 5 64.76 52 63 ## 6 68.69 53 59 ## 7 72.61 60 62 ## 8 76.54 59 60 很容易理解這是一個典型的分組二項分佈數據 (grouped binary data)。每組不同的劑量，第二列，第三列分別是死亡數和實驗總數。另外一種個人二項分佈數據 (individual binary data) 的形式是這樣的： ## dose death ## 1 49.06 1 ## 2 49.06 1 ## 3 49.06 1 ## 4 49.06 1 ## 5 49.06 1 ## 6 49.06 1 ## 7 49.06 0 ## 8 49.06 0 ## 9 49.06 0 ## 10 49.06 0 ## 11 . . ## 12 . . ## 13 . . 個人二項分佈數據其實就是把每個觀察對象的事件發生與否的信息都呈現出來。通常個人二項分佈數據又被稱爲伯努利數據，分組型的二項分佈數據被稱爲二項數據。兩種表達形式，但是存儲的是一樣的數據。 45.2 二項分佈數據的廣義線性迴歸模型 而所有的 GLM 一樣，二項分佈的 GLM 包括三個部分： 因變量的分佈 Distribution：因變量應相互獨立，且服從二項分佈 \\[\\begin{aligned} Y_i &amp;\\sim \\text{Bin}(n_i, \\pi_i), i = 1, \\cdots, n \\\\ E(Y_i) &amp;= \\mu_i = n_i\\pi_i\\end{aligned}\\] 線性預測方程 Linear predictor：第 \\(i\\) 名觀測對象的預測變量的線性迴歸模型 \\[\\eta_i = \\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}\\] 鏈接方程 Link function：鏈接方程連接的是 \\(\\mu_i = n\\pi_i\\) 和線性預測方程。一個二項分佈因變量數據，可以有許多種鏈接方程： \\(\\mathbf{logit}:\\) \\[\\text{logit}(\\pi) = \\text{ln}(\\frac{\\pi}{1-\\pi})\\] \\(\\mathbf{probit}:\\) \\[\\text{probit}(\\pi) = \\Phi^{-1}(\\pi)\\] \\(\\mathbf{complementary\\; log-log}:\\) \\[\\text{cloglog}(\\pi) = \\text{ln}\\{ - \\text{ln}(1-\\pi) \\}\\] \\(\\mathbf{log:}\\) \\[\\text{log}(\\pi) = \\text{ln}(\\pi)\\] 45.3 注 概率鏈接方程 \\(\\text{probit}\\)，\\(\\Phi\\) 被定義爲標準正態分佈的累積概率方程 (Section 7.3)： \\[\\Phi(z) = \\text{Pr}(Z \\leqslant z), \\text{ for } Z\\sim N(0,1)\\] 二項分佈數據的標準參數 (canonical parameter) \\(\\theta_i\\) 的標準鏈接方程是 \\(\\theta_i = \\text{logit}(\\pi_i)\\)。 \\(\\text{logit, probit, complementary log-log}\\) 三種鏈接方程都能達到把閾值僅限於 \\(0 \\sim 1\\) 之間的因變量概率映射到線性預測方程的全實數閾值 \\((-\\infty,+\\infty)\\) 的目的。但是最後一個 \\(\\text{log}\\) 鏈接方程只能映射全部的非零負實數 \\((-\\infty,0)\\)。 \\(\\text{logit, probit}\\) 鏈接方程都是以 \\(\\pi= 0.5\\) 爲對稱軸左右對稱的。但是 \\(\\text{cloglog}\\) 則沒有對稱的性質。 鏈接方程 \\(\\text{log}\\) 具有可以直接被解讀爲對數危險度比 (log Risk Ratio) 的優點，所以也常常在應用中見到。對數鏈接方程還有其他的優點 (非塌陷性 non-collapsibility)，但是它的最大缺點是，有時候利用這個鏈接方程的模型無法收斂 (converge)。 \\(\\text{logit}\\) 鏈接方程是我們最常見的，也最直觀易於理解。利用這個鏈接方程擬合的模型的迴歸係數能夠直接被理解爲對數比值比 (log Odds Ratio)。 如果是個人數據 (individual data)，那麼 \\(n_i = 1\\)，\\(i\\) 是每一個觀測對象的編碼。那麼 \\(Y_i = 0\\text{ or }1\\)，代表事件發生或沒發生/成功或者失敗。如果是分組數據 (grouped data)，\\(i\\) 是每個組的編號，\\(n_i\\) 指的是第 \\(i\\) 組中觀測對象的人數，\\(Y_i\\) 是第 \\(i\\) 組的 \\(n\\) 名對象中事件發生的次數/成功的次數。 45.3.1 Exercise. Link functions. 推導出鏈接參數分別是 \\(\\text{log}\\) \\(\\text{logit}\\) \\(\\text{complementary log-log}\\) 時，用參數 \\(\\alpha, \\beta_1, \\cdots, \\beta_p\\) 表達的參數 \\(\\pi_i=?, E(Y_i)=\\mu_i=?\\) 解 \\(\\text{log}\\) \\[ \\begin{aligned} \\text{ln}(\\pi_i) &amp; = \\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip} \\\\ \\Rightarrow \\pi_i &amp; = e^{\\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip}} \\\\ \\mu_i &amp; = n_i\\pi_i = n_i e^{\\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip}} \\end{aligned} \\] \\(\\text{logit}\\) \\[ \\begin{aligned} \\text{logit}(\\pi_i) &amp; = \\text{ln}(\\frac{\\pi_i}{1-\\pi_i}) \\\\ &amp; = \\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip} \\\\ \\Rightarrow \\pi_i &amp; = \\frac{e^{\\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip}}}{1+e^{\\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip}}} \\\\ \\mu_i &amp; = \\frac{n_i e^{\\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip}}}{1+e^{\\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip}}} \\end{aligned} \\] \\(\\text{complementary log-log}\\) \\[ \\begin{aligned} \\text{cloglog}(\\pi_i) &amp; = \\text{ln}\\{ - \\text{ln}(1-\\pi) \\} \\\\ &amp; = \\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip} \\\\ \\Rightarrow \\pi_i &amp; = 1 - e^{-e^{\\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip}}} \\\\ \\mu_i &amp; = n_i\\pi_i = n_i(1-e^{-e^{\\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip}}}) \\end{aligned} \\] 45.4 邏輯迴歸模型迴歸係數的實際意義 邏輯迴歸 (logistic regression) 的模型可以寫成是 \\[ \\text{logist}(\\pi_i) = \\text{ln}(\\frac{\\pi_i}{1-\\pi_i}) = \\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip} \\] 假如觀察對象 \\(j\\) 和 \\(i\\) 兩人中，其餘的預測變量都相同，二者之間有且僅有最後一個預測變量相差一個單位： \\[ \\begin{aligned} \\text{logit}(\\pi_j) &amp; = \\text{ln}(\\frac{\\pi_j}{1-\\pi_j}) = \\alpha + \\beta_1 x_{j1} + \\beta_2 x_{j2} + \\cdots + \\beta_p x_{jp} \\\\ \\text{logit}(\\pi_i) &amp; = \\text{ln}(\\frac{\\pi_i}{1-\\pi_i}) = \\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip} \\\\ \\text{Because they are} &amp; \\text{ in the same model share the same parameters, and } \\\\ x_{jp} &amp; = x_{ip} + 1\\\\ \\Rightarrow \\text{logit}(\\pi_j) - \\text{logit}(\\pi_i) &amp; = \\beta_p (x_{jp} + 1 - x_{jp}) = \\beta_p \\\\ \\Rightarrow \\beta_p &amp; = \\text{ln}(\\frac{\\pi_j}{1-\\pi_j}) - \\text{ln}(\\frac{\\pi_i}{1-\\pi_i}) \\\\ &amp; = \\text{ln}(\\frac{\\frac{\\pi_j}{1-\\pi_j}}{\\frac{\\pi_i}{1-\\pi_i}}) \\\\ &amp; = \\text{ln}(\\text{Odds Ratio}) \\end{aligned} \\] 所以迴歸係數 \\(\\beta_p\\) 可以被理解爲是 \\(j\\) 與 \\(i\\) 相比較時的對數比值比 log Odds Ratio。我們只要對迴歸係數求反函數，即可求得比值比。 45.5 邏輯迴歸實際案例 一組數據如下： 其中，牲畜來自兩大羣 (group)；每羣有五個組的牲畜被飼養五種不同濃度的飼料 (dfactor)；每組牲畜我們記錄了牲畜的總數 (cattle) 以及感染了瘋牛病的牲畜數量 (infect)： ## group dfactor cattle infect ## 1 1 1 11 8 ## 2 1 2 10 7 ## 3 1 3 12 5 ## 4 1 4 11 3 ## 5 1 5 12 2 ## 6 2 1 10 10 ## 7 2 2 10 9 ## 8 2 3 12 8 ## 9 2 4 11 6 ## 10 2 5 10 4 45.5.1 分析目的 通過對本數據的分析，回答如下的問題： 考慮了牲畜來自兩羣以後，不同的飼料 (dfactor) 是否和感染瘋牛病有關？ 兩羣牲畜之間，飼料和瘋牛病感染之間的關係是否不同？ 45.5.2 模型 1 飼料 + 羣 \\[ \\begin{aligned} \\text{Assume } Y_i &amp; \\sim \\text{Bin} (n_i, \\pi_i) \\\\ \\text{logit}(\\pi_i) &amp; = \\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} \\end{aligned} \\] Model1 &lt;- glm(cbind(infect, cattle - infect) ~ factor(group) + dfactor, family = binomial(link = logit), data = Cattle) summary(Model1) ## ## Call: ## glm(formula = cbind(infect, cattle - infect) ~ factor(group) + ## dfactor, family = binomial(link = logit), data = Cattle) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.60847 -0.17831 0.10110 0.31150 1.16876 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 2.13104 0.61130 3.4861 0.0004902 *** ## factor(group)2 1.30590 0.46540 2.8060 0.0050163 ** ## dfactor -0.78744 0.18135 -4.3422 0.00001411 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 33.52556 on 9 degrees of freedom ## Residual deviance: 2.45082 on 7 degrees of freedom ## AIC: 32.2537 ## ## Number of Fisher Scoring iterations: 4 epiDisplay::logistic.display(Model1) ## ## OR lower95ci upper95ci Pr(&gt;|Z|) ## factor(group)2 3.69102114 1.48251011 9.18957451 0.005016342395 ## dfactor 0.45500721 0.31889988 0.64920551 0.000014109282 於是，我們可以寫下這個邏輯迴歸的數學模型： \\[ \\begin{aligned} \\text{logit}(\\hat\\pi_i) &amp; = \\text{ln}(\\frac{\\hat\\pi_i}{1-\\hat\\pi_i}) = \\hat\\alpha + \\hat\\beta_1 x_{i1} + \\hat\\beta_2 x_{i2} \\\\ &amp; = 2.1310 - 0.7874 \\times \\text{dfactor} + 1.3059 \\times \\text{group} \\end{aligned} \\] 解讀這些參數估計的意義 截距 \\(\\hat\\alpha = 2.1310\\) 的含義是，當 \\(x_{1}, x_{2}\\) 都等於零，i.e. 飼料濃度 0，在第一羣的那些牲畜感染瘋牛病的對數比值 (log-odds)； 斜率 \\(\\hat\\beta_1 = -0.7874\\) 的含義是，當牲畜羣不變時，飼料濃度每增加一個單位，牲畜感染瘋牛病的對數比值的估計變化量 (estimated increase in log odds of infection)； 迴歸係數 \\(\\hat\\beta_2 = 1.3059\\) 的含義是，當飼料濃度不變時，兩羣牲畜之間感染瘋牛病的對數比值比 (log-Odds Ratio)，所以第二羣牲畜比第一羣牲畜感染瘋牛病的比值比的估計量，以及 \\(95\\%\\text{CI}\\) 的計算方法就是： \\[\\begin{aligned} \\text{exp}(\\hat\\beta_2) &amp; = \\text{exp}(1.3059) = 3.69,\\\\ \\text{ with 95% CI: } &amp; \\text{exp}(\\hat\\beta_2 \\pm 1.96\\times \\text{Std.Error}_{\\hat\\beta_2}) \\\\ &amp; = (1.48, 9.19) \\end{aligned}\\] 45.5.3 模型 2 增加交互作用項 飼料 \\(\\times\\) 羣 飼料濃度與瘋牛病感染之間的關係，是否因爲牲畜所在的 “羣” 不同而發生改變？ 定義增加了飼料和羣交互作用項的邏輯迴歸模型： \\[ \\text{logit}(\\pi_i) = \\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 x_{i1}\\times x_{i2} \\] Model2 &lt;- glm(cbind(infect, cattle - infect) ~ factor(group) + dfactor + factor(group)*dfactor, family = binomial(link = logit), data = Cattle) summary(Model2) ## ## Call: ## glm(formula = cbind(infect, cattle - infect) ~ factor(group) + ## dfactor + factor(group) * dfactor, family = binomial(link = logit), ## data = Cattle) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.71914 -0.16508 -0.02111 0.34451 1.00127 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.89028 0.73584 2.5689 0.010203 * ## factor(group)2 1.98867 1.34471 1.4789 0.139172 ## dfactor -0.70508 0.22955 -3.0716 0.002129 ** ## factor(group)2:dfactor -0.20583 0.37553 -0.5481 0.583619 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 33.52556 on 9 degrees of freedom ## Residual deviance: 2.14476 on 6 degrees of freedom ## AIC: 33.9477 ## ## Number of Fisher Scoring iterations: 4 epiDisplay::logistic.display(Model2) ## ## OR lower95ci upper95ci Pr(&gt;|Z|) ## factor(group)2 7.30580425 0.52365757 101.92686809 0.1391720038 ## dfactor 0.49406759 0.31506152 0.77477816 0.0021289774 ## factor(group)2:dfactor 0.81396890 0.38989883 1.69927508 0.5836187644 從輸出的報告來看，增加了交互作用項以後，在第一羣牲畜中，飼料濃度每增加一個單位，感染瘋牛病的比值比 (OR) 是 \\[ \\text{exp}(-0.7051) = 0.49 \\] 在第二羣牲畜中，飼料濃度每增加一個單位，感染瘋牛病的比值比 (OR) 變成了 \\[ \\text{exp}(-0.7051 - 0.2058) = 0.40 \\] 通過對 \\(\\hat\\beta_3 = 0\\) 的假設檢驗，就可以推斷飼料濃度和感染瘋牛病之間的關係是否因爲不同牲畜 “羣” 而不同。所以上面的報告中也已經有了交互作用項的檢驗結果 \\(p = 0.584\\)，所以，此處可以下的結論是：沒有足夠的證據證明交互作用存在。 "],
["section-46.html", "第 46 章 模型比較和擬合優度 46.1 嵌套式模型的比較 nested models 46.2 嵌套式模型比較實例 46.3 飽和模型，模型的偏差，擬合優度 46.4 個人數據擬合模型的優度檢驗", " 第 46 章 模型比較和擬合優度 我們用數據擬合廣義線性模型有許多不同的目的和意義： 估計某些因素的暴露和因變量之間的相關程度，同時調整其餘的混雜因素； 確定能夠強有力的預測因變量變化的因子； 用於預測未來的事件或者病人的預後等等。 但是一般情況下，我們拿到數據以後不可能立刻就能擬合一個完美無缺的模型。我們常常要擬合兩三個甚至許多個模型，探索模型和數據是否擬合，就成爲了比較哪個模型更優的硬指標。本章的目的是介紹 GLM 嵌套式模型之間的兩兩比較方法，其中一個模型的預測變量是另一個模型的預測變量的子集。 46.1 嵌套式模型的比較 nested models 假如我們用相同的數據擬合兩個 GLM，\\(\\text{Model 1, Model 2}\\)。其中，當限制 \\(\\text{Model 2}\\) 中部分參數爲零之後會變成 \\(\\text{Model 1}\\)時， 我們說 \\(\\text{Model 1}\\) 是 \\(\\text{Model 2}\\) 的嵌套模型。 例1：嵌套式模型 I 模型 1 的線性預測方程爲 \\[\\eta_i = \\alpha + \\beta_1 x_{i1}\\] 模型 2 和模型 1 的因變量相同 (分佈相同)，使用相同的鏈接方程 (link function) 和尺度參數 (scale parameter, \\(\\phi\\))，但是它的線性預測方程爲 \\[\\eta_i = \\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i1} + \\beta_3 x_{i3}\\] 此時我們說模型 1 是模型 2 的嵌套模型，因爲令 \\(\\beta_2 = \\beta_3 = 0\\) 時，模型 2 就變成了 模型 1。 例2：嵌套式模型 II 模型 1 的線性預測方程爲 (此處默認 \\(x_{i1}\\) 是連續型預測變量) \\[\\eta_i = \\alpha + \\beta_1 x_{i1}\\] 模型 2 的線性預測方程如果是 \\[\\eta_i = \\alpha + \\beta_1 x_{i1} + \\beta_2 x^2_{i1}\\] 此時我們依然認爲 模型 1 是模型 2 的嵌套模型， 因爲令 \\(\\beta_2 = 0\\) 時，模型 2 就變成了 模型 1。 關於嵌套式模型，更加一般性的定義是這樣的：標記模型 2 的參數向量是 \\(\\mathbf{(\\psi, \\lambda)}\\)，其中，當我們限制了參數向量的一部分例如 \\(\\mathbf{\\psi = 0}\\)，模型 2 就變成了 模型 1 的話，模型 1 就是嵌套於 模型 2 的。所以比較嵌套模型之間的擬合度，我們可以比較較爲複雜的 模型 2 相較 模型 1 多出來的複雜的預測變量參數部分 \\(\\mathbf{\\psi}\\) 是否是必要的。也就是說，比較嵌套模型哪個更優的情況下，零假設是 \\(\\mathbf{\\psi = 0}\\)。 這是典型的多變量的模型比較，需要用到子集似然比檢驗 19，log-likelihood ratio test： \\[ \\begin{aligned} -2pllr(\\psi = 0) &amp; = -2\\{ \\ell_p(\\psi=0) - \\ell_p(\\hat\\psi) \\} \\stackrel{\\cdot}{\\sim} \\chi^2_{df}\\\\ \\text{Where } \\hat\\psi &amp; \\text{ denotes the MLE of } \\psi \\text{ in Model 2} \\\\ \\text{With } df &amp; = \\text{ the dimension of } \\mathbf{\\psi} \\end{aligned} \\] \\(\\ell_p(\\psi=0)\\)，其實是 模型 1 的極大對數似然，記爲 \\(\\ell_1\\)。\\(\\ell_p(\\hat\\psi)\\) 其實是 模型 2 的極大對數似然，記爲 \\(\\ell_2\\)。所以這個似然比檢驗統計量就變成了： \\[ -2pllr(\\psi = 0) = -2(\\ell_1-\\ell_2) \\] 這個統計量在零假設的條件下服從自由度爲兩個模型參數數量之差的卡方分佈。如果 \\(p\\) 值小於提前定義好的顯著性水平，將會提示有足夠證據證明 模型 2 比 模型 1 更好地擬合數據。 46.2 嵌套式模型比較實例 回到之前用過的瘋牛病和牲畜羣的數據 45.5。我們當時成功擬合了兩個 GLM 模型，模型 1 的預測變量只有 “飼料”，“羣”；模型 2 的預測變量在模型 1 的基礎上增加二者的交互作用項。賓且我們當時發現交互作用項部分並無實際統計學意義 \\(p = 0.584\\)。現在用對數似然比檢驗來進行類似的假設檢驗。 先用 logLik(Model) 的方式提取兩個模型各自的對數似然，然後計算對數似然比，再去和自由度爲 1 (因爲兩個模型只差了 1 個預測變量) 的卡方分佈做比較： Model1 &lt;- glm(cbind(infect, cattle - infect) ~ factor(group) + dfactor, family = binomial(link = logit), data = Cattle) Model2 &lt;- glm(cbind(infect, cattle - infect) ~ factor(group) + dfactor + factor(group)*dfactor, family = binomial(link = logit), data = Cattle) logLik(Model1) ## &#39;log Lik.&#39; -13.12687 (df=3) logLik(Model2) ## &#39;log Lik.&#39; -12.973836 (df=4) LLR &lt;- -2*(logLik(Model1) - logLik(Model2)) 1-pchisq(as.numeric(LLR), df=1) # p value for the LLR test ## [1] 0.58010367 再和 lmtest::lrtest 的輸出結果作比較。 lmtest::lrtest(Model1, Model2) ## Likelihood ratio test ## ## Model 1: cbind(infect, cattle - infect) ~ factor(group) + dfactor ## Model 2: cbind(infect, cattle - infect) ~ factor(group) + dfactor + factor(group) * ## dfactor ## #Df LogLik Df Chisq Pr(&gt;Chisq) ## 1 3 -13.1269 ## 2 4 -12.9738 1 0.30607 0.5801 結果跟我們手計算的結果完全吻合。AWESOME !!! 46.3 飽和模型，模型的偏差，擬合優度 在簡單線性迴歸中，殘差平方和提供了模型擬合數據好壞的指標 – 決定係數 \\(R^2\\) (Section 28.2.3)，並且在 偏 F 檢驗 (Section 30.3.4) 中得到模型比較的應用。 廣義線性迴歸模型中事情雖然沒有這麼簡單，但是思想可以借鑑。先介紹飽和模型 (saturated model) 的概念，再介紹其用於模型偏差 (deviance) 比較的方法。前文中介紹過的嵌套模型之間的對數似然比檢驗，也是測量兩個模型之間偏差大小的方法。 46.3.1 飽和模型 saturated model 飽和模型 saturated model，是指一個模型中所有可能放入的參數都被放進去的時候，模型達到飽和，自由度爲零。其實就是模型中參數的數量和觀測值個數相等的情況。飽和模型的情況下，所有的擬合值和對應的觀測值相等。所以，對於給定的數據庫，飽和模型提供了所有模型中最 “完美” 的擬合值，因爲擬合值和觀測值完全一致，所以飽和模型的對數似然，比其他所有你建立的模型的對數似然都要大。但是多數情況下，飽和模型並不是合理的模型，不能用來預測也無法拿來解釋數據，因爲它本身就是數據。 46.3.2 模型偏差 deviance 令 \\(L_c\\) 是目前擬合模型的對數似然，\\(L_s\\) 是數據的飽和模型的對數似然，所以兩個模型的對數似然比是 \\(\\frac{L_c}{L_s}\\)。那麼尺度化的模型偏差 (scaled deviance) \\(S\\) 被定義爲： \\[ S=-2\\text{ln}(\\frac{L_c}{L_s}) = -2(\\ell_c - \\ell_s) \\] 值得注意的是，非尺度化偏差 (unscaled deviance) 被定義爲 \\(\\phi S\\)，其中的 \\(\\phi\\) 是尺度參數，由於泊松分佈和二項分佈的尺度參數都等於 1 (\\(\\phi = 1\\))，所以尺度化偏差和非尺度化偏差才會在數值上相等。 這裏定義的模型偏差大小，可以反應一個模型擬合數據的程度，偏差越大，該模型對數據的擬合越差。“Deviance can be interpreted as Badness of fit”. 但是，模型偏差只適用於分組型二項分佈數據。當數據是個人的二分類數據時 (inidividual binary data)，模型的偏差值變得不再適用，無法用來比較模型對數據的擬合程度。 這是因爲當你的觀測值 (個人數據) 有很多時，擬合飽和模型所需要的參數個數會趨向於無窮大，這違背了子集對數似然比檢驗的條件。 46.4 個人數據擬合模型的優度檢驗 在 R 裏面，進行邏輯迴歸模型的擬合優度檢驗的自定義方程如下，參考網站： hosmer &lt;- function(y, fv, groups=10, table=TRUE, type=2) { # A simple implementation of the Hosmer-Lemeshow test q &lt;- quantile(fv, seq(0,1,1/groups), type=type) fv.g &lt;- cut(fv, breaks=q, include.lowest=TRUE) obs &lt;- xtabs( ~ fv.g + y) fit &lt;- cbind( e.0 = tapply(1-fv, fv.g, sum), e.1 = tapply(fv, fv.g, sum)) if(table) print(cbind(obs,fit)) chi2 &lt;- sum((obs-fit)^2/fit) pval &lt;- pchisq(chi2, groups-2, lower.tail=FALSE) data.frame(test=&quot;Hosmer-Lemeshow&quot;,groups=groups,chi.sq=chi2,pvalue=pval) } lbw &lt;- read_dta(&quot;http://www.stata-press.com/data/r12/lbw.dta&quot;) lbw$race &lt;- factor(lbw$race) lbw$smoke &lt;- factor(lbw$smoke) lbw$ht &lt;- factor(lbw$ht) Modelgof &lt;- glm(low ~ age + lwt + race + smoke + ptl + ht + ui, data = lbw, family = binomial(link = logit)) hosmer(lbw$low, fitted(Modelgof)) ## 0 1 e.0 e.1 ## [0.0273,0.0827] 19 0 17.8222227 1.1777773 ## (0.0827,0.128] 17 2 16.9739017 2.0260983 ## (0.128,0.201] 13 6 15.8285445 3.1714555 ## (0.201,0.243] 18 1 14.6957098 4.3042902 ## (0.243,0.279] 12 7 14.1062047 4.8937953 ## (0.279,0.314] 12 7 13.3601242 5.6398758 ## (0.314,0.387] 13 6 12.4628053 6.5371947 ## (0.387,0.483] 12 7 10.8241660 8.1758340 ## (0.483,0.594] 9 10 8.6901416 10.3098584 ## (0.594,0.839] 5 13 5.2361795 12.7638205 ## test groups chi.sq pvalue ## 1 Hosmer-Lemeshow 10 9.6506834 0.29040407 hosmer(lbw$low, fitted(Modelgof), group=5) ## 0 1 e.0 e.1 ## [0.0273,0.128] 36 2 34.796124 3.2038756 ## (0.128,0.243] 31 7 30.524254 7.4757458 ## (0.243,0.314] 24 14 27.466329 10.5336711 ## (0.314,0.483] 25 13 23.286971 14.7130287 ## (0.483,0.839] 14 23 13.926321 23.0736789 ## test groups chi.sq pvalue ## 1 Hosmer-Lemeshow 5 2.435921 0.48698297 "],
["-poisson-regression.html", "第 47 章 計數型因變量 Poisson regression 47.1 泊松 GLM 47.2 泊松迴歸實例 47.3 過度離散 overdispersion", " 第 47 章 計數型因變量 Poisson regression 計數型變量在醫學研究中也十分常見，下面是一些例子： 某個呼吸科診所的患者中，每個人在過去一個月中哮喘發作的次數； 癲癇患者在過去一年中癲癇發作次數； 接受腦部 CT 掃描的患者中，每個人被診斷出顱內腫瘤個數。 47.1 泊松 GLM 一個計數型的隨機變量，只能取大於等於零的正整數，\\(0,1,\\cdots\\)。泊松模型可以用於計數型數據的迴歸模型的構建： \\[ \\begin{aligned} Y &amp;\\sim \\text{Po}(\\mu) \\\\ \\text{P} (Y = y) &amp; = \\frac{\\mu^y e^{-\\mu}}{y!} \\end{aligned} \\] 所以，一個泊松迴歸，默認的前提是因變量 \\(Y\\) 服從一個以預測變量 \\(x_1, \\cdots, x_p\\) 爲條件的泊松分佈。其標準鏈接方程是 \\(\\theta=\\text{log}(\\mu)\\)。 \\[ \\begin{aligned} Y_i &amp; \\sim \\text{Po}(\\mu_i) \\\\ \\text{log}(\\mu_i) &amp; = \\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip} \\end{aligned} \\] 觀測對象 1，用模型中全部的預測變量 \\(\\mathbf{x_1}=(x_{11},\\cdots,x_{1p})\\) 計算獲得的擬合值，和另一個觀測對象 0 的擬合值之比爲： \\[ \\begin{aligned} &amp; \\frac{\\text{exp}(\\alpha + \\beta_1 x_{11} + \\cdots + \\beta_p x_{1p})}{\\text{exp}(\\alpha + \\beta_1 x_{01} + \\cdots + \\beta_p x_{0p})} \\\\ = &amp; exp(\\beta_1(x_{11}-x_{01}) + \\cdots + \\beta_p(x_{1p} - x_{0p})) \\end{aligned} \\] 其中， 線性預測方程 linear predictor 中的截距 \\(\\alpha\\) 的含義是，當所有的預測變量均等於零 \\(\\mathbf{x_1} = 0\\) 時，因變量 \\(Y\\) 的均值之對數。 \\(\\beta_1\\) 的含義是，其餘預測變量保持不變時，預測變量 \\(x_1\\) 每增加一個單位時，因變量變化量的對數。 迴歸係數的指數 (自然底數) 大小，可以被理解爲是率比 (rate ratio) (詳見下一章率的 GLM)。 47.2 泊松迴歸實例 下列數據來自 UCLA 的統計學網站。數據內容是某高中全部學生，獲獎的次數。預測變量包括，1) 獲獎種類 “一般 General”，“學術類 Academic”，“技能類 Vocational”；和所有學生期末數學考試分數。 p &lt;- read.csv(&quot;https://stats.idre.ucla.edu/stat/data/poisson_sim.csv&quot;) p &lt;- within(p, { prog &lt;- factor(prog, levels=1:3, labels=c(&quot;General&quot;, &quot;Academic&quot;, &quot;Vocational&quot;)) id &lt;- factor(id) }) summary(p) ## id num_awards prog math ## 1 : 1 Min. :0.00 General : 45 Min. :33.000 ## 2 : 1 1st Qu.:0.00 Academic :105 1st Qu.:45.000 ## 3 : 1 Median :0.00 Vocational: 50 Median :52.000 ## 4 : 1 Mean :0.63 Mean :52.645 ## 5 : 1 3rd Qu.:1.00 3rd Qu.:59.000 ## 6 : 1 Max. :6.00 Max. :75.000 ## (Other):194 下面的代碼擬合因變量爲獲獎次數，預測變量爲獲獎種類 (分類) 和數學成績 (連續) 的泊松分佈，泊松分佈默認的鏈接方程就是 \\(\\text{log}\\)，所以你可以像第一行那樣把鏈接方程部分省略。結果也是一樣的。 m1 &lt;- glm(num_awards ~ prog, family=&quot;poisson&quot;, data=p) m2 &lt;- glm(num_awards ~ prog, family=poisson(link = log), data=p) summary(m1); summary(m2) ## ## Call: ## glm(formula = num_awards ~ prog, family = &quot;poisson&quot;, data = p) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.41421 -0.69282 -0.63246 0.00000 3.39133 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.60944 0.33333 -4.8283 1.377e-06 *** ## progAcademic 1.60944 0.34733 4.6338 3.590e-06 *** ## progVocational 0.18232 0.44096 0.4135 0.6793 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 287.672 on 199 degrees of freedom ## Residual deviance: 234.460 on 197 degrees of freedom ## AIC: 416.515 ## ## Number of Fisher Scoring iterations: 6 ## ## Call: ## glm(formula = num_awards ~ prog, family = poisson(link = log), ## data = p) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.41421 -0.69282 -0.63246 0.00000 3.39133 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.60944 0.33333 -4.8283 1.377e-06 *** ## progAcademic 1.60944 0.34733 4.6338 3.590e-06 *** ## progVocational 0.18232 0.44096 0.4135 0.6793 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 287.672 on 199 degrees of freedom ## Residual deviance: 234.460 on 197 degrees of freedom ## AIC: 416.515 ## ## Number of Fisher Scoring iterations: 6 輸出結果的迴歸係數部分， 該學校學生獲得學術類獎項的平均次數和獲得一般獎項的平均次數的比值是 \\(\\text{exp}(1.6094) = 4.999\\)，所以獲得的學術類獎平均次數要高於一般獎次數 \\(390\\%\\)； 獲得技能類獎的平均次數和一般獎平均次數的比值是 \\(\\text{exp}(0.1823) = 1.199\\)，也就是高出了 \\(19.9\\%\\)； 該校學生獲得一般類獎的次數平均每人是 \\(\\text{exp}(-1.6094) = 0.20\\) 次； 該校學生獲得學術獎的次數平均每人是 \\(\\text{exp}(-1.6094 + 1.6094) = 1\\) 次；(一人一次夠流弊) 該校學生獲得技能類獎的次數平均每人是 \\(\\text{exp}(-1.6094 + 0.182) = 0.24\\) 次。 看來該校師生很重視學術。 當然也可以用下面定義的函數來幫助我們計算上面這些數值，及其信賴區間。 glm.RR &lt;- function(GLM.RESULT, digits = 2) { if (GLM.RESULT$family$family == &quot;binomial&quot;) { LABEL &lt;- &quot;OR&quot; } else if (GLM.RESULT$family$family == &quot;poisson&quot;) { LABEL &lt;- &quot;RR&quot; } else { stop(&quot;Not logistic or Poisson model&quot;) } COEF &lt;- stats::coef(GLM.RESULT) CONFINT &lt;- stats::confint(GLM.RESULT) TABLE &lt;- cbind(coef=COEF, CONFINT) TABLE.EXP &lt;- round(exp(TABLE), digits) colnames(TABLE.EXP)[1] &lt;- LABEL TABLE.EXP } glm.RR(m1) ## RR 2.5 % 97.5 % ## (Intercept) 0.2 0.10 0.36 ## progAcademic 5.0 2.68 10.63 ## progVocational 1.2 0.51 2.94 47.3 過度離散 overdispersion 泊松分佈的前提條件之一是，方差和均值相等。這是一個非常強的假設，很多計數型數據其實是無法滿足這個條件的。許多時候 (包括上面的例子也是) 方差要大於或者小於均值： epiDisplay::summ(p$num_awards[p$prog == &quot;Academic&quot;], graph = FALSE) ## obs. mean median s.d. min. max. ## 105 1 1 1.279 0 6 epiDisplay::summ(p$num_awards[p$prog == &quot;General&quot;], graph = FALSE) ## obs. mean median s.d. min. max. ## 45 0.2 0 0.405 0 1 epiDisplay::summ(p$num_awards[p$prog == &quot;Vocational&quot;], graph = FALSE) ## obs. mean median s.d. min. max. ## 50 0.24 0 0.517 0 2 試想一下，實際的數據中其實是經常出現這樣的違反泊松分佈前提的計數型數據的。例如某兩個觀測對象，如果他們二者的線性預測方程給出相等的結果 (他們各自的預測變量可以完全不同)，會被認爲服從相同均值，相同方差的泊松分佈，這顯然是不合理的。例如本章用到的學校學生獲獎的例子，有的學生成績好，那麼獲得學術類獎的平均次數 (及其方差) 自然和成績排在後面的學生不同，強制這樣的兩個學生服從相同均值，相同方差的泊松分佈顯然是不合情理的。手工好的學生，可能更傾向於獲得更多得技能類獎。實際情況下，還有許許多多其他的未知因素會影響學生獲獎的次數，例如家庭教育背景的不同，有些學生鋼琴獲獎多，因爲他每天都去練習彈鋼琴等等，這些都是沒有被收集到的數據。 真實情況應該是這樣的，當有其他的我們不知道的因素存在時，這些因素會導致某些人的均值高於其他人。如果對象 \\(i\\) 的因變量 \\(Y_i\\) 服從均值爲 \\(\\mu_i\\) 的泊松分佈，那麼對於所有的 \\(\\mu_i\\)，其均值 (overall mean) 是 \\(\\mu\\)，方差 (overall variance) 是 \\(\\sigma^2\\)。這是一個典型的隨機效應模型 random effect model，我們會在後面的 hierarchical data analysis 再深入討論，但是這裏的重點是，每個觀測對象自己的均值 \\(\\mu_i\\)，是我們在普通泊松迴歸中忽略掉的隨機共變量 (the effects of omitted covariates)。 所以樣本數據來自的人羣如果共同均值 (或者叫邊際效應均值，marginal mean) 爲 \\(\\mu\\)： \\[ E(Y_i) = E(E(Y_i | \\mu_i)) = E(\\mu_i) = \\mu \\] 和共同方差 (邊際效應方差) ，需要用到 總體方差法則 (Law of total variance) 概念： \\[ \\begin{aligned} \\text{Var}(Y_i) &amp; = E(\\text{Var}(Y_i | \\mu_i)) + \\text{Var}(E(Y_i | \\mu_i)) \\\\ &amp; = E(\\mu_i) + \\text{Var}(\\mu_i) \\\\ &amp; = \\mu + \\sigma^2 \\end{aligned} \\] 47.3.1 過度離散怎麼查？ R 輸出的結果中的 模型偏差 deviance，可以用來初步判斷整體模型的擬合優度。如果模型偏差除以殘差獲得的殘差偏差 (residual deviance) 足夠小，說明擬合的模型跟數據本身比較接近，也就是模型和數據擬合程度較好，反之則提示模型本身具有較高的過度離散 overdispersion。 with(m1, cbind(res.deviance = deviance, df = df.residual, p = pchisq(deviance, df.residual, lower.tail=FALSE))) ## res.deviance df p ## [1,] 234.45997 197 0.034961171 Goodness of fit 檢驗結果 提示本模型可能存在過度離散，數據擬合度不理想。值得注意的是如果樣本很大時，模型偏差的檢驗統計量將不再服從卡方分佈，應用的時候一定要慎重。 47.3.2 負二項式分佈模型 negative binomial model 如果普通泊松迴歸模型擬合數據時，發現數據本身有過度離散的嫌疑，那麼建議使用負二項式分佈模型來重新擬合數據。負二項式分佈模型其實是泊松分佈的擴展版本，即考慮了個體的方差和均值的隨機效應 subject-specific random effect。如果設每個觀測對象的隨機效應部分爲 \\(a_i\\)，預測變量爲向量 \\(\\mathbf{x_i} = (x_{i1}, \\cdots, x_{ip})\\)，那麼因變量 \\(Y_i\\) 服從均值爲 \\(\\text{exp}(\\beta^T\\mathbf{x_i}+a_i)\\) 泊松分佈。在負二項式分佈中，個體的隨機效應部分的自然底數的指數 \\(e^{a_i}\\) 其實是服從均值爲 1， 方差爲 \\(\\alpha\\) 的伽馬分佈 (gamma distribution)。\\(\\alpha\\) 越大，说明过度离散越明显。 接下來用相同的數據，使用負二項式分佈模型在 R 裏作模型的擬合，你就會看到差別： R 裏擬合負二項式分佈模型的函數 glm.nb 在基本包 MASS 裏。 m1 &lt;- glm.nb(num_awards ~ prog, data = p) m2 &lt;- glm(num_awards ~ prog, family=poisson(link = log), data=p) summary(m1) ## ## Call: ## glm.nb(formula = num_awards ~ prog, data = p, init.theta = 1.72267107, ## link = log) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.25581 -0.67036 -0.61517 0.00000 2.32349 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.60944 0.35215 -4.5703 4.87e-06 *** ## progAcademic 1.60944 0.37291 4.3159 1.59e-05 *** ## progVocational 0.18232 0.46793 0.3896 0.6968 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for Negative Binomial(1.7227) family taken to be 1) ## ## Null deviance: 211.264 on 199 degrees of freedom ## Residual deviance: 171.066 on 197 degrees of freedom ## AIC: 406.532 ## ## Number of Fisher Scoring iterations: 1 ## ## ## Theta: 1.723 ## Std. Err.: 0.717 ## ## 2 x log-likelihood: -398.532 summary(m2) ## ## Call: ## glm(formula = num_awards ~ prog, family = poisson(link = log), ## data = p) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.41421 -0.69282 -0.63246 0.00000 3.39133 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.60944 0.33333 -4.8283 1.377e-06 *** ## progAcademic 1.60944 0.34733 4.6338 3.590e-06 *** ## progVocational 0.18232 0.44096 0.4135 0.6793 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 287.672 on 199 degrees of freedom ## Residual deviance: 234.460 on 197 degrees of freedom ## AIC: 416.515 ## ## Number of Fisher Scoring iterations: 6 仔細比較普通泊松分佈迴歸和負二項式分佈迴歸的輸出結果，你會發現 迴歸係數的計算是完全相同的 (由於我們只放了一個簡單的分類型變量作爲預測變量，一般來說泊松迴歸和負二項式分佈迴歸計算的迴歸係數會有些許不同)； 另外一個變化是標準誤的估計量在負二項式分佈模型中明顯變大了，這就是我們放寬了前提條件，允許模型考慮個體的隨機效應的體現。如果泊松模型被數據本身的過度離散影響顯著，那麼泊松迴歸計算獲得的參數標準無是偏低的； 負二項式分佈迴歸的結果最底下出現的 Theta: 1.723 部分，它的倒數是前面提到的歌廳效應部分 \\(a_i\\) 服從的伽馬分佈的方差 \\(\\alpha\\)。它是關鍵的離散程度參數 (dispersion parameter)。在 STATA 裏，如果用 nbreg 擬合負二項式分佈迴歸的模型，輸出的結果最底下會有 \\(\\alpha\\) 值的報告，注意它和 R 輸出的 Theta 結果互爲倒數。另外，STATA 的輸出結果還會對 \\(\\alpha = 0\\) 直接進行檢驗。在 R 裏面則需要給兩個模型分別進行擬合優度檢驗，多數情況下你會發現負二項式分佈迴歸的模型更加擬合數據： with(m1, cbind(res.deviance = deviance, df = df.residual, p = pchisq(deviance, df.residual, lower.tail=FALSE))) ## res.deviance df p ## [1,] 171.06608 197 0.90901874 with(m2, cbind(res.deviance = deviance, df = df.residual, p = pchisq(deviance, df.residual, lower.tail=FALSE))) ## res.deviance df p ## [1,] 234.45997 197 0.034961171 另一種獲取沒有被低估的迴歸係數的標準誤的方法來自穩健統計學手段。在 R 裏，擬合完普通泊松迴歸以後，用 sandwich 包裏的 vcovHC() 命令進行穩健的參數誤差估計 (具體說是夾心方差矩陣估計 sandwich estimator of variance)： m2 &lt;- glm(num_awards ~ prog, family=poisson(link = log), data=p) cov.m2 &lt;- vcovHC(m2, type = &quot;HC0&quot;) std.err &lt;- sqrt(diag(cov.m2)) robust.est &lt;- cbind(Estimate= coef(m2), &quot;Robust SE&quot; = std.err, &quot;Pr(&gt;|z|)&quot; = 2 * pnorm(abs(coef(m2)/std.err), lower.tail=FALSE), LL = coef(m1) - 1.96 * std.err, UL = coef(m1) + 1.96 * std.err) robust.est ## Estimate Robust SE Pr(&gt;|z|) LL UL ## (Intercept) -1.60943791 0.29814240 6.7305731e-08 -2.19379701 -1.0250788 ## progAcademic 1.60943791 0.32296809 6.2517920e-07 0.97642045 2.2424554 ## progVocational 0.18232156 0.42426407 6.6738767e-01 -0.64923602 1.0138791 "],
["-poisson-glm-for-rates.html", "第 48 章 率的廣義線性迴歸 Poisson GLM for rates 48.1 醫學中的率 48.2 泊松過程 48.3 率的模型 48.4 率的 GLM 48.5 實戰演練", " 第 48 章 率的廣義線性迴歸 Poisson GLM for rates 48.1 醫學中的率 前章介紹的事件發生次數，使用的是泊松迴歸。本章介紹同樣利用泊松迴歸，對事件發生率類型數據的泊松迴歸模型。常見的率的數據例如： 肺癌發病率 工廠職工的死亡率 術後後遺症的發生率 下列數據來自英國醫生調查 (British doctors study)，研究的是男性醫生中吸菸與否和冠心病死亡之間的關係。最後一列是每組觀測對象被追蹤的人年 (person-year)。 ## agegrp smokes deaths pyrs ## 1 35-44 Smoker 32 52407 ## 2 45-54 Smoker 104 43248 ## 3 55-64 Smoker 206 28612 ## 4 65-74 Smoker 186 12663 ## 5 75+ Smoker 102 5317 ## 6 35-44 Non-smoker 2 18790 ## 7 45-54 Non-smoker 12 10673 ## 8 55-64 Non-smoker 28 5710 ## 9 65-74 Non-smoker 28 2585 ## 10 75+ Non-smoker 31 1462 這是一個已經被整理過的數據，我們沒有辦法從這樣的數據還原到每個觀察對象的個人水平數據。冠心病的粗死亡率 (crude death rate) 可以被計算如下表 (忽略年齡分組)，此時默認的前提是死亡事件在追蹤的過程中發生的概率不發生改變。 表 48.1: Death rates due to CHD in smokers and non-smokers, collapsed over age group Group Person-years of follow-up CHD deaths Death Rate per 1000 person-years Rate Ratios Non-smokers 39220 101 2.58 1.00 Smokers 142247 630 4.43 1.72 48.2 泊松過程 設 \\(Y\\) 是代表某段時間 \\(t\\) 內事件發生次數 (死亡) 的隨機變量。如果可以假設： 每次事件的發生，是互相獨立的，即在沒有重疊的時間線上，每個事件的發生是隨機的。 在一個無限小的時間段 \\(\\delta t\\) 內，事件發生的概率是 \\(\\lambda\\times\\delta t\\)，其中 \\(\\delta t \\rightarrow 0\\)。 那麼根據泊松分佈 (Section 6) 的定義，在這個時間段內，隨機變量 \\(Y\\) 事件發生次數服從泊松分佈： \\[ \\begin{aligned} Y &amp; \\sim \\text{Po}(\\mu) \\\\ \\text{Where } \\mu &amp; = \\lambda t, \\text{ and } \\lambda \\text{ is the Rate} \\end{aligned} \\] 所以，從泊松過程可以看到，我們關心的參數是事件發生率 \\(\\lambda\\)。 48.3 率的模型 既然關心的參數只是發生率，且我們已知泊松分佈是指數分佈的家族成員，可以用廣義線性模型的概念來建模。 因變量分佈，distribution of dependent variable \\[Y_i \\sim \\text{Po}(\\mu_i), \\text{ where } \\mu_i = \\lambda_i t_i\\] 線性預測方程，linear predictor \\[\\eta_i = \\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}\\] 標準鏈接方程，canonical link function \\[\\text{log}(\\lambda_i) = \\text{log}(\\frac{\\mu_i}{t_i})\\] 所以，將率的模型整理一下，就變成了 \\[ \\begin{aligned} \\text{log}(\\mu_i) - \\text{log}(t_i) &amp; = \\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip} \\\\ \\text{log}(\\mu_i) &amp; = \\text{log}(t_i) + \\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip} \\end{aligned} \\] 你可以看到，時間項的對數部分 \\(\\text{log}(t_i)\\) 其實是被移到線性預測方程的右邊跟參數放在一起的，只是它的迴歸係數被強制爲 \\(1\\)。這個時間項被叫做 補償項 (offset)。這樣我們就成功地擬合了用於求事件發生率的一個泊松迴歸模型。在 R 裏，你可以用 glm() 命令的 offset = 選項功能，也可以把 offset(log(Person-year)) 作爲線性預測方程的一部分把時間項取對數以後放進模型裏面。 48.4 率的 GLM 所以我們一起來把率的 GLM 正式定義一下，它包含三個部分： 可被認爲互相獨立的因變量觀測值的分佈服從泊松分佈 \\[Y_i \\sim \\text{Po}(\\mu_i)\\] 其中 \\(E(Y_i) = \\mu_i = \\lambda_i t_i\\)，\\(t_i\\) 是第 \\(i\\) 個觀察對象 (或者觀察組) 的追蹤人年 (person-time)。 線性預測方程 \\[\\eta_i = \\text{log}(t_i) + \\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}\\] 鏈接方程是均值的對數方程 \\[\\text{log}(\\mu_i) = \\eta_i\\] 和分組型二項分佈數據相似，如果泊松 GLM 擬合的數據也是分組型數據，如本章開頭的英國醫生隊列數據。那麼模型偏差值 (deviance) 可以用來衡量模型擬合的好壞。在零假設條件下，模型偏差值服從自由度爲 \\(n-p\\) 的卡方分佈 (這裏的 \\(n\\) 是分組型數據中的“組的數量”，也就是飽和模型中參數的數量，\\(p\\) 是擬合的線性預測方程中參數的數量)。 48.5 實戰演練 數據是本章開頭使用的英國醫生隊列 ## agegrp smokes deaths pyrs ## 1 35-44 Smoker 32 52407 ## 2 45-54 Smoker 104 43248 ## 3 55-64 Smoker 206 28612 ## 4 65-74 Smoker 186 12663 ## 5 75+ Smoker 102 5317 ## 6 35-44 Non-smoker 2 18790 ## 7 45-54 Non-smoker 12 10673 ## 8 55-64 Non-smoker 28 5710 ## 9 65-74 Non-smoker 28 2585 ## 10 75+ Non-smoker 31 1462 每組的死亡人數用 \\(y_i, i=1,\\cdots,10\\) 標記； 每組追蹤的人年用 \\(t_i\\) 標記； \\(x_{i1} = 0\\) 時對象是吸菸者，\\(x_{i1} = 1\\) 時對象是非吸菸者； \\(x_{i2}, x_{i3}, x_{i4}, x_{i5}\\) 作爲5個年齡組的啞變量。 分析目的是： 調查吸菸與冠心病死亡率的關係 (不調整年齡)； 調查吸菸與冠心病死亡率的年齡調整後關係； 調查年齡是否對吸菸與冠心病死亡率的關係起到交互作用。 48.5.1 模型 1 第一個模型可以用下面的數學表達式： \\[ \\text{log}(\\mu_i) = \\text{log}(t_i) + \\alpha + \\beta_1 x_{i1} \\] 在 R 裏面用下面的代碼來擬合這個模型，仔細閱讀輸出的結果： # the following 2 models are equivalent Model1 &lt;- glm(deaths ~ smokes + offset(log(pyrs)), family = poisson(link = &quot;log&quot;), data = BritishD) Model1 &lt;- glm(deaths ~ smokes, offset = log(pyrs), family = poisson(link = &quot;log&quot;), data = BritishD) summary(Model1) ## ## Call: ## glm(formula = deaths ~ smokes, family = poisson(link = &quot;log&quot;), ## data = BritishD, offset = log(pyrs)) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -16.5348 -6.0313 4.6116 8.1617 13.6441 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -5.961822 0.099504 -59.9157 &lt; 2.2e-16 *** ## smokesSmoker 0.542221 0.107183 5.0588 4.219e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 935.067 on 9 degrees of freedom ## Residual deviance: 905.976 on 8 degrees of freedom ## AIC: 965.044 ## ## Number of Fisher Scoring iterations: 6 輸出報告中的參數估計部分 Estimate 就是我們擬合模型中參數的估計 \\(\\hat\\alpha, \\hat\\beta_1\\)，他們各自的含義是： \\(\\hat\\alpha = -5.96\\)：非吸菸者的冠心病估計死亡率的對數 (the estimated log rate for non-smokers)； \\(\\hat\\beta_1 = 0.547\\)：非吸菸者和吸菸者兩組之間冠心病死亡率對數之差 (the estimated difference in log rate between non-smokers and smokers)。 注意看報告中間部分模型偏差部分的數字 Residual deviance: 905.98 on 8 degrees of freedom，如果對 模型 1 進行擬合優度檢驗： with(Model1, cbind(res.deviance = deviance, df = df.residual, p = pchisq(deviance, df.residual, lower.tail=FALSE))) ## res.deviance df p ## [1,] 905.97619 8 2.9024145e-190 擬合優度檢驗結果提示，這個模型對數據的擬合非常差 (poor fit)。可能的原因是，模型 1 中忽略了“年齡”這一重要的因素，使得當僅僅使用 吸菸與否 的信息擬合的泊松迴歸模型的擬合值和觀察值之間的差異的波動非常大，大到很可能無法滿足泊松分佈的前提假設。 48.5.2 模型 2 第二個模型的線性預測方程可以寫作： \\[ \\text{log}(\\mu_i) = \\text{ln}(t_i) + \\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 x_{i3} + \\beta_4 x_{i4} + \\beta_5 x_{i5} \\] 在 R 裏面用下面的代碼來擬合這個模型，仔細閱讀輸出的結果： Model2 &lt;- glm(deaths ~ smokes + agegrp + offset(log(pyrs)), family = poisson(link = &quot;log&quot;), data = BritishD) summary(Model2) ## ## Call: ## glm(formula = deaths ~ smokes + agegrp + offset(log(pyrs)), family = poisson(link = &quot;log&quot;), ## data = BritishD) ## ## Deviance Residuals: ## 1 2 3 4 5 6 7 8 9 ## 0.901600 0.510379 0.051347 -0.087318 -0.912369 -2.179780 -1.308000 -0.137907 0.228819 ## 10 ## 1.919020 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -7.91933 0.19176 -41.2978 &lt; 2.2e-16 *** ## smokesSmoker 0.35454 0.10737 3.3019 0.0009604 *** ## agegrp45-54 1.48401 0.19510 7.6063 2.821e-14 *** ## agegrp55-64 2.62751 0.18373 14.3012 &lt; 2.2e-16 *** ## agegrp65-74 3.35049 0.18480 18.1305 &lt; 2.2e-16 *** ## agegrp75+ 3.70010 0.19222 19.2494 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 935.0673 on 9 degrees of freedom ## Residual deviance: 12.1324 on 4 degrees of freedom ## AIC: 79.2003 ## ## Number of Fisher Scoring iterations: 4 此時可以計算吸菸者與非吸菸者相比時，年齡調整後冠心病死亡率的比爲： \\[ \\begin{aligned} e^{0.3545} &amp; = 1.43 \\text{ with } 95\\% \\text{ CI: } \\\\ (e^{0.3545 - 1.96\\times0.1074}, &amp; e^{0.3545 + 1.96\\times0.1074}) = (1.16, 1.76) \\end{aligned} \\] 報告中還包含了對吸菸項迴歸係數的 Wald 檢驗結果 smokesSmoker 0.3545 0.1074 3.302 0.00096 ***，從這一結果來看，數據提供了強有力的證據證明了年齡調整以後，吸菸會引起冠心病死亡率的顯著升高。再利用模型擬合報告中模型偏差部分的數據 Residual deviance: 905.98 on 8 degrees of freedom，模型的擬合優度檢驗結果爲： with(Model2, cbind(res.deviance = deviance, df = df.residual, p = pchisq(deviance, df.residual, lower.tail=FALSE))) ## res.deviance df p ## [1,] 12.132366 4 0.016393625 結果依然提示，即使把年齡組放入這個泊松迴歸，模型對數據的擬合程度依然非常的不好。所以，到這裏，在即使調整了年齡之後模型擬合度依然不理想的情況下 (這是需要加交互作用項的證據)，我們需要在模型中加入年齡和吸菸的交互作用項 (結果是加入交互作用項的模型就變成了飽和模型)。 48.5.3 模型 3 Model3 &lt;- glm(deaths ~ smokes*agegrp + offset(log(pyrs)), family = poisson(link = &quot;log&quot;), data = BritishD) summary(Model3) ## ## Call: ## glm(formula = deaths ~ smokes * agegrp + offset(log(pyrs)), family = poisson(link = &quot;log&quot;), ## data = BritishD) ## ## Deviance Residuals: ## [1] 0 0 0 0 0 0 0 0 0 0 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -9.14793 0.70711 -12.9371 &lt; 2.2e-16 *** ## smokesSmoker 1.74687 0.72887 2.3967 0.016544 * ## agegrp45-54 2.35737 0.76376 3.0865 0.002025 ** ## agegrp55-64 3.83016 0.73192 5.2330 1.668e-07 *** ## agegrp65-74 4.62266 0.73192 6.3158 2.688e-10 *** ## agegrp75+ 5.29436 0.72956 7.2569 3.960e-13 *** ## smokesSmoker:agegrp45-54 -0.98662 0.79006 -1.2488 0.211741 ## smokesSmoker:agegrp55-64 -1.36281 0.75619 -1.8022 0.071512 . ## smokesSmoker:agegrp65-74 -1.44229 0.75653 -1.9065 0.056592 . ## smokesSmoker:agegrp75+ -1.84699 0.75717 -2.4393 0.014715 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 9.35067e+02 on 9 degrees of freedom ## Residual deviance: 4.44089e-15 on 0 degrees of freedom ## AIC: 75.0679 ## ## Number of Fisher Scoring iterations: 3 此時你會看到模型的偏差已經幾乎接近於零，因爲這已經是一個飽和模型。 "],
["section-49.html", "第 49 章 混雜的調整，交互作用，和模型的可壓縮性 49.1 混雜因素的調整 49.2 交互作用 49.3 可壓縮性 collapsibility 49.4 交互作用對尺度的依賴性", " 第 49 章 混雜的調整，交互作用，和模型的可壓縮性 臨牀醫學，流行病學研究的許多問題，需要我們通過數據來評估某些結果變量 (outcome) 和某些預測變量 (predictors/exposures) 之間的關係 (甚至是因果關係)。這些問題的最佳解決方法應該說是隨機臨牀試驗 (ramdomized clinical trial, RCT)。但是有更多的時候 (由於違反醫學倫理，或者現狀所困，甚至是知識有限) 我們無法設計 RCT 來解決這些問題，就只能藉助於觀察性研究 (observational study)。觀察性研究最大的侷限性在於無法像 RCT 那樣從實驗設計階段把混雜因素排除或者降到最低，所以觀察數據在分析的時候，混雜 (confounding) 是必須要加以考慮的一大要因。在簡單線性迴歸章節 (Section 29.5)，詳細討論過混雜因素的定義及條件： 對於一個預測變量是否夠格被叫做混雜因子，它必須滿足下面的條件： 與關心的預測變量相關 (i.e. \\(\\delta_1 \\neq 0\\))； 與因變量相關 (當關心的預測變量不變時，\\(\\beta_2\\neq0\\) )； 不在預測變量和因變量的因果關係 (如果有的話) 中作媒介。Not be on the causal pathway between the predictor of interest and the dependent variable. 下面的統計數據來自一個比較手術和超聲碎石術對於腎結石治療結果的評價。已知大多數醫生都公認，腎結石的直徑小於 2 公分時治療成功的概率較高。 表 49.1: Lithotripsy &lt; 2cm Diameter &gt;= 2cm Diameter Group Surgery Lithotripsy Surgery Lithotripsy Success 81.00 234 192.00 55 Failure 6.00 36 71.00 25 Total 87.00 270 263.00 80 Odds Ratios 2.08 NA 1.23 NA 表 49.1: Lithotripsy data \\(&lt;2\\) cm Diameter \\(\\geqslant2\\) cm Diameter Group Surgery Lithotripsy Surgery Lithotripsy Success 81 234 192 55 Failure 6 36 71 25 Total 87 270 263 80 Odds Ratios 2.08 1.23 可以看到，在上面的分組表格中，左右兩邊的四個表分別統計了腎結石尺寸小於 2 cm 和大於 2 cm 時，手術摘除腎結石的成功/失敗次數，以及超聲碎石術的成功/失敗次數。這個表格告訴我們，無論腎結石的尺寸是大於還是小於 2 cm，手術的成功的比值比都大於超聲碎石術。但是如果我們沒有把數據按照腎結石尺寸區分時，數據就被壓縮 (collapsed) 成了下面表格總結的樣子： 表 49.2: Lithotripsy collapsed Outcome Surgery Lithotripsy Success 273 (78%) 289 (83%) Failure 77 61 Total 350 350 Odds ratio 0.75 表 49.2: Lithotripsy data collapsed Outcome Surgery Lithotripsy Success 273 (78%) 289 (83%) Failure 77 61 Total 350 350 Odds ratio 0.75 當腎結石尺寸被忽略時，數據卻顯示超聲碎石術的成功比值比要高於手術，和之前的結果是矛盾的，你會信哪個？ 不要慌，數據不會撒謊，撒謊的永遠是人類。我們來把手術次數，超聲碎石術次數，以及腎結石尺寸之間的關係再列個表格： 表 49.3: Association between treatment and the size of the stone. Size of the Stone Surgery Lithotripsy \\(&lt; 2\\) cm 87 (33%) 270 (77%) \\(\\geqslant 2\\) cm 263 80 Total 350 350 可見醫生也都不是傻子，明明腎結石尺寸很大還要用超聲碎石術的人很少，有 77% 的腎結石尺寸小的患者選擇了超聲碎石術。然後我們再列一個表格來看看腎結石的尺寸大小和超聲碎石術成功與否有沒有關係： 表 49.4: Among the lithotripsy patients higher percentage of success was observed when stones were small. Outcome \\(&lt; 2\\) cm \\(\\geqslant 2\\) cm Success 234 (87%) 55 (69%) Failure 36 25 Total 370 80 可見結石尺寸較大時，超聲碎石術的成功率 (69%)，明顯低於尺寸小的時候的成功率 (87%)。在選擇做外科手術的患者中，大多數人的結石尺寸大於 2 cm，成功率仍然達到了 73%。 表 49.5: Among the surgery patients higher percentage of success in both stones compared with lithotripsy Outcome \\(&lt; 2\\) cm \\(\\geqslant 2\\) cm Success 81 (93%) 192 (73%) Failure 6 71 Total 87 263 看到這裏，你是否也發現了，腎結石尺寸大小，同時和手術類型的選擇有關 (尺寸小的傾向於選擇超聲碎石術)，尺寸大小，同樣也和手術結果的成功與否，高度相關 (結石小的人成功率高)。所以，分析手術類型和結石手術的成功率的關係的時候，患者體內結石尺寸的大小，對這個關係是產生了混雜效應的。他們三者之間的關係，可以用下面的圖 49.1 來理解： 圖 49.1: Confounding in kidney stones example 當數據被壓縮 (忽略了腎結石尺寸時)，比較兩種手術類型的成功率的時候，接受外科手術患者的尺寸大多數都較大的事實被“人爲的掩蓋住了”，但是當數據按照結石大小分層以後，你會看見外科手術不論是對付大的結石，還是小的結石，成功率都高於超聲碎石術。這個例子是混雜效應直接逆轉真實相關關係的極佳的實例。同時也提示我們，總體的比值比 (overall odds ratio) 不能通過簡單地把分層表格直接壓縮 (collapsed table) 獲得的數字來計算。 49.1 混雜因素的調整 在前面的腎結石手術的例子中，我們利用已有的背景知識 (小尺寸結石的成功率高)，和初步的統計分析 (變量之間兩兩列表分析其內在關係) 發現了混雜因素 (結石尺寸)，並且其結果也讓我們認定了要暴露因素和結果變量之間的關係，混雜因素必須被調整 (adjusted)。 如腎結石數據這樣簡單的情境下 (被認爲是混雜因素的變量和預測變量/暴露變量都只是一個二分類變量)，我們可以把變量兩兩捉對列表分析其相互關係，確定了混雜效應以後把暴露變量和結果變量按照混雜因素的有無列表之後，就可以求得混雜因素被調整後的分層的比值比。這些分層比值比，在暴露變量與結果變量的關係保持混雜因素的層之間保持不變的前提下，可以被“平均化”(簡單地說)以後求得總體/合併的比值比 (overall/pooled odds ratio)。這就是 Mantel-Haenszel 法或者 Woolf 法的合併比值比的思想出發點。我們來回顧一下 Woolf 法的全部計算過程： 現在假設我們關心的是某種疾病的患病與否 (是/否)，和某個暴露變量 (是/否) 之間的關係，但是同時想要調整另一個具有 \\(k\\) 個分層的混雜因素變量。 表 49.3: Group 1 2 Outcome Success ai bi i = 1, k Failure ci di ni 表 49.6: Woolf Method for estimating the stratified and pooled odds ratio Group \\(1\\) \\(2\\) Outcome Success \\(a_i\\) \\(b_i\\) \\(i = 1,\\cdots, k\\) Failure \\(c_i\\) \\(d_i\\) \\(n_i\\) 49.1.1 Woolf 法估算合併比值比 對想要調整的一個 \\(k\\) 組的混雜因素，把數據按照它的分組分層整理以後，可以得到上面的 \\(k\\) 個四格表 (每個分層四格表都是暴露變量和結果變量結合的四個觀察值 \\(a_i, b_i, c_i, d_i, i=1,\\cdots, k\\))。每個分層四個表的觀測比值比爲 \\(\\hat\\Psi_i = \\frac{a_id_i}{c_ib_i}\\)，且可以證明方差爲 \\[ \\text{Var}(\\text{log}\\hat\\Psi_i) \\approx \\frac{1}{a_i} + \\frac{1}{b_i} + \\frac{1}{c_i} + \\frac{1}{d_i} = \\frac{1}{w_i} \\] 合併比值比的對數 \\(\\text{log}\\hat\\Psi_w\\) 的 Woolf 的計算方法就是 \\[ \\text{log}\\hat\\Psi_w = \\frac{\\sum w_i\\text{log}\\hat\\Psi_i}{\\sum w_i} \\] 所以，每個分層的對數比值比乘以自己的方差的倒數 (權重 weights) 之後求和，再除以所有權重之和，獲得的是合併後的對數比值比，然後再逆運算回來就是 Woolf 法計算合併比值比的原理是。 這個合併比值比的對數的方差是 \\[ \\text{Var}(\\text{log}\\hat\\Psi_w) = \\frac{1}{\\sum w_i} \\] 有了加權後的合併比值比，和方差，就可以求加權後的合併比值比的信賴區間了。值得注意的是，分層之後每個分層四個表中的四個數字 (四個樣本量) 都不能太小。腎結石手術數據滿足這些條件，那麼不妨跟我一起手算一下結石尺寸調整後的手術與超聲碎石術成功與否的比值比： \\[ \\begin{aligned} \\hat\\Psi_1 = 2.08 ;&amp;\\; \\hat\\Psi_2 = 1.23 \\\\ \\text{Var}(\\text{log}\\hat\\Psi_1) = \\frac{1}{81} &amp; + \\frac{1}{234} + \\frac{1}{6} + \\frac{1}{36} = 0.2111 \\\\ \\text{Var}(\\text{log}\\hat\\Psi_2) = \\frac{1}{192} &amp; + \\frac{1}{55} + \\frac{1}{71} + \\frac{1}{25} = 0.0775 \\\\ w_1 = \\frac{1}{\\text{Var}(\\text{log}\\hat\\Psi_1)} = 4.74 ; \\;&amp; w_2 = \\frac{1}{\\text{Var}(\\text{log}\\hat\\Psi_2)} = 12.91 \\\\ \\text{log}\\hat\\Psi_w = &amp; \\frac{4.74\\times\\text{log(2.08)} + 12.91\\times\\text{log(1.23)}}{4.74 + 12.91} \\\\ = &amp; 0.3481 \\\\ \\Rightarrow \\hat\\Psi_w =&amp; e^{0.3481} = 1.42\\\\ \\text{Var}(\\hat\\Psi_w) =&amp; \\frac{1}{4.74+12.91} = 0.0567 \\\\ \\Rightarrow 95\\% \\text{ CI} = &amp; e^{0.3481 \\pm 1.96\\times\\sqrt{0.0567}} \\\\ = &amp; (0.89, 2.26) \\end{aligned} \\] Woolf 的計算調整後的合併比值比的方法是在線性迴歸和廣義線性迴歸被發現之前誕生的，但是其想法之精妙，確實令人感嘆。可惜其最大的缺陷是無法用這樣的方法進行連續型變量的調整，也很難同時進行多個變量的調整，所以現在這一算法已經逐漸被淘汰。現在我們有了廣義線性迴歸模型這一更強大的工具，只要把變量加入廣義線性模型進行調整就可以計算曾經難以計算和擴展的調整後的合併比值比。從下面的代碼計算獲得的調整後比值比 \\(1.43 (0.91, 2.34)\\) 也可以看出，Woolf 方法的計算結果也是足夠令人滿意的。 size &lt;- c(&quot;&lt; 2cm&quot;, &quot;&lt; 2cm&quot;, &quot;&gt;= 2cm&quot;, &quot;&gt;= 2cm&quot;) treatment &lt;- c(&quot;Surgery&quot;,&quot;Lithotripsy&quot;,&quot;Surgery&quot;,&quot;Lithotripsy&quot;) n &lt;- c(87, 270, 263, 80) Success &lt;- c(81, 234, 192, 55) Stone &lt;- data.frame(size, treatment, n, Success) ModelStone &lt;- glm(cbind(Success, n - Success) ~ treatment + size, family = binomial(link = logit), data = Stone) summary(ModelStone) ## ## Call: ## glm(formula = cbind(Success, n - Success) ~ treatment + size, ## family = binomial(link = logit), data = Stone) ## ## Deviance Residuals: ## 1 2 3 4 ## 0.76357 -0.35881 -0.27563 0.46948 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.93655 0.17045 11.3614 &lt; 2.2e-16 *** ## treatmentSurgery 0.35723 0.22908 1.5594 0.1189 ## size&gt;= 2cm -1.26057 0.23900 -5.2742 1.333e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 33.12395 on 3 degrees of freedom ## Residual deviance: 1.00816 on 1 degrees of freedom ## AIC: 26.3554 ## ## Number of Fisher Scoring iterations: 3 epiDisplay::logistic.display(ModelStone) ## ## Logistic regression predicting cbind(Success, n - Success) ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## treatment: Surgery vs Lithotripsy 0.75 (0.51,1.09) 1.43 (0.91,2.24) 0.119 &lt; 0.001 ## ## size: &gt;= 2cm vs &lt; 2cm 0.34 (0.23,0.51) 0.28 (0.18,0.45) &lt; 0.001 &lt; 0.001 ## ## Log-likelihood = -10.1777 ## No. of observations = 4 ## AIC value = 26.3554 所以，此次分析的結論是，在 5% 的顯著性水平下，數據無法提供有效證據證明，當調整了結石尺寸之後，外科手術和超聲碎石術治療腎結石有差別。 We can conclude that there is no evidence at the 5% level for an effect of surgery, adjusted for stone size. 49.2 交互作用 我們決定調整一個混雜因素的時候，其實同時包含了 “在不同混雜因素的程度下，暴露變量和結果變量之間的關係不變/This implicitly assumes that the effect of the exposure is the same irrespective of the levels of the confounder.” 的假設。但是，一個混雜因素，它可能同時還扮演了改變暴露變量和結果變量之間關係的角色 (effect modifier/交互作用效應)。另外還有的情況下，某變量可能改變了暴露變量和結果變量之間的關係，卻不一定是一個混雜因素。此時我們說這個起到改變關係的變量和暴露變量之間發生了交互作用。 如果暴露變量在某個分組變量的不同層 (strata) 之間是不同質的 (hetergeneous, not constant)，我們建議要分析且報告不同層各自的比值比。惟一的例外是 RCT 臨牀試驗的時候，我們更加關心調整後合併比值比。因爲一項治療藥物對不同的 “個體” 有不同的療效是必然的，但是，RCT 的目的是要評價的其實是這個藥物或者新療法在整個人羣中的療效是怎樣的。 我們給腎結石數據加上治療方案和結石尺寸大小的交互作用項，結果如下： ModelStone2 &lt;- glm(cbind(Success, n - Success) ~ treatment*size, family = binomial(link = logit), data = Stone) summary(ModelStone2) ## ## Call: ## glm(formula = cbind(Success, n - Success) ~ treatment * size, ## family = binomial(link = logit), data = Stone) ## ## Deviance Residuals: ## [1] 0 0 0 0 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.87180 0.17903 10.4553 &lt; 2.2e-16 *** ## treatmentSurgery 0.73089 0.45942 1.5909 0.1116310 ## size&gt;= 2cm -1.08334 0.30039 -3.6065 0.0003104 *** ## treatmentSurgery:size&gt;= 2cm -0.52453 0.53716 -0.9765 0.3288211 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 3.31239e+01 on 3 degrees of freedom ## Residual deviance: 3.66374e-14 on 0 degrees of freedom ## AIC: 27.3472 ## ## Number of Fisher Scoring iterations: 3 epiDisplay::logistic.display(ModelStone2) ## ## Logistic regression predicting cbind(Success, n - Success) ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## treatment: Surgery vs Lithotripsy 0.75 (0.51,1.09) 2.08 (0.84,5.11) 0.112 &lt; 0.001 ## ## size: &gt;= 2cm vs &lt; 2cm 0.34 (0.23,0.51) 0.34 (0.19,0.61) &lt; 0.001 &lt; 0.001 ## ## treatmentSurgery:size&gt;= 2cm - 0.59 (0.21,1.7) 0.329 &lt; 0.001 ## ## Log-likelihood = -9.6736 ## No. of observations = 4 ## AIC value = 27.3472 交互作用項的迴歸係數是否爲零的檢驗結果是 \\(p = 0.329\\)，提示數據無法提供足夠的證據證明結石尺寸對治療方案和手術成功與否之間的關係造成有意義的交互作用 (There is no evidence of an interaction between stone size and surgery)。所以此次的數據分析我們可以報告結石尺寸調整後的手術成功比值比就可以了。其中，交互作用項的迴歸係數 \\(-0.5245 = \\text{log}(0.59)\\)，的含義是當結石尺寸 \\(\\geqslant 2 \\text{cm}\\) 時，外科手術和超聲碎石術成功比值比的對數的差。我們可以看到一開始我們計算的分層比值比的比值 \\(\\frac{1.23}{2.08} = 0.59\\)。還注意到這已經是一個飽和模型 (模型偏差爲零)，模型的擬合值和我們的觀測值是完全相同的。 另外一點不得不提的是，交互作用項的迴歸係數的點估計 \\(0.59\\) 其實低於零假設時的 \\(1\\) 挺多的，它的 \\(95\\%\\) 信賴區間也相當的寬 \\((0.21,1.70)\\)，所以其實這裏我們沒有獲得足夠的證據證明替代假設 (有交互作用)，很難說不是因爲樣本量不足導致的統計效能較低，所以我們沒有辦法從這個數據完全排除結石尺寸對治療方案的選擇和手術成功的關係之間的交互作用。(We really cannot be sure that there is no interaction in truth - the data are consistent with quite large interactions between size and surgery effect.) 因此，有些統計學家可能會傾向於報告分層的比值比，因爲我們沒有辦法從這個樣本數據排除有較強交互作用存在的可能性。 49.3 可壓縮性 collapsibility 模型可壓縮性的概念可以這樣來理解： 當我們把一個 我們認爲很重要的混雜因子 加到模型中去時，自然而然我們會期待其對結果變量的 效果估計 (effect estimate) (迴歸係數)在調整前後發生變化。如果是反過來，當我們把一個 我們認爲不重要的非混雜因子 加到模型中去時，我們也會自然而然地期待其對結果變量的 效果估計 (effect estimate) 在調整前後不會發生改變才是。不幸的是，我們這種理想中的想當然，僅僅在某些情境下成立，其中之一是簡單線性迴歸 (Section 26)。 49.3.1 線性迴歸的可壓縮性 證明 令 \\(Y\\) 標記結果變量，\\(X\\) 標記暴露變量，\\(Z\\) 則標記我們想要調整的莫個混雜因子： \\[ Y = \\alpha + \\beta_X X + \\beta_Z Z + \\varepsilon, \\text{ where } \\varepsilon \\sim N(0, \\sigma^2) \\] 然後把等式兩邊同時取以暴露變量 \\(X\\) 爲條件的期待值： \\[ E(Y | X) = \\alpha + \\beta_X X + \\beta_Z E(Z|X) \\] 如果 \\(Z\\) 和 \\(X\\) 是相互獨立的 (即，不是 \\(X, Y\\) 之間關係的混淆因子)，那麼 \\(E(Z|X) = E(Z) = \\mu_Z\\)，因爲 \\(X\\) 不能提供任何 \\(Z\\) 的有效信息。所以，等式就變爲： \\[ E(Y|X) = \\alpha + \\beta_Z \\mu_Z + \\beta_X X \\] 所以，當我們用簡單線性迴歸來擬合 \\(X,Y\\) 之間的關係時，如果 \\(Z,X\\) 是相互獨立的，模型中增加了 \\(Z\\)，不會影響 \\(X\\) 的迴歸係數。線性迴歸的這個性質被定義爲模型的可壓縮性 (linear regression models are collapsible)。 49.3.2 邏輯鏈接方程時的不可壓縮性 使用對數鏈接方程 (\\(\\text{log link}\\)) 的迴歸模型，同樣具有和線性迴歸類似的可壓縮性。但是，邏輯鏈接方程 (\\(\\text{logit link}\\)) 的迴歸模型則不具有可壓縮性。下面舉例的分層表格和壓縮表格，證明了邏輯鏈接方程不具有可壓縮性： 表 49.7: Non-collapsibility of logit link in GLM (stratified data) Strata 1 Strata 2 Outcome Exposure \\(+\\) Exposure \\(-\\) Exposure \\(+\\) Exposure \\(-\\) Success 90 50 50 10 Failure 10 50 50 90 Total 100 100 100 100 Odds Ratios 9 9 從表格的數據計算可知，要被調整的分組變量的兩層數據中，暴露變量和結果變量的關係相同，比值比都是 \\(9\\)，沒有交互作用，也沒有混雜效應 (每一層中暴露與非暴露均佔相同的 \\(50\\%\\))。但是，你如果把這個觀測數據合併： 表 49.8: Non-collapsibility of logit link in GLM (collapsed data) Outcome Exposure \\(+\\) Exposure \\(-\\) Success 140 60 Failure 60 140 Total 200 200 Odds ratio 5.4 既然已知我們拿來分層的變量對暴露和結果的關係既沒有交互作用，也沒有混雜效應，那麼壓縮數據以後的合併比值比應該和分層比值比一樣才說的通，可惜我們獲得了截然不同的合併比值比 (非調整的)。所以在應用邏輯鏈接方程建立廣義線性迴歸模型的時候，一定不能忘記其不可壓縮性的特徵。所以，即使加入一個非混淆因子，暴露變量的邏輯迴歸的效應估計 (係數) 也會發生改變。調整了 \\(Z\\) 以後的比值比被叫做條件 (或直接使用分層) 比值比。如同表格中實例所示，條件比值比會比邊緣比值比 (非調整) 看起來要大一些。 邏輯迴歸的不可壓縮性給我們的啓示是，加入某個變量進入邏輯迴歸模型前後，其他預測變量的迴歸係數發生的變化可能僅僅是由於模型的不可壓縮性導致的變化，而非由於新加入的變量對原先變量與結果之間的關係起到了交互作用或者混雜效應。所以，擬合迴歸模型的時候，如果你要考慮對莫個因素進行調整，必須做的一件事是，先分析它和其他模型中已有的預測變量之間的關係，從而有助於分析，當把要調整的變量放進模型前後的迴歸係數變化是否是真的來自於交互作用或者混雜效應。 49.4 交互作用對尺度的依賴性 GLM 模型中的交互作用檢驗，對選用的尺度 (比值比 OR，還是危險度比 RR) 依賴性極高。用模型可壓縮性的數據例子也可以說明交互作用對尺度的依賴性。上文書說到，兩個分層中的比值比都是 9，該分層變量既沒有交互作用，也不是混淆因子 (當使用比值比的時候)。如果我們改用危險度比 (risk ratio, RR)，在分類變量的第一層 (Strata 1) 中，暴露的危險度比是 \\(\\frac{90/100}{50/100} = 1.8\\)；分類變量的第二層 (Strata 2) 中，暴露的危險度比是 \\(\\frac{50/100}{10/100} = 5\\)。所以使用危險度比作爲評價指標的時候，被調整的分類變量就突然搖身一變變成了有交互作用的因子。這裏，我們用數據，證明了交互作用的存在與否，對尺度的選用依賴性極高。這就導致我們在描述一個變量是否對我們關心的暴露和結果之間的關係有交互作用時，必須明確指出所使用的是比值比，還是危險度比進行的交互作用評價。 "],
["section-50.html", "第 50 章 流行病學中的邏輯迴歸 50.1 流行病學研究最常用的實驗設計 50.2 以簡單二分類暴露變量爲例 50.3 拓展到多個暴露變量的邏輯迴歸模型 50.4 流行病學研究中變量的調整策略", " 第 50 章 流行病學中的邏輯迴歸 50.1 流行病學研究最常用的實驗設計 在流行病學研究中，我們最關心的無非是 暴露變量 (治療方案的選用，或者一些對象的某些特徵如吸菸或飲酒等生活習慣) 與結果變量 (罹患某種我們關心的疾病與否，或者死亡與否) 之間的相關關係。爲了方便解釋本章暫且只考慮 單一的結果變量 (univariate) 的情況，不過不要忘了真實世界中的數據和實驗，我們常要 同時處理多個不同的結果變量 (multivariate)。 流行病學最常用的兩種研究設計是： 隊列研究/前瞻性研究 cohort or prospective studies； 病例對照/回顧性研究 case-control or retrospective studies。 無論是這兩種研究中的哪一種，都要從定義研究的人羣開始 (start by defining some population we wish to study)。例如某個年齡段的男性或者女性；某個特定時間段內，在某特定地區範圍內生活的所有人等。這被定義爲 潛在研究人羣 (underlying population of interest)。 如果是隊列研究，我們需要對這個潛在研究人羣取樣，選取具 有代表性的，且有足夠樣本量 的一羣個體 (隊列) 參與研究。那些我們要研究的 暴露變量 \\((\\mathbf{X})\\) 被提前定義好，然後在開始研究的時候收集整理成數據庫。之後這個隊列的參與者不斷被隨訪，這個時間段可以是先定義好的 (一年，五年，十年…)，也可以因人而異，最終直至每個個體的結果變量被觀測到 \\((D=1 \\text{ or } D=0)\\)。更一般地，如果我們要研究的暴露因素是二分類的，甚至是多分類的，我們可能會使用一些取樣的技巧，從而保證取樣構成的隊列能夠真實地反應該暴露因子在人羣中的分佈情況，保證隊列的代表性。 如果是病例對照研究，從它的別名 – 回顧性研究 – 也可以看出，它的研究起點和隊列研究相反，是從收集到的病例開始的 \\((D=1)\\)。有了病例以後，我們從人羣中沒有該結果變量 \\((D=0)\\) 的人羣中，取適合樣本量的人作爲對照組。然後再分別對病例和對照組用採訪或者問卷，或者調取過去的病例記錄/數據庫記錄等等尋找他們是否接觸過我們要研究的暴露變量。 到這裏，如果你還沒暈，恭喜你應該能理解爲什麼說病例對照研究研究的是 “結果的原因/causes of effect”；隊列研究研究的是 “原因導致的結果/effect of causes”。二者的終極目標卻是一致的 – 尋找暴露和結果二者之間的關係/To investigate the association between exposures and the outcomes – 只是手段不同而已。 觀察性研究 (不論是隊列還是病例對照研究)，除了我們一定會測量並收集的暴露變量數據，在分析過程中還不可避免地需要把混雜效應考慮進來，也就是我們還必須測量並收集那些潛在的混雜因子的數據 \\((W)\\)。圖 50.1 用簡單示意圖總結了 \\(W (\\text{ confounders }), X (\\text{ exposures }), D (\\text{ outcomes })\\) 之間，在不同實驗設計下的關係。 圖 50.1: Path diagrams showing relationships between variables in the underlying population and selection to a cohort study and a case-control study. 50.2 以簡單二分類暴露變量爲例 50.2.1 先決條件 我們以一個最簡單的二分類暴露變量 \\((X)\\)，和一個二分類結果變量 \\((D)\\) 爲例展開： 觀察對象樣本量爲 \\(n, i = 1,\\cdots,n\\)； \\(X_i\\) 爲一個二分類暴露變量 (是否接觸了某種化學試劑，\\(1=\\)是，\\(0=\\)否)； \\(D_i\\) 爲一個二分類結果變量 (是否有食道癌，\\(1=\\)是，\\(0=\\)否)。 所以，該研究的潛在研究人羣可以被分成四組：\\((X=1,D=1),(X=1,D=0),(X=0,D=1),(X=0,D=0)\\)。如果用 \\(\\pi_{11}, \\pi_{10}, \\pi_{01}, \\pi_{00}\\) 標記每組人在該潛在研究人羣中所佔的比例，那麼有： \\[ \\begin{aligned} \\pi_{xd} &amp; = \\text{Pr}(X=x, D=d) \\\\ \\pi_{11} &amp;+ \\pi_{10} + \\pi_{01} + \\pi_{00} = 1 \\end{aligned} \\tag{50.1} \\] 表 50.1: Probabilities associated with binary explanatory and binary response variables in the underlying population structure \\(D\\) \\(0\\) \\(1\\) \\(X\\) \\(0\\) \\(\\pi_{00}\\) \\(\\pi_{01}\\) \\(1\\) \\(\\pi_{10}\\) \\(\\pi_{11}\\) 應用概率標記法來輔助理解隊列研究：我們從潛在研究人羣中抽樣，觀察其暴露情況，再追蹤其結果變量。所以實際上，隊列研究的樣本，來自與對暴露與否 \\((X=0, X=1)\\) 兩組人的抽樣，所以我們實際求的是， \\[ \\begin{equation} \\text{Pr}(D=d|X=x) = \\frac{\\pi_{xd}}{\\pi_{x0} + \\pi_{x1}} \\end{equation} \\] 表 50.2: Probabilities associated with binary explanatory and binary response variables in a cohort study \\(D\\) \\(\\text{Pr}(D=d|X=x)\\) \\(X\\) \\(0\\) \\(1\\) \\(0\\) \\(\\pi_{00}\\) \\(\\pi_{01}\\) \\(\\frac{\\pi_{01}}{\\pi_{01} + \\pi_{00}}\\) \\(1\\) \\(\\pi_{10}\\) \\(\\pi_{11}\\) \\(\\frac{\\pi_{11}}{\\pi_{10} + \\pi_{11}}\\) 相反地，病例對照研究中我們從已有的病例 \\((D=1)\\) 出發，這樣做的理由有很多，通常可能由於病例可能十分稀少，如果建立隊列研究可能需要龐大的樣本量 (即便如此也不一定能夠收集到足夠分析的數據，可能還要花費相當長的隨訪時間，吃力不討好)。所以，在病例對照研究的設計中，我們其實是獨立地從兩個人羣 (病例組，\\(D=1\\)，對照組，\\(D=0\\)) 中抽取樣本。所以，病例對照研究獲得的數據，只能用於計算暴露在病例組和對照組中的條件概率： \\[ \\text{Pr}(X=x|D=d) = \\frac{\\pi_{xd}}{\\pi_{0d}+\\pi_{1d}} \\] 表 50.3: Separate samples from subpopulations \\(D=0,1\\) with relavant conditional probabilities in a case-control study \\(D\\) \\(0\\) \\(1\\) \\(X\\) \\(0\\) \\(\\pi_{00}\\) \\(\\pi_{01}\\) \\(1\\) \\(\\pi_{10}\\) \\(\\pi_{11}\\) \\(\\text{Pr}(X=x|D=d)\\) \\(\\frac{\\pi_{10}}{\\pi_{10}+\\pi_{00}}\\) \\(\\frac{\\pi_{11}}{\\pi_{11}+\\pi_{01}}\\) 50.2.2 比值比 Odds ratios 一項研究 二分類暴露變量 \\(X\\)，和 二分類結果變量 \\(D\\) 之間的關係的研究，我們其實最關心的問題是：結果變量的兩個分類 \\(D=0, D=1\\)，在暴露變量 \\(X=0, X=1\\) 兩組中到底個佔多少比例。用吸菸與肺癌的例子來解釋就是，我們最關心的是，在吸菸人羣中，發生肺癌的人的比例，是否顯著地高於非吸菸人羣中發生肺癌的人的比例，僅此而已。這句話用概率論的標記法來寫的話，則是兩個條件概率：\\(\\text{Pr}(D=1|X=1), \\text{Pr}(D=1|X=0)\\)。此處，可以定義暴露變量 \\(X=1\\) 的條件下，結果變量 \\(D=1\\) 的概率的比值 (Odds)： \\[ \\text{Odds}_1 = \\frac{\\text{Pr}(D=1|X=1)}{1-\\text{Pr}(D=1|X=1)} = \\frac{\\pi_{11}/(\\pi_{10} + \\pi_{11})}{1-\\pi_{11}/(\\pi_{10} + \\pi_{11})} \\] 類似地，暴露變量 \\(X=0\\) 的條件下，結果變量 \\(D=1\\) 的概率的比值 (Odds)： \\[ \\text{Odds}_2 = \\frac{\\text{Pr}(D=1|X=0)}{1-\\text{Pr}(D=1|X=0)} = \\frac{\\pi_{01}/(\\pi_{01} + \\pi_{00})}{1-\\pi_{01}/(\\pi_{01} + \\pi_{00})} \\] 故，從隊列研究中，可以很自然的計算暴露變量和結果變量的比值比： \\[ \\begin{aligned} \\text{Odds Ratio}_{\\text{cohort}} = \\frac{\\text{Odds}_1}{\\text{Odds}_2} &amp; = \\frac{\\frac{\\text{Pr}(D=1|X=1)}{1-\\text{Pr}(D=1|X=1)}}{\\frac{\\text{Pr}(D=1|X=0)}{1-\\text{Pr}(D=1|X=0)}}\\\\ &amp; = \\frac{\\frac{\\pi_{11}/(\\pi_{10} + \\pi_{11})}{1-\\pi_{11}/(\\pi_{10} + \\pi_{11})}}{\\frac{\\pi_{01}/(\\pi_{01} + \\pi_{00})}{1-\\pi_{01}/(\\pi_{01} + \\pi_{00})}} \\\\ &amp; = \\frac{\\frac{\\pi_{11}/(\\pi_{10}+\\pi_{11})}{\\pi_{10}/(\\pi_{10}+\\pi_{11})}}{\\frac{\\pi_{01}/(\\pi_{01}+\\pi_{00})}{\\pi_{00}/(\\pi_{01}+\\pi_{00})}} \\\\ &amp; = \\frac{\\pi_{11}\\pi_{00}}{\\pi_{10}\\pi_{01}} \\end{aligned} \\] 從病例對照研究中，推算的暴露變量和結果變量的比值比是另外一個過程： \\[ \\begin{aligned} \\text{Odds Ratio}_{\\text{case-control}} = \\frac{\\text{Odds}^\\prime_1}{\\text{Odds}^\\prime_2} &amp; = \\frac{\\frac{\\text{Pr}(X=1|D=1)}{1-\\text{Pr}(X=1|D=1)}}{\\frac{\\text{Pr}(X=0|D=0)}{1-\\text{Pr}(X=0|D=0)}} \\\\ &amp; = \\frac{\\frac{\\pi_{11}/(\\pi_{11} + \\pi_{01})}{1-\\pi_{11}/(\\pi_{11} + \\pi_{01})}}{\\frac{\\pi_{10}/(\\pi_{10} + \\pi_{00})}{1-\\pi_{10}/(\\pi_{10} + \\pi_{00})}} \\\\ &amp; = \\frac{\\frac{\\pi_{11}/(\\pi_{11}+\\pi_{01})}{\\pi_{01}/(\\pi_{11}+\\pi_{01})}}{\\frac{\\pi_{10}/(\\pi_{10}+\\pi_{00})}{\\pi_{00}/(\\pi_{10}+\\pi_{00})}} \\\\ &amp; = \\frac{\\pi_{11}\\pi_{00}}{\\pi_{10}\\pi_{01}} \\end{aligned} \\] 經過上面的推演，我們發現用病例對照研究的數據，雖然不能像隊列研究一樣直接推算正確的暴露條件下的比值 (conditional odds given exposure)，卻能用較少的樣本量中獲得真實的比值比 (OR) 。 50.2.3 邏輯迴歸應用於病例對照研究的合理性 在一個隊列研究中，當我們有不止一個暴露變量時，顯然就需要更加複雜的模型來輔助分析 (迴歸型分析法) 暴露變量和結果變量之間的關係。估計比值比最佳的模型是邏輯迴歸。如果 \\(D\\)，表示一個隨機型結果變量，其中每個觀察對象的結果變量服從暴露變量的條件二項分佈 (繼續用單一的二分類暴露變量 \\(x_i\\))： \\[ (D_i|X_i = x_i) \\sim \\text{Binomial}(1, \\pi_i) \\] 所以，可以用邏輯迴歸來擬合： \\[ \\text{logit}(\\pi_i) = \\text{log}(\\frac{\\pi_i}{1-\\pi_i}) = \\alpha + \\beta x_i \\] 把這個邏輯迴歸方程重新整理： \\[ \\begin{aligned} \\text{Pr}(D=1|X=1) &amp; = \\frac{e^{\\alpha + \\beta}}{1 + e^{\\alpha + \\beta}} \\\\ \\text{Pr}(D=1|X=0) &amp; = \\frac{e^\\alpha}{1 + e^\\alpha} \\\\ \\text{Where, }\\alpha &amp; = \\text{log}{\\frac{\\pi_{01}}{\\pi_{00}}} \\\\ \\beta &amp; = \\text{log}{\\frac{\\pi_{11}\\pi_{00}}{\\pi_{10}\\pi_{01}}} \\end{aligned} \\] 在一個病例對照研究中，結果變量 \\(D_i\\) 被鎖死，暴露變量成了服從結果變量的條件二項分佈的隨機變量： \\[ (X_i | D_i = d_i) \\sim \\text{Binomial}(1,\\pi_i^*) \\] 繼續任性地用邏輯迴歸擬合的話： \\[ \\text{logit}(\\pi_i^*) = \\text{log}(\\frac{\\pi_i^*}{1-\\pi_i^*}) = \\alpha^* + \\beta d_i \\] 同樣整理成概率方程： \\[ \\begin{aligned} \\text{Pr}(X=1|D=1) &amp; = \\frac{e^{\\alpha^* + \\beta}}{1 + e^{\\alpha^* + \\beta}} \\\\ \\text{Pr}(X=1|D=0) &amp; = \\frac{e^{\\alpha^*}}{1 + e^{\\alpha^*}} \\\\ \\text{Where, }\\alpha &amp; = \\text{log}{\\frac{\\pi_{10}}{\\pi_{00}}} \\\\ \\beta &amp; = \\text{log}{\\frac{\\pi_{11}\\pi_{00}}{\\pi_{10}\\pi_{01}}} \\end{aligned} \\] 所以，用邏輯迴歸擬合病例對照研究的數據，同樣可以得到和隊列研究一樣正確的比值比估計。但是這個截距 \\(\\alpha\\)，在隊列研究中指的是，非暴露組中患病的比值的對數 (log odds of disease in the unexposed)；在病例對照研究中指的是，對照組中暴露的比值的對數 (log odds of exposure in the controls)。是兩個完全不同含義的估計量。 綜上所述，從一個隊列研究獲得的似然方程是： \\[ \\begin{aligned} L_{\\text{cohort}} &amp; = \\prod_{i=1}^n(\\frac{e^{\\alpha + \\beta x_i}}{1+e^{\\alpha + \\beta x_i}})^{d_i}(\\frac{1}{e^{\\alpha + \\beta x_i}})^{1-d_i} \\\\ \\text{Where } d_i &amp; = \\left\\{ \\begin{array}{ll} 0 \\text{ if subjects were not observed with the outcome}\\\\ 1 \\text{ if subjects were observed with the outcome}\\\\ \\end{array} \\right. \\\\ x_i &amp; = \\left\\{ \\begin{array}{ll} 0 \\text{ if subjects were not observed with the exposure}\\\\ 1 \\text{ if subjects were observed with the exposure}\\\\ \\end{array} \\right. \\end{aligned} \\] 從一個病例對照研究獲得的似然方程是： \\[ \\begin{aligned} L_{\\text{case-control}} &amp; = \\prod_{i=1}^n(\\frac{e^{\\alpha + \\beta d_i}}{1+e^{\\alpha + \\beta d_i}})^{x_i}(\\frac{1}{e^{\\alpha + \\beta d_i}})^{1-x_i} \\\\ \\text{Where } d_i &amp; = \\left\\{ \\begin{array}{ll} 0 \\text{ if subjects were not observed with the outcome}\\\\ 1 \\text{ if subjects were observed with the outcome}\\\\ \\end{array} \\right. \\\\ x_i &amp; = \\left\\{ \\begin{array}{ll} 0 \\text{ if subjects were not observed with the exposure}\\\\ 1 \\text{ if subjects were observed with the exposure}\\\\ \\end{array} \\right. \\end{aligned} \\] 50.3 拓展到多個暴露變量的邏輯迴歸模型 現在來考慮 \\(p\\) 個暴露變量的情況：\\(X_1, \\cdots, X_p\\)，這些暴露變量可以是分類型變量，也可以是連續型變量，例如， \\(D_i = 0 \\text{ or } 1\\)，第 \\(i\\) 名研究對象觀察到有 \\((=1)\\)，或沒有 \\((=0)\\) 結果變量 (如發生胰腺癌)； \\(X_{i1} = 0 \\text{ or } 1\\)，第 \\(i\\) 名研究對象有 \\((=1)\\)，或沒有 \\((=0)\\) 暴露變量 (如吸菸)； \\(X_{i2} = 0 \\text{ or } 1\\)，第 \\(i\\) 名研究對象是男性 \\((=1)\\)，或女性 \\((=0)\\)； \\(X_{i3}\\)，第 \\(i\\) 名研究對象的年齡 (years)。 50.3.1 Mantel Haenszel 法 如果數據有且只有兩個暴露變量，\\(X_1, X_2\\)，其中 \\(X_1\\) 是一個二分類變量，\\(X_2\\) 是一個可以分成 \\(C\\) 組的分類變量。那麼如果樣本量足夠大，可以把數據整理成 \\(C\\) 個四個表用於分析每一個 \\(X_2\\) 的分層中 \\(X_1\\) 和結果變量 \\(D\\) 之間的關係。多層數據的合併比值比可以用 Mantel Haenszel 法。此法在兩個分類暴露變量的情況下還能適用，當某個(或兩個)分類變量的層數越來越多時，你會發現最終落到小格子裏的樣本量急劇下降，侷限性就體現了出來。另外，此法亦不能應用於連續型變量的調整，用處簡直就是捉襟見肘。迫切地我們需要有更加一般的 (藉助於迴歸的威力的) 方法來對多個暴露變量進行調整。 50.3.2 隊列研究和病例對照研究的似然 一個隊列研究，用邏輯迴歸擬合其結果變量 (因變量) \\(D\\) 和暴露變量 \\(X_1, \\cdots, X_p\\) 之間的關係時，可以寫作： \\[ \\begin{aligned} D_i=1 | (X_{i1} &amp; = x_{i1}, \\cdots, X_{ip} = x_{ip}) \\sim \\text{Binomial}(1, \\pi_i) \\\\ \\text{logit} (\\pi_i) &amp; = \\text{log}(\\frac{\\pi_i}{1-\\pi_i}) = \\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip} \\end{aligned} \\] 將這個迴歸方程重新整理成爲概率方程： \\[ \\text{Pr}(D_i = 1 | X_{i1} = x_{i1}, \\cdots, X_{ip} = x_{ip}) = \\frac{e^{\\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}}}{1+e^{\\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}}} \\] 截距 \\(\\alpha\\) 的含義是，當所有的暴露變量都取 \\(0\\) 時，研究對象觀察到結果變量爲 \\(1\\) 的對數比值 \\((\\text{log odds})\\)； 迴歸係數 \\(\\beta_k\\) 的含義是，當其餘的暴露變量保持不變時，\\(x_k\\) 每增加一個單位，結果變量爲 \\(1\\) 的對數比值比 \\((\\text{log odds-ratio})\\) (即，調整了其餘所有變量之後，\\(x_k\\) 和結果變量之間的對數比值比)。 所以，隊列研究的數據，其似然方程是： \\[ \\begin{aligned} L_{\\text{cohort}} &amp; = \\prod_{i=1}^n\\text{Pr}(D_i = d_i | X_{i1} = x_{i1}, \\cdots, X_{ip} = x_{ip}) \\\\ &amp; = \\prod_{i=1}^n\\text{Pr}(\\frac{e^{\\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}}}{1+e^{\\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}}})^{d_i}(\\frac{1}{1+e^{\\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}}})^{1-d_i} \\end{aligned} \\] 當數據變成了病例對照研究，其似然方程會變成怎樣呢？ \\[ L_{\\text{case-control}} = \\prod_{i=1}^n\\text{Pr}(X_{i1} = x_{i1}, \\cdots, X_{ip} = x_{ip} |D_i = d_i) \\] 這裏，我們很難看出這到底是怎樣的一個條件概率，如果預測變量中同時包括了連續型變量和分類變量，情況就更加複雜，剪不斷理還亂。 50.3.3 病例對照研究中的邏輯迴歸 用 \\(\\text{Pr}(S_i=1 \\text{ or } 0)\\) 表示在潛在研究人羣 (underlying study population) 中，被抽樣 (或者沒有被抽樣) 進入該隊列研究的概率。那麼，理想情況下，可認爲實施病例對照研究時，病例是稀少的，即我們收集到的病例，幾乎等價於我們關心的潛在研究人羣中全部的病例，且可以被證明： \\[ \\begin{aligned} &amp; \\text{Pr}(X_{i1} = x_{i1}, \\cdots, X_{ip} = x_{ip} |D_i = 1) \\\\ =&amp; \\text{Pr}(X_{i1} = x_{i1}, \\cdots, X_{ip} = x_{ip} |D_i = 1, S_i=1) \\\\ =&amp; \\frac{e^{\\alpha^* + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}}}{1+e^{\\alpha^* + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}}} \\\\ &amp; \\;\\;\\;\\; \\times \\frac{\\text{Pr}(X_{i1} = x_{i1}, \\cdots, X_{ip} = x_{ip} |S_i=1)}{\\text{Pr}(D_i = 1 | S_i = 1)} \\\\ \\text{Where } \\alpha^* &amp; = \\alpha + \\text{log}(\\frac{\\text{Pr}(D_i = 0)}{\\text{Pr}(D_i = 1)}) + \\text{log}(\\frac{\\text{Pr}(D_i = 1|S_i=1)}{\\text{Pr}(D_i = 0|S_i=1)}) \\end{aligned} \\tag{50.2} \\] 概率方程 (50.2) 中，可以看出第一部分 \\(\\frac{e^{\\alpha^* + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}}}{1+e^{\\alpha^* + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}}}\\) 是一個邏輯迴歸模型。跟隊列研究的邏輯迴歸模型相比較，差別只是截距不同 \\(\\alpha \\neq \\alpha^*\\)。其餘的部分如 \\(\\text{Pr}(X_{i1} = x_{i1}, \\cdots, X_{ip} = x_{ip} |S_i=1)\\) 的含義是潛在人羣中被取樣放入該隊列研究，且預測變量各自不同的隨機概率分佈，其實和我們尋找的參數 \\(\\beta_1,\\cdots,\\beta_p\\)，是沒有什麼關係的。最後一部分分母的 \\(\\text{Pr}(D_i = 1 | S_i = 1)\\) 的意思是，結果變量爲 \\(1\\) 的人被選入本項病例對照研究的概率，理想的實驗設計下這被認爲是接近於 \\(1\\) 的，即使不是，它也是一個固定不變的常數。所以，病例對照研究的似然方程中，我們關心的只有第一部分，邏輯迴歸模型： \\[ L_{\\text{case-control}} \\propto \\prod_{i=1}^n(\\frac{e^{\\alpha^* + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}}}{1+e^{\\alpha^* + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}}})^{d_i}(\\frac{1}{1+e^{\\alpha^* + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}}})^{1-d_i} \\] 這裏必須明確的一點是，病例對照研究擬合的邏輯迴歸，其截距是 \\(\\alpha^*\\)，並非 \\(\\alpha\\)。這個 \\(\\alpha^*\\) 其實是包含了 \\(\\text{Pr}(D_i=1),\\text{Pr}(D_i=0)\\) 的，可惜這些概率也無法用病例對照研究設計獲得。所以，病例對照研究數據擬合了邏輯迴歸模型以後的截距，其實沒有太多實際的含義。 50.4 流行病學研究中變量的調整策略 圖 50.2: relationships between three variables in an underlying population of interest 圖 50.2 展示的是在潛在研究人羣中 \\(W (\\text{potential confounder}),X (\\text{exposure}),D (\\text{outcome})\\) 三者之間可能存在的四種關係。 圖 50.2 - (a) \\(W\\) 和 \\(X, D\\) 都沒有關係，那麼我們研究 \\(X,D\\) 之間的關係時，完全可以忽略掉 \\(W\\)，不用調整。 但是，如果在邏輯迴歸模型中調整了一個和暴露變量結果變量之間無關的變量，獲得的比值比估計幾乎不會有太大改變，但是代價是會獲得較大的對數比值比的標準誤 (standard error)，降低了對比值比估計的精確程度。 圖 50.2 - (b) \\(W\\) 和 \\(X, D\\) 同時都相關，且不在 \\(X\\rightarrow D\\) 的因果關係通路上，此種情況下，必須對 \\(W\\) 進行調整，否則獲得的比值比估計是帶有嚴重偏倚的。 圖 50.2 - (c) \\(W\\) 僅僅和 \\(X\\) 有關係，和結果變量 \\(D\\) 沒有相關性。此時研究 \\(X,D\\) 之間的關係時，忽略掉 \\(W\\)，不需要對之進行任何調整。和 (a) 一樣，如果此時調整了 \\(W\\)，估計的比值比不會發生質變，但是會損失估計的精確度。 圖 50.2 - (d) \\(W\\) 僅僅和結果變量 \\(D\\) 有關係，和暴露變量 \\(X\\) 無關時，如果模型對 \\(W\\) 進行調整，我們會獲得完全不同的比值比估計，因爲這種情況下其實調整 \\(W\\) 前後的比值比估計的是具有不同含義的，二者都具有實際意義。調整前的估計量，是總體估計，有助於作總體的決策；調整後的估計量，是帶有某些特徵的部分人羣估計，有助於評價個人水平的 \\(X,D\\) 之間的關係。 "],
["section-51.html", "第 51 章 分析策略 51.1 明確分析目的 51.2 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect) 51.3 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect) 51.4 分析目的 2 和 3 – 建立預測模型 (predictive models)", " 第 51 章 分析策略 51.1 明確分析目的 作爲統計學家，着手分析數據之前，千萬記得，必須要制定一個儘可能詳盡的分析計劃。即使你的分析，可能並不一定受到第三方的監管或者調控，因爲同行評審的專家們，喜歡看到你分析的目的明確，假設檢驗的過程是經過仔細推敲的。同時，也可以避免陷入 “玩弄數據 (data dredging)” 指控的危險。 數據分析的目的，可以分成三大類： 估計一個或者幾個暴露變量，對結果變量的影響。以此目的的數據分析過程，需要我們有醫學偵探一樣的眼光和見解，從數據中判斷那些需要被調整和控制的混雜因子，從而提高你的分析效率。最常見的例子是分析隨機對照臨牀實驗 (RCT) 中，療效的差異；或者流行病學研究中，分析某種生活習慣，和疾病的發生或者死亡之間的關係。 在現有的數據庫中，尋找並且建立 “最佳” 模型。以此目的的數據分析，需要我們對模型中的結果變量有極爲深入的瞭解，把與之相關的所有要因，儘可能多的納入你的分析模型。常見的例子如，在某個特定人羣的數據庫中尋找並確定能夠決定自殺這一結果變量的決定性因素，之所以有這樣的目的，背後可能有決策者希望尋找這些決定性因素後採取一些對策從而達到改善現狀的最終目的。所以找到和結果變量相關的因素，是此類研究的重中之重。 建立預測模型。例如，某項研究的目的是爲了能夠建立一個能夠預測孕期胎兒患有唐氏綜合症的預測模型，用能夠測量的一些指標(如血液指標，或者母親的一些健康指標)，通過模型的算法，去計算胎兒患病的概率是多大。這樣的模型，對與診斷醫學有重大意義。所以，此類研究的目的，不是爲了尋找確定和胎兒患病相關的全部要因，而是怎樣才能提高模型預測的準確度，提高診斷的效率，減少錯誤診斷，拯救生命。 當然，上述目的中的 2 和 3 有時候易讓人混淆，因爲我們可能建立最佳模型，除了想要找到和 “自殺” 這一結果相關的所有要因，還可能希望通過該模型做出預測，尋找可能自殺的高危人羣，進行干預。這並不矛盾。 51.2 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect) 先揀最軟的柿子捏，RCT 的療效比較作爲數據分析的目的時，情況要比其他的目的相對簡單些。RCT 的隨機過程，確保了臨牀試驗不會受到混雜因素的影響。但是我們還會出於爲了提高統計分析效能，改善估計的精確度的目的，對參與臨牀試驗的受試者最初測量的一些特徵進行調整。當然，不是所有的數據專家，也不是所有的 RCT 實施者都同意進行這一調整的。如果確定要調整，放入模型中的變量，可能常常是一開始隨機分配時用到的那些用於將受試者分層歸類或者最小化 (minimisation) 的那些變量。 基線值調整 (baseline adjustment)，在結果變量爲連續型，同時模型是線性迴歸模型時，能夠顯著提高統計效能 (statistical efficiency)，降低估計值的標準誤。理論上，一個基線測量時的連續型變量，如果它和實驗後測量的連續型結果變量之間的 皮爾森相關係數 Pearson correlation coefficient 是 \\(r\\)，那麼如果你用 ANCOVA 模型調整了這個基線值的話，療效差異估計值的標準誤會是沒有調整時的 \\(\\sqrt{1-r^2}\\) 倍 (也就是永遠比不調整時要小，大大提高精確度，縮小療效差異估計值的 95% 信賴區間)。 但是，但是，但是！如果一個 RCT 測量的結果變量是一個二分類變量 (死亡/存活)，線性迴歸模型不適用，只能使用邏輯迴歸時，模型中加入和結果變量相關 (和暴露變量無關) 的基線值的做法对分析效能的提高顯得十分有限，相反還会受到邏輯迴歸的不可壓縮性較大的影響 (Section 49.3.2)。 再把之前講邏輯迴歸不可壓縮性時用过的例子拿过来这里解释这个现象： 表 51.1: Non-collapsibility of logit link in GLM (stratified data) Strata 1 Strata 2 Outcome Drug Placebo Drug Placebo Success 90 50 50 10 Failure 10 50 50 90 Total 100 100 100 100 Odds Ratios 9 9 上面的數據表示，分層變量 (Strata 1-2) 本身和使用藥物和安慰劑無交互作用，也和藥物使用與臨牀試驗結果之間的關係無關。但是，即使這個分類變量無關，壓縮後的數據計算獲得的比值比和分層時的比值比差異巨大： 表 51.2: Non-collapsibility of logit link in GLM (collapsed data) Outcome Drug Placebo Success 140 60 Failure 60 140 Total 200 200 Odds ratio 5.4 實際在 R 裏擬合邏輯迴歸模型的結果如下： ## ## Call: ## glm(formula = Result ~ Treatment, family = binomial(link = logit), ## data = RCT) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.5518 -0.8446 0.0000 0.8446 1.5518 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.84730 0.15430 5.4911 3.994e-08 *** ## TreatmentPlacebo -1.69460 0.21822 -7.7656 8.125e-15 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 554.518 on 399 degrees of freedom ## Residual deviance: 488.691 on 398 degrees of freedom ## AIC: 492.691 ## ## Number of Fisher Scoring iterations: 4 ## ## Call: ## glm(formula = Result ~ Treatment + Strata, family = binomial(link = logit), ## data = RCT) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.1460 -1.1774 0.0000 1.1774 2.1460 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 2.19722 0.26505 8.2898 &lt; 2.2e-16 *** ## TreatmentPlacebo -2.19722 0.27486 -7.9941 1.306e-15 *** ## Strata2 -2.19722 0.27486 -7.9941 1.306e-15 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 554.518 on 399 degrees of freedom ## Residual deviance: 407.292 on 397 degrees of freedom ## AIC: 413.292 ## ## Number of Fisher Scoring iterations: 4 從結果的迴歸係數估計和計算的標準誤來看，調整了其他的變量會引起： 使對數比值比的估計量升高 (這是由於模型的不可壓縮性) \\(1.69 \\rightarrow 2.19\\)； 對數比值比的標準誤估計升高 (非但不能增加估計精確度，反而起到了反作用) \\(0.22\\rightarrow0.27\\)； 對數比值比的統計檢驗量升高 (由於對數比值比的升高比標準誤升高的更多一些) \\(7.77\\rightarrow7.99\\)。 事實上，上面的現象在使用邏輯迴歸的時候基本上都會呈現。在經典論文 (Robinson and Jewell 1991) 中給出了詳細的論證。所以其實使用邏輯迴歸擬合數據的 RCT 臨牀試驗，我們可以推論，當模型中加入第三個僅和結果變量有關的基線共變量 (baseline covariates)，如果模型估計的對數比值比在調整前後變化不大 (即，不可壓縮性造成的影響很小)，那這樣的調整對於改善分析的統計效能上幾乎也沒有貢獻。(跟使用線性迴歸的 RCT 完全不同！) 由於邏輯迴歸受使用 \\(\\text{logit}\\) 鏈接方程時不可壓縮性的侷限，同時還由於使用 \\(\\text{log}\\) 鏈接方程時獲得的危險度比 (risk ratios) 比比值比 (odds ratios) 更加容易讓人理解，結果變量爲二分類的 RCT 臨牀試驗常常會選用 \\(\\text{log}\\) 鏈接方程的廣義線性迴歸模型 (見 Section 45.3 第 5 條討論)。選用 \\(\\text{log}\\) 鏈接方程的 GLM 最大的問題在於，當模型中加入過多的預測變量時，會導致模型無法收斂 (converge)–無法找到極大似然估計。 至於使用泊松迴歸模型的時候，預測變量如果放入不合理，那麼很容易違反泊松分佈的前提 (方差和均值相同)。對於違反了泊松分佈前提，模型變得過度離散 (over-dispersed) 的 GLM，加入適當的基線共變量 (baseline covariates) 則有助於減少模型的過度離散，減小參數估計的標準誤 (使之變得更精確些)。和線性迴歸相同的是，泊松迴歸模型不受不可壓縮性 (non-collapsibility) 的影響。 51.2.1 RCT 數據分析的一些不成熟的小建議 RCT 臨牀試驗通常都有嚴格的數據管理和監控，且統計分析計劃 (statistical analysis plan, SAP) 在任何一個 RCT 都已經是必須條件。除此之外，還要在試驗進行前就制訂所有詳細的計劃，並寫成實驗實施計劃文件，以供參與的所有人及倫理審查委員會等各種第三方機構的監督。所以，RCT 的統計分析計劃必須儘量考慮到所有的可能情況，因爲一旦開始了試驗，分析計劃是很難改動的。 SAP 必須詳細記錄哪些共變量需要被調整，常見的是實驗設計階段用於實施隨機化過程的那些特徵變量。對於連續型結果變量，(還有過度離散的計數型變量)，基線共變量的調整許多時候會有助於改善參數估計的精確度，提高統計效能。對於使用邏輯迴歸模型的試驗，調整基線共變量則沒有太多的好處，且調整後的比值比的含義會發生較大的改變，需慎重。 有些統計學家支持調整基線共變量，認爲這樣做有助於減少萬一隨機化不徹底造成的治療組和對照組之間隨機產生的殘差偏倚 (residual bias)，但是你無法提前欲知那些變量可能會產生隨機的殘差偏倚，這樣便無法在事先需要準備的SAP計劃文件中明確到底哪些基線變量需要被調整。 另有許多研究者喜歡在 RCT 中尋找交互作用的存在，但是他們常常忽略掉的一點是，一個 RCT 本身的檢驗效能是 80%-90%，其用於檢驗交互作用的效能會更低。建議在 RCT 中儘量少 (甚至不建議) 進行任何交互作用的統計檢驗。 51.3 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect) 前文討論的關於調整僅僅和結果變量相關 (與暴露變量無關) 的基線共變量的內容，同樣適用與一般的流行病學研究。流行病學研究中另一個 (應該是更加) 重要的點是，混雜因子的排查和調整。 實例： \\(Y\\) 標記結果變量，如嬰兒的出生體重； \\(X_1\\) 標記最主要的 (想要分析其與結果變量之間的關係的) 預測變量，如母親孕期高血壓 (是/否)； \\(X_2, X_3, \\cdots, X_Q\\) 標記其他非主要預測變量，但是可能是 \\(X_1, Y\\) 之間關係中重要的潛在混雜因子，如嬰兒的性別/母親孕前體重/嬰兒胎齡等等。 在這個簡單流行病學研究實例中，我們關心的問題包括： 主要暴露變量–孕期高血壓，和結果變量–嬰兒出生體重二者的未调整前 (粗) 關係 (crude/before adjustment association) 是什麼樣的？ 主要暴露變量和結果變量之間的關係是否被其他因素影響 (例如胎齡)？如果有，那麼調整後的關係會發生怎樣的變化？ 有沒有其他的變量會改變 (modify) 主要暴露變量和結果變量之間的關係？也就是，有沒有那個變量和主要暴露變量有交互作用？ 有沒有其他的變量和主要暴露變量無關，卻可能和結果變量有關係呢？如果存在這樣的變量，模型中調整它在一些情況下可能會改善擬合的結果提高模型的統計效能 (statistical power)。 收集的變量中，有沒有哪個變量可能是在主要暴露變量和結果變量之間因果關係 (如果存在因果關係的話) 的通路上 (on the causal pathway) 的呢？如果有，這樣的變量應該被認爲是媒介因子 (mediator)。 51.3.1 不成熟的小策略 這是很常見的簡單流行病學數據分析。可以按照 (但不一定非要按照) 下面建議的步驟實施統計分析： 第一步，分析主要暴露變量和結果變量之間的未調整前 (粗) 關係： \\[g\\{ E(Y|X_1) \\} = \\alpha + \\beta_1 X_1\\] 第二步，逐個分析其餘的變量和主要暴露變量之間的關係，以及這些潛在的混雜因子和結果變量之間的關係。注意，這一步可能耗時較長，但是它並不是決定模型中是否要加入某個或某些非主要暴露變量的步驟，通過這一步過程有助於我們分析和理解，進一步分析中調整前後的參數估計變化。 第三步，建立主要暴露變量和這些潛在混雜因子同時放入模型中的 GLM，逐步放入，一次放入一個 (one at a time) 潛在混雜因子，和上一步分析的三者之間的關係相結合，分析調整該潛在混雜因子前後，主要暴露變量的迴歸係數的參數估計變化的原因。 \\[g\\{ E(Y|X_1, X_k) \\} = \\alpha^* + \\beta_1^*X_1 + \\beta_kX_k,\\; k= 1,\\cdots,Q\\] 我們來分析這個可以從 Stata 網站上下載的數據： 第一步，先看看暴露變量和結果變量之間的關係 lbw &lt;- read_dta(&quot;http://www.stata-press.com/data/r12/lbw.dta&quot;) lbw$race &lt;- factor(lbw$race) lbw$smoke &lt;- factor(lbw$smoke) lbw$ht &lt;- factor(lbw$ht) a &lt;- Epi::stat.table(list(&quot;Birthweight &lt;2500g&quot; = low, &quot;History of hypertension&quot;=ht), list(count(),percent(low)), data = lbw, margins = TRUE) # We first tabulate the data print(a, digits = c(percent = 2)) ## -------------------------------------- ## -History of hypertension- ## Birthweight 0 1 Total ## &lt;2500g ## -------------------------------------- ## 0 125 5 130 ## 70.62 41.67 68.78 ## ## 1 52 7 59 ## 29.38 58.33 31.22 ## ## ## Total 177 12 189 ## 100.00 100.00 100.00 ## -------------------------------------- 第二步，分析母親高血壓病史和嬰兒低出生體重之間的調整前 (粗) 關係。 Model0 &lt;- glm(low~ht, data = lbw, family = binomial(link = &quot;logit&quot;)) summary(Model0); epiDisplay::logistic.display(Model0) ## ## Call: ## glm(formula = low ~ ht, family = binomial(link = &quot;logit&quot;), data = lbw) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.32323 -0.83407 -0.83407 1.56519 1.56519 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.87707 0.16502 -5.3150 1.066e-07 *** ## ht1 1.21354 0.60835 1.9948 0.04606 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 234.672 on 188 degrees of freedom ## Residual deviance: 230.650 on 187 degrees of freedom ## AIC: 234.65 ## ## Number of Fisher Scoring iterations: 4 ## ## Logistic regression predicting low ## ## OR(95%CI) P(Wald&#39;s test) P(LR-test) ## ht: 1 vs 0 3.37 (1.02,11.09) 0.046 0.045 ## ## Log-likelihood = -115.3249 ## No. of observations = 189 ## AIC value = 234.6499 所以，數據提供了一些證據證明母親的高血壓病史和嬰兒低出生體重之間可能存在正關係，這個調整前的關係是，粗比值比 (crude odds ratio) 爲 3.37 (1.02, 11.09)。 接下來，分析潛在的混雜因子是否和主要暴露變量相關： # lwt is the last weight of mothers before pregnancy Model1 &lt;- lm(lwt ~ ht, data = lbw) summary(Model1); epiDisplay::regress.display(Model1) ## ## Call: ## lm(formula = lwt ~ ht, data = lbw) ## ## Residuals: ## Min 1Q Median 3Q Max ## -62.5000 -17.9435 -7.9435 10.0565 122.0565 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 127.9435 2.2390 57.1426 &lt; 2e-16 *** ## ht1 29.5565 8.8858 3.3262 0.00106 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 29.788 on 187 degrees of freedom ## Multiple R-squared: 0.05586, Adjusted R-squared: 0.050811 ## F-statistic: 11.064 on 1 and 187 DF, p-value: 0.0010596 ## Linear regression predicting lwt ## ## Coeff.(95%CI) P(t-test) P(F-test) ## ht: 1 vs 0 29.56 (12.03,47.09) 0.001 0.001 ## ## No. of observations = 189 可見，有高血壓病史的母親，孕前體重較高。再看其與結果變量是否有關係： Model2 &lt;- glm(low ~ lwt, data = lbw, family = binomial(link = &quot;logit&quot;)) summary(Model2); epiDisplay::logistic.display(Model2) ## ## Call: ## glm(formula = low ~ lwt, family = binomial(link = &quot;logit&quot;), data = lbw) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.09482 -0.90217 -0.80197 1.36105 1.98141 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.9957634 0.7852434 1.2681 0.20476 ## lwt -0.0140371 0.0061685 -2.2756 0.02287 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 234.672 on 188 degrees of freedom ## Residual deviance: 228.708 on 187 degrees of freedom ## AIC: 232.708 ## ## Number of Fisher Scoring iterations: 4 ## ## Logistic regression predicting low ## ## OR(95%CI) P(Wald&#39;s test) P(LR-test) ## lwt (cont. var.) 0.99 (0.97,1) 0.023 0.015 ## ## Log-likelihood = -114.354 ## No. of observations = 189 ## AIC value = 232.7081 由此知，母親孕前體重較高的人，有較低的可能剩下低出生體重的嬰兒。這兩個單獨的關係，各自看都具有 5% 的統計學意義，但是這 (或者其他變量分析的結果沒有統計學意義時) 並不是決定模型中是否加入母親孕前體重這一潛在的混雜因子的理由。接下來，我們通過模型中加入母親孕前體重這一變量前後模型的參數估計變化來分析： Model3 &lt;- glm(low ~ ht + lwt, data = lbw, family = binomial(link = &quot;logit&quot;)) summary(Model3);epiDisplay::logistic.display(Model3) ## ## Call: ## glm(formula = low ~ ht + lwt, family = binomial(link = &quot;logit&quot;), ## data = lbw) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.85912 -0.87274 -0.73845 1.29224 2.17964 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.4478621 0.8208975 1.7638 0.077773 . ## ht1 1.8544773 0.7008245 2.6461 0.008142 ** ## lwt -0.0186285 0.0065928 -2.8256 0.004720 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 234.672 on 188 degrees of freedom ## Residual deviance: 221.165 on 186 degrees of freedom ## AIC: 227.165 ## ## Number of Fisher Scoring iterations: 4 ## ## Logistic regression predicting low ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## ht: 1 vs 0 3.37 (1.02,11.09) 6.39 (1.62,25.23) 0.008 0.006 ## ## lwt (cont. var.) 0.99 (0.97,1) 0.98 (0.97,0.99) 0.005 0.002 ## ## Log-likelihood = -110.5827 ## No. of observations = 189 ## AIC value = 227.1654 加入了孕前體重的模型給出的母親是否有高血壓病史對嬰兒的低出生體重關係的比值比估計爲 \\(6.39\\)，這很明顯比調整孕前體重前的粗比值比 \\((3.37)\\) 大了很多。這個比值比估計的變化有兩個原因： (常被忽略的) 邏輯迴歸模型的不可壓縮性導致的； 母親孕前體重對高血壓病史和嬰兒的低出生體重之間的關係造成了混雜效應。 上面的分析結果，告訴我們，數據提供了足夠的證據證明母親孕前體重和是否有高血壓病史，在調整了彼此之後，仍然獨立地和嬰兒低出生體重的發生有相關性。這裏，我們可以下結論認爲，模型中加入母親孕前體重作爲混雜因子，是合情合理的。 完成了目前爲止的初步分析和混雜因子的判斷以後，下一階段的分析側重於尋找有沒有任何第三方的預測變量，會對主要暴露變量 \\(X_1\\) (孕期高血壓) 與結果變量 \\(Y\\) (嬰兒出生體重過低) 之間的關係產生交互作用。如果數據中的預測變量有多個，那可能導致需要分析潛在的交互作用有許多對，通常建議在遇到多個預測變量之間的複雜關係需要討論的時候，建議不要一股腦全部作交互作用的分析，而是限定一個或者幾個最有可能有交互作用的變量就可以了。否則模型過於複雜，反而不利於理解。一般生物醫學的統計分析中考慮的重要交互作用分析，需要有重要的生物學意義，常見的例子是年齡，性別等。 本節使用的例子中，令人感興趣的是，母親的孕前體重，會不會對妊娠高血壓的有無與嬰兒出生體重過低之間的關係造成交互作用： Model4 &lt;- glm(low ~ ht*lwt, family = binomial(link = &quot;logit&quot;), data = lbw) summary(Model4); epiDisplay::logistic.display(Model4) ## ## Call: ## glm(formula = low ~ ht * lwt, family = binomial(link = &quot;logit&quot;), ## data = lbw) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.77338 -0.87349 -0.74658 1.28246 2.20403 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.5393115 0.9174755 1.6778 0.093392 . ## ht1 1.2869895 2.5493528 0.5048 0.613678 ## lwt -0.0193796 0.0074129 -2.6143 0.008941 ** ## ht1:lwt 0.0037324 0.0161735 0.2308 0.817490 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 234.672 on 188 degrees of freedom ## Residual deviance: 221.113 on 185 degrees of freedom ## AIC: 229.113 ## ## Number of Fisher Scoring iterations: 4 ## ## Logistic regression predicting low ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## ht: 1 vs 0 3.37 (1.02,11.09) 3.62 (0.02,535.73) 0.614 0.605 ## ## lwt (cont. var.) 0.99 (0.97,1) 0.98 (0.97,1) 0.009 1 ## ## ht1:lwt - 1.0037 (0.9724,1.0361) 0.817 0.819 ## ## Log-likelihood = -110.5567 ## No. of observations = 189 ## AIC value = 229.1133 由於交互作用項結果爲 ht1:lwt 0.003732 0.016173 0.231 0.81749，無足夠的證據證明孕前體重會對妊娠高血壓和嬰兒出生體重過低之間的關係造成交互作用。 如果確認沒有交互作用，建立本例最終模型前的幾個建議： 最終分析 \\(X_1, Y\\) 之間關係的模型，需要加入我們逐一甄別之後確認過的混淆因子，此時稱爲模型 1； 對於確認不是 \\(X_1, Y\\) 之間關係的混淆因子的那些剩餘變量，逐一加入模型 1，比較前後是否模型中各個混淆因子的參數估計是否發生了變化 (有沒有混淆因子的混淆因子？)； 最終模型中的變量，需要包含前兩步確認過的全部混淆因子； 在報告中把調整前後的參數估計整理成表格。 如果在分析過程中發現了有重要意義的交互作用，那麼除了包含全部的混淆因子之外，你的最終模型中還需加入重要的交互作用項。此時需要報告的參數估計是有交互作用項部分的分層比值比/其他指標。 51.3.2 補充 除了使用二項分佈的邏輯迴歸之外，當結果變量是連續型或者計數型，也就是分析模型使用線性迴歸 (ANCOVA)，或者 (可能過度離散的) 泊松迴歸時，爲了提高模型的統計效能，減小參數估計的標準誤，模型可以選擇進一步調整一個或幾個只和結果變量有關的基線變量。此時，在你寫論文或者報告時，必須把這些變量和確認是混雜因子的變量加以區分，因爲加它們進入模型的目的不同。 51.4 分析目的 2 和 3 – 建立預測模型 (predictive models) 建立預測模型的過程，其實就是選擇哪個或者那些變量進入模型的過程。方法有很多，可惜的是，沒有哪種是公認完美的。這裏只介紹兩種最常見，也最常被批評的方法 – 前/後 逐步選擇法 (forward stepwise selection/backward elimination)。強調一下，逐步法本身並不是神奇法術，不同的算法選擇的變量自然會有不同，如果你用了逐步選擇法，選出來的模型變量僅僅只能作爲參考，而不能作爲最終結論。 vitc &lt;- haven::read_dta(&quot;backupfiles/vitC.dta&quot;) vitc$ctakers &lt;- factor(vitc$ctakers) vitc$sex &lt;- factor(vitc$sex) step(lm(seruvitc~1,data=vitc[complete.cases(vitc),]),direction=&quot;forward&quot;,scope=~age+height+weight+sex+cigs+ctakers) ## Start: AIC=575.43 ## seruvitc ~ 1 ## ## Df Sum of Sq RSS AIC ## + ctakers 1 6967.43 42659.6 563.663 ## + sex 1 3688.53 45938.5 570.402 ## + cigs 1 2470.90 47156.1 572.783 ## + height 1 1243.73 48383.3 575.121 ## &lt;none&gt; 49627.0 575.430 ## + age 1 273.59 49353.4 576.927 ## + weight 1 1.53 49625.5 577.427 ## ## Step: AIC=563.66 ## seruvitc ~ ctakers ## ## Df Sum of Sq RSS AIC ## + sex 1 2713.526 39946.0 559.683 ## + cigs 1 2150.581 40509.0 560.956 ## + height 1 1049.000 41610.6 563.398 ## &lt;none&gt; 42659.6 563.663 ## + age 1 247.944 42411.6 565.133 ## + weight 1 18.227 42641.3 565.625 ## ## Step: AIC=559.68 ## seruvitc ~ ctakers + sex ## ## Df Sum of Sq RSS AIC ## + cigs 1 1527.704 38418.3 558.134 ## &lt;none&gt; 39946.0 559.683 ## + weight 1 445.296 39500.7 560.663 ## + age 1 183.277 39762.8 561.264 ## + height 1 131.722 39814.3 561.382 ## ## Step: AIC=558.13 ## seruvitc ~ ctakers + sex + cigs ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 38418.3 558.134 ## + weight 1 257.1523 38161.2 559.523 ## + age 1 205.2889 38213.0 559.647 ## + height 1 58.2745 38360.1 559.996 ## ## Call: ## lm(formula = seruvitc ~ ctakers + sex + cigs, data = vitc[complete.cases(vitc), ## ]) ## ## Coefficients: ## (Intercept) ctakers1 sex1 cigs ## 46.0283 19.8317 9.7642 -12.2550 step(lm(seruvitc~.,data=vitc[complete.cases(vitc),]),direction=&quot;backward&quot;) ## Start: AIC=563.38 ## seruvitc ~ serial + age + height + cigs + weight + sex + ctakers ## ## Df Sum of Sq RSS AIC ## - height 1 1.48 37272.5 561.379 ## - age 1 64.18 37335.2 561.532 ## - weight 1 174.65 37445.7 561.801 ## - serial 1 808.36 38079.4 563.328 ## &lt;none&gt; 37271.1 563.375 ## - cigs 1 979.26 38250.3 563.735 ## - sex 1 1123.50 38394.6 564.078 ## - ctakers 1 6407.24 43678.3 575.811 ## ## Step: AIC=561.38 ## seruvitc ~ serial + age + cigs + weight + sex + ctakers ## ## Df Sum of Sq RSS AIC ## - age 1 65.27 37337.8 559.538 ## - weight 1 217.51 37490.0 559.908 ## - serial 1 807.51 38080.1 561.329 ## &lt;none&gt; 37272.5 561.379 ## - cigs 1 977.97 38250.5 561.736 ## - sex 1 2584.37 39856.9 565.479 ## - ctakers 1 6442.37 43714.9 573.887 ## ## Step: AIC=559.54 ## seruvitc ~ serial + cigs + weight + sex + ctakers ## ## Df Sum of Sq RSS AIC ## - weight 1 366.60 37704.4 558.427 ## - serial 1 823.37 38161.2 559.523 ## &lt;none&gt; 37337.8 559.538 ## - cigs 1 944.21 38282.0 559.811 ## - sex 1 2816.28 40154.1 564.155 ## - ctakers 1 6462.15 43800.0 572.064 ## ## Step: AIC=558.43 ## seruvitc ~ serial + cigs + sex + ctakers ## ## Df Sum of Sq RSS AIC ## - serial 1 713.92 38418.3 558.134 ## &lt;none&gt; 37704.4 558.427 ## - cigs 1 1156.10 38860.5 559.176 ## - sex 1 2451.95 40156.4 562.161 ## - ctakers 1 6385.14 44089.5 570.664 ## ## Step: AIC=558.13 ## seruvitc ~ cigs + sex + ctakers ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 38418.3 558.134 ## - cigs 1 1527.70 39946.0 559.683 ## - sex 1 2090.65 40509.0 560.956 ## - ctakers 1 5841.01 44259.3 569.014 ## ## Call: ## lm(formula = seruvitc ~ cigs + sex + ctakers, data = vitc[complete.cases(vitc), ## ]) ## ## Coefficients: ## (Intercept) cigs sex1 ctakers1 ## 46.0283 -12.2550 9.7642 19.8317 References "],
["-model-checking.html", "第 52 章 檢查你的模型 Model Checking 52.1 線性預測方程的定義 52.2 共變量模式殘差 covariate pattern residuals 52.3 鏈接方程 52.4 NHANES 飲酒量數據實例 52.5 Practical 10", " 第 52 章 檢查你的模型 Model Checking 每次定義一個 GLM 模型的時候 (Section 44.2)，均分三步走，所以一個模型會出錯的部分，就在這三步驟中的任何一步： 因變量分佈定義錯誤 (或者分佈的假設不成立) mis-specified distribution: 因變量之間是否相互獨立，且服從某個已知的分佈，這兩個條件中的任意一個不能滿足，第一步都無法成立。例如，最常見的是我們用泊松迴歸模型來擬合計數型數據時，因爲缺乏一些關鍵變量，導致模型遇到過度離散的問題 (over-dispersed for a Poisson distribution due to an omitted covariate)； 線性預測方程定義錯誤 mis-specified linear predictor: 線性預測方程中放入的變量，有的可能需要被轉換 (連續型轉換成分類型，或者是需要數學轉換)。或者是應該加入的交互作用項被我們粗心忽略了； 鏈接方程錯誤 mis-specified link function: 對前一步定義好的線性預測方程，第三步的鏈接方程指定很可能出現錯誤。或者是，我們可以考慮選用別的鏈接方程 (\\(\\text{log instead of logit}\\))，改變了鏈接方程之後，很可能原先認爲有交互作用的變量之間交互作用就消失了 (Section 49.4)。 本章介紹一些廣義線性迴歸模型診斷的方法，這些手段雖然偶爾有一些檢驗方法，但更多的診斷方法需要繪圖通過視覺判斷。介紹邏輯迴歸時解釋過模型比較時使用的模型偏差 (deviance) 概念 (Section 46.3.2) Pearson 的擬合優度檢驗，以及使用 Hosmer-Lemeshow 檢驗法檢驗個人二分類變量數據的邏輯迴歸擬合優度 (Section 46.4) 法。值得注意的是，這些方法是一種整體檢驗 (global test)，其零假設是 “模型可以擬合數據”，如果擬合優度檢驗的結果是拒絕這個零假設，那麼可以認爲模型建立的不佳，即接受 “模型不能擬合數據” 的替代假設。如果擬合優度檢驗的結果是無法拒絕零假設，那麼我們僅僅只能認爲無證據證明 “模型不可以擬合數據”，而不能證明設計的模型可以良好的擬合數據。所以，擬合優度的檢驗結果可以警告我們模型擬合有沒有錯誤，卻不能證明這個模型到底是不是一個良好的模型 (個人感覺應把擬合優度檢驗 goodness of fit 的名稱改爲 擬合劣度檢驗 badness of fit)。 52.1 線性預測方程的定義 線性預測方程定義錯誤的最常見的就是“忽略了不該忽略的交互作用”，及連續型變量可能被以不恰當的方式加入預測方程中。當然，你可以通過把一個變量放入模型前後，該變量本身的迴歸係數是否有意義 (Wald test) 或者你關心的預測變量的迴歸係數的變化程度 (magnitude of the corresponding parameter estimate) 來判斷是否保留這個變量在你的模型裏。這麼做的時候，你要當心自己陷入多重比較 (multiple testing) 的陷阱 (某次或者某幾次出現的統計學有意義的結果，可以僅僅是由於偶然，而不是因爲它真的有意義)。 52.1.1 殘差 觀測值跟擬合值之間的差距，就是我們常說的殘差。 以二項分佈數據爲例， \\[Y_i\\sim\\text{Bin}(n_i, \\pi_i), \\\\ \\text{where n is the number of subjects in one group} \\\\ \\text{logit}(\\pi_i) = \\eta_i\\] 其第 \\(i\\) 個觀測值的原始殘差 (raw residual)，是 \\[ \\begin{aligned} r_i &amp; = y_i - \\hat\\mu_i \\\\ &amp; = y_i - n_i\\hat\\pi_i \\end{aligned} \\] 觀測值 \\(Y_i\\) 的變化程度 (variability) 本身並不是一成不變的 (會根據模型中加入的共變量而改變)，其變化程度可能是觀測值 \\(Y_i\\) 的方差導致的。二項分佈數據的方差已知是 \\(\\text{Var}(Y_i) = n_i\\pi_i(1-\\pi_i)\\)。舉個栗子，如果 \\(n_i = 10, \\hat\\pi_i = 0.01, Y_i = 10\\)，那麼 \\(r_i \\approx 10\\)，這是一個很差的擬合效果。如果，\\(n_i = 100000, \\hat\\pi_i = 0.5, Y_i = 5010\\)，那麼 \\(r_i = 10\\)，此時的殘差也是 \\(10\\) 又證明了這是一個擬合效果良好的模型。相同的殘差，由於方差不同，判斷則不一樣，所以我們需要有一個類似簡單線性迴歸中標準化殘差 (Section 31.6.1) 的過程 – Pearson 殘差: \\[ p_i = \\frac{r_i}{\\sqrt{\\hat{\\text{Var}}}(Y_i)} \\] 所以，二項分佈數據的 Pearson 殘差公式爲 \\[ p_i = \\frac{r_i}{\\sqrt{n_i\\hat\\pi_i(1-\\hat\\pi_i)}} \\] Pearson 殘差的平方和，就是 Pearson 卡方統計量，在只有分類變量的邏輯迴歸模型中可以用於擬合度診斷 (Section 53.1)，自由度爲 \\(1\\)： \\[ \\sum_i^Np^2_i = \\text{Pearson&#39;s } \\chi^2 \\text{ statistic} \\] 和標準化 Pearson 殘差相似地，另一個選項是使用偏差殘差 (deviance residual)。只要使偏差殘差 \\(d_i\\) 和原始殘差 \\(r_i\\) 保持相同的符號，偏差殘差也可以被標準化用於模型診斷。 用二項分佈數據的例子， \\[ \\begin{aligned} d_i &amp; = \\text{sign}(r_i)\\sqrt{2\\{ y_i\\text{ln}(\\frac{y_i}{\\hat\\mu_i}) + (n_i - y_i)\\text{ln}(\\frac{n_i-y_i}{n_i - \\hat\\mu_i})\\}} \\\\ \\sum_{i=1}^n d^2 = D &amp; = 2\\sum_{i=1}^N\\{ y_i\\text{ln}(\\frac{y_i}{\\hat\\mu_i}) + (n_i - y_i)\\text{ln}(\\frac{n_i - y_i}{n_i - \\hat\\mu_i}) \\} \\end{aligned} \\] 52.1.2 GLM 在 R 裏獲取殘差 boot::glm.diag(modelname)$rp ## 可以獲取 standardized Pearson residuals resid(modelname, type = &quot;pearson&quot;) ## 可以獲取 Pearson residuals rstandard(modelname) ## 可以獲取 standardized deviance residuals resid(modelname) ## 可以獲取 deviance residuals 52.1.3 如何利用獲得的殘差 將殘差和觀測值的排序作散點圖–查看是否有觀測值擁有過大的標準化殘差； 作殘差和線性預測方程值的散點圖–如果模型合理的話，這兩者之間視覺上可以判斷是沒有關係的 (no systematic relationship)； 作殘差和模型中任意一個連續型變量 (如果有的話) – 可以判定該連續型變量的放入方式是否合理； 作殘差和數據中尚未加入模型的新變量之間的散點圖 (甚至是已有變量的二次/三次方值)–如果二者之間有明顯的相關性，需要考慮是否加入這個新變量到模型中去。 做這些散點圖時，推薦都加上 lowess 的非線性平滑曲線，用於輔助判斷是否變量之間存在特殊關係。 52.2 共變量模式殘差 covariate pattern residuals 52.3 鏈接方程 52.4 NHANES 飲酒量數據實例 數據的變量和每個變量的解釋如下表，總樣本量是 2548 人，飲酒量大於 5 杯每日者被定義爲重度飲酒者。 Variable Description gender 1=male, 2=female ageyrs Age in years at survey bmi Body mass index \\((\\text{kg/m}^2)\\) sbp Systolic blood pressure \\((\\text{mmHg})\\) ALQ130 Reported average number of drinks per day NHANES &lt;- read_dta(&quot;backupfiles/nhanesglm.dta&quot;) NHANES &lt;- NHANES %&gt;% mutate(Gender = ifelse(gender == 1, &quot;Male&quot;, &quot;Female&quot;)) %&gt;% mutate(Gender = factor(Gender, levels = c(&quot;Male&quot;, &quot;Female&quot;))) with(NHANES, table(gender)) ## gender ## 1 2 ## 1391 1157 NHANES &lt;- mutate(NHANES, Heavydrinker = ALQ130 &gt; 5) Model_NH &lt;- glm(Heavydrinker ~ gender + ageyrs, data = NHANES, family = binomial(link = &quot;logit&quot;)) logistic.display(Model_NH);summary(Model_NH) ## ## Logistic regression predicting Heavydrinker ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## gender (cont. var.) 0.17 (0.12,0.24) 0.16 (0.11,0.23) &lt; 0.001 &lt; 0.001 ## ## ageyrs (cont. var.) 0.97 (0.97,0.98) 0.97 (0.96,0.98) &lt; 0.001 &lt; 0.001 ## ## Log-likelihood = -801.292 ## No. of observations = 2548 ## AIC value = 1608.5839 ## ## Call: ## glm(formula = Heavydrinker ~ gender + ageyrs, family = binomial(link = &quot;logit&quot;), ## data = NHANES) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.86408 -0.57154 -0.34828 -0.22281 2.85177 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.6410885 0.2755315 5.9561 2.584e-09 *** ## gender -1.8249474 0.1736041 -10.5121 &lt; 2.2e-16 *** ## ageyrs -0.0304506 0.0039882 -7.6351 2.257e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1810.21 on 2547 degrees of freedom ## Residual deviance: 1602.58 on 2545 degrees of freedom ## AIC: 1608.58 ## ## Number of Fisher Scoring iterations: 6 當用邏輯迴歸模型擬合數據，線性迴歸方程加入年齡和性別時，數據給出了極強的證據證明性別和年齡和是否爲重度飲酒者都有很大的關係。但是，擬合完這樣一個邏輯迴歸模型之後，我們最大的擔心是，模型中的年齡變量和 \\(\\text{logit}(\\text{P}(Y=1))\\) 之間的關係，用簡單線性是不是恰當？要檢驗這樣的擔憂，最好的方法是追加一個非線性轉換後的年齡值，去看看模型的擬合程度是否得到改善： NHANES &lt;- mutate(NHANES, age2 = ageyrs^2) Model_NH2 &lt;- glm(Heavydrinker ~ gender + ageyrs + age2, data = NHANES, family = binomial(link = &quot;logit&quot;)) logistic.display(Model_NH2) ; summary(Model_NH2) ## ## Logistic regression predicting Heavydrinker ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## gender (cont. var.) 0.17 (0.12,0.24) 0.16 (0.11,0.23) &lt; 0.001 &lt; 0.001 ## ## ageyrs (cont. var.) 0.9726 (0.9652,0.9801) 1.01 (0.966,1.056) 0.663 0.662 ## ## age2 (cont. var.) 0.9997 (0.9996,0.9998) 0.9996 (0.9991,1) 0.073 0.067 ## ## Log-likelihood = -799.6124 ## No. of observations = 2548 ## AIC value = 1607.2249 ## ## Call: ## glm(formula = Heavydrinker ~ gender + ageyrs + age2, family = binomial(link = &quot;logit&quot;), ## data = NHANES) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.80207 -0.60342 -0.32980 -0.23312 2.87272 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.83418082 0.52440600 1.5907 0.11167 ## gender -1.82748612 0.17346142 -10.5354 &lt; 2e-16 *** ## ageyrs 0.00991164 0.02272523 0.4362 0.66273 ## age2 -0.00043512 0.00024311 -1.7898 0.07348 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1810.21 on 2547 degrees of freedom ## Residual deviance: 1599.22 on 2544 degrees of freedom ## AIC: 1607.22 ## ## Number of Fisher Scoring iterations: 6 擬合了年齡的平方 (age2) 進入邏輯迴歸模型中之後，age2 的迴歸係數的 Wald 檢驗結果是 \\(p = 0.073\\)，這證明用簡單的線性關係把年齡放在模型裏並不算不妥當 (not unreasonable)。 另外，可以提取 Model_NH 的標準化 Pearson 殘差和年齡作如下的散點圖： 圖 52.1: Standardized Pearson residuals agianst age, in logistic model with gender and linear age as covariates 圖 52.1 中靠近橫軸的藍色實線是 LOWESS 平滑曲線，它十分接近平直的橫線，也證明了 Pearson 標準化殘差值和年齡本身並無關聯。這同時也佐證了，將年齡以連續型共變量的形式放入本次邏輯迴歸模型中並非不合理 (not unreasonable)。 下一步，我們再來考慮，模型中加入 bmi 是否合理 (能改善模型的擬合度)： Model_NH3 &lt;- glm(Heavydrinker ~ gender + ageyrs + bmi, data = NHANES, family = binomial(link = &quot;logit&quot;)) logistic.display(Model_NH3) ; summary(Model_NH3) ## ## Logistic regression predicting Heavydrinker ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## gender: Female vs Male 0.17 (0.12,0.24) 0.16 (0.11,0.23) &lt; 0.001 &lt; 0.001 ## ## ageyrs (cont. var.) 0.97 (0.97,0.98) 0.97 (0.96,0.98) &lt; 0.001 &lt; 0.001 ## ## bmi (cont. var.) 0.9965 (0.9756,1.0179) 1.0084 (0.9855,1.0318) 0.477 0.479 ## ## Log-likelihood = -801.0412 ## No. of observations = 2548 ## AIC value = 1610.0825 ## ## Call: ## glm(formula = Heavydrinker ~ gender + ageyrs + bmi, family = binomial(link = &quot;logit&quot;), ## data = NHANES) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.93712 -0.57479 -0.34466 -0.22359 2.82847 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.4048605 0.3588732 -1.1281 0.2593 ## genderFemale -1.8299784 0.1738183 -10.5281 &lt; 2.2e-16 *** ## ageyrs -0.0306880 0.0040105 -7.6518 1.982e-14 *** ## bmi 0.0083460 0.0117336 0.7113 0.4769 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1810.21 on 2547 degrees of freedom ## Residual deviance: 1602.08 on 2544 degrees of freedom ## AIC: 1610.08 ## ## Number of Fisher Scoring iterations: 6 BMI的迴歸係數是否爲零的 Wald 檢驗 \\(p=0.477\\)，提示數據無法提供證據去反對零假設：“調整了年齡和性別之後，BMI 和是否是重度飲酒者的概率的對數比值 \\(\\text{log-odds}\\) 之間無線性關係”，也就是二者之間可能有非線性關係。如果把 Pearson 標準化殘差和 BMI 作殘差散點圖，如下所示： 圖 52.2: Standardized Pearson residuals agianst BMI, in logistic model with gender and linear age as covariates 此殘差圖 52.2 的 LOWESS 平滑曲線卻提示我們，BMI 和殘差之間不完全是毫無關係的 (應該是非線性的，拋物線關係？)。如果我們把 BMI 取平方放入模型中再看其結果： NHANES &lt;- mutate(NHANES, bmi2 = bmi^2) Model_NH4 &lt;- glm(Heavydrinker ~ gender + ageyrs + bmi + bmi2, data = NHANES, family = binomial(link = &quot;logit&quot;)) summary(Model_NH4) ## ## Call: ## glm(formula = Heavydrinker ~ gender + ageyrs + bmi + bmi2, family = binomial(link = &quot;logit&quot;), ## data = NHANES) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.93349 -0.57566 -0.34335 -0.21636 2.85524 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.9061959 1.4516174 -2.6909 0.007125 ** ## genderFemale -1.7784430 0.1745978 -10.1859 &lt; 2.2e-16 *** ## ageyrs -0.0323786 0.0040936 -7.9096 2.583e-15 *** ## bmi 0.2551992 0.1003287 2.5436 0.010971 * ## bmi2 -0.0041230 0.0016854 -2.4464 0.014430 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1810.21 on 2547 degrees of freedom ## Residual deviance: 1594.91 on 2543 degrees of freedom ## AIC: 1604.91 ## ## Number of Fisher Scoring iterations: 6 logistic.display(Model_NH4) ## ## Logistic regression predicting Heavydrinker ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## gender: Female vs Male 0.17 (0.12,0.24) 0.17 (0.12,0.24) &lt; 0.001 &lt; 0.001 ## ## ageyrs (cont. var.) 0.97 (0.97,0.98) 0.97 (0.96,0.98) &lt; 0.001 &lt; 0.001 ## ## bmi (cont. var.) 1 (0.98,1.02) 1.29 (1.06,1.57) 0.011 0.006 ## ## bmi2 (cont. var.) 0.9999 (0.9995,1.0002) 0.9959 (0.9926,0.9992) 0.014 0.007 ## ## Log-likelihood = -797.4554 ## No. of observations = 2548 ## AIC value = 1604.9108 lmtest::lrtest(Model_NH, Model_NH4) ## Likelihood ratio test ## ## Model 1: Heavydrinker ~ gender + ageyrs ## Model 2: Heavydrinker ~ gender + ageyrs + bmi + bmi2 ## #Df LogLik Df Chisq Pr(&gt;Chisq) ## 1 3 -801.292 ## 2 5 -797.455 2 7.67309 0.021568 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 通過似然比檢驗比較加了 bmi, bmi2 兩個共變量的模型和只有 gender, ageyrs 兩個共變量的模型 \\((p=0.022)\\)，提示我們 BMI 和是否是重度飲酒者 (概率的對數比值 \\(\\text{log-odds}\\)) 之間的關係並非簡單的線性關係。不過這樣的關係似乎並不是特別的明顯，圖 52.2 的平滑曲線的彎曲程度也沒有特別明顯。所以，在這樣的情況下，有的統計學家可能還是會選擇不放 BMI 進入模型裏。 52.5 Practical 10 繼續沿用 NHANES 數據，此次練習我們把重點放在收集到的收縮期血壓數據上。定義收縮期血壓大於 140 \\(\\text{mmHg}\\) 者爲高血壓患者。 # 1. load the data and define a binary variable indicating whether # each observation has hypertension (1) or not (0) NHANES &lt;- read_dta(&quot;backupfiles/nhanesglm.dta&quot;) NHANES &lt;- NHANES %&gt;% mutate(Gender = ifelse(gender == 1, &quot;Male&quot;, &quot;Female&quot;)) %&gt;% mutate(Gender = factor(Gender, levels = c(&quot;Male&quot;, &quot;Female&quot;))) NHANES &lt;- mutate(NHANES, hypertension = sbp &gt;= 140) tab1(NHANES$hypertension, graph = FALSE) ## NHANES$hypertension : ## Frequency Percent Cum. percent ## FALSE 2116 83 83 ## TRUE 432 17 100 ## Total 2548 100 100 # 2. Bearing in mind that we know blood pressure increases with age # we begin by including age into a logistic regression for the # the binary hypertension variable. We can use a lowess smoother # plot to examine how the probability of hypertension varies with # age. pi &lt;- with(NHANES, predict(loess(hypertension ~ ageyrs))) with(NHANES, scatter.smooth(ageyrs, logit(pi), pch = 20, span = 0.6, lpars = list(col = &quot;blue&quot;, lwd = 3, lty = 1), col=rgb(0,0,0,0.004), xlab = &quot;Age in years&quot;, ylab = &quot;Logit(probability) of Hypertension&quot;, frame = FALSE)) 圖 52.3: The loess plot of the observed proportin with hypertension against age. Span = 0.6 Lowess 平滑曲線圖提示，高血壓患病的可能性的 \\(\\text{logit}\\)，和年齡之間的關係似乎不是簡單直線關係。我們可能需要把年齡本身和年齡的平方放入邏輯迴歸模型中去看看。 # 3. Include age into the logistic regression in the way suggested by the lowess plot. # do your results support your findings from the previous graph? NHANES &lt;- mutate(NHANES, agesq = ageyrs^2) Model_NH5 &lt;- glm(hypertension ~ ageyrs + agesq, data = NHANES, family = binomial(link = &quot;logit&quot;)) logistic.display(Model_NH5) ; summary(Model_NH5) ## ## Logistic regression predicting hypertension ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## ageyrs (cont. var.) 1.07 (1.06,1.07) 1.15 (1.1,1.21) &lt; 0.001 &lt; 0.001 ## ## agesq (cont. var.) 1.0005 (1.0005,1.0006) 0.9993 (0.9989,0.9997) 0.001 &lt; 0.001 ## ## Log-likelihood = -943.7811 ## No. of observations = 2548 ## AIC value = 1893.5622 ## ## Call: ## glm(formula = hypertension ~ ageyrs + agesq, family = binomial(link = &quot;logit&quot;), ## data = NHANES) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.20772 -0.61574 -0.33152 -0.18319 2.97415 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -6.92931228 0.67205641 -10.311 &lt; 2.2e-16 *** ## ageyrs 0.13933661 0.02419897 5.758 8.514e-09 *** ## agesq -0.00067035 0.00020870 -3.212 0.001318 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2319.51 on 2547 degrees of freedom ## Residual deviance: 1887.56 on 2545 degrees of freedom ## AIC: 1893.56 ## ## Number of Fisher Scoring iterations: 6 正如同 Lowess 平滑曲線建議的那樣，數據提供了極強的證據證明年齡和患有高血壓概率的對數比值 \\((\\text{log-odds})\\) 之間呈現的是拋物線關係。 # 4. Generate Pearson residuals and investigate whether the way in # which you have included age in the logistic regression in the # previous part is correct. # obtain the standardized Pearson residuals by covariate pattern Diag &lt;- LogisticDx::dx(Model_NH5) ggplot(Diag, aes(x = ageyrs, y = sPr)) + geom_point() + geom_smooth(span = 0.9, se = FALSE) + theme_bw() + theme(axis.text = element_text(size = 15), axis.text.x = element_text(size = 15), axis.text.y = element_text(size = 15)) + labs(x = &quot;Age in years&quot;, y = &quot;standardised Pearson residual&quot;) + theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8), axis.line = element_line(colour = &quot;black&quot;), panel.border = element_blank(), panel.background = element_blank()) 圖 52.4: Standardized Pearson residuals (by covariate pattern) vs. age. Logistic mdoel with linear and quadratic age as covariates. 標準化 Pearson 殘差 (共變量模式) 和年齡之間的散點圖 52.4 提示此時的殘差和年齡之間再無明顯的關係。也就是說，年齡作爲連續變量和高血壓患病概率的對數比值之間的關係，用拋物線 (二次方程) 擬合並非不合理 (not unreasonable)。 # 5. Next, use individual level residuals to examine whether BMI ought to be # included in the model, and depending on what you find, continue with you # previous model or add BMI. In the latter case, generate new residuals and # assess if you have included BMI using the most appropriate functional form. NHANES$stresPearson &lt;- boot::glm.diag(Model_NH5)$rp ggplot(NHANES, aes(x = bmi, y = stresPearson)) + geom_point() + theme_bw() + geom_smooth(span = 0.8, se = FALSE) + theme(axis.text = element_text(size = 15), axis.text.x = element_text(size = 15), axis.text.y = element_text(size = 15)) + labs(x = &quot;Body Mass Index&quot;, y = &quot;Standardized Pearson residual&quot;) + theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8), axis.line = element_line(colour = &quot;black&quot;), panel.border = element_blank(), panel.background = element_blank()) 圖 52.5: Standardized Pearson residuals vs. BMI. Logistic mdoel with just linear and quadratic age as covariates. 圖 52.5，提示，標準化 Pearson 殘差和連續型 BMI 值之間應該存在相關性，也就是該圖提示需要加入連續型變量 BMI 進入邏輯迴歸模型中去！ Model_NH6 &lt;- glm(hypertension ~ ageyrs + agesq + bmi, data = NHANES, family = binomial(link = &quot;logit&quot;)) logistic.display(Model_NH6) ; summary(Model_NH6) ## ## Logistic regression predicting hypertension ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## ageyrs (cont. var.) 1.07 (1.06,1.07) 1.14 (1.09,1.2) &lt; 0.001 &lt; 0.001 ## ## agesq (cont. var.) 1.0005 (1.0005,1.0006) 0.9994 (0.999,0.9998) 0.005 0.004 ## ## bmi (cont. var.) 1.02 (1.01,1.04) 1.03 (1.01,1.05) 0.007 0.007 ## ## Log-likelihood = -940.1583 ## No. of observations = 2548 ## AIC value = 1888.3166 ## ## Call: ## glm(formula = hypertension ~ ageyrs + agesq + bmi, family = binomial(link = &quot;logit&quot;), ## data = NHANES) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.32095 -0.61276 -0.33033 -0.18260 2.85207 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -7.54111034 0.71010300 -10.6197 &lt; 2.2e-16 *** ## ageyrs 0.13107997 0.02430813 5.3924 6.951e-08 *** ## agesq -0.00059168 0.00021030 -2.8135 0.004900 ** ## bmi 0.02840320 0.01046359 2.7145 0.006638 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2319.51 on 2547 degrees of freedom ## Residual deviance: 1880.32 on 2544 degrees of freedom ## AIC: 1888.32 ## ## Number of Fisher Scoring iterations: 6 加入連續型變量 BMI 進入模型後，bmi 項的 Wald 檢驗結果果然證實了 之前殘差圖提示的 BMI 和高血壓患病概率之間存在相關性。再對 Model_NH6 的殘差和 bmi 作殘差散點圖： 圖 52.6: Standardized Pearson residuals vs. BMI. Logistic mdoel with linear and quadratic age and BMI as covariates. 現在的殘差散點圖提示殘差和 bmi 之間不再有關係，所以之前把 bmi 加入邏輯迴歸模型是個並非不合理 (not unreasonable)的選擇。 # 6. So far we have ingored gender. Explore whether gender should be included # in the model. including whether or not the other covariates included # already interact with gender with their effects on hypertension. Model_NH7 &lt;- glm(hypertension ~ ageyrs + agesq + bmi + Gender, data = NHANES, family = binomial(link = &quot;logit&quot;)) logistic.display(Model_NH7) ; summary(Model_NH7) ## ## Logistic regression predicting hypertension ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## ageyrs (cont. var.) 1.07 (1.06,1.07) 1.14 (1.09,1.2) &lt; 0.001 &lt; 0.001 ## ## agesq (cont. var.) 1.0005 (1.0005,1.0006) 0.9994 (0.999,0.9998) 0.005 0.004 ## ## bmi (cont. var.) 1.02 (1.01,1.04) 1.03 (1.01,1.05) 0.009 0.009 ## ## Gender: Female vs Male 1.1 (0.9,1.36) 1.24 (0.98,1.56) 0.07 0.07 ## ## Log-likelihood = -938.5164 ## No. of observations = 2548 ## AIC value = 1887.0328 ## ## Call: ## glm(formula = hypertension ~ ageyrs + agesq + bmi + Gender, family = binomial(link = &quot;logit&quot;), ## data = NHANES) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.37006 -0.61503 -0.33044 -0.18099 2.89593 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -7.64411420 0.71405324 -10.7052 &lt; 2.2e-16 *** ## ageyrs 0.13206361 0.02435967 5.4214 5.913e-08 *** ## agesq -0.00059709 0.00021066 -2.8344 0.004592 ** ## bmi 0.02730943 0.01043204 2.6178 0.008849 ** ## GenderFemale 0.21213190 0.11703954 1.8125 0.069912 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2319.51 on 2547 degrees of freedom ## Residual deviance: 1877.03 on 2543 degrees of freedom ## AIC: 1887.03 ## ## Number of Fisher Scoring iterations: 6 lmtest::lrtest(Model_NH6, Model_NH7) ## Likelihood ratio test ## ## Model 1: hypertension ~ ageyrs + agesq + bmi ## Model 2: hypertension ~ ageyrs + agesq + bmi + Gender ## #Df LogLik Df Chisq Pr(&gt;Chisq) ## 1 4 -940.158 ## 2 5 -938.516 1 3.28378 0.069967 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # some evidence of an effect of gender. # the Wald test and the likelihood ratio test are both borderline # statistically significant. Model_NH8 &lt;- glm(hypertension ~ ageyrs + agesq + bmi*Gender, data = NHANES, family = binomial(link = &quot;logit&quot;)) logistic.display(Model_NH8) ## ## Logistic regression predicting hypertension ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## ageyrs (cont. var.) 1.07 (1.06,1.07) 1.14 (1.09,1.2) &lt; 0.001 &lt; 0.001 ## ## agesq (cont. var.) 1.0005 (1.0005,1.0006) 0.9994 (0.999,0.9998) 0.006 0.005 ## ## bmi (cont. var.) 1.02 (1.01,1.04) 1.05 (1.01,1.08) 0.005 1 ## ## Gender: Female vs Male 1.1 (0.9,1.36) 3.01 (0.9,10) 0.072 0.072 ## ## bmi:GenderFemale - 0.97 (0.93,1.01) 0.139 0.139 ## ## Log-likelihood = -937.423 ## No. of observations = 2548 ## AIC value = 1886.846 lmtest::lrtest(Model_NH7, Model_NH8) ## Likelihood ratio test ## ## Model 1: hypertension ~ ageyrs + agesq + bmi + Gender ## Model 2: hypertension ~ ageyrs + agesq + bmi * Gender ## #Df LogLik Df Chisq Pr(&gt;Chisq) ## 1 5 -938.516 ## 2 6 -937.423 1 2.18675 0.1392 # no strong evidence of an interaction between BMI and gender # from both wald test and likelihood ratio test. Model_NH9 &lt;- glm(hypertension ~ ageyrs*Gender + agesq + bmi, data = NHANES, family = binomial(link = &quot;logit&quot;)) logistic.display(Model_NH9) ## ## Logistic regression predicting hypertension ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## ageyrs (cont. var.) 1.07 (1.06,1.07) 1.13 (1.08,1.19) &lt; 0.001 1 ## ## Gender: Female vs Male 1.1 (0.9,1.36) 0.34 (0.14,0.84) 0.02 0.018 ## ## agesq (cont. var.) 1.0005 (1.0005,1.0006) 0.9994 (0.999,0.9998) 0.004 0.003 ## ## bmi (cont. var.) 1.02 (1.01,1.04) 1.03 (1.01,1.05) 0.008 0.009 ## ## ageyrs:GenderFemale - 1.02 (1.01,1.04) 0.004 0.004 ## ## Log-likelihood = -934.2658 ## No. of observations = 2548 ## AIC value = 1880.5315 lmtest::lrtest(Model_NH7, Model_NH9) ## Likelihood ratio test ## ## Model 1: hypertension ~ ageyrs + agesq + bmi + Gender ## Model 2: hypertension ~ ageyrs * Gender + agesq + bmi ## #Df LogLik Df Chisq Pr(&gt;Chisq) ## 1 5 -938.516 ## 2 6 -934.266 1 8.50127 0.003549 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # strong evidence of an interaction between gender and age lmtest::lrtest(Model_NH6, Model_NH9) ## Likelihood ratio test ## ## Model 1: hypertension ~ ageyrs + agesq + bmi ## Model 2: hypertension ~ ageyrs * Gender + agesq + bmi ## #Df LogLik Df Chisq Pr(&gt;Chisq) ## 1 4 -940.158 ## 2 6 -934.266 2 11.7851 0.00276 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # joint test of gender and its interaction with age is also significant 增加性別項進入邏輯迴歸模型以後，數據提供了臨界有意義證據 \\((p = 0.070)\\) 證明了調整了年齡和 BMI 以後，高血壓的患病概率依然和性別有關係。增加了 BMI 和性別的交互作用項之後發現，無證據證明性別和 BMI 之間存在有意義的交互作用 \\((p=0.139)\\)。但是，增加了年齡和性別的交互作用項以後，發現了有很強的證據證明性別和年齡之間存在交互作用 \\((p=0.004)\\)。增加性別以及性別和年齡的交互作用項，顯著提升了模型對數據的擬合度 \\((p = 0.0028)\\)。此處，我們可以下結論認爲，雖然加入年齡本身，對模型擬合程度提升有有限的幫助，但是當模型考慮了年齡和性別的交互作用之後，擬合數據的程度得到極爲顯著的改善。 當然，想要繼續下去也是可以的，例如 Model_NH9 的前提下，再加入年齡平方與性別的交互作用項，會發現其 Wald 檢驗結果提示年齡平方，和性別的交互作用是沒有意義的 \\((p=0.58)\\)。 # 7. Based on your final model, calculate fitted probabilities for an individual # aged 60 years, at BMI values from 20 to 40 in increments of 5, separately # for men and women, and plot the resulting values. a &lt;- data.frame(bmi = seq(20, 40, 5), ageyrs = rep(60, 5), agesq = rep(3600, 5), Gender = factor(rep(&quot;Male&quot;, 5))) b &lt;- data.frame(bmi = seq(20, 40, 5), ageyrs = rep(60, 5), agesq = rep(3600, 5), Gender = factor(rep(&quot;Female&quot;, 5))) Predict_men &lt;- predict(Model_NH9, a, se.fit = TRUE)$fit Predict_men_se &lt;- predict(Model_NH9, a, se.fit = TRUE)$se.fit Point_pred_men &lt;- exp(Predict_men)/(1+exp(Predict_men)) PredictCI_men_L &lt;- exp(Predict_men - 1.96*Predict_men_se)/(1+exp(Predict_men- 1.96*Predict_men_se)) PredictCI_men_U &lt;- exp(Predict_men + 1.96*Predict_men_se)/(1+exp(Predict_men+ 1.96*Predict_men_se)) cbind(Point_pred_men, PredictCI_men_L, PredictCI_men_U) ## Point_pred_men PredictCI_men_L PredictCI_men_U ## 1 0.20999989 0.16990237 0.25663492 ## 2 0.23409879 0.19980473 0.27227618 ## 3 0.26005285 0.22575914 0.29755387 ## 4 0.28780311 0.24411252 0.33583907 ## 5 0.31724500 0.25701542 0.38428866 Predict_women &lt;- predict(Model_NH9, b, se.fit = TRUE)$fit Predict_women_se &lt;- predict(Model_NH9, b, se.fit = TRUE)$se.fit Point_pred_women &lt;- exp(Predict_women)/(1+exp(Predict_women)) PredictCI_women_L &lt;- exp(Predict_women - 1.96*Predict_women_se)/(1+exp(Predict_women- 1.96*Predict_women_se)) PredictCI_women_U &lt;- exp(Predict_women + 1.96*Predict_women_se)/(1+exp(Predict_women+ 1.96*Predict_women_se)) cbind(Point_pred_women, PredictCI_women_L, PredictCI_women_U) ## Point_pred_women PredictCI_women_L PredictCI_women_U ## 1 0.24913421 0.20076523 0.30471354 ## 2 0.27615418 0.23478059 0.32175308 ## 3 0.30491460 0.26477267 0.34825967 ## 4 0.33528289 0.28659479 0.38774675 ## 5 0.36707847 0.30191960 0.43748678 "],
["-assessing-model-performance.html", "第 53 章 評價模型的表現 Assessing model performance 53.1 精準度 calibration 53.2 可解釋因變量的變異度及 \\(R^2\\) 決定係數 53.3 分辨能力 descrimination", " 第 53 章 評價模型的表現 Assessing model performance 在廣義線性迴歸的模型表現中，還有幾個重要的概念，精準度 (calibration)，變異度 (variation)，和分辨能力 (descrimination)，本章繼續用二分類結果變量和多個共變量的廣義線性迴歸模型來理解這幾個概念。本章使用邏輯迴歸，也就是 \\(\\text{logit}\\) 鏈接方程的 GLM 來解釋，但是實際上使用其他鏈接方程時，這些概念也是一樣通用的。 當用邏輯迴歸模型擬合了觀測數據。我們可以通過擬合的模型來計算每個觀測對象的預測“成功”概率 (the predicted probability of “success” for each subject)。當使用 \\(\\text{logit}\\) 作鏈接方程時，每個人的預測概率 (predicted probability) 爲： \\[ \\hat\\pi_i = \\frac{\\text{exp}(\\hat\\alpha + \\hat\\beta_1x_{i1} + \\cdots + \\hat\\beta_px_{ip})}{1+\\text{exp}(\\hat\\alpha + \\hat\\beta_1x_{i1} + \\cdots + \\hat\\beta_px_{ip})} \\] 53.1 精準度 calibration 模型具有良好的精準度時，其計算獲得的每個觀測對象的預測概率，和每個觀測對象本身“成功”的概率期望值保持一致。 \\[ E(Y|\\hat\\pi = p) = p \\] 當一個 GLM 具有良好精準度時，我們可以利用它在臨牀醫學中發揮重要的作用 (如預測患者死亡，發病或療效等)。如果模型的精準度不佳，那可能導致的嚴重後果有：治療不必要治療的“健康人”，或者漏掉應該治療的“患者”。當一個模型的預測變量只包含了分類型變量，比較觀測概率和預測概率的過程較爲簡單，比較各個分類變量的排列組合後，不同共變量類型 (covariate pattern) 的患者的觀測值和預測值即可。 這裏再沿用之前 NHANES 的重度飲酒相關的數據 (Section 52.4)來繼續下面對精準度的說明，先擬合一個只有性別作爲預測變量的邏輯迴歸模型： NHANES &lt;- read_dta(&quot;backupfiles/nhanesglm.dta&quot;) NHANES &lt;- NHANES %&gt;% mutate(Gender = ifelse(gender == 1, &quot;Male&quot;, &quot;Female&quot;)) %&gt;% mutate(Gender = factor(Gender, levels = c(&quot;Male&quot;, &quot;Female&quot;))) with(NHANES, table(Gender)) ## Gender ## Male Female ## 1391 1157 NHANES &lt;- mutate(NHANES, Heavydrinker = ALQ130 &gt; 5) Model_perf &lt;- glm(Heavydrinker ~ Gender, data = NHANES, family = binomial(link = &quot;logit&quot;)) logistic.display(Model_perf) ## ## Logistic regression predicting Heavydrinker ## ## OR(95%CI) P(Wald&#39;s test) P(LR-test) ## Gender: Female vs Male 0.17 (0.12,0.24) &lt; 0.001 &lt; 0.001 ## ## Log-likelihood = -834.1079 ## No. of observations = 2548 ## AIC value = 1672.2158 完成這個模型之後，在 STATA 裏可以用簡便的 estat gof, table 命令獲取模型擬合的觀測值和期待值表格，然而 R 裏面需要用到 LogisticDx 包裏的診斷命令 dx 獲取 (我花了好幾個小時才找到這個命令，不得不說 STATA 對於流行病的傳統計算真的是比較方便)： LogisticDx::dx(Model_perf)[, 2:6] ## GenderFemale y P n yhat ## 1: 0 249 0.179007908 1391 249 ## 2: 1 42 0.036300778 1157 42 # obtain Pearson&#39;s test statistics chi2 &lt;- sum((LogisticDx::dx(Model_perf)$sPr)^2) pval &lt;- pchisq(chi2, 1, lower.tail=FALSE) data.frame(test=&quot;Pearson chi2(1)&quot;,chi.sq=chi2,pvalue=pval) ## test chi.sq pvalue ## 1 Pearson chi2(1) 7.5334682e-25 1 在這個只有性別作預測變量的邏輯迴歸模型裏，當然只有男，女，兩種共變量模式 (covariate patterns)。此時，模型的精準度100% (y 是觀測值， yhat 是期待值)。接下來，再在模型中加入一個是否體重超重的二分類變量。再獲取其觀測值和期待值表格如下： NHANES &lt;- mutate(NHANES, highbmi = bmi &gt; 25) Model_perf &lt;- glm(Heavydrinker ~ Gender + highbmi, data = NHANES, family = binomial) logistic.display(Model_perf) ## ## Logistic regression predicting Heavydrinker ## ## crude OR(95%CI) adj. OR(95%CI) P(Wald&#39;s test) P(LR-test) ## Gender: Female vs Male 0.17 (0.12,0.24) 0.17 (0.12,0.24) &lt; 0.001 &lt; 0.001 ## ## highbmi 1.21 (0.93,1.58) 1.11 (0.84,1.46) 0.456 0.453 ## ## Log-likelihood = -833.8269 ## No. of observations = 2548 ## AIC value = 1673.6539 LogisticDx::dx(Model_perf)[,2:7] ## GenderFemale highbmiTRUE y P n yhat ## 1: 0 1 175 0.183662501 961 176.499664 ## 2: 0 0 74 0.168605433 430 72.500336 ## 3: 1 1 29 0.037620159 731 27.500336 ## 4: 1 0 13 0.034036770 426 14.499664 # obtain Pearson&#39;s test statistics chi2 &lt;- sum((LogisticDx::dx(Model_perf)$sPr)^2) pval &lt;- pchisq(chi2, 1, lower.tail=FALSE) data.frame(test=&quot;Pearson chi2(1)&quot;,chi.sq=chi2,pvalue=pval) ## test chi.sq pvalue ## 1 Pearson chi2(1) 0.29881856 0.58462403 此時的模型有 4 種共變量模式 (covariate patterns)，其實就是性別和超重與否的四種排列組合。這裏報告的 Pearson's test statisitics 我們在前一章講邏輯迴歸殘差的部分有講過，它就是 Pearson 標準化殘差的平方和。此處它的卡方檢驗，檢驗零假設是“模型制定正確”。所以，我們無足夠的證據 \\((p=0.58)\\) 來反對零假設，數據觀測值和模型的期待值似乎也較爲吻合。 但是一旦模型裏加入了新的連續型變量，整個模型的共變量模式 (covariate patterns)，將會變得很難進行上面的觀測值和期待值的比較，由於加入的連續型變量會導致模型的共變量模式變得越來越多，甚至接近與樣本量個數 \\(n\\)，也就是每個共變量模式的樣本越來越小，直至等於 \\(1\\)。連續型變量的模型中我們 Hosmer-Lemeshow 檢驗 (Section 46.4) 而不是 Pearson 統計檢驗量。 53.2 可解釋因變量的變異度及 \\(R^2\\) 決定係數 精準度的確重要，但是模型精準度好，只代表它和過去擬合它的觀測數據之間關係接近，不代表它能準確地預測其他的個體的概率。前文中只有性別作爲預測變量的邏輯迴歸模型就是實例，它和擬合的觀測數據做到了 100% 完美擬合，但是不用大腦思考也知道，除了性別還有其他更多的能預測一個人是否是重度飲酒者的變量，且擁有能提升模型的擬合程度的潛質。只有性別作預測變量的邏輯迴歸模型，最大的問題在於，它只能解釋個體之間重度飲酒者概率的變異度(variation)中極少的部分。事實上，它只能解釋能夠用性別解釋的個體之間重度飲酒者概率的變異度。所以，此處打算引伸出的概念就是類似簡單線性迴歸中的 \\(R^2\\) 決定係數 (Section 28.2.3) 的定義。 你應該還能記得，在簡單線性迴歸中決定係數 \\(R^2\\) 的含義是因變量的平方和 (平方和) 中能被模型解釋的部分： \\[ R^2 = \\frac{SS_{REG}}{SS_{yy}} = \\frac{\\sum_{i=1}^n(\\hat{y}_i-\\bar{y})^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2} = 1-\\frac{\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2} \\] 許多前人嘗試過試圖將線性迴歸的決定係數概念擴展到廣義線性迴歸模型中來，但是目前爲止的嘗試都不太成功。所以，只有一些借鑑了簡單線性迴歸的的決定係數思想的概念，得到了擴展，但是要注意，他們本身和決定係數是有區別的。 “假決定係數 (pseudo-R2)”，別名 McFadden 的似然比係數 (McFadden’s likelihood ratio index) \\[R^r_{\\text{McFadden}} = 1 - \\frac{\\ell_c}{\\ell_\\text{null}}\\] 其中 \\(\\ell_c, \\ell_{\\text{null}}\\) 分別是模型的極大似然值 和零模型時的極大似然值。 假決定係數，之所以被冠名“假”，因爲這個係數你也可以在簡單線性迴歸下計算，但是其大小常常和一般我們熟知的決定係數結果有些差距。所以，常有人質疑其到底是否可用 (因爲它在現實生活中根本不可能取到 \\(0\\) 或 \\(1\\))。 在 R 裏，擬合了邏輯迴歸以後通常也不會報告假決定係數值的大小。所以想要獲得它，需要 DescTools::PseudoR2() 命令來獲取： PseudoR2(Model_perf) ## McFadden ## 0.078752188 上文中包含了性別和是否超重的模型的假決定係數只有區區 \\(0.0785\\)，可見，只有性別和是否超重兩個變量只能解釋結果變量變異度中極少的部分。 53.3 分辨能力 descrimination 53.3.1 敏感度和特異度 評價一個邏輯迴歸的表現，最後的一個手段是，看這個模型對觀測對象的分辨能力。也就是，當我們人爲地指定一個概率值 \\(p\\) 作爲是否患病的閾值，那麼，觀測對象通過模型計算獲得的概率，已經觀測對象本身的觀測概率之間，其實可以用診斷學的敏感度和特異度的概念來評價模型對於觀測對象的分別能力到底如何。所以邏輯迴歸模型的敏感度就是，病例中通過模型計算被判斷爲陽性的概率；特異度是，非病例中，通過模型計算本判斷爲陰性的概率。這個敏感度特異度當然會隨着我們選擇的閾值而變化。 圖 53.1 所示的是，將性別， BMI，和年齡三個變量放入邏輯迴歸模型之後，模型對於觀察對象的分辨能力的 ROC 示意圖。計算所得的 ROC 曲線下面積爲 0.7484。如果一個模型是失敗的，那麼其曲線下面積爲 (接近) 0.5。也就是會十分貼近 \\(y=x\\) 的直線。 Model_perf &lt;- glm(Heavydrinker ~ Gender + bmi + ageyrs, data = NHANES, family = binomial) ROC_graph &lt;- lroc(Model_perf, grid.col = &quot;grey&quot;, lwd = 3, frame = FALSE) 圖 53.1: Receiver operating curve for model for heavy drinking with gender, age, and BMI ROC_graph$auc ## [1] 0.74835297 曲線下面積，AUC 的另一個有用的意義是，從觀測對象中任意選取兩個人，一個是病例 \\((y_i = 1)\\)，一個是非病例 \\((y_j = 0)\\)，那麼曲線下面積就是模型能夠正確將這兩個對象按照是否患病的可能性進行排序的概率。 \\(\\text{AUC} = \\text{Pr}(\\pi_i &gt; \\pi_j | y_i = 1 \\&amp; y_j = 0)\\) ROC 曲線本身有自己的優點，也有許多侷限性。最近有另外一個用於診斷的新型曲線–預測曲線(Pepe et al. 2007)。預測曲線繪製的是，觀測對象的擬合後概率 \\(\\hat\\pi_i\\) 和這個概率在所有觀察對象的擬合後概率的百分位數 (percentile) 之間的曲線。一個模型，如果給許多對象相似的概率，那麼不能說這個模型的分辨能力足夠好。同時，此圖也能一目瞭然讓人看到大概多少對象的患病概率是大於一定水平的。 Predictive &lt;- data.frame(fitted(Model_perf), rank(fitted(Model_perf))/2548) names(Predictive) &lt;- c(&quot;hatpi&quot;, &quot;percentile&quot;) ggplot(Predictive, aes(x = percentile, y = hatpi)) + geom_line() + ylim(0, 0.4) + labs(x = &quot;Risk percentile&quot;, y = &quot;Heavy drinker risk&quot;) + theme_bw() + theme(axis.title = element_text(size = 17), axis.text.x = element_text(size = 15), axis.text.y = element_text(size = 15)) 圖 53.2: Predictiveness curve for model for heavy drinking with gender, age, and BMI as covariate 圖 53.2 所示的是，性別，年齡，BMI作爲共變量的邏輯迴歸模型的預測變量，預測重度飲酒概率的模型給出的預測曲線。從圖中可見，大多數人的概率值各不相同。而且，圖中也能告訴我們大約 20% 的觀測對象其重度飲酒的概率大於 0.2。 References "],
["section-54.html", "第 54 章 配對實驗數據的分析法 54.1 配對的原理 54.2 結果變量爲連續型變量的配對實驗 54.3 結果變量是二分類變量的配對實驗 54.4 條件 (conditional) 比值比和邊際 (marginal) 比值比", " 第 54 章 配對實驗數據的分析法 配對實驗是指觀察對象中的一個以上 (通常是2-3個) 以事先確定的條件進行配對 (matched under conditions)。配對實驗中根據條件配對後的觀察對象常常被稱爲一個個區塊 (block)。 例1： 配對交叉設計實驗，結果變量爲連續型。 給予五十名實驗對象抗高血壓藥物用於降低其舒張期血壓 (diastolic blood pressure)。舒張期血壓在實驗前 \\((y_{i1})\\) 和實驗後 \\((y_{i2})\\) 分別測量。此時的實驗區塊是每個患者的自身前後對照數據。 例2： 干預實驗，結果變量爲二分類型。 77名已經有眼底病變的糖尿病患者被選爲實驗對象，每人隨機選取一隻眼睛接受最新的雷射激光治療，另一隻眼睛使用標準治療法。經過五年的隨訪，觀察患者的兩隻眼睛是病變爲全盲 (是/否)。此時的實驗區塊是每個患者自己，左右眼互爲對照。 例3： 隊列研究中的配對設計，結果變量爲二分類型。 100 名觀察對像根據性別年齡和 100 名服他汀類藥物 (statin) 的患者，以高膽固醇血癥的有無作爲對照變量 (病例對照同時患病，或同時無病) 一一對應。這 200 名對象被追蹤隨訪 3 年，記錄他們是否罹患心血管疾病。此時的實驗區塊，是 100 個成對的實驗對象。 例4： 配對病例對照實驗。 20 名肺癌患者，和另外 20 名沒有肺癌的對照以同年齡，同性別爲條件配對。研究人員詢問每個實驗參與者過去的吸菸史。本實驗的結果變量爲對象是否吸過香菸。此時的實驗區塊是一名肺癌患者和一名同年齡，同性別的對照。 配對實驗中，我們通常認爲在每個區塊裏的個人，或者他們的測量值應該比不同一區塊裏的觀察對象的測量值更加相似。 例1 中，每個個體實驗前後的血壓值，理論上會比另外一個個體的血壓值相比更加接近，無論他是否接受抗高血壓治療，故每個個體本身，構成了“完美”的病例 (實驗前) 和對照 (實驗後)。 例3 中，無論一個人是否服用他汀類藥物，兩個同時都是高膽固醇血癥的人理論上會比無此症狀的人更加有可能罹患心血管疾病。 例4 中，年齡和性別可能既和一個人是否患有肺癌有關係，也和一個人是否吸菸有關。所以，在考察吸菸和肺癌關係的時候，需要在相同年齡，性別的條件下才是公平的。 54.1 配對的原理 不同的實驗，配對的設計可能有不同的理由： 在 RCT 設計中，配對實驗是爲了提升實驗數據對治療的真實效果的估計 (to improve the precision of the estimated effect of the treatment on the outcome)； 隊列研究和病例對照研究中，使用配對實驗設計 主要是爲了在實驗設計階段就控制已知的混雜因素。當然有時也有人使用配對設計去提升差異估計的精確度。 54.1.1 爲了提升估計的精確度 使用配對實驗設計，獲得數據以後就應使用相應的統計手法，從而達到提高差異估計的精確度。因爲配對實驗設計允許我們在分析階段去除掉 “區塊差異 block variability”： \\[ \\begin{aligned} Y_{ij} &amp; = C_j + P_i + O_{ij} \\\\ \\text{Where } Y_{ij} &amp; = \\text{outcome for block } i \\text{ under treatment } j\\\\ C_j &amp; = \\text{component of outcome due to treatment } j \\\\ P_i &amp; = \\text{component of outcome due to characteristics of block } i\\\\ O_{ij} &amp; = \\text{residual component of outcome} \\end{aligned} \\] 在上述式子描述的配對實驗設計下，如果成對的觀察值是 \\(Y_{i1}, Y_{i2} (i = 1,\\cdots, n)\\)，那麼可以把二者的差用於估計治療效果： \\[ \\begin{equation} Y_{i2} - Y_{i1} = C_2 - C_1 + O_{i2} - O_{i1} \\end{equation} \\tag{54.1} \\] 所以，配對實驗中，由於區塊 \\((P_i)\\) 造成的估計的方差被從隨機變異 (random variation) 中去除掉，\\(C_j\\) 之間的差異的估計精確度得到提高。這一結論在結果變量是連續型或是二分類型中同樣適用。 54.1.2 控制混雜因素 在病例對照實驗中，常常用配對設計來控制已知的混雜。但是必須強調的是，如果實驗設計中用了配對，那麼統計分析時，也必須用配對實驗的分析方法。 隊列研究中： 暴露組對象和非暴露組對象之間的配對根據一些已知的混雜變量，常見的如年齡和性別進行。 病例對照研究中：病例和對照之間通過某些特徵配對，從而控制這些特徵的混雜，常見的也是年齡和性別。另外還有的病例會從他/她居住的區域附近中尋找相似的對照，或者從他/她的家庭醫生的患者中尋找相似的對象，這時配對設計爲的是控制那些可能無法精確測量的如社會經濟條件，或環境因子。有些研究會尋找病例同一家族中的非患病者作爲對照，從而達到控制 “遺傳因素” 這一混雜因子的效果。 54.2 結果變量爲連續型變量的配對實驗 用 \\(Y_{i1}, Y_{i2}, (i = 1,\\cdots, n)\\) 標記 \\(n\\) 組配對實驗對象的結果變量的測量值。所以每對實驗對象中的兩個成員，分別被給予不同的實驗條件 (治療或安慰劑，暴露或非暴露)，用數字 \\(1,2\\) 表示。所以，分析此種數據的策略是，計算每個實驗區塊的結果變量之差： \\[ \\begin{equation} Y_{i2} - Y_{i1}, (i = 1, \\cdots, n) \\end{equation} \\tag{54.2} \\] 所以，配對實驗的結果變量是連續型變量時，等同於單樣本的假設檢驗，零假設是結果變量在不同實驗條件下的差等於零。 54.2.1 一般檢驗方法 常用的有： 均值的配對 \\(t\\) 檢驗。其實就是和 \\(0\\) 作比較的單樣本 \\(t\\) 檢驗 (Section 22.6)； Wilcoxon 配對檢驗 (Wilcoxon matched pairs test)。此法其實是 Wilcoxon 符號秩和檢驗 (Wilcoxon signed rank test)，在零假設是兩組數據中位數之差等於零的條件下的假設檢驗 (Section 36.2)。 符號檢驗 (Sign test) (Section 36.1)。 例：17名實驗對象同時給予抗高血壓治療，數據記錄了實驗前後收縮壓的測量值： library(haven) sbp &lt;- read_dta(&quot;backupfiles/sbp.dta&quot;) sbp ## # A tibble: 17 x 4 ## ptid sbp_A sbp_B diff_AB ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.00 148 132 16.0 ## 2 2.00 128 120 8.00 ## 3 3.00 152 148 4.00 ## 4 4.00 135 134 1.00 ## 5 5.00 150 128 22.0 ## 6 6.00 165 140 25.0 ## 7 7.00 155 138 17.0 ## 8 8.00 132 136 - 4.00 ## 9 9.00 140 135 5.00 ## 10 10.0 165 144 21.0 ## 11 11.0 145 115 30.0 ## 12 12.0 140 126 14.0 ## 13 13.0 135 140 - 5.00 ## 14 14.0 135 130 5.00 ## 15 15.0 122 132 -10.0 ## 16 16.0 144 118 26.0 ## 17 17.0 158 115 43.0 ## Wilcoxon signed-rank test wilcox.test(sbp$sbp_A, sbp$sbp_B, paired = TRUE, correct = FALSE) ## ## Wilcoxon signed rank test ## ## data: sbp$sbp_A and sbp$sbp_B ## V = 137.5, p-value = 0.0038567 ## alternative hypothesis: true location shift is not equal to 0 ## 秩和檢驗結果提示，數據提供了顯著性水平低於 1% (0.0038567) 的證據 ## 證明實驗前後收縮期血壓值的變化的中位數不等於零。 ## 由此可以下結論，數據能夠提供足夠的證據證明實驗前後的收縮期血壓的 ## 分佈，是不同的。 ## 注意，這不是一個 RCT，所以，這樣的不同不一定是由於抗高血壓治療。 ## 3 different methods to conduct sign test Positive_n &lt;- sum(sbp$diff_AB &gt;0) total_n &lt;- length(sbp$diff_AB) 2*pbinom(total_n-Positive_n, total_n, 0.5) ## sign test -- just p-value ## [1] 0.01272583 binom.test(Positive_n, total_n,0.5) ## sign test through binomial test ## ## Exact binomial test ## ## data: Positive_n and total_n ## number of successes = 14, number of trials = 17, p-value = 0.012726 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.56568213 0.96201493 ## sample estimates: ## probability of success ## 0.82352941 BSDA::SIGN.test(sbp$sbp_A, sbp$sbp_B) ## sign-test from BSDA package ## ## Dependent-samples Sign-Test ## ## data: sbp$sbp_A and sbp$sbp_B ## S = 14, p-value = 0.012726 ## alternative hypothesis: true median difference is not equal to 0 ## 95 percent confidence interval: ## 4.0101487 21.9898513 ## sample estimates: ## median of x-y ## 14 ## ## Achieved and Interpolated Confidence Intervals: ## ## Conf.Level L.E.pt U.E.pt ## Lower Achieved CI 0.8565 5.0000 21.0000 ## Interpolated CI 0.9500 4.0101 21.9899 ## Upper Achieved CI 0.9510 4.0000 22.0000 符號檢驗的結果，相比 Wilcoxon 秩和檢驗的結果來說， P 值稍大，由於符號檢驗需要的假設前提比 Wilcoxon 秩和檢驗更少，更穩健 (檢驗效能更低, lacks power)。即便如此，數據依然提供足夠的證據 (p = 0.01273) 證明，實驗前後的收縮期血壓的中位數之差不等於零。 下面是 STATA 中同一數據的 Wilcoxon 秩和檢驗和符號檢驗的結果，和上面的 R 輸出結果作比較： . signrank sbp_A = sbp_B Wilcoxon signed-rank test sign | obs sum ranks expected -------------+--------------------------------- positive | 14 137.5 76.5 negative | 3 15.5 76.5 zero | 0 0 0 -------------+--------------------------------- all | 17 153 153 unadjusted variance 446.25 adjustment for ties -0.63 adjustment for zeros 0.00 ---------- adjusted variance 445.63 Ho: sbp_A = sbp_B z = 2.890 Prob &gt; |z| = 0.0039 . signtest sbp_A = sbp_B Sign test sign | observed expected -------------+------------------------ positive | 14 8.5 negative | 3 8.5 zero | 0 0 -------------+------------------------ all | 17 17 One-sided tests: Ho: median of sbp_A - sbp_B = 0 vs. Ha: median of sbp_A - sbp_B &gt; 0 Pr(#positive &gt;= 14) = Binomial(n = 17, x &gt;= 14, p = 0.5) = 0.0064 Ho: median of sbp_A - sbp_B = 0 vs. Ha: median of sbp_A - sbp_B &lt; 0 Pr(#negative &gt;= 3) = Binomial(n = 17, x &gt;= 3, p = 0.5) = 0.9988 Two-sided test: Ho: median of sbp_A - sbp_B = 0 vs. Ha: median of sbp_A - sbp_B != 0 Pr(#positive &gt;= 14 or #negative &gt;= 14) = min(1, 2*Binomial(n = 17, x &gt;= 14, p = 0.5)) = 0.0127 54.2.2 用迴歸法分析 配對實驗數據還可以使用迴歸手段分析。使用迴歸分析時，需要考慮兩種不同的情形： 配對使用的特徵具有唯一性，即有且只有一個對照。 自己作自己的對照，如實驗前實驗後的觀測值變化； 同一個實驗對象，左右兩眼隨機抽取一隻作病例，一隻作對照； 病例和自己的配偶配對。 配對使用的特徵不具有唯一性，病例可以有多個潛在對照。 病例和性別相同，年齡相近的對照； 第 1 種情況：配對使用的特徵具有唯一性 用 \\(Y_{ij}\\) 標記第 \\(j\\) 個配對實驗區塊中第 \\(i\\) 個對象的觀測結果。我們可以使用下面的迴歸模型： \\[ \\begin{equation} Y_{ij} = \\beta_0 + \\beta_1 X_{ij} + \\gamma_j + \\varepsilon_{ij} \\end{equation} \\tag{54.3} \\] 其中， \\(\\gamma_j\\) 是第 \\(j\\) 個配對實驗區塊的固定效應 (fixed effect)；\\(\\varepsilon_{ij}\\) 是殘差。這個模型可以在簡單線性迴歸中直接加入一個代表不同配對實驗區塊的變量 (分類型) 進行調整即可。用簡單線性迴歸擬合 (54.3) 是一個等同於配對 \\(t\\) 檢驗的迴歸方程。 注意：在迴歸模型中加入代表實驗區塊的分類型變量調整僅適用與簡單線性迴歸。非線性迴歸例如邏輯迴歸，方程中試圖加入區塊變量作爲固定效應是不合適的。 在模型中加入隨機效應 (random effect)，作爲另一種迴歸手段，則可以同時應用於線性迴歸和非線性迴歸。這種模型被叫做分層迴歸模型 (hierarchical models)，或混合效應模型 (mixed effect model)，或隨機效應模型 (random effect model)。這將會在分層迴歸模型這一章節中詳細討論，此處且先按下不表。 第 2 種情況：配對使用的特徵不具有唯一性 用 \\(Y_i\\) 標記第 \\(i\\) 個個體的觀測結果， \\(X_i\\) 標記主要關心的暴露變量，\\(W_i\\) 標記用於配對的一系列變量的向量。那麼我們可以擬合兩種迴歸模型，差別在於是否調整配對變量向量： \\[ \\begin{equation} Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i \\end{equation} \\tag{54.4} \\] \\[ \\begin{equation} Y_i = \\beta_0 + \\beta_1 X_i + \\beta_2^TW_i + \\delta_i \\end{equation} \\tag{54.5} \\] 需要指出的是，這兩個模型，都是合理有效的迴歸模型，理論上會給出相同或者十分近似的 \\(\\beta_1\\) 估計。因爲配對，意味着在該樣本中，\\(X_i\\) 和 \\(W_i\\) 是無關的，所以加入 \\(W_i\\) 不會影響 \\(\\beta_1\\) 的估計值。即使，實驗樣本所來自的潛在人羣 (the unerlying population) 中，\\(X_i, W_i\\) 是相關的 (也是最主要的要拿 \\(W_i\\) 進行配對的動機所在)，兩個模型給出的 \\(\\beta_1\\) 估計理論上也不會有太大差距。但是，如果說配對是爲了控制混雜 (即人羣中 \\(X_i, W_i\\) 是相關的)，那麼建議使用模型 (54.5)。因爲模型 (54.5) 給出的 \\(\\beta_1\\) 的標準誤估計會比較小 (更小的 95% 信賴區間，更精確)。 前一節提到的一般檢驗法，是直接把“配對”這個條件放在檢驗過程中，它們只關心差異大小是否有意義。本小節討論的迴歸方法，則需要一些前提假設 (參考簡單線性迴歸的前提和邏輯迴歸的前提)。當前提條件可以滿足時，我們會更推薦使用迴歸方法對配對數據進行檢驗。因爲通常除了拿來配對的變量，我們對觀察對象還收集了其他的潛在混雜因子數據，使用迴歸方法可以進一步對其餘未用於配對的變量進行調整。 54.3 結果變量是二分類變量的配對實驗 用 \\(Y_{i1}, Y_{i2} (i = 1,\\cdots,n)\\) 標記 \\(n\\) 個配對的二分類型的結果變量，其對應的暴露變量是 \\(X_{i1}, X_{i2}\\)。 這樣的數據，有兩種方法來分析暴露和結果之間是否相關： McNemar’s test; Odds ratio. 用前文中糖尿病患者眼底病變和是否變盲的例子來說明就是：第 \\(i\\) 個實驗對象，他/她接受標準治療的眼睛是否變盲，決定了 \\(Y_{i1} = 1 \\text{ or } 0\\)；他/她接受新的治療的那隻眼睛是否變盲決定了 \\(Y_{i2} = 1 \\text{ or } 0\\)。 但是，用病例對照實驗 (肺癌例) 來解釋時，20 名肺癌患者被一一和同性別，年齡相近的 20 名非肺癌對象配對，每個實驗對象都被詢問其吸菸史。這樣的配對病例對照實驗的設計，決定了其實際上是把我們關心的問題 (吸菸是否導致肺癌) 逆轉了的 (肺癌患者中吸菸的比例是否大於沒有患肺癌的人)。此時應當使用 比值比 Odds ratio 來評價吸菸和肺癌之間的關係。 54.3.1 第一步 對數據作表格 有兩種方式對結果變量是二分類變量的實驗數據作表格歸納。其一，配對與否的信息被忽略掉 (表格 54.1)；其二，包含配對信息 (表格 54.2)。 表 54.1: Unmatched presentation of data from a study with binary outcome and binary treatment New treatment Standard treatment Blind 10 34 Not blind 67 43 Total 77 77 表 54.2: Matched presentation of data from a study with binary outcome and binary treatment New treatment Not blind Blind Standard treatment Not blind 39 4 43 Blind 28 6 34 67 10 77 54.3.2 McNemar’s test 下面的表格，是前面表格 54.2 的一般化形式。可以用於 McNemar 檢驗。在暴露對象中，結果變量等於 \\(Y_{i1} = 1\\) 的配對數量的比例是 \\(p_1 = (n_{10} + n_{11})/n\\)；在非暴露對象中，結果變量等於 \\(Y_{i2} = 2\\) 的配對數量的比例是 \\(p_2 = (n_{01} + n_{11})/n\\)。 表 54.3 General arrangement of data for McNemar’s test Exposed \\((j = 1)\\) Failure \\((Y_{i1} = 0)\\) Success \\((Y_{i1} = 1)\\) Unexposed \\((j = 2)\\) Failure \\((Y_{i2} = 0)\\) \\(n_{00}\\) \\(n_{10}\\) \\(n_{00}+n_{10}\\) Success \\((Y_{i2} = 1)\\) \\(n_{01}\\) \\(n_{11}\\) \\(n_{01}+n_{11}\\) \\(n_{00}+n_{01}\\) \\(n_{10}+n_{11}\\) \\(n\\) McNemar 檢驗的零假設是，\\(p_2 - p_1 = 0\\)，其實這等價於比較表格中 \\(n_{10}, n_{01}\\) 是否相等。所以，在零假設條件下： \\[ n_{10} \\sim \\text{Binomial}(n_{10} + n_{01}, 0.5) \\] 此時既可以選用精確的二項分佈檢驗，也可以用正態分佈近似法進行假設檢驗。用表格 54.2 的數據進行的檢驗結果如下： binom.test(28, 32, 0.5) ## ## Exact binomial test ## ## data: 28 and 32 ## number of successes = 28, number of trials = 32, p-value = 0.000019301 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.71005158 0.96486935 ## sample estimates: ## probability of success ## 0.875 54.3.3 二分類型結果變量配對實驗的比值比 McNemar 檢驗只能用於判斷暴露和結果之間是否有關係。衡量這個關係的大小，還需要用比值比 (odds ratio)。我們已知可以用 Mantel Haenszel 方法來總結以某個分類變量爲條件的分層/合併比值比。同樣的方法也可以用於配對實驗數據的分析。此時的分層變量使用的是配對的實驗區塊 (blocks)。每個實驗區塊的數據可以歸納成下面的表格： 表 54.4 Example of matched data in stratum \\(i\\): numbers of individuals in stratum \\(i\\) with each combination Unexposed (0) Exposed (1) Outcome 0 \\(a_i\\) \\(b_i\\) Outcome 1 \\(c_i\\) \\(d_i\\) 實驗區塊 \\(i\\) 的比值比 OR 是： \\[ \\text{OR} = \\frac{a_id_i}{b_ic_i} \\] Mantel Haenszel 合併 OR 是： \\[ \\Psi = \\frac{\\sum_i(a_id_i/n_i)}{\\sum_i(b_ic_i/n_i)} \\\\ \\text{where } n_i = 2 \\] 可以繼續推導： \\[ \\begin{aligned} \\Psi &amp; = \\frac{\\sum_i(a_id_i/n_i)}{\\sum_i(b_ic_i/n_i)} \\\\ &amp; = \\frac{\\text{number of blocks with } Y_{i1} = 1 \\;\\&amp;\\; Y_{i2} = 0}{\\text{number of blocks with } Y_{i1} = 0 \\;\\&amp;\\; Y_{i2} = 1} \\\\ &amp; = \\frac{n_{10}}{n_{01}} \\end{aligned} \\] 所以，從上述推導可知，在配對實驗中，比值比只取決於那些配對中出現了不同結果的數據。這些結果不一致的配對被命名爲不一致配對 (discordant pairs)。那些結果變量相同的配對對最終的比值比估計毫無用處。 54.3.4 配對實驗比值比的信賴區間 配對實驗比值比信賴區間的精確計算步驟如下： \\(\\pi\\) 標記暴露對象中，結果變量等於 \\(Y_{i1} = 1\\)，且非暴露對象中，結果變量等於 \\(Y_{i2} = 0\\) 的配對數在全部不一致配對數中所佔的比例：\\[\\hat\\pi = \\frac{n_{10}}{n_{10} + n_{01}}\\] \\(\\Psi\\) 爲不一致配對的比值比：\\[\\hat\\Psi = \\frac{n_{10}}{n_{01}}\\] \\(\\pi, \\Psi\\) 之間的關係是：\\[\\Psi = \\frac{\\pi}{1-\\pi}\\] \\(n_{10}\\) 服從二項分佈：\\[n_{10}\\sim \\text{Binomial}(n_{10} + n_{01}, \\pi)\\] 根據二項分佈的性質計算 \\(\\pi\\) 的信賴區間： \\[\\pi_L, \\pi_U\\] 所以 \\(\\Psi\\) 的信賴區間就可以計算爲：\\[(\\frac{\\pi_L}{1-\\pi_L},\\frac{\\pi_U}{1-\\pi_U})\\] 用表格54.2 的數據計算其比值比估計： \\[\\hat{\\text{OR}} = \\frac{n_{10}}{n_{01}} = \\frac{4}{28} = 0.14\\] \\(n_{10} = 4 \\sim \\text{Binomial}(32, \\pi = 4/32 = 0.125)\\) 所以 \\(\\pi\\) 的 95% 信賴區間爲： FSA::binCI(4, 32) ## 95% LCI 95% UCI ## Exact 0.035130653 0.28994842 ## Wilson 0.049701344 0.28068305 ## Asymptotic 0.010413848 0.23958615 那麼該比值比的精確 95% 信賴區間爲： \\[ \\begin{aligned} &amp; (\\frac{0.03513065}{1-0.03513065},\\frac{0.2899484}{1-0.2899484}) \\\\ =&amp; (0.036, 0.408) \\end{aligned} \\] 精確計算的結果和 R 裏獲得的結果一致： library(exact2x2) mcnemar.exact(matrix(c(39, 28, 4, 6),2,2)) ## ## Exact McNemar test (with central confidence intervals) ## ## data: matrix(c(39, 28, 4, 6), 2, 2) ## b = 4, c = 28, p-value = 0.000019301 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 0.036409751 0.408348391 ## sample estimates: ## odds ratio ## 0.14285714 54.4 條件 (conditional) 比值比和邊際 (marginal) 比值比 從配對實驗獲得的比值比是條件比值比 (conditional odds ratio)，所謂條件比值比，意思就是從配對實驗獲得的比值比是以配對的試驗區塊爲條件的。 用表格 54.2 的糖尿病患者眼底病變的數據來進一步解釋：該實驗獲得的條件比值比爲 0.143，實驗區塊是每位眼底發生病變的糖尿病患者本身。這個條件比值比應被正確解讀爲：每位眼底發生病變的患者中的兩隻眼睛中接受新療法的眼睛最終失明的機率 (odds)，和另一隻接受標準療法的眼睛最終失明的機率的比值是 0.143。數學表達式標記爲： \\[ \\text{Conditional OR} = \\frac{\\frac{\\text{Pr(Blind|new, individual) } i}{\\text{Pr(Not Blind|new, individual) } i}}{\\frac{\\text{Pr(Blind|standard, individual) } i}{\\text{Pr(Not blind|standard, individual) } i}} \\] 此條件比值比被認爲在該樣本不同的患者\\((i)\\)中保持不變。需要指出的是這個條件比值比不等同於認爲在糖尿病人羣中接受新療法治療的眼睛失明機率和接受標準療法的眼睛失明機率之比爲 0.134 (邊際比值比 marginal odds ratio)。邊際比值比的數學表達式爲： \\[ \\text{Marginal OR} = \\frac{\\text{Pr(Blind | new)/PR(Not blind | new)}}{\\text{Pr(Blind | standard)/PR(Not blind | standard)}} \\] 如果要估計上式的邊際比值比，我們需要有糖尿病人羣中失明的危險度 (the risk of blindness in the population)，以及失明高危人羣，低危人羣各自接受標準療法的失明概率。假如已知如下的信息： 糖尿病人羣中有 50% 的人可以被歸類爲失明高危人羣 (high risk, HR)，另 50% 可以被歸類會失明低危人羣 (low risk, LR)； 接受標準療法時，高危人羣失明的概率是 90%，低危人羣失明的概率是 10%。 上述信息告訴我們，總體糖尿病人羣中接受標準療法失明的概率 \\(\\text{Pr(Blind|standard)}\\) 是： \\[ \\begin{aligned} \\text{Pr(Blind|standard)} &amp; = \\text{Pr(Blind|standard,HR)Pr(HR)} \\\\ &amp; \\;\\;\\;+ \\text{Pr(Blind|standard, LR)Pr(LR)} \\\\ &amp; = 0.9\\times0.5 + 0.1\\times0.5 = 0.5 \\end{aligned} \\] 再利用條件比值比 \\(0.143\\) 我們可以計算糖尿病人羣中接受新療法失明的概率 \\(\\text{Pr(Blind | new)}\\) 是： \\[ \\begin{aligned} \\frac{\\text{Pr(Blind|new, HR)}}{\\text{PR(Not blind | new, HR)}} &amp; = 0.143 \\times \\frac{\\text{Pr(Blind|standard, HR)}}{\\text{Pr(Not blind|standard, HR)}} \\\\ &amp; = 0.143 \\times \\frac{0.9}{0.1} = 1.287 \\\\ \\frac{\\text{Pr(Blind|new, LR)}}{\\text{PR(Not blind | new, LR)}} &amp; = 0.143 \\times \\frac{\\text{Pr(Blind|standard, LR)}}{\\text{Pr(Not blind|standard, LR)}} \\\\ &amp; = 0.143 \\times \\frac{0.1}{0.9} = 0.016 \\\\ \\Rightarrow \\text{Pr(Blind|new, HR)} &amp; = 1.287/(1+1.287) = 0.563 \\\\ \\text{Pr(Blind|new, LR)} &amp; = 0/016/(1+0.016) = 0.016 \\\\ \\Rightarrow\\;\\;\\; \\text{Pr(Blind | new)} &amp; = \\text{Pr(Blind|new, HR)Pr(HR)} + \\text{Pr(Blind|new, LR)PR(LR)} \\\\ &amp; = 0.563\\times0.5 + 0.016\\times0.5 = 0.290 \\end{aligned} \\] 獲得了 \\(\\text{Pr(Blind|standard), Pr(Blind | new)}\\) 之後，邊際比值比 (糖尿病人羣中接受新療法治療的眼睛失明機率和接受標準療法的眼睛失明機率之比)： \\[ \\begin{aligned} \\text{Marginal OR} &amp; = \\frac{\\text{Pr(Blind | new)/Pr(Not blind | new)}}{\\text{Pr(Blind | standard)/Pr(Not blind | standard)}} \\\\ &amp; = \\frac{0.5/(1-0.5)}{0.290/(1-0.290)} = 0.408 \\end{aligned} \\] 比起條件比值比 (0.143)，邊際比值比 (0.408) 要大出許多來。 "],
["-conditional-logistic-regression.html", "第 55 章 條件邏輯迴歸 Conditional logistic regression 55.1 配對實驗的邏輯迴歸模型", " 第 55 章 條件邏輯迴歸 Conditional logistic regression 配對實驗設計可以用於 RCT，隊列研究，病例對照研究： RCT裏，接受治療方案 A 的患者，和接受治療方案 B 的患者，以 1:1 的比例按照他們的某種醫學特徵配對。這種配對可以是同一個患者在交叉設計RCT 實驗中的觀測值，也可以是同一個患者接受治療的前後測量值，當然還可以是同一個患者的左右兩隻眼睛 (手臂，腿，等等)； 隊列研究裏，暴露和非暴露對象根據事先決定的配對原則配對 (相同性別，年齡接近，或者居住在同一社區，或者是同意家庭中暴露和非暴露的兩個個體)； 病例對照研究裏，病例和非病例按照事先決定的配對原則配對，一個病例可能和一個或者多個對照相匹配。 本章節着重討論病例對照研究中，條件邏輯迴歸模型的使用。配對病例對照研究中，研究者常用一些最常見的混雜因素作爲配對的變量 (如性別年齡)，且這些配對所使用的變量本身不是該實驗主要探討的話題。有些研究者還認爲配對是一個方便地尋找對照組的手段。當然，選取對照組的原則，可以是具有唯一性的配對原則 (使對照有且僅有1-2個)，或者是無唯一性的配對原則 (病例可以有多個潛在的對照)。唯一性配對原則導致的最大問題是，你可能根本找不到合適的對照，所以研究者會更傾向於把配對原則放寬一些，以獲取足夠的對照組樣本量，但是這也會帶來別的附加問題，那就是需要用匹配的數學模型來控制殘差之間的依賴性 (residual dependency)。在考慮了生存時間的一些病例對照研究中，原則上還會考慮選取和病例存活相同時間 (年齡) 的人作對照，詳細會繼續在生存分析中深入探討。 55.1 配對實驗的邏輯迴歸模型 定義 \\(X_u\\) 是一個簡單的二分類暴露變量，\\(D_u\\) 是一個簡單的二分類結果變量，\\(u = 1, \\cdots, n\\) 是配對的個數。第 \\(u\\text{th}\\) 組中的研究對象，互爲配對。在某些特殊場合，每組配對只有2個研究對象 (例如糖尿病患者的左右兩隻眼睛)。 用概率標記法定義每個患者的概率： \\[ \\begin{equation} \\pi_{u;xd} = \\text{Pr}(X_u = x, D_u = d) \\end{equation} \\tag{55.1} \\] 用 (Section 50.2) 中相似的表格來理解，第 \\(u\\) 組 \\((u = 1, \\cdots, n)\\) 配對中的研究對象可以用下表來歸納其概率。 表 55.1: Separate samples from subpopulations \\(D=0,1\\) with relavant conditional probabilities in a matched case-control study within each pair \\(D\\) \\(0\\) \\(1\\) \\(X\\) \\(0\\) \\(\\pi_{u;00}\\) \\(\\pi_{u;01}\\) \\(1\\) \\(\\pi_{u;10}\\) \\(\\pi_{u;11}\\) \\(\\text{Pr}(X_u=x|D_u=d)\\) \\(\\frac{\\pi_{u;10}}{\\pi_{u;10}+\\pi_{u;00}}\\) \\(\\frac{\\pi_{u;11}}{\\pi_{u;11}+\\pi_{u;01}}\\) 那麼第 \\(u\\) 組配對中，暴露和結果之間真實的比值比 (odds ratio)是： \\[ \\begin{equation} \\frac{\\pi_{u;11}\\pi_{u;00}}{\\pi_{u;10}\\pi_{u;01}} \\end{equation} \\tag{55.2} \\] 所以，在配對病例對照研究中，一個最重要的前提被假設：那就是每個配對中的比值比是不變的 (we assume that the true log odds ratio relating exposure to disease is the same for all pairs)： \\[ \\begin{equation} \\frac{\\pi_{u;11}\\pi_{u;00}}{\\pi_{u;10}\\pi_{u;01}} = e^\\beta \\end{equation} \\tag{55.3} \\] 在探討非配對的病例對照研究時，我們給二分類型暴露變量定義過下列邏輯迴歸模型 (Section 50.2.3)： \\[ \\begin{equation} \\text{Pr}(X_i = 1 | D_i = d_i) = \\frac{e^{\\lambda^*+\\beta d_i}}{1+e^{\\lambda^*+\\beta d_i}}\\\\ \\text{Where } i \\text{ refers to an individual} \\end{equation} \\tag{55.4} \\] "],
["multinomial-logistic-regression.html", "第 56 章 Multinomial Logistic Regression", " 第 56 章 Multinomial Logistic Regression "],
["ordinal-logistic-regression.html", "第 57 章 Ordinal Logistic Regression", " 第 57 章 Ordinal Logistic Regression "],
["section-58.html", "第 58 章 相互依賴數據及簡單的應對方案 58.1 相互依賴的數據 58.2 依賴性的來源在哪裏 58.3 數據有依賴性導致的結果 58.4 依賴數據的簡單處理手法 58.5 簡單線性迴歸複習 58.6 練習題", " 第 58 章 相互依賴數據及簡單的應對方案 58.1 相互依賴的數據 58.2 依賴性的來源在哪裏 58.3 數據有依賴性導致的結果 58.4 依賴數據的簡單處理手法 58.5 簡單線性迴歸複習 58.6 練習題 58.6.1 數據 High-School-and-Beyond 數據 本數據來自1982年美國國家教育統計中心 (National Center for Education Statistics, NCES) 對美國公立學校和天主教會學校的一項普查。曾經在 Hierarchical Linear Model (Raudenbush and Bryk 2002) 一書中作爲範例使用。其數據的變量名和各自含義如下： minority indicatory of student ethinicity (1 = minority, 0 = other) female pupil&#39;s gender ses standardized socio-economic status score mathach measure of mathematics achievement size school&#39;s total number of pupils sector school&#39;s sector: 1 = catholic, 0 = not catholic schoolid school identifier PEFR 數據 數據本身是 17 名研究對象用兩種不同的測量方法測量兩次每個人的最大呼氣流速 (peak-expiratory-flow rate, PEFR)。最早在1986年的柳葉刀雜誌發表 (Bland and Altman 1986)。兩種測量法的名稱分別是 “Standard Wright” 和 “Mini Wright” peak flow meter。變量名和個字含義如下： id participant identifier wp1 standard wright measure at 1st occasion wp2 standard wright measure at 2nd occasion wm1 mini wright measure at 1st occasion wm2 mini wright measure at 2nd occasion 58.6.2 問題 58.6.3 將 High-School-and-Beyond 數據導入 R 中，熟悉數據結構及內容，特別要注意觀察每個學校的學生特徵。 hsb_selected &lt;- read_dta(&quot;backupfiles/hsb_selected.dta&quot;) length(unique(hsb_selected$schoolid)) ## number of school = 160 ## [1] 160 ## create a subset data with only the first observation of each school hsb &lt;- hsb_selected[!duplicated(hsb_selected$schoolid), ] ## about 44 % of the schools are Catholic schools with(hsb, tab1(sector, graph = FALSE, decimal = 2)) ## sector : ## Frequency Percent Cum. percent ## 0 90 56.25 56.25 ## 1 70 43.75 100.00 ## Total 160 100.00 100.00 ## among all the pupils, about 53% are females with(hsb_selected, tab1(female, graph = FALSE, decimal = 2)) ## female : ## Frequency Percent Cum. percent ## 0 3390 47.18 47.18 ## 1 3795 52.82 100.00 ## Total 7185 100.00 100.00 ## among all the pupils, about 27.5% are from ethnic minorities with(hsb_selected, tab1(minority, graph = FALSE, decimal = 2)) ## minority : ## Frequency Percent Cum. percent ## 0 5211 72.53 72.53 ## 1 1974 27.47 100.00 ## Total 7185 100.00 100.00 58.6.4 爲了簡便起見，接下來的分析只節選數據中前五所學校 188 名學生的數學成績，和 SES。分別計算每所學校的數學成績,及 SES 的平均值。 hsb5 &lt;- subset(hsb_selected, schoolid &lt; 1320) Mean_ses_math &lt;- ddply(hsb5,~schoolid,summarise,mean_ses=mean(ses),mean_math=mean(mathach)) ## the mean SES score ranges from -0.4255 to +0.5280 ## the mean Maths score ranges from 7.636 to 16.255 Mean_ses_math ## schoolid mean_ses mean_math ## 1 1224 -0.43438298 9.7154468 ## 2 1288 0.12159999 13.5108000 ## 3 1296 -0.42550000 7.6359583 ## 4 1308 0.52800000 16.2554999 ## 5 1317 0.34533333 13.1776875 58.6.5 先無視掉學校這一分層變量，把所有學生看作是相互獨立的，擬合總體的 SES 和數學成績的線性迴歸 (Total regression model)。把該總體模型的預測值提取並存儲在數據庫中。 ## plot the scatter of mathach and ses among these 5 schools ggplot(hsb5, aes(x = ses, y = mathach)) + geom_point() + theme_bw() + theme(axis.text = element_text(size = 15), axis.text.x = element_text(size = 15), axis.text.y = element_text(size = 15)) + labs(x = &quot;SES&quot;, y = &quot;Math achievement&quot;) + xlim(-2.05, 2.05)+ ylim(-10, 30) + theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8), axis.line = element_line(colour = &quot;black&quot;), panel.border = element_blank(), panel.background = element_blank()) 圖 58.1: Scatter plot of SES and math achievements among all pupils from first 5 schools, assuming that they are all independent Total_reg &lt;- lm(mathach ~ ses, data = hsb5) ## the total regression model gives an estimated regression coefficient for the SES ## of each pupil equal to 3.31 (SE=0.66) summary(Total_reg) ## ## Call: ## lm(formula = mathach ~ ses, data = hsb5) ## ## Residuals: ## Min 1Q Median 3Q Max ## -15.23022 -5.08316 -0.68614 5.11170 14.68513 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 11.45652 0.47342 24.1997 &lt; 2.2e-16 *** ## ses 3.30696 0.66021 5.0089 1.267e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.4708 on 186 degrees of freedom ## Multiple R-squared: 0.11886, Adjusted R-squared: 0.11412 ## F-statistic: 25.09 on 1 and 186 DF, p-value: 1.2667e-06 hsb5$Pred_T &lt;- Total_reg$fitted.values # save the fitted values to the dataset 58.6.6 用各個學校 SES 和數學成績的均值擬合一個學校間的線性迴歸模型 (between regression model)。 Btw_reg &lt;- lm(mean_math ~ mean_ses, data = Mean_ses_math) ## the regression model for the school level variables (between model) gives ## an estimated regression coefficient of 7.29 (SE=1.41) summary(Btw_reg) ## ## Call: ## lm(formula = mean_math ~ mean_ses, data = Mean_ses_math) ## ## Residuals: ## 1 2 3 4 5 ## 1.02010 0.76212 -1.12415 0.54401 -1.20209 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 11.86216 0.55664 21.3102 0.0002261 *** ## mean_ses 7.29039 1.40703 5.1814 0.0139557 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.2418 on 3 degrees of freedom ## Multiple R-squared: 0.89949, Adjusted R-squared: 0.86598 ## F-statistic: 26.847 on 1 and 3 DF, p-value: 0.013956 Mean_ses_math$Pred_B &lt;- Btw_reg$fitted.values # save the fitted values to the dataset 58.6.7 分別對每個學校內的學生進行 SES 和數學成績擬合線性迴歸模型。 Within_schl1 &lt;- lm(mathach ~ ses, data = hsb5[hsb5$schoolid == 1224,]) Within_schl2 &lt;- lm(mathach ~ ses, data = hsb5[hsb5$schoolid == 1288,]) Within_schl3 &lt;- lm(mathach ~ ses, data = hsb5[hsb5$schoolid == 1296,]) Within_schl4 &lt;- lm(mathach ~ ses, data = hsb5[hsb5$schoolid == 1308,]) Within_schl5 &lt;- lm(mathach ~ ses, data = hsb5[hsb5$schoolid == 1317,]) # the within school regressions gives estimated slopes which have a mean of 1.65 # and which ranges between 0.126 and 3.255 summary(c(Within_schl1$coefficients[2], Within_schl2$coefficients[2], Within_schl3$coefficients[2], Within_schl4$coefficients[2], Within_schl5$coefficients[2])) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.12602 1.07596 1.27391 1.64799 2.50858 3.25545 # the SEs ranging between 1.21 and 3.00 summary(c(summary(Within_schl1)$coefficients[4], summary(Within_schl2)$coefficients[4], summary(Within_schl3)$coefficients[4], summary(Within_schl4)$coefficients[4], summary(Within_schl5)$coefficients[4])) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.2090 1.4359 1.7652 1.8987 2.0797 3.0034 hsb5$Pred_W &lt;- c(Within_schl1$fitted.values, Within_schl2$fitted.values, Within_schl3$fitted.values, Within_schl4$fitted.values, Within_schl5$fitted.values) ## save the predicted value into the dataset 58.6.8 比較三種模型計算的數學成績的擬合值，他們一致？還是有所不同？爲什麼會有不同？ 總體模型 (Total regression model) 實際上無視了學生的性別，種族等可能帶來的混雜效果； 學校間模型 (Between model) 估計的實際上是SES均值每增加一個單位，與之對應的數學平均成績的改變量，這個模型絕對不可用與評估個人的 SES 與數學成績之間的關係； 學校內模型 (Within model) 擬合的 SES 與數學成績之間的關係變得十分地不精確 (SEs are fairly large)，變化幅度也很大。 58.6.9 把三種模型的數學成績擬合值散點圖繪製在同一張圖內。 Mean &lt;- Mean_ses_math[, 1:3] names(Mean) &lt;- c(&quot;schoolid&quot;, &quot;ses&quot;, &quot;Pred_W&quot;) ggplot(hsb5, aes(x = ses, y = Pred_W, group = schoolid)) + geom_line(linetype = 2, size = 1) + geom_abline(intercept = Total_reg$coefficients[1], slope = Total_reg$coefficients[2], colour = &quot;dark blue&quot;) + geom_abline(intercept = Btw_reg$coefficients[1], slope = Btw_reg$coefficients[2], colour = &quot;red&quot;) + geom_point(data = Mean, shape = 17, size = 4, colour = &quot;Red&quot;) + theme_bw() + theme(axis.text = element_text(size = 15), axis.text.x = element_text(size = 15), axis.text.y = element_text(size = 15)) + labs(x = &quot;SES&quot;, y = &quot;Fitted regression lines (Maths achievement)&quot;) + xlim(-2.05, 2.05)+ ylim(5, 20) + theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8), axis.line = element_line(colour = &quot;black&quot;), panel.border = element_blank(), panel.background = element_blank()) + theme(plot.caption = element_text(size = 12, hjust = 0)) + labs(caption = &quot;Black dash line: Within regression model; Blue solid line: Total regression model; Red solid line: Between regression model; Red triangle: School mean values&quot;) 圖 58.2: High-school-and-beyond data: Predicted values by Total, Between, and Within regression models 58.6.10 用這 5 個學校的數據擬合一個固定效應線性迴歸模型 Fixed_reg &lt;- lm(mathach ~ ses + factor(schoolid), data = hsb5) ## Fitting a fixed effect model to these data is equivalent to forcing ## a common slope onto the five within regression models. It gives an ## estimated slope of 1.789 (SE=0.76), close to their average of 1.64799. ## Note that controlling for female, minority, and sector but not for ## schoolid leads to roughly the same estimate (slope = 1.68, SE=0.75) summary(Fixed_reg) ## ## Call: ## lm(formula = mathach ~ ses + factor(schoolid), data = hsb5) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.97593 -4.19683 -0.75189 5.22088 16.38133 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.49254 0.96761 10.8438 &lt; 2.2e-16 *** ## ses 1.78896 0.75939 2.3558 0.019548 * ## factor(schoolid)1288 2.80072 1.60041 1.7500 0.081803 . ## factor(schoolid)1296 -2.09538 1.27973 -1.6374 0.103283 ## factor(schoolid)1308 4.81839 1.81826 2.6500 0.008758 ** ## factor(schoolid)1317 2.06736 1.41005 1.4662 0.144332 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.2362 on 182 degrees of freedom ## Multiple R-squared: 0.1992, Adjusted R-squared: 0.1772 ## F-statistic: 9.0544 on 5 and 182 DF, p-value: 1.0512e-07 summary(lm(mathach ~ ses + female + minority + sector, data = hsb5)) ## ## Call: ## lm(formula = mathach ~ ses + female + minority + sector, data = hsb5) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.09128 -4.17332 -0.46306 4.50807 15.33205 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 12.54543 0.86027 14.5831 &lt; 2.2e-16 *** ## ses 1.68055 0.74489 2.2561 0.0252480 * ## female -1.54861 0.94857 -1.6326 0.1042780 ## minority -3.19635 0.95450 -3.3487 0.0009857 *** ## sector 3.98121 1.11941 3.5565 0.0004785 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.1696 on 183 degrees of freedom ## Multiple R-squared: 0.2119, Adjusted R-squared: 0.19467 ## F-statistic: 12.301 on 4 and 183 DF, p-value: 7.0265e-09 58.6.11 讀入 PEFR 數據。 pefr &lt;- read_dta(&quot;backupfiles/pefr.dta&quot;) # the data are in wide format pefr ## # A tibble: 17 x 5 ## id wp1 wp2 wm1 wm2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.00 494 490 512 525 ## 2 2.00 395 397 430 415 ## 3 3.00 516 512 520 508 ## 4 4.00 434 401 428 444 ## 5 5.00 476 470 500 500 ## 6 6.00 557 611 600 625 ## 7 7.00 413 415 364 460 ## 8 8.00 442 431 380 390 ## 9 9.00 650 638 658 642 ## 10 10.0 433 429 445 432 ## 11 11.0 417 420 432 420 ## 12 12.0 656 633 626 605 ## 13 13.0 267 275 260 227 ## 14 14.0 478 492 477 467 ## 15 15.0 178 165 259 268 ## 16 16.0 423 372 350 370 ## 17 17.0 427 421 451 443 # transform data into long format pefr_long &lt;- pefr %&gt;% gather(key, value, -id) %&gt;% separate(key, into = c(&quot;measurement&quot;, &quot;occasion&quot;), sep = 2) %&gt;% arrange(id, occasion) %&gt;% spread(measurement, value) pefr_long ## # A tibble: 34 x 4 ## id occasion wm wp ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.00 1 512 494 ## 2 1.00 2 525 490 ## 3 2.00 1 430 395 ## 4 2.00 2 415 397 ## 5 3.00 1 520 516 ## 6 3.00 2 508 512 ## 7 4.00 1 428 434 ## 8 4.00 2 444 401 ## 9 5.00 1 500 476 ## 10 5.00 2 500 470 ## # ... with 24 more rows ## figure shows slightly closer agreement between the repeated measures of standard Wright, ## than between those of Mini Wright ggplot(pefr_long, aes(x = id, y = wp, fill = occasion)) + geom_point(size = 4, shape = 21) + geom_hline(yintercept = mean(pefr_long$wp), colour = &quot;red&quot;) + theme_bw() + scale_x_continuous(breaks = 1:17)+ theme(axis.text = element_text(size = 15), axis.text.x = element_text(size = 15), axis.text.y = element_text(size = 15)) + labs(x = &quot;Subject ID&quot;, y = &quot;W Measurements&quot;) + theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8), axis.line = element_line(colour = &quot;black&quot;), panel.border = element_blank(), panel.background = element_blank()) 圖 58.3: Two recordings of PEFR taken with the standard Wright meter 58.6.12 求每個患者的 wp 兩次測量平均值 # the means range from 171.5 to 644.5 with(pefr_long, summ(wp, by = id, graph = FALSE)) ## For id = 1 ## obs. mean median s.d. min. max. ## 2 492 492 2.828 490 494 ## ## For id = 2 ## obs. mean median s.d. min. max. ## 2 396 396 1.414 395 397 ## ## For id = 3 ## obs. mean median s.d. min. max. ## 2 514 514 2.828 512 516 ## ## For id = 4 ## obs. mean median s.d. min. max. ## 2 417.5 417.5 23.335 401 434 ## ## For id = 5 ## obs. mean median s.d. min. max. ## 2 473 473 4.243 470 476 ## ## For id = 6 ## obs. mean median s.d. min. max. ## 2 584 584 38.184 557 611 ## ## For id = 7 ## obs. mean median s.d. min. max. ## 2 414 414 1.414 413 415 ## ## For id = 8 ## obs. mean median s.d. min. max. ## 2 436.5 436.5 7.778 431 442 ## ## For id = 9 ## obs. mean median s.d. min. max. ## 2 644 644 8.485 638 650 ## ## For id = 10 ## obs. mean median s.d. min. max. ## 2 431 431 2.828 429 433 ## ## For id = 11 ## obs. mean median s.d. min. max. ## 2 418.5 418.5 2.121 417 420 ## ## For id = 12 ## obs. mean median s.d. min. max. ## 2 644.5 644.5 16.263 633 656 ## ## For id = 13 ## obs. mean median s.d. min. max. ## 2 271 271 5.657 267 275 ## ## For id = 14 ## obs. mean median s.d. min. max. ## 2 485 485 9.899 478 492 ## ## For id = 15 ## obs. mean median s.d. min. max. ## 2 171.5 171.5 9.192 165 178 ## ## For id = 16 ## obs. mean median s.d. min. max. ## 2 397.5 397.5 36.062 372 423 ## ## For id = 17 ## obs. mean median s.d. min. max. ## 2 424 424 4.243 421 427 58.6.13 在 R 裏先用 ANOVA 分析個人的 wp 變異。再用 lme4::lmer 擬合用 id 作隨機效應的混合效應模型。確認後者報告的 Std.Dev for id effect 其實可以用 ANOVA 結果的 \\(\\sqrt{\\frac{\\text{MMS-MSE}}{n}}\\) (n 是每個個體重複測量值的個數)。 with(pefr_long, anova(lm(wp~factor(id)))) ## Analysis of Variance Table ## ## Response: wp ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## factor(id) 16 441599 27599.91 117.8 3.145e-14 *** ## Residuals 17 3983 234.29 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #library(lme4) ( fit &lt;- lmer(wp ~ (1|id), data=pefr_long) ) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: wp ~ (1 | id) ## Data: pefr_long ## REML criterion at convergence: 353.5472 ## Random effects: ## Groups Name Std.Dev. ## id (Intercept) 116.974 ## Residual 15.307 ## Number of obs: 34, groups: id, 17 ## Fixed Effects: ## (Intercept) ## 447.88 sqrt((27600 - 234)/2) ## [1] 116.97436 58.6.14 擬合結果變量爲 wp，解釋變量爲 id 的簡單線性迴歸模型。用數學表達式描述這個模型。 Reg &lt;- lm(wp ~ factor(id), data = pefr_long) # The fixed effect regression model leads to the same ANOVA # table. To the same estimate of the residual SD = (15.307) # However, it does not give an estimate of the &quot;SD of id effect&quot; # Instead it gives estimates of mean PEFR for participant number 1 # = 492 and estimates of the difference in means from him/her # for all the other 16 pariticipants anova(Reg) ## Analysis of Variance Table ## ## Response: wp ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## factor(id) 16 441599 27599.91 117.8 3.145e-14 *** ## Residuals 17 3983 234.29 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(Reg) ## ## Call: ## lm(formula = wp ~ factor(id), data = pefr_long) ## ## Residuals: ## Min 1Q Median 3Q Max ## -27.00 -3.75 0.00 3.75 27.00 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 492.000 10.823 45.4569 &lt; 2.2e-16 *** ## factor(id)2 -96.000 15.307 -6.2718 8.435e-06 *** ## factor(id)3 22.000 15.307 1.4373 0.1687894 ## factor(id)4 -74.500 15.307 -4.8672 0.0001448 *** ## factor(id)5 -19.000 15.307 -1.2413 0.2313547 ## factor(id)6 92.000 15.307 6.0105 1.405e-05 *** ## factor(id)7 -78.000 15.307 -5.0958 8.972e-05 *** ## factor(id)8 -55.500 15.307 -3.6259 0.0020883 ** ## factor(id)9 152.000 15.307 9.9303 1.715e-08 *** ## factor(id)10 -61.000 15.307 -3.9852 0.0009574 *** ## factor(id)11 -73.500 15.307 -4.8018 0.0001662 *** ## factor(id)12 152.500 15.307 9.9630 1.635e-08 *** ## factor(id)13 -221.000 15.307 -14.4382 5.665e-11 *** ## factor(id)14 -7.000 15.307 -0.4573 0.6532334 ## factor(id)15 -320.500 15.307 -20.9386 1.413e-13 *** ## factor(id)16 -94.500 15.307 -6.1738 1.020e-05 *** ## factor(id)17 -68.000 15.307 -4.4425 0.0003571 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.307 on 17 degrees of freedom ## Multiple R-squared: 0.99106, Adjusted R-squared: 0.98265 ## F-statistic: 117.8 on 16 and 17 DF, p-value: 3.145e-14 上面的模型用數學表達式來描述就是： \\[ \\begin{aligned} Y_{ij} &amp; = \\alpha_1 + \\delta_i + \\varepsilon_{ij} \\\\ \\text{Where } \\delta_j &amp; = \\alpha_j - \\alpha_1 \\\\ \\text{and } \\delta_1 &amp; = 0 \\end{aligned} \\] 58.6.15 將 wp 中心化之後，重新擬合相同的模型，把截距去除掉。寫下這個模型的數學表達式。 Reg1 &lt;- lm((wp - mean(wp)) ~ 0 + factor(id), data = pefr_long) # it leads to the same ANOVA table again, same residual SD anova(Reg1) ## Analysis of Variance Table ## ## Response: (wp - mean(wp)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## factor(id) 17 441599 25976.38 110.871 4.5349e-14 *** ## Residuals 17 3983 234.29 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(Reg1) ## ## Call: ## lm(formula = (wp - mean(wp)) ~ 0 + factor(id), data = pefr_long) ## ## Residuals: ## Min 1Q Median 3Q Max ## -27.00 -3.75 0.00 3.75 27.00 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## factor(id)1 44.118 10.823 4.0761 0.0007863 *** ## factor(id)2 -51.882 10.823 -4.7935 0.0001692 *** ## factor(id)3 66.118 10.823 6.1087 1.158e-05 *** ## factor(id)4 -30.382 10.823 -2.8071 0.0121232 * ## factor(id)5 25.118 10.823 2.3207 0.0329951 * ## factor(id)6 136.118 10.823 12.5762 4.894e-10 *** ## factor(id)7 -33.882 10.823 -3.1305 0.0060933 ** ## factor(id)8 -11.382 10.823 -1.0516 0.3076854 ## factor(id)9 196.118 10.823 18.1197 1.493e-12 *** ## factor(id)10 -16.882 10.823 -1.5598 0.1372300 ## factor(id)11 -29.382 10.823 -2.7147 0.0147164 * ## factor(id)12 196.618 10.823 18.1659 1.432e-12 *** ## factor(id)13 -176.882 10.823 -16.3425 7.887e-12 *** ## factor(id)14 37.118 10.823 3.4294 0.0031978 ** ## factor(id)15 -276.382 10.823 -25.5355 5.342e-15 *** ## factor(id)16 -50.382 10.823 -4.6549 0.0002269 *** ## factor(id)17 -23.882 10.823 -2.2065 0.0413886 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.307 on 17 degrees of freedom ## Multiple R-squared: 0.99106, Adjusted R-squared: 0.98212 ## F-statistic: 110.87 on 17 and 17 DF, p-value: 4.5349e-14 上面的模型用數學表達式來描述就是： \\[ \\begin{aligned} Y_{ij} - \\mu &amp; = \\gamma_j + \\varepsilon_{ij} \\\\ Y_{ij} &amp; = \\mu + \\gamma_j + \\varepsilon_{ij} \\\\ \\text{Where } \\mu &amp; \\text{ is the overall mean} \\\\ \\text{and } \\sum_{j=1}^J\\gamma_j &amp; = 0\\\\ \\end{aligned} \\] 58.6.16 計算這些迴歸係數 (其實是不同羣之間的隨機截距) 的均值和標準差。 # the individual level intercepts have mean zero and SD = 117.47, larger than the estimated # Std.Dev for id effect. Reg1$coefficients ## factor(id)1 factor(id)2 factor(id)3 factor(id)4 factor(id)5 factor(id)6 factor(id)7 ## 44.117647 -51.882353 66.117647 -30.382353 25.117647 136.117647 -33.882353 ## factor(id)8 factor(id)9 factor(id)10 factor(id)11 factor(id)12 factor(id)13 factor(id)14 ## -11.382353 196.117647 -16.882353 -29.382353 196.617647 -176.882353 37.117647 ## factor(id)15 factor(id)16 factor(id)17 ## -276.382353 -50.382353 -23.882353 summ(Reg1$coefficients, graph = FALSE) ## obs. mean median s.d. min. max. ## 17 0 -16.882 117.473 -276.382 196.618 References "],
["-random-intercept-model.html", "第 59 章 隨機截距模型 random intercept model 59.1 隨機截距模型的定義 59.2 隨機截距模型的參數估計 59.3 如何在 R 或 STATA 中進行隨機截距模型的擬合 59.4 隨機截距模型中的統計推斷 59.5 練習題", " 第 59 章 隨機截距模型 random intercept model 59.1 隨機截距模型的定義 59.2 隨機截距模型的參數估計 59.3 如何在 R 或 STATA 中進行隨機截距模型的擬合 59.4 隨機截距模型中的統計推斷 59.5 練習題 59.5.1 數據 GHQ 數據 該數據包含 12 名學生前後兩次回答 General Health Questionnaire (GHQ) 問卷獲得的數據。該問卷用於測量學生的心理壓力，其變量名和含義如下： id Student identifier GHQ1 General Health Questionnaire score- 1st occasion GHQ2 General Health Questionnaire score- 2nd occasion Siblings 數據 該數據是來自一項對 3978 名媽媽關於她們 8604 名孩子的出生體重及健康狀況的問卷調查。該數據的變量名和含義如下： momid Mother identifier idx Baby identifier mage Maternal age (years) meduc Maternal education gestat gestational age (weeks) birwt Birth weight (g) smoke Maternal smoking (0 = no, 1 = yes) male Baby boy (0 = no, 1 = yes) year Year of birth married Maternal marital status (0 = no, 1 = yes) hsgrad Maternal high school education (0 = no, 1 = yes) black Maternal race (1 = black, 0 = other) 59.5.2 讀入 GHQ 數據，探索其內容，該數據是否是平衡數據 (balanced)？計算每名學生的兩次問卷成績平均分。 ghq &lt;- read_dta(&quot;backupfiles/ghq.dta&quot;) ghq ## # A tibble: 12 x 3 ## id GHQ1 GHQ2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.00 12.0 12.0 ## 2 2.00 8.00 7.00 ## 3 3.00 22.0 24.0 ## 4 4.00 10.0 14.0 ## 5 5.00 10.0 8.00 ## 6 6.00 6.00 4.00 ## 7 7.00 8.00 5.00 ## 8 8.00 4.00 6.00 ## 9 9.00 14.0 14.0 ## 10 10.0 6.00 5.00 ## 11 11.0 2.00 5.00 ## 12 12.0 22.0 16.0 ghq &lt;- ghq %&gt;% mutate(mean = (GHQ1 + GHQ2)/2) # each student has 2 observations (i.e. n_j = n = 2) # and therefore the data are balanced. # the overall mean is 10.167 and its SD is 6.073 with(ghq, summ(mean, graph = FALSE)) ## obs. mean median s.d. min. max. ## 12 10.167 8.25 6.073 3.5 23 59.5.3 把數據從寬 (wide) 改變成長 (long) 的形式 # transform data into long format ghq_long &lt;- ghq %&gt;% gather(key, value, -id, -mean) %&gt;% separate(key, into = c(&quot;measurement&quot;, &quot;occasion&quot;), sep = 3) %&gt;% arrange(id, occasion) %&gt;% spread(measurement, value) ghq_long ## # A tibble: 24 x 4 ## id mean occasion GHQ ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1.00 12.0 1 12.0 ## 2 1.00 12.0 2 12.0 ## 3 2.00 7.50 1 8.00 ## 4 2.00 7.50 2 7.00 ## 5 3.00 23.0 1 22.0 ## 6 3.00 23.0 2 24.0 ## 7 4.00 12.0 1 10.0 ## 8 4.00 12.0 2 14.0 ## 9 5.00 9.00 1 10.0 ## 10 5.00 9.00 2 8.00 ## # ... with 14 more rows # after reshaping there are 24 records. the summary statistics are # overall mean sd and min max with(ghq_long, summ(GHQ, graph = FALSE)) ## obs. mean median s.d. min. max. ## 24 10.167 8 6.098 2 24 # between groups mean sd and min summ(ghq_long[!duplicated(ghq_long$id), ]$mean, graph = FALSE) ## obs. mean median s.d. min. max. ## 12 10.167 8.25 6.073 3.5 23 # within groups mean sd and min (came from the difference between # the overall mean and the within difference) observations for # each group = 2 ghq_long &lt;- ghq_long %&gt;% mutate(dif_GHQ = mean(GHQ) - (GHQ - mean)) with(ghq_long, summ(dif_GHQ, graph = FALSE)) ## obs. mean median s.d. min. max. ## 24 10.167 10.167 1.383 7.167 13.167 GHQ 的分佈並不左右對稱。 圖 59.1: Histogram of GHQ by occasion 59.5.4 對數據按照 id 分層進行 ANOVA with(ghq_long, anova(lm(GHQ~factor(id)))) ## Analysis of Variance Table ## ## Response: GHQ ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## factor(id) 11 811.333 73.7576 20.1157 4.7782e-06 *** ## Residuals 12 44.000 3.6667 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #library(lme4) ( fit &lt;- lmer(GHQ ~ (1|id), data=ghq_long) ) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: GHQ ~ (1 | id) ## Data: ghq_long ## REML criterion at convergence: 131.3492 ## Random effects: ## Groups Name Std.Dev. ## id (Intercept) 5.9199 ## Residual 1.9149 ## Number of obs: 24, groups: id, 12 ## Fixed Effects: ## (Intercept) ## 10.167 \\(\\sigma_u, \\sigma_e\\) 的估計值分別是 5.92 (between)， 1.91 (within)。可以計算層間相關係數 (intra-class correlation) \\(\\hat\\lambda = \\frac{\\sigma^2_u}{\\sigma^2_u + \\sigma^2_e} = 0.905\\)。且 \\(\\hat\\sigma_u = \\sqrt{\\frac{73.8 - 3.7}{2}} = 5.92\\)，和前一次練習一樣地，這個隨機效應的方差，可以通過方差分析表格來直接手動計算 (當且僅當分層數據是平衡狀態的)。和前面計算的樣本數據比較，樣本層間標準差是高估了的 (sample between variance = 6.073 &gt; 5.92)，相反樣本層內標準差 (within sd) 則是低估了的 (sample within sd = 1.383 &lt; 1.91)。兩個層內標準差的關係是： \\[ \\sqrt{1.383^2\\times\\frac{23}{12}} = 1.91 \\] 59.5.5 用 R 裏的 nlme 包，使用限制性極大似然法 (restricted maximum likelihood, REML) 擬合截距混合效應模型，比較其結果和前文中隨機效應 ANOVA 的結果 summary(nlme::lme(fixed = GHQ ~ 1, random = ~ 1 | id, data = ghq_long, method = &quot;REML&quot;)) ## Linear mixed-effects model fit by REML ## Data: ghq_long ## AIC BIC logLik ## 137.34924 140.75573 -65.674622 ## ## Random effects: ## Formula: ~1 | id ## (Intercept) Residual ## StdDev: 5.9199181 1.9148548 ## ## Fixed effects: GHQ ~ 1 ## Value Std.Error DF t-value p-value ## (Intercept) 10.166667 1.7530632 12 5.7993727 0.0001 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -1.337372043 -0.578482697 0.073557531 0.414059981 1.796024881 ## ## Number of Observations: 24 ## Number of Groups: 12 截距混合效應模型的參數估計和隨機效應 ANOVA 的參數估計是一樣的。 59.5.6 用極大似然法 (maximum likelihood, ML) method = &quot;ML&quot; 重新擬合前面的混合效應模型，比較結果有什麼不同。 #( fit &lt;- lmer(GHQ ~ (1|id), data=ghq_long, REML = FALSE) ) # same but from `lme4` package summary(lme(fixed = GHQ ~ 1, random = ~ 1 | id, data = ghq_long, method = &quot;ML&quot;)) ## Linear mixed-effects model fit by maximum likelihood ## Data: ghq_long ## AIC BIC logLik ## 140.26571 143.79987 -67.132857 ## ## Random effects: ## Formula: ~1 | id ## (Intercept) Residual ## StdDev: 5.6543976 1.9148545 ## ## Fixed effects: GHQ ~ 1 ## Value Std.Error DF t-value p-value ## (Intercept) 10.166667 1.7145299 12 5.929711 0.0001 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -1.31652454 -0.58359637 0.08024454 0.40422622 1.81687284 ## ## Number of Observations: 24 ## Number of Groups: 12 用極大似然法估計的隨機殘差標準差 \\(\\sigma_e\\) 和 REML/ANOVA 法估計的相同，但是隨機效應標準差 \\(\\sigma_u\\) 略小 5.65 &lt; 5.92。 59.5.7 用簡單線性迴歸擬合一個固定效應模型 Fixed_reg &lt;- lm(GHQ-mean(GHQ) ~ 0 + factor(id), data = ghq_long) summary(Fixed_reg) ## ## Call: ## lm(formula = GHQ - mean(GHQ) ~ 0 + factor(id), data = ghq_long) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3 -1 0 1 3 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## factor(id)1 1.8333 1.3540 1.3540 0.2006847 ## factor(id)2 -2.6667 1.3540 -1.9695 0.0724256 . ## factor(id)3 12.8333 1.3540 9.4780 6.371e-07 *** ## factor(id)4 1.8333 1.3540 1.3540 0.2006847 ## factor(id)5 -1.1667 1.3540 -0.8616 0.4057744 ## factor(id)6 -5.1667 1.3540 -3.8158 0.0024580 ** ## factor(id)7 -3.6667 1.3540 -2.7080 0.0190252 * ## factor(id)8 -5.1667 1.3540 -3.8158 0.0024580 ** ## factor(id)9 3.8333 1.3540 2.8311 0.0151447 * ## factor(id)10 -4.6667 1.3540 -3.4466 0.0048356 ** ## factor(id)11 -6.6667 1.3540 -4.9237 0.0003516 *** ## factor(id)12 8.8333 1.3540 6.5238 2.836e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.9149 on 12 degrees of freedom ## Multiple R-squared: 0.94856, Adjusted R-squared: 0.89712 ## F-statistic: 18.439 on 12 and 12 DF, p-value: 6.8362e-06 可以看到輸出報告最底段部分 Residual standard error: 1.91 on 12 degrees of freedom 就是前文三種不同模型擬合的隨機殘差效應的標準差。在 STATA 裏被叫做 Root MSE。 59.5.8 計算這些隨機截距的均值和標準差 summ(Fixed_reg$coefficients, graph = FALSE) ## obs. mean median s.d. min. max. ## 12 0 -1.917 6.073 -6.667 12.833 這裏僅僅用固定效應模型時，不同羣截距的均值雖然和用混合效應模型估計的一樣爲零，但是其估計的標準差要大於無論是 REML (5.92) 或者是 ML (5.65) 估計值的大小，其實這裏簡單線性迴歸給出的截距均值，就是本練習一開始讓你計算的樣本均值的標準差 (between group sd)。這是因爲簡單線性迴歸 (固定效應模型) 忽視了這些不同組的均值的不確定性。 59.5.9 忽略掉所有的分層和解釋變量擬合 GHQ 的簡單線性迴歸 Fixed_simple &lt;- lm(GHQ ~ 1, data = ghq_long) summary(Fixed_simple) ## ## Call: ## lm(formula = GHQ ~ 1, data = ghq_long) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.1667 -4.4167 -2.1667 3.8333 13.8333 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.1667 1.2448 8.1673 3.001e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.0982 on 23 degrees of freedom 此時的模型估計的 Residual standard error: 6.09 on 23 degrees of freedom 其實就是一開始讓你計算的樣本整體的標準差 (overall sd) 59.5.10 用分層的穩健法 (三明治標準誤法) 計算簡單線性迴歸時，截距的標準誤差，和簡單線性迴歸時的結果作比較 # sandwich robust method with cluster id robustReg &lt;- clubSandwich::coef_test(Fixed_simple, vcov = &quot;CR1&quot;, cluster = ghq_long$id) rob.std.err &lt;- robustReg$SE naive.std.err&lt;-summary(Fixed_simple)$coefficients[,2] better.table &lt;- cbind(&quot;Estimate&quot; = coef(Fixed_simple), &quot;Naive SE&quot; = naive.std.err, &quot;Pr(&gt;|z|)&quot; = 2 * pt(abs(coef(Fixed_simple)/naive.std.err), df=nrow(ghq_long)-2, lower.tail = FALSE), &quot;LL&quot; = coef(Fixed_simple) - 1.96 * naive.std.err, &quot;UL&quot; = coef(Fixed_simple) + 1.96 * naive.std.err, &quot;Robust SE&quot; = rob.std.err, &quot;Pr(&gt;|z|)&quot; = 2 * pt(abs(coef(Fixed_simple)/rob.std.err), df=nrow(ghq_long)-2, lower.tail = FALSE), &quot;LL&quot; = coef(Fixed_simple) - qt(df=robustReg$df, 0.975) * rob.std.err, &quot;UL&quot; = coef(Fixed_simple) + qt(df=robustReg$df, 0.975) * rob.std.err) rownames(better.table)&lt;-c(&quot;Constant&quot;) better.table ## Estimate Naive SE Pr(&gt;|z|) LL UL Robust SE Pr(&gt;|z|) LL ## Constant 10.166667 1.2447959 4.1792464e-08 7.7268666 12.606467 1.7530637 7.7968698e-06 6.3081995 ## UL ## Constant 14.025134 59.5.11 讀入 siblings 數據。先總結嬰兒的出生體重，思考這個數據中嬰兒出生體重之間是否可能存在關聯性？它的來源是哪裏。用這個數據擬合兩個混合效應模型 (ML, REML)，不加入任何解釋變量。 siblings &lt;- read_dta(&quot;backupfiles/siblings.dta&quot;) Fixed_ml &lt;- lme(fixed = birwt ~ 1, random = ~ 1 | momid, data = siblings, method = &quot;ML&quot;) summary(Fixed_ml) ## Linear mixed-effects model fit by maximum likelihood ## Data: siblings ## AIC BIC logLik ## 130956.97 130978.15 -65475.486 ## ## Random effects: ## Formula: ~1 | momid ## (Intercept) Residual ## StdDev: 368.28656 377.65778 ## ## Fixed effects: birwt ~ 1 ## Value Std.Error DF t-value p-value ## (Intercept) 3467.969 7.1380683 4626 485.84138 0 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -6.2745852602 -0.4860398560 0.0036050084 0.5054348663 4.0506129253 ## ## Number of Observations: 8604 ## Number of Groups: 3978 Fixed_reml &lt;- lme(fixed = birwt ~ 1, random = ~ 1 | momid, data = siblings, method = &quot;REML&quot;) summary(Fixed_reml) ## Linear mixed-effects model fit by REML ## Data: siblings ## AIC BIC logLik ## 130951.2 130972.38 -65472.601 ## ## Random effects: ## Formula: ~1 | momid ## (Intercept) Residual ## StdDev: 368.35596 377.65768 ## ## Fixed effects: birwt ~ 1 ## Value Std.Error DF t-value p-value ## (Intercept) 3467.9688 7.1385551 4626 485.80822 0 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -6.2743063820 -0.4860194138 0.0035299824 0.5053550416 4.0503923643 ## ## Number of Observations: 8604 ## Number of Groups: 3978 由於該數據樣本量足夠大 (混合效應模型中等同於說數據的層數足夠多) "],
["section-60.html", "第 60 章 隨機截距模型中加入共變量 60.1 多重線性迴歸的延伸 60.2 siblings 數據中新生兒體重的實例 60.3 賦值予隨機效應成分 60.4 混合效應模型的診斷 60.5 分層階段的協方差 60.6 層內層間效應估計 60.7 到底選擇固定還是混合模型？ 60.8 練習題目", " 第 60 章 隨機截距模型中加入共變量 60.1 多重線性迴歸的延伸 60.2 siblings 數據中新生兒體重的實例 60.3 賦值予隨機效應成分 60.4 混合效應模型的診斷 60.5 分層階段的協方差 60.6 層內層間效應估計 60.7 到底選擇固定還是混合模型？ 60.8 練習題目 60.8.1 把 High-school-and-Beyong 數據讀入 R 中。 hsb_selected &lt;- read_dta(&quot;backupfiles/hsb_selected.dta&quot;) length(unique(hsb_selected$schoolid)) ## number of school = 160 ## [1] 160 ## create a subset data with only the first observation of each school hsb &lt;- hsb_selected[!duplicated(hsb_selected$schoolid), ] ## about 44 % of the schools are Catholic schools with(hsb, tab1(sector, graph = FALSE, decimal = 2)) ## sector : ## Frequency Percent Cum. percent ## 0 90 56.25 56.25 ## 1 70 43.75 100.00 ## Total 160 100.00 100.00 ## among all the schools, average school size is 1098 with(hsb, summ(size, graph = FALSE, decimal = 2)) ## obs. mean median s.d. min. max. ## 160 1097.825 1061 629.506 100 2713 ## among all the pupils, about 53% are females with(hsb_selected, tab1(female, graph = FALSE, decimal = 2)) ## female : ## Frequency Percent Cum. percent ## 0 3390 47.18 47.18 ## 1 3795 52.82 100.00 ## Total 7185 100.00 100.00 ## among all the pupils, about 27.5% are from ethnic minorities with(hsb_selected, tab1(minority, graph = FALSE, decimal = 2)) ## minority : ## Frequency Percent Cum. percent ## 0 5211 72.53 72.53 ## 1 1974 27.47 100.00 ## Total 7185 100.00 100.00 60.8.2 擬合兩個隨機截距模型 (ML, REML)，結果變量用 mathach，解釋變量用 ses。觀察結果是否不同。 Fixed_reml &lt;- lme(fixed = mathach ~ ses, random = ~ 1 | schoolid, data = hsb_selected, method = &quot;REML&quot;) summary(Fixed_reml) ## Linear mixed-effects model fit by REML ## Data: hsb_selected ## AIC BIC logLik ## 46653.169 46680.687 -23322.585 ## ## Random effects: ## Formula: ~1 | schoolid ## (Intercept) Residual ## StdDev: 2.1836149 6.0855894 ## ## Fixed effects: mathach ~ ses ## Value Std.Error DF t-value p-value ## (Intercept) 12.6574803 0.18798514 7024 67.332344 0 ## ses 2.3901958 0.10571908 7024 22.608935 0 ## Correlation: ## (Intr) ## ses 0.003 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.126073464 -0.727203135 0.021883209 0.757716938 2.919115780 ## ## Number of Observations: 7185 ## Number of Groups: 160 Fixed_ml &lt;- lme(fixed = mathach ~ ses, random = ~ 1 | schoolid, data = hsb_selected, method = &quot;ML&quot;) summary(Fixed_ml) ## Linear mixed-effects model fit by maximum likelihood ## Data: hsb_selected ## AIC BIC logLik ## 46649.005 46676.524 -23320.502 ## ## Random effects: ## Formula: ~1 | schoolid ## (Intercept) Residual ## StdDev: 2.1745135 6.0852108 ## ## Fixed effects: mathach ~ ses ## Value Std.Error DF t-value p-value ## (Intercept) 12.6576233 0.18734713 7024 67.562409 0 ## ses 2.3914997 0.10570732 7024 22.623785 0 ## Correlation: ## (Intr) ## ses 0.003 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.126312319 -0.727660113 0.021999773 0.757808614 2.918598714 ## ## Number of Observations: 7185 ## Number of Groups: 160 其實由於樣本量 (層數) 足夠多，兩個隨機截距模型給出的參數估計十分接近。 60.8.3 觀察學校類型是否爲天主教學校 sector 的分佈，把它加入剛擬合的兩個隨機截距模型，它們估計的隨機效應標準差 \\(\\hat\\sigma_u\\)，和隨機誤差標準差 \\(\\hat\\sigma_e\\)，和之前有什麼不同？ “ML，REML” 的選用對結果有影響嗎？ Fixed_reml &lt;- lme(fixed = mathach ~ ses + factor(sector), random = ~ 1 | schoolid, data = hsb_selected, method = &quot;REML&quot;) summary(Fixed_reml) ## Linear mixed-effects model fit by REML ## Data: hsb_selected ## AIC BIC logLik ## 46621.151 46655.548 -23305.575 ## ## Random effects: ## Formula: ~1 | schoolid ## (Intercept) Residual ## StdDev: 1.9196456 6.085796 ## ## Fixed effects: mathach ~ ses + factor(sector) ## Value Std.Error DF t-value p-value ## (Intercept) 11.7189077 0.22805848 7024 51.385538 0 ## ses 2.3747113 0.10549107 7024 22.511017 0 ## factor(sector)1 2.1008365 0.34112426 158 6.158567 0 ## Correlation: ## (Intr) ses ## ses 0.063 ## factor(sector)1 -0.672 -0.091 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.148567047 -0.731003511 0.019287931 0.753657138 2.926344842 ## ## Number of Observations: 7185 ## Number of Groups: 160 Fixed_ml &lt;- lme(fixed = mathach ~ ses + factor(sector), random = ~ 1 | schoolid, data = hsb_selected, method = &quot;ML&quot;) summary(Fixed_ml) ## Linear mixed-effects model fit by maximum likelihood ## Data: hsb_selected ## AIC BIC logLik ## 46616.436 46650.835 -23303.218 ## ## Random effects: ## Formula: ~1 | schoolid ## (Intercept) Residual ## StdDev: 1.9031216 6.0854569 ## ## Fixed effects: mathach ~ ses + factor(sector) ## Value Std.Error DF t-value p-value ## (Intercept) 11.7192735 0.22655231 7024 51.728774 0 ## ses 2.3770966 0.10546439 7024 22.539329 0 ## factor(sector)1 2.1000541 0.33882309 158 6.198084 0 ## Correlation: ## (Intr) ses ## ses 0.064 ## factor(sector)1 -0.672 -0.092 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.149152187 -0.730911671 0.019584616 0.754184074 2.925230767 ## ## Number of Observations: 7185 ## Number of Groups: 160 可以看出，sector 變量在學校層面上都是沒有變化的，所以加它進入混合效應的固定部分，只會對隨機效應標準差 (within level/cluster/group error) \\(\\hat\\sigma_u\\) 的估計造成影響，隨機誤差標準差 \\(\\hat\\sigma_e\\) 則幾乎不受影響。同樣的 “ML, REML” 兩種方法對結果的影響微乎其微。 60.8.4 現在把學校規模 size 這一變量加入混合效應模型的固定效應部分，記得先把該變量中心化，並除以 100，會有助於對結果的解釋 (比平均值每增加100名學生)。仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化。 hsb_selected &lt;- hsb_selected %&gt;% mutate(c_size = (size - with(hsb, mean(size)))/100) Fixed_reml &lt;- lme(fixed = mathach ~ ses + factor(sector) + c_size, random = ~ 1 | schoolid, data = hsb_selected, method = &quot;REML&quot;) summary(Fixed_reml) ## Linear mixed-effects model fit by REML ## Data: hsb_selected ## AIC BIC logLik ## 46625.177 46666.452 -23306.588 ## ## Random effects: ## Formula: ~1 | schoolid ## (Intercept) Residual ## StdDev: 1.9070019 6.0855999 ## ## Fixed effects: mathach ~ ses + factor(sector) + c_size ## Value Std.Error DF t-value p-value ## (Intercept) 11.5883785 0.23856005 7024 48.576359 0.0000 ## ses 2.3748756 0.10545908 7024 22.519405 0.0000 ## factor(sector)1 2.4011753 0.37937827 157 6.329238 0.0000 ## c_size 0.0535525 0.03019786 157 1.773389 0.0781 ## Correlation: ## (Intr) ses fct()1 ## ses 0.063 ## factor(sector)1 -0.710 -0.086 ## c_size -0.309 -0.009 0.447 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.142084041 -0.732777592 0.018257318 0.755374256 2.922664411 ## ## Number of Observations: 7185 ## Number of Groups: 160 Fixed_ml &lt;- lme(fixed = mathach ~ ses + factor(sector) + c_size, random = ~ 1 | schoolid, data = hsb_selected, method = &quot;ML&quot;) summary(Fixed_ml) ## Linear mixed-effects model fit by maximum likelihood ## Data: hsb_selected ## AIC BIC logLik ## 46615.26 46656.539 -23301.63 ## ## Random effects: ## Formula: ~1 | schoolid ## (Intercept) Residual ## StdDev: 1.8826676 6.0852839 ## ## Fixed effects: mathach ~ ses + factor(sector) + c_size ## Value Std.Error DF t-value p-value ## (Intercept) 11.5892342 0.23621021 7024 49.063223 0.0000 ## ses 2.3784305 0.10541864 7024 22.561764 0.0000 ## factor(sector)1 2.3993444 0.37556251 157 6.388668 0.0000 ## c_size 0.0534557 0.02989802 157 1.787934 0.0757 ## Correlation: ## (Intr) ses fct()1 ## ses 0.064 ## factor(sector)1 -0.710 -0.087 ## c_size -0.309 -0.009 0.447 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.142724517 -0.733277144 0.018425816 0.756191379 2.920848698 ## ## Number of Observations: 7185 ## Number of Groups: 160 增加了 size 進入混合效應模型的固定效應部分，對兩種參數估計方法輸出的結果 \\((\\hat\\sigma_u, \\hat\\sigma_e)\\) 並沒有太大的影響。 60.8.5 在模型的固定效應部分增加 size*sector 的交互作用項。觀察輸出結果中該交互作用項是否有意義。用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據？ Fixed_reml &lt;- lme(fixed = mathach ~ ses + factor(sector)*c_size, random = ~ 1 | schoolid, data = hsb_selected, method = &quot;REML&quot;) summary(Fixed_reml) ## Linear mixed-effects model fit by REML ## Data: hsb_selected ## AIC BIC logLik ## 46627.455 46675.609 -23306.728 ## ## Random effects: ## Formula: ~1 | schoolid ## (Intercept) Residual ## StdDev: 1.8866444 6.0858048 ## ## Fixed effects: mathach ~ ses + factor(sector) * c_size ## Value Std.Error DF t-value p-value ## (Intercept) 11.6653272 0.24028978 7024 48.546913 0.0000 ## ses 2.3777195 0.10540859 7024 22.557171 0.0000 ## factor(sector)1 2.6189122 0.39527038 156 6.625622 0.0000 ## c_size 0.0221855 0.03460344 156 0.641134 0.5224 ## factor(sector)1:c_size 0.1244623 0.06901630 156 1.803375 0.0733 ## Correlation: ## (Intr) ses fct()1 c_size ## ses 0.063 ## factor(sector)1 -0.611 -0.083 ## c_size -0.351 -0.007 0.214 ## factor(sector)1:c_size 0.176 -0.001 0.308 -0.501 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.13045751 -0.73048747 0.01818318 0.75334231 2.92240238 ## ## Number of Observations: 7185 ## Number of Groups: 160 Fixed_ml &lt;- lme(fixed = mathach ~ ses + factor(sector)*c_size, random = ~ 1 | schoolid, data = hsb_selected, method = &quot;ML&quot;) summary(Fixed_ml) ## Linear mixed-effects model fit by maximum likelihood ## Data: hsb_selected ## AIC BIC logLik ## 46613.952 46662.11 -23299.976 ## ## Random effects: ## Formula: ~1 | schoolid ## (Intercept) Residual ## StdDev: 1.8541258 6.0855402 ## ## Fixed effects: mathach ~ ses + factor(sector) * c_size ## Value Std.Error DF t-value p-value ## (Intercept) 11.6666062 0.23710165 7024 49.205081 0.0000 ## ses 2.3826010 0.10535223 7024 22.615573 0.0000 ## factor(sector)1 2.6163944 0.38986548 156 6.711018 0.0000 ## c_size 0.0219834 0.03414728 156 0.643781 0.5207 ## factor(sector)1:c_size 0.1245981 0.06806754 156 1.830506 0.0691 ## Correlation: ## (Intr) ses fct()1 c_size ## ses 0.064 ## factor(sector)1 -0.611 -0.084 ## c_size -0.351 -0.007 0.214 ## factor(sector)1:c_size 0.176 -0.001 0.307 -0.502 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.130885753 -0.730493654 0.017705646 0.753635339 2.919878733 ## ## Number of Observations: 7185 ## Number of Groups: 160 在兩個估計方法的包工中，交互作用項均不具有統計學意義。 60.8.6 把上面八個模型估計的隨機效應標準差，和隨機誤差標準差總結成表格，它們之間有什麼規律嗎？ Random effect sd and random residual sd from previous 8 mixed effect models REML ML Model with \\(\\sigma_u\\) \\(\\sigma_e\\) \\(\\sigma_u\\) \\(\\sigma_e\\) ses 2.184 6.085 2.175 6.085 ses &amp; sector 1.920 6.086 1.903 6.086 ses, size &amp; sector 1.907 6.086 1.883 6.085 ses, size &amp; sector &amp; size*sector 1.887 6.086 1.854 6.086 \\(\\hat\\sigma_e\\) 幾乎在所有模型的估計中都保持不變。因爲我們在固定效應中增加的共變量在學校層面 (level 2) 都是一樣的。也就是說對於同一學校的學生，新增的共變量是一模一樣沒有變化的，所以在個人水平 (level 1) 的隨機效應幾乎不會發生變化。且注意到 “ML” 極大似然法估計的隨機效應標準差比 “REML” 限制性極大似然估計法給出的結果略小 1% 左右。 60.8.7 在混合效應模型的固定效應部分增加學生性別 female，和學生是否是少數族裔 minority 兩個變量。再觀察 \\(\\hat\\sigma_u, \\hat\\sigma_e\\) 是否發生變化？ Fixed_reml &lt;- lme(fixed = mathach ~ ses + factor(sector) + c_size + factor(female) + factor(minority), random = ~ 1 | schoolid, data = hsb_selected, method = &quot;REML&quot;) summary(Fixed_reml) ## Linear mixed-effects model fit by REML ## Data: hsb_selected ## AIC BIC logLik ## 46352.38 46407.411 -23168.19 ## ## Random effects: ## Formula: ~1 | schoolid ## (Intercept) Residual ## StdDev: 1.472837 5.9931928 ## ## Fixed effects: mathach ~ ses + factor(sector) + c_size + factor(female) + factor(minority) ## Value Std.Error DF t-value p-value ## (Intercept) 12.9447718 0.217832263 7022 59.425411 0.0000 ## ses 2.0596747 0.105072740 7022 19.602370 0.0000 ## factor(sector)1 2.7312924 0.310817225 157 8.787455 0.0000 ## c_size 0.0763719 0.024801611 157 3.079313 0.0024 ## factor(female)1 -1.2520526 0.160241464 7022 -7.813537 0.0000 ## factor(minority)1 -3.0984209 0.200626538 7022 -15.443724 0.0000 ## Correlation: ## (Intr) ses fctr(s)1 c_size fctr(f)1 ## ses 0.000 ## factor(sector)1 -0.624 -0.116 ## c_size -0.265 -0.025 0.448 ## factor(female)1 -0.390 0.060 0.005 0.018 ## factor(minority)1 -0.206 0.212 -0.080 -0.074 0.011 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.285989371 -0.719628708 0.037599613 0.755533985 2.883226747 ## ## Number of Observations: 7185 ## Number of Groups: 160 Fixed_ml &lt;- lme(fixed = mathach ~ ses + factor(sector) + c_size + factor(female) + factor(minority), random = ~ 1 | schoolid, data = hsb_selected, method = &quot;ML&quot;) summary(Fixed_ml) ## Linear mixed-effects model fit by maximum likelihood ## Data: hsb_selected ## AIC BIC logLik ## 46337.991 46393.029 -23160.996 ## ## Random effects: ## Formula: ~1 | schoolid ## (Intercept) Residual ## StdDev: 1.4495814 5.9921784 ## ## Fixed effects: mathach ~ ses + factor(sector) + c_size + factor(female) + factor(minority) ## Value Std.Error DF t-value p-value ## (Intercept) 12.9471134 0.21589131 7022 59.970516 0.0000 ## ses 2.0626898 0.10502030 7022 19.640868 0.0000 ## factor(sector)1 2.7298386 0.30739095 157 8.880673 0.0000 ## c_size 0.0762685 0.02453268 157 3.108852 0.0022 ## factor(female)1 -1.2537827 0.16011163 7022 -7.830678 0.0000 ## factor(minority)1 -3.1011547 0.20030024 7022 -15.482531 0.0000 ## Correlation: ## (Intr) ses fctr(s)1 c_size fctr(f)1 ## ses 0.000 ## factor(sector)1 -0.623 -0.117 ## c_size -0.264 -0.025 0.448 ## factor(female)1 -0.393 0.060 0.005 0.018 ## factor(minority)1 -0.208 0.213 -0.080 -0.075 0.011 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.28717727 -0.71993454 0.03838002 0.75631887 2.88307699 ## ## Number of Observations: 7185 ## Number of Groups: 160 混合效應模型的固定效應部分增加了學生性別，以及是否是少數族裔以後，“ML/REML” 估計的 \\(\\hat\\sigma_u, \\hat\\sigma_e\\) 均發生了顯著變化。因爲它們在個人水平都不一樣 (level 1, within group random residuals)。 60.8.8 檢查學生性別和族裔是否和學校是否是天主教會學校有關係，先作分類型數據的分佈表格，然後把它們各自與 sector 的交互作用項加入混合效應模型中的固定效應部分，記錄下此時的 \\(\\hat\\sigma_u, \\hat\\sigma_e\\) # Only minority is associated with sector. There are more pupils from # ethnic minorities attending catholic schools with(hsb_selected, tabpct( sector, minority, graph = FALSE)) ## ## Original table ## minority ## sector 0 1 Total ## 0 2721 921 3642 ## 1 2490 1053 3543 ## Total 5211 1974 7185 ## ## Row percent ## minority ## sector 0 1 Total ## 0 2721 921 3642 ## (74.7) (25.3) (100) ## 1 2490 1053 3543 ## (70.3) (29.7) (100) ## ## Column percent ## minority ## sector 0 % 1 % ## 0 2721 (52.2) 921 (46.7) ## 1 2490 (47.8) 1053 (53.3) ## Total 5211 (100) 1974 (100) with(hsb_selected, tabpct( sector, female, graph = FALSE)) ## ## Original table ## female ## sector 0 1 Total ## 0 1730 1912 3642 ## 1 1660 1883 3543 ## Total 3390 3795 7185 ## ## Row percent ## female ## sector 0 1 Total ## 0 1730 1912 3642 ## (47.5) (52.5) (100) ## 1 1660 1883 3543 ## (46.9) (53.1) (100) ## ## Column percent ## female ## sector 0 % 1 % ## 0 1730 (51) 1912 (50.4) ## 1 1660 (49) 1883 (49.6) ## Total 3390 (100) 3795 (100) ## there was no significant interaction between female sex and sector so ## this is deleted from the final model Fixed_reml &lt;- lme(fixed = mathach ~ ses + factor(sector)*factor(female) + c_size + factor(minority), random = ~ 1 | schoolid, data = hsb_selected, method = &quot;REML&quot;) summary(Fixed_reml) ## Linear mixed-effects model fit by REML ## Data: hsb_selected ## AIC BIC logLik ## 46354.618 46416.527 -23168.309 ## ## Random effects: ## Formula: ~1 | schoolid ## (Intercept) Residual ## StdDev: 1.477646 5.993252 ## ## Fixed effects: mathach ~ ses + factor(sector) * factor(female) + c_size + factor(minority) ## Value Std.Error DF t-value p-value ## (Intercept) 12.9662563 0.22677759 7021 57.176093 0.0000 ## ses 2.0588315 0.10509176 7021 19.590800 0.0000 ## factor(sector)1 2.6715007 0.35420161 157 7.542317 0.0000 ## factor(female)1 -1.2949312 0.20096518 7021 -6.443560 0.0000 ## c_size 0.0766860 0.02487285 157 3.083119 0.0024 ## factor(minority)1 -3.0978260 0.20070576 7021 -15.434664 0.0000 ## factor(sector)1:factor(female)1 0.1185732 0.33249890 7021 0.356612 0.7214 ## Correlation: ## (Intr) ses fctr(s)1 fctr(f)1 c_size fctr(m)1 ## ses -0.001 ## factor(sector)1 -0.658 -0.099 ## factor(female)1 -0.463 0.051 0.291 ## c_size -0.246 -0.025 0.378 -0.006 ## factor(minority)1 -0.198 0.212 -0.070 0.009 -0.074 ## factor(sector)1:factor(female)1 0.272 -0.006 -0.476 -0.603 0.033 0.000 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.278858365 -0.720574025 0.036990386 0.756219388 2.879202470 ## ## Number of Observations: 7185 ## Number of Groups: 160 ## There is an interaction between minority and sector Fixed_reml &lt;- lme(fixed = mathach ~ ses + factor(sector)*factor(minority) + c_size + factor(female), random = ~ 1 | schoolid, data = hsb_selected, method = &quot;REML&quot;) summary(Fixed_reml) ## Linear mixed-effects model fit by REML ## Data: hsb_selected ## AIC BIC logLik ## 46324.414 46386.323 -23153.207 ## ## Random effects: ## Formula: ~1 | schoolid ## (Intercept) Residual ## StdDev: 1.4746055 5.9807998 ## ## Fixed effects: mathach ~ ses + factor(sector) * factor(minority) + c_size + factor(female) ## Value Std.Error DF t-value p-value ## (Intercept) 13.1830150 0.22211246 7021 59.352884 0.0000 ## ses 2.0068664 0.10530291 7021 19.058033 0.0000 ## factor(sector)1 2.2495661 0.32310709 157 6.962293 0.0000 ## factor(minority)1 -4.2268343 0.28729849 7021 -14.712344 0.0000 ## c_size 0.0943352 0.02502303 157 3.769937 0.0002 ## factor(female)1 -1.2507559 0.15994509 7021 -7.819908 0.0000 ## factor(sector)1:factor(minority)1 2.1674475 0.39543102 7021 5.481228 0.0000 ## Correlation: ## (Intr) ses fctr(s)1 fctr(m)1 c_size fctr(f)1 ## ses -0.017 ## factor(sector)1 -0.642 -0.086 ## factor(minority)1 -0.281 0.212 0.142 ## c_size -0.232 -0.036 0.392 -0.145 ## factor(female)1 -0.382 0.059 0.005 0.007 0.018 ## factor(sector)1:factor(minority)1 0.196 -0.090 -0.272 -0.717 0.131 0.001 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.258450948 -0.718733897 0.036399219 0.762392656 2.930454863 ## ## Number of Observations: 7185 ## Number of Groups: 160 數據顯示，少數族裔更多地選擇天主教會學校學習。學生性別則與是否是天主教會學校之間沒有顯著的關係。少數族裔和教會學校之間的交互作用同時也被發現具有統計學意義。 60.8.9 對上面最後一個模型進行殘差分析和模型的診斷。 #fit &lt;- lmer(mathach ~ ses + factor(sector)*factor(minority) + c_size + # factor(female) + (1| schoolid), data=hsb_selected) #summary(fit) hsb &lt;- hsb %&gt;% mutate(# extract the random effect (EB) residuals (at school level) uhat_eb = ranef(Fixed_reml)$`(Intercept)`, # number of students in each school npupil = count(hsb_selected$schoolid)[2]$freq, # shrinkage factor = sigma_u^2/(sigma_u^2+sigma_e^2/n_j) R = 1.474^2/(1.474^2 + (5.981^2)/npupil), # Empirical Bayes prediction of variance of uhat var_eb = R*1.474^2, # standardize the uhat uhat_st = uhat_eb/sqrt(var_eb)) # extract the standardized random (EB) residuals (at pupil level) hsb_selected$ehat &lt;- residuals(Fixed_reml, level = 1, type = &quot;normalized&quot;) par(mfrow=c(1,2)) hist(hsb$uhat_st, freq = FALSE, breaks = 12, col=&#39;lightblue&#39;) qqnorm(hsb$uhat_st, ylab = &quot;Standardized level 1 residuals&quot;); qqline(hsb$uhat_st, col=2) 圖 60.1: Histogram and Q-Q plot of cluster (school) level standardized residuals for the intercept par(mfrow=c(1,2)) hist(hsb_selected$ehat, freq = FALSE, breaks = 38, col=&#39;lightblue&#39;) qqnorm(hsb_selected$ehat, ylab = &quot;Standardized level 1 residuals&quot;); qqline(hsb_selected$ehat, col=2) 圖 60.2: Histogram and Q-Q plot of cluster (school) level standardized residuals for the intercept "],
["crude-and-stratified-rate-ratios.html", "第 61 章 Crude and stratified rate ratios", " 第 61 章 Crude and stratified rate ratios 本章內容不討論任何理論的東西，着重強調用 R 進行實際數據的分析，並加強對輸出結果的理解。 此次實戰演練的目的是學會怎樣計算死亡率比 (Rate Ratios, RR)。學會用 Mantel-Haenszel 法總結 RR，並討論其意義。 whitehal &lt;- read_dta(&quot;backupfiles/whitehal.dta&quot;) whitehal$followupyrs &lt;- (whitehal$timeout - whitehal$timein)/365.25 max(whitehal$followupyrs*365.25) # time difference in days ## Time difference of 7078.9927 days summary(whitehal$followupyrs &lt;- as.numeric(whitehal$followupyrs)) # time difference in years ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.15063 17.16357 17.96020 16.46116 18.56262 19.38123 # categorize agein into groups (40-44, 45-49, 50-54, ... , 65-69) whitehal$agecat &lt;- cut(whitehal$agein, breaks = seq(40, 70, 5), right = FALSE) with(whitehal, table(agecat)) ## agecat ## [40,45) [45,50) [50,55) [55,60) [60,65) [65,70) ## 277 445 362 340 215 38 # examine how mortality rates change with age at entry with(whitehal %&gt;% group_by(agecat) %&gt;% summarise(D = sum(all), Y = sum(followupyrs)), cbind(whitehal$agecat, pois.exact(x = D, pt = Y/1000))) ## whitehal$agecat x pt rate lower upper conf.level ## 1 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 2 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 3 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 4 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 5 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 6 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 7 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 8 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 9 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 10 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 11 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 12 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 13 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 14 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 15 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 16 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 17 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 18 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 19 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 20 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 21 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 22 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 23 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 24 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 25 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 26 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 27 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 28 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 29 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 30 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 31 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 32 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 33 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 34 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 35 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 36 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 37 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 38 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 39 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 40 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 41 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 42 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 43 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 44 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 45 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 46 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 47 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 48 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 49 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 50 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 51 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 52 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 53 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 54 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 55 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 56 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 57 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 58 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 59 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 60 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 61 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 62 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 63 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 64 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 65 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 66 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 67 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 68 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 69 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 70 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 71 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 72 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 73 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 74 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 75 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 76 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 77 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 78 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 79 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 80 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 81 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 82 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 83 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 84 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 85 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 86 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 87 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 88 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 89 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 90 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 91 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 92 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 93 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 94 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 95 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 96 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 97 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 98 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 99 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 100 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 101 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 102 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 103 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 104 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 105 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 106 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 107 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 108 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 109 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 110 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 111 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 112 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 113 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 114 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 115 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 116 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 117 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 118 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 119 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 120 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 121 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 122 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 123 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 124 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 125 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 126 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 127 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 128 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 129 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 130 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 131 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 132 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 133 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 134 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 135 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 136 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 137 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 138 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 139 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 140 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 141 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 142 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 143 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 144 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 145 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 146 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 147 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 148 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 149 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 150 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 151 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 152 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 153 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 154 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 155 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 156 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 157 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 158 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 159 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 160 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 161 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 162 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 163 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 164 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 165 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 166 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 167 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 168 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 169 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 170 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 171 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 172 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 173 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 174 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 175 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 176 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 177 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 178 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 179 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 180 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 181 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 182 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 183 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 184 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 185 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 186 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 187 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 188 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 189 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 190 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 191 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 192 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 193 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 194 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 195 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 196 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 197 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 198 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 199 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 200 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 201 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 202 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 203 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 204 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 205 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 206 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 207 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 208 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 209 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 210 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 211 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 212 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 213 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 214 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 215 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 216 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 217 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 218 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 219 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 220 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 221 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 222 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 223 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 224 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 225 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 226 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 227 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 228 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 229 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 230 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 231 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 232 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 233 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 234 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 235 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 236 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 237 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 238 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 239 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 240 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 241 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 242 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 243 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 244 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 245 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 246 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 247 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 248 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 249 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 250 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 251 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 252 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 253 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 254 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 255 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 256 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 257 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 258 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 259 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 260 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 261 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 262 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 263 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 264 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 265 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 266 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 267 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 268 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 269 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 270 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 271 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 272 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 273 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 274 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 275 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 276 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 277 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 278 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 279 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 280 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 281 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 282 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 283 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 284 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 285 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 286 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 287 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 288 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 289 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 290 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 291 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 292 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 293 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 294 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 295 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 296 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 297 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 298 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 299 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 300 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 301 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 302 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 303 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 304 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 305 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 306 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 307 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 308 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 309 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 310 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 311 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 312 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 313 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 314 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 315 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 316 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 317 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 318 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 319 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 320 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 321 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 322 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 323 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 324 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 325 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 326 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 327 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 328 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 329 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 330 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 331 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 332 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 333 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 334 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 335 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 336 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 337 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 338 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 339 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 340 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 341 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 342 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 343 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 344 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 345 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 346 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 347 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 348 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 349 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 350 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 351 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 352 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 353 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 354 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 355 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 356 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 357 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 358 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 359 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 360 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 361 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 362 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 363 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 364 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 365 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 366 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 367 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 368 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 369 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 370 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 371 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 372 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 373 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 374 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 375 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 376 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 377 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 378 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 379 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 380 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 381 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 382 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 383 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 384 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 385 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 386 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 387 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 388 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 389 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 390 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 391 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 392 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 393 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 394 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 395 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 396 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 397 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 398 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 399 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 400 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 401 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 402 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 403 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 404 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 405 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 406 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 407 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 408 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 409 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 410 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 411 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 412 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 413 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 414 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 415 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 416 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 417 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 418 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 419 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 420 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 421 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 422 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 423 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 424 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 425 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 426 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 427 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 428 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 429 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 430 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 431 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 432 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 433 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 434 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 435 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 436 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 437 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 438 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 439 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 440 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 441 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 442 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 443 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 444 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 445 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 446 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 447 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 448 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 449 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 450 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 451 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 452 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 453 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 454 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 455 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 456 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 457 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 458 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 459 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 460 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 461 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 462 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 463 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 464 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 465 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 466 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 467 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 468 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 469 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 470 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 471 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 472 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 473 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 474 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 475 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 476 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 477 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 478 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 479 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 480 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 481 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 482 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 483 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 484 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 485 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 486 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 487 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 488 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 489 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 490 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 491 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 492 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 493 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 494 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 495 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 496 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 497 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 498 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 499 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 500 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 501 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 502 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 503 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 504 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 505 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 506 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 507 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 508 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 509 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 510 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 511 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 512 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 513 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 514 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 515 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 516 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 517 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 518 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 519 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 520 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 521 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 522 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 523 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 524 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 525 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 526 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 527 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 528 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 529 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 530 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 531 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 532 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 533 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 534 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 535 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 536 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 537 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 538 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 539 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 540 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 541 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 542 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 543 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 544 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 545 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 546 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 547 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 548 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 549 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 550 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 551 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 552 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 553 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 554 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 555 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 556 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 557 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 558 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 559 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 560 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 561 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 562 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 563 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 564 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 565 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 566 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 567 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 568 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 569 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 570 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 571 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 572 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 573 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 574 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 575 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 576 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 577 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 578 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 579 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 580 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 581 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 582 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 583 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 584 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 585 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 586 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 587 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 588 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 589 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 590 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 591 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 592 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 593 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 594 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 595 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 596 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 597 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 598 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 599 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 600 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 601 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 602 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 603 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 604 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 605 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 606 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 607 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 608 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 609 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 610 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 611 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 612 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 613 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 614 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 615 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 616 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 617 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 618 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 619 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 620 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 621 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 622 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 623 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 624 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 625 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 626 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 627 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 628 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 629 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 630 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 631 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 632 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 633 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 634 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 635 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 636 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 637 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 638 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 639 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 640 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 641 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 642 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 643 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 644 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 645 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 646 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 647 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 648 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 649 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 650 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 651 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 652 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 653 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 654 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 655 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 656 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 657 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 658 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 659 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 660 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 661 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 662 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 663 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 664 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 665 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 666 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 667 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 668 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 669 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 670 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 671 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 672 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 673 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 674 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 675 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 676 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 677 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 678 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 679 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 680 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 681 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 682 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 683 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 684 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 685 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 686 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 687 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 688 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 689 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 690 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 691 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 692 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 693 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 694 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 695 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 696 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 697 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 698 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 699 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 700 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 701 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 702 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 703 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 704 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 705 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 706 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 707 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 708 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 709 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 710 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 711 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 712 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 713 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 714 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 715 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 716 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 717 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 718 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 719 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 720 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 721 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 722 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 723 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 724 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 725 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 726 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 727 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 728 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 729 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 730 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 731 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 732 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 733 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 734 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 735 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 736 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 737 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 738 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 739 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 740 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 741 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 742 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 743 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 744 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 745 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 746 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 747 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 748 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 749 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 750 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 751 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 752 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 753 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 754 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 755 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 756 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 757 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 758 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 759 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 760 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 761 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 762 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 763 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 764 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 765 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 766 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 767 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 768 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 769 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 770 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 771 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 772 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 773 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 774 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 775 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 776 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 777 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 778 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 779 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 780 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 781 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 782 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 783 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 784 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 785 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 786 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 787 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 788 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 789 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 790 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 791 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 792 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 793 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 794 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 795 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 796 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 797 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 798 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 799 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 800 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 801 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 802 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 803 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 804 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 805 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 806 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 807 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 808 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 809 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 810 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 811 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 812 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 813 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 814 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 815 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 816 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 817 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 818 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 819 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 820 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 821 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 822 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 823 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 824 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 825 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 826 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 827 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 828 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 829 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 830 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 831 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 832 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 833 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 834 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 835 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 836 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 837 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 838 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 839 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 840 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 841 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 842 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 843 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 844 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 845 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 846 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 847 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 848 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 849 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 850 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 851 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 852 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 853 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 854 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 855 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 856 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 857 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 858 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 859 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 860 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 861 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 862 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 863 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 864 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 865 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 866 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 867 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 868 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 869 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 870 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 871 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 872 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 873 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 874 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 875 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 876 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 877 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 878 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 879 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 880 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 881 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 882 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 883 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 884 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 885 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 886 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 887 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 888 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 889 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 890 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 891 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 892 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 893 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 894 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 895 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 896 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 897 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 898 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 899 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 900 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 901 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 902 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 903 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 904 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 905 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 906 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 907 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 908 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 909 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 910 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 911 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 912 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 913 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 914 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 915 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 916 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 917 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 918 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 919 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 920 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 921 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 922 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 923 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 924 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 925 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 926 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 927 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 928 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 929 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 930 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 931 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 932 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 933 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 934 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 935 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 936 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 937 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 938 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 939 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 940 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 941 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 942 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 943 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 944 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 945 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 946 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 947 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 948 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 949 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 950 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 951 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 952 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 953 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 954 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 955 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 956 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 957 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 958 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 959 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 960 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 961 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 962 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 963 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 964 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 965 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 966 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 967 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 968 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 969 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 970 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 971 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 972 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 973 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 974 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 975 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 976 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 977 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 978 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 979 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 980 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 981 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 982 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 983 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 984 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 985 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 986 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 987 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 988 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 989 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 990 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 991 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 992 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 993 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 994 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 995 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 996 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 997 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 998 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 999 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1000 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1001 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1002 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1003 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1004 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1005 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1006 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1007 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1008 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1009 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1010 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1011 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1012 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1013 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1014 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1015 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1016 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1017 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1018 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1019 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1020 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1021 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1022 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1023 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1024 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1025 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1026 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1027 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1028 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1029 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1030 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1031 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1032 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1033 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1034 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1035 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1036 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1037 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1038 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1039 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1040 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1041 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1042 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1043 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1044 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1045 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1046 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1047 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1048 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1049 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1050 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1051 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1052 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1053 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1054 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1055 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1056 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1057 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1058 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1059 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1060 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1061 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1062 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1063 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1064 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1065 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1066 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1067 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1068 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1069 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1070 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1071 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1072 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1073 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1074 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1075 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1076 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1077 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1078 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1079 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1080 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1081 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1082 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1083 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1084 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1085 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1086 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1087 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1088 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1089 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1090 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1091 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1092 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1093 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1094 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1095 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1096 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1097 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1098 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1099 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1100 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1101 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1102 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1103 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1104 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1105 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1106 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1107 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1108 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1109 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1110 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1111 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1112 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1113 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1114 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1115 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1116 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1117 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1118 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1119 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1120 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1121 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1122 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1123 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1124 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1125 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1126 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1127 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1128 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1129 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1130 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1131 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1132 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1133 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1134 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1135 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1136 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1137 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1138 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1139 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1140 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1141 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1142 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1143 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1144 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1145 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1146 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1147 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1148 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1149 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1150 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1151 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1152 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1153 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1154 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1155 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1156 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1157 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1158 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1159 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1160 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1161 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1162 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1163 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1164 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1165 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1166 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1167 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1168 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1169 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1170 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1171 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1172 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1173 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1174 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1175 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1176 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1177 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1178 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1179 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1180 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1181 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1182 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1183 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1184 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1185 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1186 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1187 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1188 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1189 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1190 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1191 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1192 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1193 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1194 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1195 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1196 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1197 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1198 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1199 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1200 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1201 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1202 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1203 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1204 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1205 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1206 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1207 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1208 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1209 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1210 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1211 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1212 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1213 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1214 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1215 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1216 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1217 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1218 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1219 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1220 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1221 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1222 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1223 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1224 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1225 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1226 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1227 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1228 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1229 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1230 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1231 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1232 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1233 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1234 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1235 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1236 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1237 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1238 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1239 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1240 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1241 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1242 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1243 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1244 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1245 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1246 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1247 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1248 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1249 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1250 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1251 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1252 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1253 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1254 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1255 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1256 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1257 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1258 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1259 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1260 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1261 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1262 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1263 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1264 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1265 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1266 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1267 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1268 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1269 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1270 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1271 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1272 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1273 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1274 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1275 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1276 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1277 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1278 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1279 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1280 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1281 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1282 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1283 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1284 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1285 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1286 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1287 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1288 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1289 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1290 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1291 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1292 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1293 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1294 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1295 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1296 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1297 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1298 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1299 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1300 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1301 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1302 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1303 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1304 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1305 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1306 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1307 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1308 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1309 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1310 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1311 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1312 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1313 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1314 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1315 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1316 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1317 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1318 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1319 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1320 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1321 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1322 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1323 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1324 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1325 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1326 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1327 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1328 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1329 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1330 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1331 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1332 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1333 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1334 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1335 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1336 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1337 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1338 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1339 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1340 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1341 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1342 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1343 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1344 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1345 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1346 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1347 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1348 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1349 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1350 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1351 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1352 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1353 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1354 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1355 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1356 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1357 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1358 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1359 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1360 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1361 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1362 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1363 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1364 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1365 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1366 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1367 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1368 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1369 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1370 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1371 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1372 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1373 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1374 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1375 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1376 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1377 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1378 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1379 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1380 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1381 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1382 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1383 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1384 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1385 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1386 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1387 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1388 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1389 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1390 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1391 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1392 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1393 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1394 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1395 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1396 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1397 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1398 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1399 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1400 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1401 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1402 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1403 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1404 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1405 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1406 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1407 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1408 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1409 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1410 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1411 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1412 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1413 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1414 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1415 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1416 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1417 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1418 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1419 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1420 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1421 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1422 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1423 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1424 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1425 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1426 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1427 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1428 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1429 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1430 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1431 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1432 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1433 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1434 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1435 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1436 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1437 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1438 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1439 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1440 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1441 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1442 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1443 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1444 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1445 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1446 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1447 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1448 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1449 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1450 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1451 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1452 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1453 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1454 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1455 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1456 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1457 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1458 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1459 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1460 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1461 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1462 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1463 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1464 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1465 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1466 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1467 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1468 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1469 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1470 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1471 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1472 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1473 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1474 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1475 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1476 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1477 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1478 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1479 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1480 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1481 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1482 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1483 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1484 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1485 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1486 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1487 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1488 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1489 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1490 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1491 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1492 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1493 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1494 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1495 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1496 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1497 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1498 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1499 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1500 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1501 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1502 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1503 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1504 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1505 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1506 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1507 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1508 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1509 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1510 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1511 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1512 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1513 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1514 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1515 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1516 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1517 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1518 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1519 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1520 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1521 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1522 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1523 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1524 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1525 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1526 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1527 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1528 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1529 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1530 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1531 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1532 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1533 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1534 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1535 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1536 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1537 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1538 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1539 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1540 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1541 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1542 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1543 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1544 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1545 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1546 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1547 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1548 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1549 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1550 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1551 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1552 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1553 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1554 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1555 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1556 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1557 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1558 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1559 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1560 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1561 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1562 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1563 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1564 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1565 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1566 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1567 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1568 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1569 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1570 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1571 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1572 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1573 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1574 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1575 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1576 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1577 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1578 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1579 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1580 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1581 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1582 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1583 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1584 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1585 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1586 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1587 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1588 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1589 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1590 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1591 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1592 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1593 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1594 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1595 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1596 [65,70) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1597 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1598 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1599 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1600 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1601 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1602 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1603 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1604 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1605 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1606 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1607 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1608 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1609 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1610 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1611 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1612 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1613 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1614 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1615 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1616 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1617 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1618 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1619 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1620 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1621 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1622 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1623 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1624 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1625 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1626 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1627 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1628 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1629 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1630 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1631 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1632 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1633 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1634 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1635 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1636 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1637 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1638 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1639 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1640 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1641 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1642 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1643 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1644 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1645 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1646 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1647 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1648 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1649 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1650 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1651 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1652 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1653 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1654 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1655 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1656 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1657 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1658 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1659 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1660 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1661 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1662 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1663 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1664 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1665 [40,45) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1666 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1667 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1668 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1669 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1670 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1671 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1672 [45,50) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1673 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1674 [60,65) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1675 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1676 [50,55) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1677 [55,60) 403 27.605371 14.598609 13.207921 16.095899 0.95 ## rate ratios and 95% CIs for each age category compare with [40,44) age group Model0 &lt;- glm(all ~ agecat + offset(log(followupyrs)), family = poisson(link = &quot;log&quot;), data = whitehal); ci.exp(Model0) ## exp(Est.) 2.5% 97.5% ## (Intercept) 0.0048794197 0.0032705278 0.0072797841 ## agecat[45,50) 1.1740971320 0.7154062934 1.9268827913 ## agecat[50,55) 2.7732622719 1.7597191900 4.3705743919 ## agecat[55,60) 4.5784055712 2.9519678778 7.1009572062 ## agecat[60,65) 6.6882727538 4.2856745766 10.4377949444 ## agecat[65,70) 17.1110624279 10.1140257533 28.9487553770 ## The rate ratios are increasing with age although there is no statistical evidence ## at 5% level that the rate among 45-49 year olds is different to the rate among men ## who are &lt;40 years with(whitehal %&gt;% group_by(grade) %&gt;% summarise(D = sum(all), Y = sum(followupyrs)), cbind(whitehal$grade, pois.exact(x = D, pt = Y/1000))) ## whitehal$grade x pt rate lower upper conf.level ## 1 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 2 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 3 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 4 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 5 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 6 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 7 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 8 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 9 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 10 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 11 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 12 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 13 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 14 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 15 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 16 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 17 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 18 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 19 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 20 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 21 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 22 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 23 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 24 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 25 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 26 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 27 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 28 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 29 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 30 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 31 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 32 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 33 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 34 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 35 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 36 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 37 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 38 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 39 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 40 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 41 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 42 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 43 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 44 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 45 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 46 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 47 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 48 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 49 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 50 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 51 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 52 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 53 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 54 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 55 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 56 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 57 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 58 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 59 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 60 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 61 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 62 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 63 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 64 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 65 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 66 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 67 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 68 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 69 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 70 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 71 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 72 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 73 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 74 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 75 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 76 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 77 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 78 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 79 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 80 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 81 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 82 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 83 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 84 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 85 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 86 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 87 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 88 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 89 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 90 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 91 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 92 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 93 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 94 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 95 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 96 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 97 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 98 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 99 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 100 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 101 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 102 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 103 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 104 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 105 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 106 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 107 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 108 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 109 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 110 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 111 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 112 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 113 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 114 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 115 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 116 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 117 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 118 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 119 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 120 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 121 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 122 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 123 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 124 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 125 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 126 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 127 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 128 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 129 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 130 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 131 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 132 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 133 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 134 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 135 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 136 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 137 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 138 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 139 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 140 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 141 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 142 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 143 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 144 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 145 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 146 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 147 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 148 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 149 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 150 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 151 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 152 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 153 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 154 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 155 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 156 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 157 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 158 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 159 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 160 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 161 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 162 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 163 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 164 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 165 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 166 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 167 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 168 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 169 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 170 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 171 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 172 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 173 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 174 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 175 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 176 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 177 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 178 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 179 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 180 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 181 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 182 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 183 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 184 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 185 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 186 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 187 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 188 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 189 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 190 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 191 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 192 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 193 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 194 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 195 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 196 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 197 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 198 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 199 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 200 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 201 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 202 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 203 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 204 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 205 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 206 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 207 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 208 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 209 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 210 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 211 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 212 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 213 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 214 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 215 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 216 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 217 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 218 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 219 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 220 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 221 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 222 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 223 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 224 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 225 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 226 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 227 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 228 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 229 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 230 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 231 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 232 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 233 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 234 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 235 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 236 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 237 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 238 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 239 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 240 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 241 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 242 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 243 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 244 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 245 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 246 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 247 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 248 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 249 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 250 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 251 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 252 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 253 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 254 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 255 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 256 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 257 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 258 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 259 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 260 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 261 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 262 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 263 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 264 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 265 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 266 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 267 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 268 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 269 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 270 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 271 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 272 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 273 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 274 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 275 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 276 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 277 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 278 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 279 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 280 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 281 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 282 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 283 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 284 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 285 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 286 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 287 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 288 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 289 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 290 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 291 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 292 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 293 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 294 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 295 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 296 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 297 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 298 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 299 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 300 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 301 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 302 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 303 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 304 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 305 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 306 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 307 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 308 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 309 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 310 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 311 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 312 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 313 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 314 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 315 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 316 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 317 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 318 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 319 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 320 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 321 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 322 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 323 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 324 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 325 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 326 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 327 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 328 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 329 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 330 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 331 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 332 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 333 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 334 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 335 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 336 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 337 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 338 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 339 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 340 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 341 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 342 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 343 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 344 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 345 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 346 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 347 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 348 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 349 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 350 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 351 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 352 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 353 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 354 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 355 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 356 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 357 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 358 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 359 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 360 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 361 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 362 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 363 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 364 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 365 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 366 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 367 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 368 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 369 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 370 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 371 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 372 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 373 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 374 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 375 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 376 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 377 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 378 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 379 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 380 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 381 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 382 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 383 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 384 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 385 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 386 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 387 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 388 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 389 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 390 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 391 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 392 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 393 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 394 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 395 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 396 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 397 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 398 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 399 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 400 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 401 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 402 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 403 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 404 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 405 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 406 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 407 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 408 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 409 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 410 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 411 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 412 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 413 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 414 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 415 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 416 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 417 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 418 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 419 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 420 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 421 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 422 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 423 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 424 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 425 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 426 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 427 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 428 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 429 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 430 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 431 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 432 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 433 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 434 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 435 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 436 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 437 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 438 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 439 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 440 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 441 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 442 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 443 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 444 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 445 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 446 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 447 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 448 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 449 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 450 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 451 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 452 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 453 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 454 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 455 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 456 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 457 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 458 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 459 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 460 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 461 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 462 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 463 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 464 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 465 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 466 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 467 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 468 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 469 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 470 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 471 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 472 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 473 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 474 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 475 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 476 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 477 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 478 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 479 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 480 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 481 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 482 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 483 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 484 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 485 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 486 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 487 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 488 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 489 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 490 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 491 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 492 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 493 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 494 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 495 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 496 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 497 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 498 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 499 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 500 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 501 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 502 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 503 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 504 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 505 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 506 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 507 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 508 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 509 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 510 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 511 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 512 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 513 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 514 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 515 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 516 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 517 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 518 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 519 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 520 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 521 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 522 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 523 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 524 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 525 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 526 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 527 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 528 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 529 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 530 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 531 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 532 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 533 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 534 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 535 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 536 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 537 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 538 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 539 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 540 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 541 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 542 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 543 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 544 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 545 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 546 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 547 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 548 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 549 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 550 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 551 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 552 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 553 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 554 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 555 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 556 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 557 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 558 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 559 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 560 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 561 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 562 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 563 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 564 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 565 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 566 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 567 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 568 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 569 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 570 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 571 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 572 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 573 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 574 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 575 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 576 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 577 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 578 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 579 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 580 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 581 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 582 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 583 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 584 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 585 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 586 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 587 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 588 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 589 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 590 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 591 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 592 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 593 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 594 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 595 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 596 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 597 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 598 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 599 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 600 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 601 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 602 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 603 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 604 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 605 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 606 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 607 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 608 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 609 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 610 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 611 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 612 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 613 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 614 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 615 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 616 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 617 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 618 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 619 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 620 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 621 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 622 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 623 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 624 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 625 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 626 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 627 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 628 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 629 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 630 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 631 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 632 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 633 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 634 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 635 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 636 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 637 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 638 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 639 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 640 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 641 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 642 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 643 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 644 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 645 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 646 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 647 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 648 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 649 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 650 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 651 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 652 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 653 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 654 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 655 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 656 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 657 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 658 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 659 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 660 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 661 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 662 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 663 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 664 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 665 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 666 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 667 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 668 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 669 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 670 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 671 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 672 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 673 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 674 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 675 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 676 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 677 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 678 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 679 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 680 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 681 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 682 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 683 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 684 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 685 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 686 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 687 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 688 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 689 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 690 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 691 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 692 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 693 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 694 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 695 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 696 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 697 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 698 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 699 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 700 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 701 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 702 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 703 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 704 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 705 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 706 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 707 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 708 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 709 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 710 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 711 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 712 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 713 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 714 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 715 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 716 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 717 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 718 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 719 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 720 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 721 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 722 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 723 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 724 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 725 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 726 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 727 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 728 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 729 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 730 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 731 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 732 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 733 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 734 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 735 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 736 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 737 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 738 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 739 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 740 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 741 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 742 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 743 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 744 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 745 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 746 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 747 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 748 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 749 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 750 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 751 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 752 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 753 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 754 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 755 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 756 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 757 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 758 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 759 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 760 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 761 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 762 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 763 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 764 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 765 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 766 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 767 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 768 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 769 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 770 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 771 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 772 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 773 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 774 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 775 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 776 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 777 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 778 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 779 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 780 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 781 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 782 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 783 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 784 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 785 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 786 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 787 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 788 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 789 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 790 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 791 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 792 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 793 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 794 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 795 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 796 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 797 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 798 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 799 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 800 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 801 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 802 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 803 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 804 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 805 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 806 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 807 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 808 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 809 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 810 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 811 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 812 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 813 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 814 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 815 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 816 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 817 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 818 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 819 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 820 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 821 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 822 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 823 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 824 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 825 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 826 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 827 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 828 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 829 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 830 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 831 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 832 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 833 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 834 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 835 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 836 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 837 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 838 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 839 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 840 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 841 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 842 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 843 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 844 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 845 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 846 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 847 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 848 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 849 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 850 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 851 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 852 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 853 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 854 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 855 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 856 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 857 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 858 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 859 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 860 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 861 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 862 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 863 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 864 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 865 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 866 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 867 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 868 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 869 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 870 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 871 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 872 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 873 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 874 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 875 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 876 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 877 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 878 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 879 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 880 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 881 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 882 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 883 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 884 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 885 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 886 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 887 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 888 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 889 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 890 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 891 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 892 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 893 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 894 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 895 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 896 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 897 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 898 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 899 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 900 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 901 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 902 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 903 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 904 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 905 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 906 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 907 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 908 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 909 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 910 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 911 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 912 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 913 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 914 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 915 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 916 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 917 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 918 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 919 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 920 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 921 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 922 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 923 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 924 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 925 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 926 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 927 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 928 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 929 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 930 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 931 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 932 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 933 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 934 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 935 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 936 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 937 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 938 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 939 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 940 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 941 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 942 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 943 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 944 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 945 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 946 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 947 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 948 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 949 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 950 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 951 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 952 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 953 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 954 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 955 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 956 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 957 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 958 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 959 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 960 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 961 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 962 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 963 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 964 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 965 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 966 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 967 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 968 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 969 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 970 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 971 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 972 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 973 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 974 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 975 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 976 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 977 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 978 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 979 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 980 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 981 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 982 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 983 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 984 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 985 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 986 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 987 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 988 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 989 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 990 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 991 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 992 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 993 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 994 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 995 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 996 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 997 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 998 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 999 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1000 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1001 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1002 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1003 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1004 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1005 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1006 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1007 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1008 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1009 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1010 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1011 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1012 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1013 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1014 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1015 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1016 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1017 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1018 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1019 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1020 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1021 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1022 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1023 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1024 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1025 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1026 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1027 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1028 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1029 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1030 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1031 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1032 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1033 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1034 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1035 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1036 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1037 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1038 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1039 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1040 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1041 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1042 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1043 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1044 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1045 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1046 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1047 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1048 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1049 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1050 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1051 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1052 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1053 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1054 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1055 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1056 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1057 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1058 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1059 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1060 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1061 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1062 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1063 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1064 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1065 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1066 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1067 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1068 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1069 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1070 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1071 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1072 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1073 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1074 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1075 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1076 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1077 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1078 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1079 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1080 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1081 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1082 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1083 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1084 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1085 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1086 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1087 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1088 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1089 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1090 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1091 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1092 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1093 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1094 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1095 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1096 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1097 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1098 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1099 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1100 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1101 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1102 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1103 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1104 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1105 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1106 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1107 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1108 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1109 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1110 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1111 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1112 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1113 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1114 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1115 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1116 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1117 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1118 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1119 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1120 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1121 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1122 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1123 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1124 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1125 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1126 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1127 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1128 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1129 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1130 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1131 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1132 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1133 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1134 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1135 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1136 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1137 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1138 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1139 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1140 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1141 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1142 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1143 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1144 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1145 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1146 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1147 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1148 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1149 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1150 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1151 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1152 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1153 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1154 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1155 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1156 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1157 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1158 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1159 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1160 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1161 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1162 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1163 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1164 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1165 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1166 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1167 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1168 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1169 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1170 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1171 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1172 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1173 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1174 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1175 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1176 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1177 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1178 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1179 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1180 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1181 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1182 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1183 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1184 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1185 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1186 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1187 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1188 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1189 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1190 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1191 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1192 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1193 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1194 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1195 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1196 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1197 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1198 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1199 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1200 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1201 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1202 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1203 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1204 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1205 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1206 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1207 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1208 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1209 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1210 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1211 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1212 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1213 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1214 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1215 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1216 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1217 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1218 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1219 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1220 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1221 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1222 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1223 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1224 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1225 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1226 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1227 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1228 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1229 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1230 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1231 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1232 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1233 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1234 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1235 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1236 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1237 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1238 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1239 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1240 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1241 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1242 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1243 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1244 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1245 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1246 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1247 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1248 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1249 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1250 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1251 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1252 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1253 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1254 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1255 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1256 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1257 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1258 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1259 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1260 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1261 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1262 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1263 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1264 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1265 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1266 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1267 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1268 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1269 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1270 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1271 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1272 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1273 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1274 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1275 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1276 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1277 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1278 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1279 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1280 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1281 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1282 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1283 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1284 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1285 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1286 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1287 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1288 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1289 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1290 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1291 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1292 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1293 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1294 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1295 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1296 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1297 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1298 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1299 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1300 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1301 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1302 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1303 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1304 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1305 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1306 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1307 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1308 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1309 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1310 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1311 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1312 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1313 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1314 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1315 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1316 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1317 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1318 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1319 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1320 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1321 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1322 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1323 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1324 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1325 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1326 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1327 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1328 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1329 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1330 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1331 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1332 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1333 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1334 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1335 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1336 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1337 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1338 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1339 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1340 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1341 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1342 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1343 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1344 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1345 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1346 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1347 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1348 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1349 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1350 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1351 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1352 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1353 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1354 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1355 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1356 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1357 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1358 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1359 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1360 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1361 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1362 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1363 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1364 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1365 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1366 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1367 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1368 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1369 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1370 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1371 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1372 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1373 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1374 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1375 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1376 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1377 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1378 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1379 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1380 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1381 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1382 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1383 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1384 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1385 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1386 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1387 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1388 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1389 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1390 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1391 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1392 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1393 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1394 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1395 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1396 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1397 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1398 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1399 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1400 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1401 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1402 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1403 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1404 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1405 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1406 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1407 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1408 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1409 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1410 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1411 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1412 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1413 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1414 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1415 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1416 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1417 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1418 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1419 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1420 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1421 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1422 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1423 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1424 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1425 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1426 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1427 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1428 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1429 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1430 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1431 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1432 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1433 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1434 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1435 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1436 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1437 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1438 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1439 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1440 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1441 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1442 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1443 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1444 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1445 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1446 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1447 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1448 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1449 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1450 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1451 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1452 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1453 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1454 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1455 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1456 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1457 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1458 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1459 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1460 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1461 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1462 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1463 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1464 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1465 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1466 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1467 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1468 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1469 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1470 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1471 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1472 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1473 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1474 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1475 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1476 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1477 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1478 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1479 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1480 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1481 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1482 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1483 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1484 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1485 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1486 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1487 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1488 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1489 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1490 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1491 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1492 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1493 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1494 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1495 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1496 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1497 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1498 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1499 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1500 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1501 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1502 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1503 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1504 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1505 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1506 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1507 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1508 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1509 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1510 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1511 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1512 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1513 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1514 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1515 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1516 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1517 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1518 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1519 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1520 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1521 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1522 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1523 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1524 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1525 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1526 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1527 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1528 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1529 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1530 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1531 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1532 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1533 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1534 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1535 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1536 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1537 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1538 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1539 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1540 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1541 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1542 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1543 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1544 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1545 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1546 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1547 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1548 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1549 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1550 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1551 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1552 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1553 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1554 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1555 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1556 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1557 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1558 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1559 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1560 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1561 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1562 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1563 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1564 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1565 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1566 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1567 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1568 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1569 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1570 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1571 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1572 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1573 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1574 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1575 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1576 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1577 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1578 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1579 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1580 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1581 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1582 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1583 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1584 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1585 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1586 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1587 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1588 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1589 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1590 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1591 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1592 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1593 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1594 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1595 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1596 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1597 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1598 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1599 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1600 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1601 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1602 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1603 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1604 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1605 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1606 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1607 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1608 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1609 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1610 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1611 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1612 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1613 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1614 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1615 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1616 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1617 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1618 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1619 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1620 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1621 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1622 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1623 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1624 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1625 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1626 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1627 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1628 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1629 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1630 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1631 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1632 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1633 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1634 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1635 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1636 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1637 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1638 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1639 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1640 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1641 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1642 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1643 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1644 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1645 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1646 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1647 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1648 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1649 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1650 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1651 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1652 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1653 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1654 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1655 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1656 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1657 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1658 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1659 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1660 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1661 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1662 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1663 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1664 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1665 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1666 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1667 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1668 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1669 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1670 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1671 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1672 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1673 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1674 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1675 2 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1676 1 403 27.605371 14.598609 13.207921 16.095899 0.95 ## 1677 1 403 27.605371 14.598609 13.207921 16.095899 0.95 Model1 &lt;- glm(all ~ factor(grade) + offset(log(followupyrs)), family = poisson(link = &quot;log&quot;), data = whitehal); ci.exp(Model1) ## exp(Est.) 2.5% 97.5% ## (Intercept) 0.010865404 0.0095233128 0.012396632 ## factor(grade)2 2.305446287 1.8947528380 2.805158793 ## There is strong evidence that the all cause mortality rate differs between high ## and low grade workers. ## To examine whether the estimated RR for grade is confounded by age at entry ## we compare the crude RR =2.31 (1.90, 2.81) with the Mantel-Haenszel summary ## estimate. whitehal_table &lt;- aggregate(cbind(all, followupyrs) ~ grade + agecat, data=whitehal, sum) stmh_array &lt;- array(c(4, 20, 693.1284,4225.4893, 10,35, 1363.821,6491.072, 30,52, 1399.63, 4660.12, 51,67, 1832.169,3449.846, 59,42, 1660.597,1434.251, 28,5, 316.23840, 79.00879), dim=c(2,2,6), dimnames = list( Grade=c(&quot;2&quot;,&quot;1&quot;), c(&quot;death&quot;, &quot;Person_years&quot;), Agecat=names(table(whitehal$agecat)) )) stmh_array ## , , Agecat = [40,45) ## ## ## Grade death Person_years ## 2 4 693.1284 ## 1 20 4225.4893 ## ## , , Agecat = [45,50) ## ## ## Grade death Person_years ## 2 10 1363.821 ## 1 35 6491.072 ## ## , , Agecat = [50,55) ## ## ## Grade death Person_years ## 2 30 1399.63 ## 1 52 4660.12 ## ## , , Agecat = [55,60) ## ## ## Grade death Person_years ## 2 51 1832.169 ## 1 67 3449.846 ## ## , , Agecat = [60,65) ## ## ## Grade death Person_years ## 2 59 1660.597 ## 1 42 1434.251 ## ## , , Agecat = [65,70) ## ## ## Grade death Person_years ## 2 28 316.23840 ## 1 5 79.00879 mhgrade_age &lt;- epi.2by2(stmh_array, method = &quot;cohort.time&quot;, units = 1000) mhgrade_age ## Outcome + Time at risk Inc rate * ## Exposed + 182 7266 25.0 ## Exposed - 221 20340 10.9 ## Total 403 27605 14.6 ## ## Point estimates and 95 % CIs: ## ------------------------------------------------------------------- ## Inc rate ratio (crude) 2.31 (1.88, 2.82) ## Inc rate ratio (M-H) 1.43 (1.16, 1.76) ## Inc rate ratio (crude:M-H) 1.61 ## Attrib rate (crude) * 14.18 (10.27, 18.10) ## Attrib rate (M-H) * 6.28 (2.42, 10.15) ## Attrib rate (crude:M-H) 2.26 ## ------------------------------------------------------------------- ## Wald confidence limits ## M-H: Mantel-Haenszel ## * Outcomes per 1000 units of population time at risk ## Overall estimate and Wald 95% confidence intervals, ## controlling for agecate mhgrade_age$massoc$IRR.mh.wald ## est lower upper ## 1 1.429211 1.1598631 1.7611078 mhgrade_age$massoc$chisq.mh ## p-value for age-adjusted MH rate ratio ## test.statistic df p.value ## 1 10.760807 1 0.0010367217 ## The Mantel-Haenszel summary estimate RR = 1.43 (1.16, 1.76). ## The result shows that the crude estimate of the effect of grade was ## partly confounded by age at entry. ## To assess whether there is effect modification betwee grade and ## agecat we examine the stratum specific estimates and assess ## whether there is evidence of important variation between them. mhgrade_age$massoc$IRR.strata.wald ## est lower upper ## 1 1.2192515 0.30302945 3.6397113 ## 2 1.3598500 0.60057144 2.8059055 ## 3 1.9208868 1.18309546 3.0676307 ## 4 1.4332751 0.97576189 2.0941999 ## 5 1.2132872 0.80308583 1.8474726 ## 6 1.3991002 0.53338106 4.6404658 ## The result indicates that the data are compatible with the assumption ## of no interaction/effect modification (p=0.79) ## test for unequal RRs (effect modification): mhgrade_age$res$RR.homog ## test.statistic df p.value ## 1 2.407279 5 0.79038965 ## Hence, we do not need to present the stratum-specific estimates. "],
["references.html", "参考文献", " 参考文献 以下是我的 R 進程信息： sessionInfo() ## R version 3.4.3 (2017-11-30) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Ubuntu 16.04.3 LTS ## ## Matrix products: default ## BLAS: /usr/lib/libblas/libblas.so.3.6.0 ## LAPACK: /usr/lib/lapack/liblapack.so.3.6.0 ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C LC_TIME=en_GB.UTF-8 ## [4] LC_COLLATE=en_GB.UTF-8 LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] grid splines stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] abind_1.4-5 stargazer_5.2.1 exact2x2_1.5.2 exactci_1.3-3 ## [5] ssanv_1.1 binomTools_1.0-1 limma_3.32.10 DescTools_0.99.23 ## [9] ggsci_2.8 plyr_1.8.4 ggthemes_3.4.0 car_2.1-6 ## [13] scatterplot3d_0.3-40 mvtnorm_1.0-7 kableExtra_0.7.0 sandwich_2.4-0 ## [17] nlme_3.1-131 lme4_1.1-15 Matrix_1.2-11 PredictABEL_1.2-2 ## [21] PBSmodelling_2.68.6 ROCR_1.0-7 gplots_3.0.1 Hmisc_4.1-1 ## [25] Formula_1.2-2 lattice_0.20-35 psych_1.7.8 margins_0.3.0 ## [29] epiDisplay_3.2.2.0 nnet_7.3-12 MASS_7.3-48 foreign_0.8-69 ## [33] rgl_0.99.9 epiR_0.9-93 shiny_1.0.5 eha_2.5.1 ## [37] epitools_0.5-10 flexsurv_1.1 mstate_0.2.10 cmprsk_2.2-7 ## [41] gnm_1.0-8 KMsurv_0.1-5 Epi_2.24 gridExtra_2.3 ## [45] plotly_4.7.1 haven_1.1.1 survminer_0.4.2 ggpubr_0.1.6 ## [49] magrittr_1.5 ggfortify_0.4.2 survival_2.41-3 forcats_0.3.0 ## [53] stringr_1.3.0 dplyr_0.7.4 purrr_0.2.4 readr_1.1.1 ## [57] tidyr_0.8.0 tibble_1.4.2 ggplot2_2.2.1 tidyverse_1.2.1 ## [61] kfigr_1.2 knitr_1.20 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.0.0 backports_1.1.2 BSDA_1.2.0 lazyeval_0.2.1 ## [5] crosstalk_1.0.0 digest_0.6.15 htmltools_0.3.6 gdata_2.18.0 ## [9] relimp_1.0-5 checkmate_1.8.5 cluster_2.0.6 etm_0.6-2 ## [13] modelr_0.1.1 colorspace_1.3-2 rvest_0.3.2 BiasedUrn_1.07 ## [17] xfun_0.1 tcltk_3.4.3 crayon_1.3.4 jsonlite_1.5 ## [21] bindr_0.1 zoo_1.8-1 glue_1.2.0 gtable_0.2.0 ## [25] MatrixModels_0.4-1 SparseM_1.77 scales_0.5.0 Rcpp_0.12.15 ## [29] viridisLite_0.3.0 xtable_1.8-2 htmlTable_1.11.2 deSolve_1.20 ## [33] km.ci_0.5-2 prediction_0.2.0 htmlwidgets_1.0 httr_1.3.1 ## [37] qvcalc_0.9-1 RColorBrewer_1.1-2 acepack_1.4.1 manipulate_1.0.1 ## [41] pkgconfig_2.0.1 XML_3.98-1.10 utf8_1.1.3 rlang_0.2.0 ## [45] reshape2_1.4.3 munsell_0.4.3 cellranger_1.1.0 tools_3.4.3 ## [49] cli_1.0.0 broom_0.4.3 evaluate_0.10.1 yaml_2.1.16 ## [53] survMisc_0.5.4 caTools_1.17.1 bindrcpp_0.2 mime_0.5 ## [57] quantreg_5.35 xml2_1.2.0 compiler_3.4.3 pbkrtest_0.4-7 ## [61] rstudioapi_0.7 e1071_1.6-8 stringi_1.1.6 highr_0.6 ## [65] nloptr_1.0.4 pillar_1.1.0 lmtest_0.9-35 data.table_1.10.4-3 ## [69] bitops_1.0-6 httpuv_1.3.5 R6_2.2.2 latticeExtra_0.6-28 ## [73] bookdown_0.7 muhaz_1.2.6 KernSmooth_2.23-15 codetools_0.2-15 ## [77] boot_1.3-20 gtools_3.5.0 assertthat_0.2.0 rprojroot_1.3-2 ## [81] mnormt_1.5-5 expm_0.999-2 mgcv_1.8-23 parallel_3.4.3 ## [85] hms_0.4.1 quadprog_1.5-5 rpart_4.1-12 class_7.3-14 ## [89] minqa_1.2.4 FSA_0.8.17 rmarkdown_1.8 numDeriv_2016.8-1 ## [93] lubridate_1.7.2 base64enc_0.1-3 "]
]
