# (PART) 因果推斷 Causal Inference {-}

# Causal Languages 因果推斷的語法

## 當我們在談論因果推斷的時候，我們在談論什麼？

衆多的醫學研究，科研工作者們苦苦收集數據，都是爲了能夠給觀察到的現象作出**因果關系的結論**。研究者帶着的研究問題通常是: 

- 這個治療方案有沒有效果？
- 暴露在某種可能有害的因素中到底有沒有危險？
- 提出的新的衛生政策到底能不能解決實際的醫療問題？

這些都是內在爲因果關系的設問。隨機對照實驗，之所以要隨機設計，且對其**隨機性**要求精準且苛刻，就是爲了一個能夠清晰可靠地作出因果關系的結論。在很多流行病學研究中，隨機設計可能因爲倫理因素不能使用。但每一個精心設計的實驗或者觀察性研究，其終極目的都是爲了解答暴露和結果之間到底有沒有因果關系這一設問。

這裏我們用 “因果推斷” 來命名一類 “專門以探尋因果關系爲目的的” 統計學方法。其與傳統的統計學方法最大的不同點在於因果推斷用一套**正式的科學語言**，來解釋現象中到底有沒有因果關系。

之所以發明這一套因果推斷專用的科學語言，有這樣幾個目的: 

1. 更清晰地描述，我們到底要估計的 (estimate) 是什麼。
2. 更徹底地強調，因果推斷結論背後的統計學前提和假設。
3. 建立在前兩條前提的基礎上，我們可以使用專門爲統計推斷設計的新的統計學技巧，達到爲因果推斷提供證據的目的。


因果推斷包括三個部分: 

1. 清晰描述因果關系概念的正式科學語言 (causal language)。
2. 因果關系示意圖 (causal diagram) -- 清晰地展示研究者對變量之間存在的所有可能因果關系的假設，在實驗設計，和數據分析兩個階段都需要用到。
3. 因果關系統計學方法 (causal inference methods) -- 從獲得的數據中，用和傳統方法不同的假設，作出因果關系的推斷。


## 傳統的統計學方法

用一個簡單實例來理解傳統統計學方法實際上做的是什麼: 


```{example}
臨牀上認爲，給有貧血的患者靜脈內補充鐵劑是進行髖關節置換手術 (hip replacement operation) 之前建議的手段。研究者收集了某個醫院 2009 年至 2014 年間接受髖關節置換手術且有貧血的患者數據。在這個研究中，暴露變量 (exposure) 是患者是否在術前接受了靜脈內鐵劑補充，結果變量是髖關節置換手術之後，患者是否存活時間達到 90 天及以上。其他同時收集的數據有: 年齡，性別，伴隨疾病 (心血管疾病，糖尿病，腎病)，手術過程中是否接受了外來血源的輸血，以及住院時間。
```



### 初步分析 

很多人第一步想到的，一定是先制作 2×2 的暴露 (FeIV) 和結果 (Death90) 的表格: 

```{r CI-tab1-1, echo=FALSE, eval = TRUE, cache=TRUE}
dt <- read.csv("backupfiles/ci-tab1-1.csv", header = T)
names(dt) <- c(" ", " ", "0", "1")
kable(dt, digits = 3, row.names = FALSE, align = "c",
              caption = NULL, format = "html") %>%
kable_styling(bootstrap_options = c("striped", "condensed"),
        position = "center", full_width = FALSE) %>%
add_header_above(c(" " = 2, "Death90" = 2)) %>%
  column_spec(c(1,2), bold = T) %>%
  collapse_rows(columns = 1:2)
```


從這個四格表我們計算的初步對數比值比是: 0.04 (95% CI: -0.12, 0.19)。

請問在這個對數比值比的計算過程中，我們估計的到底是什麼？ 這裏的被估計量 (estimand) 是: 

$$
\log \text{OR}_{Y|X} = \log\{\frac{\text{Pr}(Y=1 | X = 1)}{1- \text{Pr}(Y = 1|X = 1)}\} - \log\{\frac{\text{Pr}(Y=1 | X = 0)}{1- \text{Pr}(Y = 1|X = 0)}\}
$$

```{definition, label="estimand"}
<br>
1. Estimand (被估計量): 我們想要知道的到底是什麼，例如，英國人口中收縮期血壓的平均值，這是一個無法知道，但是肯定存在確定量的量 (unknown fixed quantity)。<br>
2. Estimator (估計量): 數據用來計算被估計量的某種**方程**，例如，隨機從街上找來100個人，測量他們的血壓，求出來的平均值，這是一個隨機變量 (random variable)，會隨着隨機挑選的樣本而變化。<br>
3. Estimate (估計): 給定數據下，計算獲得的具體的量，例如，我做了隨機抽取100名英國人血壓測量的實驗，獲得 130.4 mmHg 這個平均收縮期血壓的測量值，這是一個可以計算成爲已知的確定量 (known fixed quantity)。
```


### 混雜

我們知道，單純這樣簡單初步計算獲得的對數比值比，我們是無法對其作出因果關系的解釋的，因爲通常這樣的分析都忽略掉了潛在的混雜。在目前爲止我們學習過的傳統統計學方法中，混雜被我們粗略地定義成: "和暴露，結果兩個變量同時且獨立地相關，但是確定不存在在暴露和結果的因果通路上的變量 (associated with the exposure and independently associated with the outcome, without being on the causal pathway from exposure to outcome)"，下一章我們會看到，這其實是一個不能令人滿意的定義。

例如，可能之所以有些病人在髖關節置換術之前會被提供靜脈鐵劑支持，其原因不僅是貧血，還可能他們本身體質虛弱，年紀較大，或者是貧血得太嚴重，或者還有許多其他的並發症，那麼表面看起來靜脈鐵劑支持，和術後90天生存率沒有關系的對數比值比就成了一個表面現象。這些因素會混淆，甚至是掩蓋靜脈鐵劑可能對貧血患者的潛在保護作用。此時我們說初步分析的對數比值比被混雜偏倚所影響 (suffer from confounding bias)。(關於偏倚在統計推斷中的概念，滾回章節 \@ref(bias)。)

當我們說，初步分析的對數比值比被混雜偏倚影響，那麼其實是在說，我們心裏想要的那個被估計量 (estimand)，和實際計算中使用的被估計量是兩個不同的概念。我們心裏想要的那個--沒有被偏倚影響的--被估計量，是可以有因果關系的推論的。所以偏倚，就是一種漸進偏倚 (an asymptotic bias)，它是我們心裏想要的那個被估計量，和實際被用到的被估計量之間的差。

### 以共變量爲條件 conditioning on covariates 

對於混雜偏倚，常見的做法是要麼進行分層分析，或者直接丟到回歸模型中去做調整，這樣的做法，其實是把我們使用的被估計量從一個初步對數比值比，改成了一個條件對數比值比: 

$$
\log\text{OR}_{Y|X\cdot C} = \log\{\frac{\text{Pr}(Y=1 | X = 1, \mathbf{C})}{1- \text{Pr}(Y = 1|X = 1, \mathbf{C})}\} - \log\{\frac{\text{Pr}(Y=1 | X = 0, \mathbf{C})}{1- \text{Pr}(Y = 1|X = 0, \mathbf{C})}\}
$$

其中，$\mathbf{C}$ 就是被調整的變量組成的向量。

**應該調整哪些變量？**

從簡單的理解來看，輸血與否，和住院時間長短，應該是處在暴露和結果兩個變量的因果通路之上的，所以不應該調整這兩個變量。所以，隨着這個思路，我們雖然不能調整輸血與否，和住院時間長短兩個變量，但是可以調整諸如年齡，性別，心血管疾病，糖尿病，腎病，貧血嚴重程度，和手術的種類等。

調整了上述變量之後，我們獲得的條件對數比值比 (conditional log-odds ratio) 是 -0.24 (95%CI -0.41, -0.07)。

**可以給予這個條件對數比值比以因果關系的解釋嗎？**

顯然，由於還有其他我們不知道的因素，可能混淆這裏的暴露和結果變量 (我們沒有收集)，所以此時漸進偏倚定義是上面的這個條件對數比值比和我們心裏那個真實想要測量的因果被估計量 (causal estimand) 之間的差: 

$$
\log\text{OR}_{Y|X\cdot C} - \{ \text{True value of some causally -interpretable estimand} \}
$$

在哪些前提條件下，這個漸進偏倚可以被認爲等於零？此時我們需要因果推斷的科學定義和語言來幫助我們理解。

## 更加正規的方法
### 因果推斷使用的語言

**概率與統計學**

概率論和統計學中使用的詞匯和語言，允許我們估計，描述很多觀察變量之間的聯合分布 (joint distribution)，例如均值，方差，協方差，四分位，回歸系數，相關系數等。

但是這一標準的統計學語言，卻無法描述這些聯合分布在受到外在影響或者幹預 (external intervention) 之後，會發生怎樣的變化。用這裏使用的例子來說就是，當所有患者都被提供了靜脈內鐵劑支持，(注意到這是和現實情況不一樣的)
 患者的生存概率會是多少？
 

因果關系的思考，其實是在追問這樣一個問題: 當暴露變量 $X$，可以改變，並且**以與我們觀察到的相反的形式出現**，那麼結果變量 $Y$ 會發生怎樣的變化？本書，我們使用 [@Neyman1923] 當年創立，後來被 [@Rubin1974] 發展的概念: 潛在結果框架 (potential outcome framework)。

```{definition}
**潛在結果 Potential outcome**: 定義 $Y(x)$ 爲當暴露變量 $X$ 取假設的值 (x) 時，結果變量的取值。
```

對於一個而二分類暴露變量 $X$，每個個體/研究對象，我們賦予它一個潛在的可能取值結果的概念: $Y(0)$ 和 $Y(1)$。$Y(0)$ 的意思是當暴露變量是 $0$ 的時候該對象可能的取值，$Y(1)$ 的意思是當暴露變量是 $1$ 的時候，該對象可能的取值。但是，在現實情況下，我們只能觀察到二者中的一種結果。在我們的例題中，當一個患者真的接受了靜脈鐵劑補充，那麼他/她的觀察結果 $Y = Y(1)$，也就是此時觀察結果等於暴露爲 $(1)$ 時的潛在結果 $Y(1)$。對與這個患者來說，他/她在沒有接受經脈鐵劑補充的情況下的另一種潛在結果 $Y(0)$ 是沒有被觀測到的。但是，這個患者的潛在結果 $Y(0)$，表示的是他/她如果接受沒有接受靜脈鐵劑補充的話，他/她在90天時死亡/存活的**潛在結果**。

```{definition}
**用潛在結果表示邊緣和條件因果對比 marginal and conditional causal contrast:** <br>
邊緣對比: $$E\{Y(1)\} - E\{ Y(0) \}$$ 
條件對比: $$E\{ Y(1) | \mathbf{V=v} \} - E\{ Y(0) | \mathbf{V=v} \}$$
```

這種潛在結果的統計框架，曾經被 [@Dawid2000] 批判爲一種不恰當的方法。以爲潛在結果框架建議說存在另一個完全不存在的平行宇宙，使得觀察對象在一個空間裏做一件事，在另一個空間裏做一件相反的事情，看會發生怎樣的結果，這實際是在說存在這種潛在的完美聯合分布。另外，我們會在第四章中看見的，在潛在結果的框架下，我們可能問的問題是，當所有人都接受了暴露變量時，暴露和結果之間的因果效應的平均值: 

$$
E\{ Y(1) - Y(0) | X = 1 \}
$$


潛在結果框架不是完美的。但是它非常實用: 

1. 使不確定性變得明確而清晰;
2. 把研究的問題變得更加容易理解; 
3. 能夠保證研究者明確做因果推斷時的前提條件; 
4. 改善實驗設計; 
5. 有助於設計更能回答研究問題的統計分析方案;
6. 可以給結果恰當的因果關系解釋。

但是我們需要注意的是: 

1. 不要過度相信你做的因果推斷的前提假設是正確的 (over confidence in assumptions); 
2. 不要錯誤的解讀你的分析結果。

### 因果推斷的被估計量 causal estimands

於是，現在用這些重新定義過的名詞和語言，我們來描述 (二分類結果變量在) 因果推斷中的被估計量: 


邊緣被估計量 (marginal estimands): 

$$
\begin{aligned}
\text{Potential risk difference: } & \text{Pr}\{Y(1) = 1| \mathbf{V=v}\} - \text{Pr}\{Y(0) = 1| \mathbf{V=v}\} \\
\text{Potential risk ratio: } & \frac{\text{Pr}\{ Y(1) = 1 | \mathbf{V=v}\}}{\text{Pr}\{Y(0) = 1 | \mathbf{V=v}\} } \\
\text{Potential log odds ratio: } & \\
                \log[\frac{ \text{Pr}\{Y(1) = 1| \mathbf{V=v}\}}{1- \text{Pr}\{Y(1) = 1| \mathbf{V=v}\}}] & - \log[\frac{\text{Pr}\{Y(0) = 1| \mathbf{V=v} \}}{1-\text{Pr}\{Y(0) = 1| \mathbf{V=v} \}}]
\end{aligned}
$$

條件被估計量: 

$$
\begin{aligned}
\text{Potential risk difference: } & \text{Pr}\{Y(1) = 1\} - \text{Pr}\{Y(0) = 1\} \\
\text{Potential risk ratio: } & \frac{\text{Pr}\{ Y(1) = 1 \}}{\text{Pr\{Y(0) = 1 \}}} \\
\text{Potential log odds ratio: } & \\
                \log[\frac{ \text{Pr}\{Y(1) = 1\}}{1- \text{Pr}\{Y(1) = 1\}}] & - \log[\frac{\text{Pr\{Y(0) = 1 \}}}{1-\text{Pr\{Y(0) = 1 \}}}]
\end{aligned}
$$


### 鑑定因果推斷時的前提假設 assumptions for identification

- **無相互幹擾 no interference**

$Y_i(x)$ 表示的是，如果第 $i$ 個個體的暴露變量被設定爲 $x$ 時，結果變量的值。所以是 $X_i$ 被設定成爲 $x (i = 1, \cdots, n)$ 時， $Y_i$ 的潛在結果。此時，我們已經有了一個前提假設，那就是，潛在結果 $Y_i$，和另一個個體的潛在暴露 $X_j (j\neq i)$ 是相互獨立的。這個前提被稱爲無相互幹擾前提。這個前提，在暴露變量是某些特殊情況 (如注射疫苗) 的情況下，是無法成立的。因爲人羣中如果有些人注射了疫苗，同樣也能保護那些沒有注射疫苗的人。

- **一致性 consistency**

$$
X_i = x \Rightarrow Y_i = Y_i(x)
$$

一致性的含義是，對於某個觀察對象來說，他/她的暴露變量是 $x$ 時，觀測到的結果變量的觀測值 $Y_i$，和在**虛擬世界中**，該觀察對象接受潛在 $(x)$ 暴露變量時獲得的潛在結果 $Y_i(x)$，是一樣的。更具體地說: 

1. 暴露變量的定義，要清晰明確。
2. 爲了保持一致性，也就是在實際實驗中，如果暴露變量是 $x$，那麼你觀察到的結果 $Y$，必須和理論討論的虛擬世界中我們預想的那樣潛在變量 $(x)$ 導致的潛在結果 $Y(x)$ 是相同的。

在臨牀試驗的設定下，用本文一開始的靜脈鐵劑補充例子來說明就是，我們構築的潛在世界框架下的幹預手段 (靜脈鐵劑補充)，對患者起到的不論是積極的還是負面的作用，它的理論效果，和我們在實際現實世界中觀察到的對患者進行靜脈鐵劑補充起到的效果，是相同的。

在非臨牀試驗的設定下，一致性有許多值得探討的地方。假如，潛在暴露變量是體質指數 (BMI)，這時候的一致性前提就十分微妙。因爲能夠改變 BMI (運動，飲食，服藥，接受抽脂手術，吸煙，吸毒，甚至是截肢)，以及BMI變化導致的結果 (如心血管疾病) 途徑非常多。所以，當我們在這種觀察實驗的設定下，寫下某個潛在暴露量 X (BMI = 20) 時的潛在結果 Y 時，就必須把暴露變量達到 20 的特定條件指明才可以 (need to be clear under what sort of intervention we imagine that BMI is set to 20)。所以，在非臨牀試驗的觀察性研究中，如果探討的是類似 BMI 這樣的暴露變量，那麼在我們想象的平行世界中對BMI造成影響的因素將會和現實世界一樣是非常復雜的，單一的想象幹預，如抽脂手術，不可能滿足**一致性**的前提假設。所以，觀察對象的 BMI 達到 20 的條件，更加合理的是多種方法的組合 (it is more likely that the individuals in our observational study achieved their different BMI level through a combination of different ways.)，那麼在一致性的前提下，在那個我們想象出來的平行世界裏，潛在暴露 BMI 獲得的幹預，就是各種和 BMI 有關的所有變量。

- **條件可置換性 conditional exchangeability**

第三個前提假設是條件可置換性:

$$
Y(x) \perp\perp X |\mathbf{C}, \forall x
$$


$\perp\perp$ 表示條件獨立 (conditional independence)，所以 $A\perp\perp B|C$ 的正確讀法是: "在C的條件下，A條件獨立於B"。$A\perp\perp B$ 的意思就是， A 和 B 之間互爲 (邊際 marginally) 獨立。

在條件向量 $\mathbf{C}$ 的條件下，觀測對象的實際暴露狀況 $X$ 和他/她/它的所有潛在結果之間相互獨立。


我們可以把第三個前提條件設想爲: 潛在結果 $Y(x)$ 已經能夠把對象身上所有的和結果 $Y$ 相關的特點都包含進來，唯一不包含的是他/她/它在現實世界中的觀測暴露變量。也就是，如果我們知道潛在結果 $Y(0), Y(1)$，且我們知道 $X$，那麼我們就可以知道 Y，因爲 $Y = XY(1) + (1-X) Y(0)$。


```{example}
還是靜脈鐵劑補充的例子，如果我們手裏拿到的數據如下表。一共只有24名患者，假定只有一個條件變量 C (貧血嚴重與否)，表格中羅列的是觀察變量 $X,Y,C$，同時還羅列了兩個平行世界的潛在結果變量 $Y(1), Y(0)$。這裏我們爲了解釋條件可置換性，我們先假裝真的可以獲得所有的潛在結果，實際情況下是不可能的。
```


```{r CI-tab1-2, echo=FALSE, eval = TRUE, cache=TRUE}
dt <- read.csv("backupfiles/ci-tab1-2.csv", header = T)
names(dt) <- c("Patient ID", "X", "Y", "C", "Y(0)", "Y(1)")
kable(dt, digits = 3, row.names = FALSE, align = "c",
              caption = NULL, format = "html") %>%
kable_styling(bootstrap_options = c("striped", "condensed"),
        position = "center", full_width = FALSE)  %>%
    scroll_box(width = "400px", height = "500px", extra_css="margin-left: auto; margin-right: auto;")
```

在這個表格的數據中，我們注意到一致性的前提得到滿足，因爲對於每個 $X=1$ 的研究對象 $Y = Y(1)$，對於每個 $X=0$ 的研究對象 $Y=Y(0)$。

- 邊際概率 marginal probability: 

接下來，第一步，假設我們的數據中沒有條件變量 C，我們來看看數據是否能滿足可置換性 ($Y(0), Y(1)$ 和 $X$ 互相獨立)。

$$
\begin{aligned}
\text{Pr}\{ Y(0)=1|X=1 \} &= \frac{2}{3}, \;\; \text{Pr}\{ Y(0)=1|X=0 \} = \frac{7}{12} \\
\text{Pr}\{ Y(1)=1|X=1 \} &= \frac{5}{12}, \;\; \text{Pr}\{ Y(1)=1|X=0 \} = \frac{1}{3}
\end{aligned}
$$

這裏條件概率計算的結果告訴我們，邊際概率此時不具有可置換性，因爲潛在結果變量 $Y(0) = 1$ 的概率取決與 觀測暴露變量 $X$。

- 條件概率 conditional probability: 

$$
\begin{aligned}
\text{Pr}\{ Y(0) = 1 | X=1, C=0\} & = \frac{1}{2} \;\; \text{Pr}\{Y(0) = 1 | X=0, C=0 \} = \frac{1}{2}\\ 
\text{Pr}\{ Y(1) = 1 | X=1, C=0\} & = \frac{1}{4} \;\; \text{Pr}\{ Y(1) = 1 | X=0, C=0\}  = \frac{1}{4} \\
\text{Pr}\{ Y(0) = 1 | X=1, C=1\} & = \frac{3}{4} \;\; \text{Pr}\{ Y(0) = 1 | X=0, C=1\}  = \frac{3}{4} \\
\text{Pr}\{ Y(1) = 1 | X=1, C=1\} & = \frac{1}{2} \;\; \text{Pr}\{ Y(1) = 1 | X=0, C=1\}  = \frac{1}{2} 
\end{aligned}
$$

在 C 條件下，我們發現這個時候 $Y(0) = 1$ 和 $X$ 之間相互獨立，$Y(1) = 1$ 也和 $X$ 之間相互獨立了。這就是條件可置換性的最直觀展示。

### 鑑定 identification

假設 $X,Y$ 兩個變量都是二分類變量。我們關心他們二者之間的邊際因果危險度差: 

$$
\text{Pr}\{ Y(1) = 1 \} - \text{Pr}\{ Y(0) = 1 \}
$$

假定，**互相無幹擾前提成立**，用 $\mathbf{C}$ 標記要被控制的混雜變量向量。用概率論的全概率法則，

$$
\text{Pr}\{ Y(x) = 1 \} = \sum_c \text{Pr}\{ Y(x) = 1|C=c \} \text{Pr}(C=c)
$$


假定，**條件可置換的前提成立**，那麼上面的式子可以變成

$$
\sum_c\text{Pr}\{ Y(x) =1 | X=x, C=c \}\text{Pr}(C = c)
$$

這是因爲條件可置換性告訴我們，在 C 的條件下，潛在結果 $Y(x)$ 和實際觀測的暴露變量值之間相互獨立，所以可以在上面條件概率公式的右半邊可以加入 $X=x$。

假定，**一致性的前提成立**，那麼上面的式子有可以繼續變成

$$
\sum_c \text{Pr}\{ Y = 1 | X = x, C=c \}\text{Pr}(C=c)
$$

這是因爲一致性告訴我們，現實條件下 $X=x$ 時導致的結果變量 $Y$， 和平行世界中的潛在暴露變量 $(x)$ 導致導致的潛在結果 $Y(x)$ 相同。那麼，接下來就可以把編輯因果危險度差的式子推導成爲: 

$$
\begin{aligned}
\text{Pr}\{ & Y(1) = 1 \}  - \text{Pr}\{ Y(0) = 1 \} \\ 
                         & = \sum_c\text{Pr}(Y=1 | X=1,C = c)\text{Pr}(C=c)  \\
                         & \;\;\;\; -\sum_c\text{Pr}(Y=0 | X=1,C = c)\text{Pr}(C=c)
\end{aligned}
(\#eq:Causal-infe-1-1)
$$

```{definition}
**標準化和 g computation 公式**: 
$$\text{Pr}\{ Y(x) = 1 \} = \sum_c\text{Pr}(Y=1|X=x,C=c)\text{Pr}(C=c)$$
是我們在因果推斷中說的 g computation 公式的簡單例子。這個過程在流行病學中，被命名爲標準化 standardisation。所以，條件因果效應 (conditional causal effect): 
  
$$\text{Pr}(Y=1 | X=1, C=c) - \text{Pr}(Y=1 | X=1, C=c)$$ 
  
在這個 g computation 的過程中，被根據條件變量 C 在人羣衆的分布給標準化了。就是在這個根據條件變量的分布標準化 (或者叫邊際化 marginalisation) 的過程中，條件效應的含義華麗轉身變成了邊際因果效應 (marginal causal risk difference)。
```

```{definition}
**鑑定和估計 identification vs. estimation:** 在因果推斷的語境中，鑑定過程和估計過程被嚴格區分。

鑑定 identification 指的是，因果被估計量利用因果推斷的假設把無法觀察的概率分布用可以觀察的數據的分布推導計算的過程。

估計 estimation 指的是，當我們對因果關系鑑定完畢之後，接下來進行的用實際觀察數據來估計被估計量的過程。這個過程通常不需要再進行公式推導，會使用統計模型，這些統計模型自己又自帶另外的一些前提假設。

所以，鑑定過程的前提假設是因果推斷的命根，最最底層的前提。接下來的數據計算或者模型擬合帶來的別的假設和鑑定過程的假設有本質的區別。區分這兩個過程的另一目的還包括鑑定過程的前提假設基本上是無法找到統計學方法進行檢驗的 (untestable structual assumptions) 結構性假設。

**對機器學習的一點點暗示:**
在因果推斷中新興的一個重要話題 -- 機器學習 (machine learning，或者叫做 data-adaptive estimation techniques 數據適應性估計技巧) 在當今大數據時代顯得特別突出。常有人認爲，數據適應性估計技巧可以用於預測，但是不能用於因果推斷。這其實只能是說對了一部分。機器學習本身，其實是在給定了 (一大堆) 變量之後，尋找某個變量的最佳預測量。但是從我們目前爲止在因果推斷中的推導來看，相信你也能看出來，因果推斷本身也包括了預測的過程。因果推斷的第一個部分 -- 鑑定過程是處理的是因果之間的前提假設，以及判斷因果推斷中用到的參數怎樣和已觀察到的數據在這裏因果條件下連接起來 -- 這個部分是不能放到機器中去的。但是因果推斷的第二部分 -- 估計 -- 就是純粹的預測過程啦。這裏想強調的是機器學習的方法，可以被用在因果推斷的第二部分，而不是第一部分。第一部分還是要由人來完成。[@Laan2017]
```

```{example}
用前面的靜脈內鐵劑補充的24名患者數據來看，由於我們不切實際地假定了我們可以知道每個對象的所有潛在結果。所以，我們可以直接先用這個結果計算因果危險度差 (causal risk difference): 
  
$$\text{Pr}\{Y(1) = 1\} - \text{Pr}\{ Y(0) =1 \} = \frac{9}{24} - \frac{15}{24} = -\frac{1}{4}$$  
  
如果我們忽略掉患者貧血嚴重程度 C 的混雜效果，從觀察數據 X, Y, 計算獲得的粗危險度差 (crude risk difference) 就是 

$$\text{Pr}(Y=1 | X=1) - \text{Pr}(Y=1|X=0) = \frac{5}{12} - \frac{7}{12} = -\frac{1}{6}$$
  
可見在這個例子中，忽略了貧血嚴重程度時，粗危險度差是往無效的方向偏倚的。但是其實那些被給予了靜脈內鐵劑補充支持的患者本身體質就弱，貧血就嚴重，粗危險度差的結果掩蓋掉了補充鐵劑對患者實際存在的保護作用。

當考慮了貧血嚴重程度時，我們知道，在前提條件條件可置換性和一致性成立時，我們可以用\@ref(eq:Causal-infe-1-1) 來進行因果危險度差的計算: 
  
$$
\begin{aligned}
\text{Pr}\{ Y(1) = 1 \} & - \text{Pr}\{ Y(0) = 1 \} \\
& = \sum_{c=0}^1\text{Pr}(Y=1|X=1,C=c)\text{Pr}(C=c) \\ 
& \;\;\; - \sum_{c=0}^1\text{Pr}(Y=1|X=0,C=c)\text{Pr}(C=c) \\
& = \text{Pr}(Y=1|X=1,C=0)\text{Pr}(C=0) \\
& \;\;\; + \text{Pr}(Y=1|X=1,C=1)\text{Pr}(C=1) \\ 
& \;\;\; -  \text{Pr}(Y=1|X=0,C=0)\text{Pr}(C=0) \\
& \;\;\; - \text{Pr}(Y=1|X=0,C=1)\text{Pr}(C=1) \\
& = \frac{1}{4}\times\frac{1}{2} + \frac{1}{2}\times\frac{1}{2} - \frac{1}{2}\times\frac{1}{2} - \frac{3}{4}\times\frac{1}{2} \\
& = -\frac{1}{4} \\
\end{aligned}
$$
  
和前面計算的相吻合。
```

當 C 是連續型變量時，$\text{Pr}(C=c)$ 變成關於 $c$ 的概率密度方程，加號就變成了積分符號:


$$
\text{Pr}\{ Y(x) = 1 \} = \int_c \text{Pr}\{ Y(x) = 1 | \mathbf{C=c} \}p_\mathbf{C}(\mathbf{c})d\mu_\mathbf{C}(\mathbf{c}) 
$$

Where $p_\mathbf{C}(\cdot)$ is the joint probability density/mass function for $\mathbf{C}$, $\mu_\mathbf{C}(\mathbf{c})$ is a dominating measure (Lebesque for continuous components of $\mathbf{C}$ and counting measure otherwise).

By conditional exchangeability, this can be rewritten as:

$$
\int_c \text{Pr}\{ Y(x) = 1 | X=x, \mathbf{C=c} \}p_\mathbf{C}(\mathbf{c})d\mu_\mathbf{C}(\mathbf{c}) 
$$

By consistency, this is 

$$
\int_c \text{Pr}\{ Y = 1 | X=x, \mathbf{C=c} \}p_\mathbf{C}(\mathbf{c})d\mu_\mathbf{C}(\mathbf{c}) 
$$

Thus we have 

$$
\text{Pr}\{ Y(x) = 1 \} - \text{Pr}\{ Y(0) = 1 \} \\
= \int_c \text{Pr}\{ Y = 1 | X=1, \mathbf{C=c} \}p_\mathbf{C}(\mathbf{c})d\mu_\mathbf{C}(\mathbf{c}) - \\
 \int_c \text{Pr}\{ Y = 1 | X=0, \mathbf{C=c} \}p_\mathbf{C}(\mathbf{c})d\mu_\mathbf{C}(\mathbf{c}) 
$$


# Graphical Models 因果推斷的圖形模型

條件可置換性 (conditional exchangeability) 是因果推斷中最重要的前提假設。

$$
Y(x) \perp\perp X|\mathbf{C}, \forall x 
$$


當你的變量太多的時候，用圖形來表示變量之間的條件關系顯得十分直觀。有向無環圖 (Directed acyclic graphs, DAG) 就是能夠幫助我們理解變量之間條件獨立性關系的好工具。


## 統計學中的有向無環圖

```{definition}
**DAG**, 是一種包括了多個節點 (nodes)，並且用箭頭直線連接這些節點的一種示意圖，值得注意的是，我們用的 DAG 示意圖中，沒有閉環 (也就是沒有哪個節點會隨着箭頭回到該節點本身成爲一個閉環，所以叫做有向無環圖)。且，DAG示意圖中也沒有雙向箭頭鏈接任何兩個節點。
```


統計學中，DAG 用來表示一系列變量的聯合分布 (joint distribution)，它的箭頭指向表示了不同變量之間的向量關系。(DAGs are used to represent the factorisation of a joint distribution.) 如果一組變量組成向量 $\mathbf{V}=(V_1, V_2, V_3, V_4, V_5, V_6)$，且這些變量之間的聯合分布關系是這樣子: 

$$
\begin{aligned}
&p_\mathbf{V}(\mathbf{v}) = \\
&\;p_{V_1}(v_1)p_{V_2}(v_2)p_{V_3|V_1,V_2}(v_3|v_1,v_2)p_{V_4|V_1,V_3}(v_4|v_1,v_3)p_{V_5|V_1,V_2}(v_5|v_1, v_2)p_{V_6|V_5}(v_6|v_5)
\end{aligned}
$$

那麼這些變量之間關系對應的 DAG 圖就是這樣子: 

```{r DAG01, fig.asp=.7, fig.width=3.5, fig.cap="Example of a DAG", fig.align='center', out.width='50%', cache=TRUE}
g <- dagitty('dag {
    V6 [pos="2,0"]
    V4 [pos="1,-1"]
    V5 [pos="1,1"]
    V2 [pos="-1,-1"]
    V3 [pos="-1,1"]   
    V1 [pos="-2,0"]   

   V1 -> V4
   V1 -> V5 -> V6 
   V1 -> V3 -> V4 
   V2 -> V3 -> V4 
   V2 -> V5 -> V6
}')
plot(g)
```

上面長長的因子化 (factorisation) 公式可以簡略爲: 

$$
p_{\mathbf{V}}(\mathbf{v}) = \prod_jp_{V_j|S_j}(v_j|s_j)
$$

其中 $S_j$ 是 $V_j$ 的子集，在DAG圖中，我們可以添加從 $V_k$ 到 $V_j$ 箭頭的充分且必要條件是 $V_k \in \mathbf{S}_j$。

### DAG 和條件獨立性 conditional independence

DAG 圖包含了變量之間的條件獨立性關系。如果 $V_k$ 到 $V_j$ 沒有箭頭，意味着這兩個變量在所有其他有指向 $V_j$ 箭頭的變量的條件下，互相獨立: 


$$
V_4 \perp\perp V_2 | V_1, V_3
$$


### DAG 圖的術語 

```{definition}
**父與子 parent and child**: $V_i\rightarrow V_j$，那麼 $V_i$ 是 $V_j$ 的父，$V_j$ 是 $V_i$ 的子。圖\@ref(fig:DAG01)中 $V_2$ 是 $V_5$ 的父，$V_5$ 是 $V_2$ 的子。
```

```{definition}
**通路 path**: 從節點 $V_i$ 到另一個節點 $V_j$ 如果可以用 DAG 箭頭 (方向可左可右) 從頭到尾連接起來，成爲一個通路。$V_i, V_{k_1}, \cdots ,V_{k_n}, V_j$ 之間如果有通路，那麼這個通路上的每兩個變量之間都有一個箭頭連接 (無論哪個方向)。圖 \@ref(fig:DAG01) 中 $V_1\rightarrow V_3 \leftarrow V_2 \rightarrow V_5$ 是一條從 $V_1$ 到 $V_5$ 的通路。
```

```{definition}
**有向通路 directed path**: 從節點 $V_i$ 到節點 $V_j$ 之間如果有通路，且箭頭的方向只有從左往右，那麼這個通路被叫做有向通路。圖 \@ref(fig:DAG01) 中 $V_1\rightarrow V_5 \rightarrow V_6$ 是一條從 $V_1$ 到 $V_6$ 的有向通路。
```


```{definition}
**祖先與後代 ancestor and descendant**: 如果 $V_i$ 和 $V_j$ 之間有一條有向通路，那麼我們說 $V_i$ 是 $V_j$ 的祖先，$V_j$ 是 $V_i$ 的後代。圖 \@ref(fig:DAG01) 中 $V_2$ 是 $V_6/V_5$ 的祖先，$V_6/V_5$ 是 $V_2$ 的後代。
```


```{definition}
**對撞因子 collider**: 如果一條通路上的某個變量 $V_{K_i}$ 有左右兩個箭頭同時指向它本身，那麼$V_{K_i}$ 被叫做對撞因子。圖 \@ref(fig:DAG01) 中 $V_1\rightarrow V_3 \leftarrow V_2$，的通路上 $V_3$ 是一個對撞因子。
```

### 阻斷通路 blocking paths

```{definition}
當 $\mathbf{Z}\in\mathbf{V}$ 時，如果一條通路 $p$ 上存在一個節點 $W$ 滿足這兩個條件中的一個: (1) $W$ 是通路 $p$ 上的一個對撞因子，且 $W$ 和它的任何後代都 $\notin \mathbf{Z}$。(2) $W$ 不是通路 $p$ 上的對撞因子，且 $W\in\mathbf{Z}$。我們說 $\mathbf{Z}$ 阻斷了通路 $p$。
```

### 以對撞因子爲條件 conditioning on a collider

如下圖 \@ref(fig:DAG02) 所示，$V_3$ 取決於 $V_1, V_2$，且 $V_1, V_2$ 互相獨立。那麼給定了 $V_3$ 之後 $V_1, V_2$ 其實就變成了條件依賴的關系 (conditionally dependent)。盡管 $V_1, V_2$ 這兩個變量之間是邊際獨立 (marginally independent) 的關系。

```{r DAG02, fig.asp=.7, fig.width=3.5, fig.cap="Conditioning on a collider", fig.align='center', out.width='50%', cache=TRUE, echo=FALSE}
g <- dagitty('dag {
    V1 -> V3 ;
    V2 -> V3 ; 
}')
plot(graphLayout(g))
```


## 以非對撞銀子爲條件 conditioning on a non-collider

如果 $V_1,V_2$ 同時取決於 $V_3$: 

```{r DAG03, fig.asp=.7, fig.width=3.5, fig.cap="Conditioning on a non-collider (1)", fig.align='center', out.width='50%', cache=TRUE, echo=FALSE}
g <- dagitty('dag {
    V1 <- V3 -> V2
}')
plot(graphLayout(g))
```


那麼此時 $V_1,V_2$ 的關系是邊際依賴 (marginally dependent)，但是以 $V_3$ 爲條件獨立 (conditionally independent)。

假設三個變量之間的關系又變成: $V_3$ 取決於 $V_1$，$V_2$ 取決於 $V_3$: 


```{r DAG04, fig.asp=.7, fig.width=3.5, fig.cap="Conditioning on a non-collider (2)", fig.align='center', out.width='50%', cache=TRUE, echo=FALSE}
g <- dagitty('dag {
    V1 -> V3 -> V2
}')
plot(graphLayout(g))
```

類似地，此種情形底下， $V_1,V_2$ 的關系也是邊際依賴 (conditionally dependent)，但是以 $V_3$ 爲條件獨立 (conditionally independent)。

### 條件的總結

- 以 $V_3$ 爲條件會殺死 圖 \@ref(fig:DAG03) 和 \@ref(fig:DAG04) 中 $V_1, V_2$ 之間的關系;
- 以 $V_3$ 爲條件會創建 圖 \@ref(fig:DAG02) 中 $V_1, V_2$ 之間的關系; 
- 以 $V_3$ 爲條件會阻斷 圖 \@ref(fig:DAG03) 和 \@ref(fig:DAG04) 中 $V_1, V_2$ 之間的關系;
- 以 $V_3$ 爲條件會解鎖 圖 \@ref(fig:DAG02) 中 $V_1, V_2$ 之間的關系。

### D 分離 d-separation 


```{definition}
一組變量組成的向量 $\mathbf{V}$，如果它的三個沒有交集的子集向量 $\mathbf{X,Y,Z}$ 之間中的一個 $\mathbf{Z}$ 把 $\mathbf{X}$ 到 $\mathbf{Y}$ 的通路**全部阻斷** (block)，我們說 $\mathbf{Z}$ 把 $\mathbf{X}$ 中的任何一個節點到 $\mathbf{Y}$ 中任何一個節點 d 分離了 (d-seperate)。
```

```{example}
圖 \@ref(fig:DAG04) 中，$V_2$ 是否阻斷了 $V_3$ 到 $V_6$ 的通路呢？

從 $V_3$ 到 $V_6$ 的通路一共有如下幾條:

$$
\begin{aligned}
1.& V_3 \leftarrow V_1 \rightarrow V_5 \rightarrow V_6 \\
2.& V_3 \leftarrow V_2 \rightarrow V_5 \rightarrow V_6 \\
3.& V_3 \rightarrow V_4 \leftarrow V_1 \rightarrow V_5 \rightarrow V_6
\end{aligned}
$$

其中，第 2,3 條通路，是被 $V_2$ 阻斷了的，但是第 1 條沒有被 $V_2$ 阻斷。
因此，我不能說 $V_2$ 把 $V_3$ 到 $V_6$ 之間的全部通路阻斷 (d-分離，d-separation)。
```


```{r DAG05, fig.asp=.7, fig.width=3.5, fig.cap="Example of a DAG", fig.align='center', out.width='50%', cache=TRUE, echo=FALSE}
g <- dagitty('dag {
    V6 [pos="2,0"]
    V4 [pos="1,-1"]
    V5 [pos="1,1"]
    V2 [pos="-1,-1"]
    V3 [pos="-1,1"]   
    V1 [pos="-2,0"]   

   V1 -> V4
   V1 -> V5 -> V6 
   V1 -> V3 -> V4 
   V2 -> V3 -> V4 
   V2 -> V5 -> V6
}')
plot(g)
```



```{theorem}
**D分離和條件獨立性**: 如果 $\mathbf{X, Y, Z}$ 之間互無交集，且 $\mathbf{Z}$ d 分離了從 $\mathbf{X}$ 到 $\mathbf{Y}$ 之間的所有通路那麼有: 
  
  $$\mathbf{X}\perp\perp\mathbf{Y|Z}$$
```


根據 D 分離的定義來看，通過 DAG 圖，可以直觀地分析一組變量和另一組變量在已第三組變量爲條件的基礎上通路的變化和變量之間的獨立性。以某組變量爲條件之後，很可能阻斷了某些通路的同時，又解鎖了某些通路，當殺死一些通路的同時，可能建立起其他變量之間的聯系。這是一個有內在邏輯聯系的關系網絡。

變量之間通路的打開，阻斷，d 分離過程，用手繪制當然可行，但是變量如果很多，這個過程就顯得太過於繁瑣，幸好我們已經有了完美的解決方案，可以使用[在線DAG工具: www.dagitty.net](www.dagitty.net)。





# Regression Methods with continuous outcomes 結果變量爲連續型變量

## 用於對連續型結果變量做因果推斷的被估計量 

邊際潛在結果的差 marginal potential outcomes:

$$
E\{ Y(1) - Y(0) \}
$$

或者是條件下潛在結果的差 conditional potential outcomes:

$$
E\{ Y(1) - Y(2) | \mathbf{V = v} \}
$$

邊際潛在結果的差，有專門的名字: the *Average Causal Effect (ACE) 平均因果效應* 或者叫 *Average Treatment Effect 平均治療效應*。這裏的 "treatment" 其實不是特指治療，而是泛指所有我們想要比較的暴露。

## 鑑定 identification - revision

### 條件因果均差 conditional causal mean difference

$$
\begin{aligned}
E\{ Y(1) - Y(0) | \mathbf{C = c} \} & =  E\{ Y(1) | \mathbf{C=c} \} - E\{ Y(0) | \mathbf{C=c} \} \\
 \text{(By} & \text{ conditional exchangeability given } \mathbf{C}:) \\
&= E\{  Y(1) | X = 1, \mathbf{C=c} \} - E\{  Y(0) | X = 0, \mathbf{C=c} \}  \\
 \text{(By} & \text{ consistency:)} \\ 
& =   E\{  Y | X = 1, \mathbf{C=c} \} - E\{  Y | X = 0, \mathbf{C=c} \}  \\
\end{aligned}
$$


### 簡單分類型條件變量 $C$ 的 ACE

$$
\begin{aligned}
E\{ Y(1) - Y(0)\}  & = \sum_cE\{ Y(1) | C=c \}\text{Pr}(C = c) - \sum_c E\{ Y(0) | C=c \}\text{Pr}(C=c) \\
 \text{(By} & \text{ the law of total probability }\uparrow) \\ 
& =  \sum_cE\{  Y(1) | X = 1, \mathbf{C=c} \}\text{Pr}(C=c) \\
& \;\;\;\;\;\;\;\;\;- \sum_cE\{  Y(0) | X = 0, \mathbf{C=c} \} \text{Pr}(C = c) \\
 \text{(By} & \text{ conditional exchangeability }\uparrow) \\
& = \sum_cE\{  Y | X = 1, \mathbf{C=c} \}\text{Pr}(C=c) \\ 
& \;\;\;\;\;\;\;\;\;- \sum_cE\{  Y | X = 0, \mathbf{C=c} \} \text{Pr}(C = c) \\
 \text{(By} & \text{ consistency }\uparrow) \\ 
& = \sum_c\{ E(Y|X = 1, C=c) -E(Y|X=0, C=c) \}\text{Pr}(C=c)
\end{aligned}
(\#eq:causalinfer3-2)
$$

### 簡單連續型條件變量 $C$ 的ACE



$$
\begin{aligned}
E\{ Y(1) - Y(0)\}  & = \int_cE\{ Y(1) | C=c \}f_C(c)\text{d}c - \int_c E\{ Y(0) | C=c \}f_C(c)\text{d}c \\
& =  \int_cE\{  Y(1) | X = 1, \mathbf{C=c} \}f_C(c)\text{d}c \\ 
 & \;\;\;\;\;\;\;\;\;- \int_cE\{  Y(0) | X = 0, \mathbf{C=c} \} f_C(c)\text{d}c \\
& = \int_cE\{  Y | X = 1, \mathbf{C=c} \}f_C(c)\text{d}c \\
& \;\;\;\;\;\;\;\;\;- \int_cE\{  Y | X = 0, \mathbf{C=c} \} f_C(c)\text{d}c \\
& = \int_c\{ E(Y|X = 1, C=c) -E(Y|X=0, C=c) \}f_C(c)\text{d}c
\end{aligned}
(\#eq:causalinfer3-3)
$$



## 通過線性回歸模型來估計 ACE

### 條件因果均值差

假設$Y,X$分別表示結果變量和暴露變量，有三個變量需要調整 (做爲條件變量): $C_1$ 連續型，$C_2$ 二分類型(0/1)，$C_3$ 分類型(0/1/2/3)，然後我們擬合的線性回歸模型如下: 

$$
\begin{aligned}
E(Y|X = x, C_1 = c_1, C_2 = c_2, C_3 = c_3) & = \alpha + \beta_Xx + \gamma_{C_1}c_1 + \gamma_{C_2}c_2 \\
 \;\;\; +\gamma_{C_{31}}I(c_3 =1)+&\gamma_{C_{32}}I(c_3 =2)+\gamma_{C_{33}}I(c_3 =3)
\end{aligned}
(\#eq:causalinfer3-4)
$$


如果，**無相互幹擾 no interference，一致性 consistency，條件可置換性 conditional exchangeability**三個最主要的前提條件得到滿足，加上，公式 \@ref(eq:causalinfer3-4) 中三個條件變量得到了正確的模型敘述 (specification of the model is correct)。那麼，這個模型估計的回歸系數 $\beta_Xx$ 就可以被賦予因果關系的解讀: 

$$
E\{ Y(1) -Y(0) |\mathbf{C=c}\}
$$


```{example}
**孕期吸煙和嬰兒出生體重的關系**: 數據來自[@Cattaneo2010d]
  結果變量是出生體重 `bweight`，暴露變量是孕期母親是否吸煙 `mbsmoke`。這裏先只考慮3個條件變量: 懷孕時的年齡 `mage`，嬰兒是否是該母親的第一個孩子 `fbaby`，三個懷孕階段中，該母親第一次訪問婦產科醫生的時間段 `prenatal`，那麼我們可以擬合的最簡單模型其實是這樣的: 
```

```{r CI-3-1, echo=TRUE, eval = TRUE, cache=TRUE}
cattaneo2 <- read_dta("backupfiles/cattaneo2.dta")
Cat_mod <- lm(bweight ~ as.factor(mbsmoke) + mage + as.factor(fbaby) + as.factor(prenatal), data = cattaneo2)
summary(Cat_mod)
```

在**無相互幹擾 no interference，一致性 consistency，條件可置換性 conditional exchangeability，和該模型是正確模型**的前提下，線性回歸的結果 `-252.26` 可以被賦予因果推斷的解釋: **在懷孕年齡，嬰兒是否是第一胎，第一次訪問婦產科醫生的孕期時期都相同的條件下，如果比較一個懷孕母親全部都在吸煙，和另一個懷孕母親全部都沒有在吸煙的兩個潛在世界，孕期吸煙的世界的母親生的嬰兒平均出生體重比另一個全部都不吸煙的母親生的嬰兒的出生體重輕 252.3 克。且在我們擬合的模型中，認爲這個新生兒體重的差在其他條件變量取任何值時都保持不變。**

**模型是正確的**這個前提其實是可以放寬的，因爲你可能會擬合這樣一個線性回歸模型: 


```{r CI-3-2, echo=TRUE, eval = TRUE, cache=TRUE}
Cat_mod2 <- lm(bweight ~ as.factor(mbsmoke) + mage + I(mage^2) + as.factor(fbaby)*as.factor(prenatal), data = cattaneo2)
summary(Cat_mod2)
```


這個模型裏，我們給懷孕時年齡擬合了二次項，又允許 `fbaby` 和 `prenatal` 之間有交互作用，但是，這並不妨礙我們對我們最關心的因果關系 `mbsmke` 的回歸系數的解讀，因爲這兩個模型的結果基本沒有差別。

還有別人可能給出的模型是這樣的: 

```{r CI-3-3, echo=TRUE, eval = TRUE, cache=TRUE}
Cat_mod3 <- lm(bweight ~ as.factor(mbsmoke)*as.factor(fbaby) + mage + I(mage^2) + as.factor(prenatal), data = cattaneo2)
summary(Cat_mod3)
```


模型 `Cat_mod3` 中，`mbsmoke` 和新生兒體重之間的因果關系的解釋發生了變化，因爲我們對 `mbsmoke` 和 `fbaby` 之間的交互作用進行了檢驗，是有意義的 `p = 0.0024*`。這時候，在**無相互幹擾 no interference，一致性 consistency，條件可置換性 conditional exchangeability，和該模型是正確模型**的前提下，且模型 `Cat_mod3` 是正確的話，數據中的因果關系解釋及就不止一個了: `-304.71` 的條件因果關系均差 (conditional causal mean difference) 是針對那些已經有過孩子媽媽來說的; `-304.71 + 132.784 = -171.9` 這一條件因果關系均差 (conditional causal mean difference) 是對那些第一次懷孕當媽媽的人來說的。吸煙這個本來應該十分有害的行爲，對新生兒體重的影響因果關系似乎在第一次當媽媽的人當中影響較小 (這個因果關系陳述以相同懷孕年齡，和有相同的第一次訪問產科醫生時期爲前提)。


### 效應修正 effect modification 和 交互作用 interaction


在上文中模型 `Cat_mod3` 中，如果模型是正確的，且無互相幹擾，一致性，條件可置換性前提都得到滿足時，嬰兒是否是第一胎 `fbaby` 這一變量，對於我們研究的暴露變量 `mbsmoke` (孕期吸煙) 和結果變量 `bweight` (新生兒體重) 之間的關系起到了效應修正作用 (effect modification)。因爲我們看到該模型的結果是孕期吸煙對新生兒體重的影響因爲嬰兒是否是第一胎而發生了很大的變化。流行病學中把這個稱爲交互作用 (interaction)。但是，在因果推斷的研究領域中，傾向於把效應修正和交互作用加以區分。效應修正指對我們關心的關系造成效應修正的變量本身，並沒有因果關系的解釋 (effect modification is not causal with respect to the second variable)，**對因果關系造成了效應修正的變量本身，沒有"無互相幹擾，一致性，條件可置換性"前提的要求**。它只是衆多的條件變量之一。

**相反，因果推斷的研究中，把交互作用的專有名詞保留給兩個暴露變量之間，也就是發生了交互作用的兩個變量，都是要研究的暴露變量，都有和結果變量之間因果關系的討論，所以兩個發生了交互作用的暴露變量，都需要滿足"無互相幹擾，一致性，條件可置換性"前提。**


假如不光研究孕期吸煙，研究者還想一起研究孕期飲酒習慣 $(X_2)$，和吸煙習慣 $(X_1)$ 共同對新生兒體重的因果關系影響:

$$
\{ X_1, X_2 \} \perp\perp Y(x_1, x_2) | \mathbf{C}, \forall x_1,x_2
$$


所以，只有當暴露變量有兩個時 (因爲要同時對飲酒習慣和吸煙習慣兩個暴露變量做潛在結果分析 potential outcome)，才會用到交互作用 (interaction)。

### 分類型條件變量的平均因果效應 (ACE) 

Average Causal Effect (ACE) 平均因果效應: 

$$
E\{ Y(1) - Y(0) \}
$$

在只有一個分類型條件變量的情況下，我們推導過其 ACE (See equations: \@ref(eq:causalinfer3-2)):

$$
\sum_c\{ E(Y|X=1, C=c) - E(Y|X=0, C=c) \}\text{Pr}(C=c)
$$

假設分類條件變量 $C$ 有四個水平 $0/1/2/3$，那麼我們可以針對 $C$ 的每一層水平擬合線性回歸模型:

$$
\begin{aligned}
E(Y|X=x, C=c) & = \alpha + \beta_0 x + \gamma_1 I(c=1) + \gamma_2 I(c=2) + \gamma_3 I(c=3) \\
& \;\;\; + \beta_1 xI(c = 1) + \beta_2 x I(c=2)  + \beta_3 x I (c=3)
\end{aligned}
(\#eq:CI-3-5)
$$


模型 \@ref(eq:CI-3-5) 是一個飽和模型，因爲 X 和 C 之間一共只有四種分組組合，我們又擬合了一個含有 8 個參數的模型。也就是說，這個模型允許這 8 種 X 和 C 之間的分組，每組都有不同的結果。

$$
\begin{aligned}
          \beta_0 & = E(Y|X=1,C=0) - E(Y|X=0, C=0) \\
\beta_0 + \beta_1 & = E(Y|X=1,C=1) - E(Y|X=0, C=1) \\
\beta_0 + \beta_2 & = E(Y|X=1,C=2) - E(Y|X=0, C=2) \\
\beta_0 + \beta_3 & = E(Y|X=1,C=3) - E(Y|X=0, C=3) \\
\end{aligned}
$$


爲了簡便起見，給他們分別命名: 

$$
\begin{aligned}
\beta_0 & = \eta_0 \\
\beta_0 + \beta_1 & = \eta_1 \\
\beta_0 + \beta_2 & = \eta_2 \\
\beta_0 + \beta_3 & = \eta_3
\end{aligned}
$$


在只有一個分類型條件變量時，當無相互幹擾，一致性，和條件可置換性的前提被滿足，我們可以把公式 \@ref(eq:causalinfer3-2) 中的 $E(Y|X=1, C=c) - E(Y|X=0, c=c)$ 全部替換成爲 $\eta_c$: 

$$
\begin{aligned}
E\{ Y(1) - Y(0) \} & = \sum_c\{ E(Y|X=1, C=c) - E(Y|X=0, c=c)\}\text{Pr}(C = c) \\
& = \sum_c \eta_c \text{Pr}(C=c)
\end{aligned}
$$



```{r CI-3-4, echo=TRUE, eval = TRUE, cache=TRUE}
Cat_mod4 <- lm(bweight ~ as.factor(mbsmoke)*as.factor(prenatal), data = cattaneo2)
summary(Cat_mod4)
```

$$
\begin{aligned}
\widehat{\eta_0} & = -317.2 \\
\widehat{\eta_1} & = -317.2 + 35.9 = -281.2 \\
\widehat{\eta_2} & = -317.2 + 163.5 = -153.7\\
\widehat{\eta_3} & = -317.2 + 87.2 = -230.0 \\
\end{aligned}
$$


爲了估計平均因果效應，我們還需要 `prenatal` 的分布概率: 

```{r CI-3-5, echo=TRUE, eval = TRUE, cache=TRUE} 
with(cattaneo2, tab1(prenatal, graph = F))
```

所以: 

$$
\begin{aligned}
\widehat{ACE} & = \sum_c \widehat{\eta_c}\widehat{\text{Pr}}(C=c) \\
& = -317.2 \times \frac{70}{4642} -281.2\times\frac{3720}{4642} -153.7\times\frac{697}{4642}-230.0\times\frac{155}{4642} \\
& = -260.9
\end{aligned}
$$


### Positivity 非零性
 
當我們用下面的飽和模型的時候，八個可能的分組中，每個格子裏都不能是零，這一前提條件被成爲非零性 (positivity)。

```{r CI-3-6, echo=TRUE, eval = FALSE, cache=TRUE}
Cat_mod4 <- lm(bweight ~ as.factor(mbsmoke)*as.factor(prenatal), data = cattaneo2)
```

用概率來表達，就是，在所有可能的 $c$ 層中的對象，其中暴露變量爲 1 的概率必須在 0, 1 之間: 

$$
\textbf{Positivity: } \text{if Pr}(C=c) > 0 \text{ then: } 0<\text{Pr}(X=1|C=c) <1  
$$

### 連續型變量的平均因果效應



```{r CI-3-7, echo=TRUE, eval = TRUE, cache=TRUE}
Cat_mod5 <- lm(bweight ~ factor(mbsmoke) + mage*factor(mbsmoke) + I(mage^2)*factor(mbsmoke), data = cattaneo2)

summary(Cat_mod5)

with(cattaneo2, summ(mage, graph = F))
with(cattaneo2, summ(mage^2, graph = F))


Y <- cattaneo2$bweight
# X <- with(cattaneo2, cbind(fbaby, mmarried, alcohol, fedu, mage))
X <- with(cattaneo2, cbind(mage, mage^2))
treat <- cattaneo2$mbsmoke
fit1<-ATE(Y,treat,X)

summary(fit1)

```

$$
\begin{aligned}
\widehat{\beta_0} & = 1121.035 \\
\widehat{\beta_1} & = -92.690 \\ 
\widehat{\beta_2} & = 1.444 \\
\Rightarrow \widehat{ACE} & = 1121.035 - 92.690\times26.505 + 1.444\times734.056 \\ 
& = -275.7
\end{aligned}
$$


和 STATA 的 `teffects ra` 結果做個對比: 

```
. teffects ra (bweight mage mage2) (mbsmoke)

Iteration 0:   EE criterion =  9.667e-23  
Iteration 1:   EE criterion =  7.554e-27  

Treatment-effects estimation                    Number of obs     =      4,642
Estimator      : regression adjustment
Outcome model  : linear
Treatment model: none
----------------------------------------------------------------------------------------
                       |               Robust
               bweight |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-----------------------+----------------------------------------------------------------
ATE                    |
               mbsmoke |
(smoker vs nonsmoker)  |  -275.9901   22.74918   -12.13   0.000    -320.5777   -231.4025
-----------------------+----------------------------------------------------------------
POmean                 |
               mbsmoke |
            nonsmoker  |   3409.482   9.284654   367.22   0.000     3391.284    3427.679
----------------------------------------------------------------------------------------
```

小數點以後的略差異應該是四舍五入的差異。別的估計包括 Robust Std. Err. 都是十分接近的。

## Practical03 - causal inference



注意: 這裏的練習使用的是STATA 因爲，我在 R 裏找不到像 STATA 的 `teffects` 這樣靈活且方便的命令，如果你知道，歡迎告訴我: abelardccwang@gmail.com。


```{r switch_engine, echo=TRUE, message=FALSE}
require(knitr)
statapath <- "/usr/local/stata/stata" # <- 設定你的 STATA 路徑
opts_chunk$set(engine="stata", engine.path=statapath, comment="")
```

數據還是吸煙和新生兒體重的關系的數據: 

```{r description, cache=TRUE, echo=FALSE}
use "backupfiles/cattaneo2.dta"
describe
tab mbsmoke

summ bweight, detail

*1. 用簡單線性回顧分析一下 `mbsmoke` 和 `bweight` 之間的關系: 
*a) 
regress bweight i.mbsmoke


*b) 

regress bweight i.mbsmoke i.fbaby

*2. 調整了 `fbaby` 之後，暴露和結果之間的關系發生了怎樣的變化？
//說明 `fbaby` 是什麼類型的混雜因子？

*看兩個結果的報告，吸煙的線性回歸系數從調整 `fbaby` 前的 `-275.25`，
// 絕對值變大爲 `-281.06`，這是一種負方向混雜 (negative confounding)。
// 這種混雜可以分析 `fbaby` 和 `mbsmoke` 以及 `bweight`
// 各自的關系看出，懷第一胎的母親比較少吸煙，且第一胎嬰兒的出生體重
// 均值比不是第一胎嬰兒的出生體重要低: 

tab fbaby mbsmoke, row

tabstat bweight, by(fbaby)

tabstat bweight, by(mbsmoke)

// 這裏需要重新強調的是，通過比較調整新變量前後的回歸系數的變化，
// 能且僅僅只能在線性回歸模型 (可壓縮模型) 時使用，邏輯回歸中不適用。


*3 在怎樣的假設條件下，這裏的線性回歸模型的回歸系數 `mbsmoke` 
// 可以被賦予因果關系？

// 1. 無相互幹擾 no interference: 一個懷孕母親吸煙與否，和另一個母親
//    生下的嬰兒的出生體重之間沒有關系。
// 2. 一致性 consistency: 實際觀察到的孕期吸煙母親的嬰兒出生體重，和
//    潛在條件下 (當一個懷孕母親被強制吸煙時) 的嬰兒出生體重 (潛在結果)
//    是相同的。同樣地，在另一種潛在條件下 (懷孕母親被禁止吸煙時) 的
//    嬰兒出生體重 (潛在結果)，和實際觀察到的不吸煙的母親生下的嬰兒體重
//    是相同的。
// 3. 條件可置換性 conditional exchangeability: 在 `fbaby` 的各個組別中，
//    兩種潛在暴露造成的潛在結果，調整了其它共變量之後，和她們真實的暴露情況
//    (母親是否吸煙)之間是相互獨立的。在這個模型裏，我們只調整了 `fbaby` 
//    一個共變量，所以如果要給它的回歸系數加上因果關系結論，還必須假設 (雖然
//    很可能不合理) 控制 `fbaby` 這個單一的變量，就完全調整了了母親孕期吸煙和
//    新生兒體重之間關系的全部混雜因素。
// 4. 模型被正確擬合 correct specification of the regression model: 這是指，
//    模型中加入的變量與變量之間的關系，被正確地擬合了，因爲目前只有兩個
//    分類型變量在模型中，且該模型沒有加入交互作用項，那麼這條前提假設的含義
//    就是，我們認爲 `fbaby` 對孕期吸煙和新生兒體重之間的關系沒有交互作用。

*4 在前面解釋過的因果關系的前提條件下，要給 `mbsmoke` 一個因果關系的解釋
// 的話，(b) 模型的回歸系數該怎麼解釋呢？用潛在結果的概念解釋。

//    在 3. 的前提條件下， `mbsmoke` 的回歸系數的因果關系解讀可以是: 
//    當條件變量 `fbaby` 嬰兒是否是第一胎的變量保持不變時，281.0638 是暴露
//    (孕期吸煙) 導致的新生兒體重下降的量，其95%信賴區間是 (238.9961, 323.1314)。
//    這是一個潛在結果的差，所以假如所有的媽媽孕期都吸煙，和所有的媽媽孕期都
//    不吸煙相比(潛在暴露)，嬰兒的出生平均體重要輕 281.0638 克: 
//     E{Y(1) | C = c} - E{Y(0) | C = c} = 281.0638

*5 用 STATA 的 `teffects ra` 命令擬合相同的模型: 
  
teffects ra (bweight fbaby) (mbsmoke)

// 因果均差 (ACE) 的估計在 STATA 被叫做 `ATE`，但是估計的結果略低於
// 模型 (b) 的結果: -273.1552 vs. -281.0638。

*6 在線性回歸模型中加入 `i.mbsmoke##i.fbaby` 的交互作用項，試着計算
// `fbaby` 爲 0/1 時各自的 `mbsmoke` 回歸系數: 
  
regress bweight i.mbsmoke##i.fbaby
est store a

*to get the stratum specific effects: 

lincom 1.mbsmoke  // when baby is not first born 

lincom 1.mbsmoke + 1.mbsmoke#1.fbaby // when baby is first born

*7 計算 `fbaby` 各組所佔的百分比: (爲了計算孕期吸煙導致的新生兒體重下降
// 的邊際效應 marginal effect)

tab fbaby

*8 用 6, 7 的結果，手動計算一下 ACE 的估計量: 
  

*now restore model estimates
est restore a 

lincom 0.562*1.mbsmoke  + 0.438*(1.mbsmoke + 1.mbsmoke#1.fbaby)

margins, dydx(mbsmoke) // 你也可以用這個 margins 的命令，很方便，但是它估計的標準誤不使用穩健統計學方法，所以略有不同。

*9 爲什麼沒有加交互作用項的模型 (b) 給出的回歸系數估計和 `teffects ra`
// 的結果相差很大？

//   這是因爲如果給模型 (b) 的回歸系數賦予因果關系的解釋的話，第四個前提假設
//   -- 模型選擇正確且變量在模型中的形式也是正確 -- 太過樂觀了。這個前提假設
//   認爲沒有交互作用，但是，如果你看加交互作用項的第三個模型中，交互作用項
//   的回顧系數其實是有意義的 (有證據顯示交互作用存在): 
  
// mbsmoke#|
//       fbaby |
// smoker#Yes  |   152.2046   44.02482     3.46   0.001     65.89506    238.5142  

*10 現在給模型中加入更多的共變量，用兩種命令分別擬合，比較其結果:
  
regress bweight mbsmoke fbaby mmarried alcohol fedu mage


teffects ra (bweight fbaby mmarried alcohol fedu mage) (mbsmoke)


//   此時我們發現，簡單現行回歸估計的因果均值差(ATE)總是和考慮了更復雜關系的模型相比
//   相差較多。

*11 你可以用下面的非 teffects 代碼還原上面的計算: 
  
 qui regress bweight mbsmoke fbaby mmarried alcohol fedu mage if mbsmoke==0
 predict Y0
 
 qui regress bweight mbsmoke fbaby mmarried alcohol fedu mage if mbsmoke==1
 predict Y1
 
 sum Y0
 gen E0=r(mean) 
 
 sum Y1
 gen E1=r(mean)
 
 gen ACE = E1-E0 
 sum ACE 
 
 // 或者使用方便的 margins
 
qui regress bweight i.mbsmoke fbaby mmarried alcohol fedu mage ///
		i.mbsmoke#i.fbaby i.mbsmoke#i.mmarried i.mbsmoke#i.alcohol i.mbsmoke#c.fedu ///
		i.mbsmoke#c.mage
		
margins, dydx(mbsmoke)

// 值得注意的是，即使是使用 `teffects ra` 我們可能對模型形式的指定還是過於簡單，
// 例如上面的模型中加入了許多變量，但是 STATA 其實並沒有考慮有三個或者三個以上
// 變量之間發生交互作用的情況，而且， `fedu, mage` 被認爲和結果變量 `bweight`
// 呈簡單一次的線性關系。
```


```{r switch_engine01, echo=TRUE, message=FALSE}
require(knitr)
# statapath <- "/usr/local/stata/stata" # <- 設定你的 STATA 路徑
opts_chunk$set(engine="R")
```



# Regression Methods with binary outcomes 結果變量爲二分類變量 

## 二分類結果變量的因果被估計量 (causal estimand): 

Average causal effect (因果邊際危險度差，marginal causal risk difference), ACE : 

$$
\text{Pr}\{Y(1) = 1\} - \text{Pr}\{Y(0) = 1\}
$$

因果邊際危險度比 (marginal causal risk ratio):

$$
\frac{\text{Pr}\{Y(1) = 1\}}{\text{Pr}\{Y(0) = 1\}}
$$


或，因果邊際比值比 (marginal causal odds ratio):

$$
\frac{[\frac{\text{Pr}\{Y(1) = 1\}}{1-\text{Pr}\{Y(1) = 1\}}]}{[\frac{\text{Pr}\{Y(0) = 1\}}{1-\text{Pr}\{Y(0) = 1\}}]}
$$

或，因果邊際對數危險度比/比值比: 


$$
\log\{\text{Pr}\{Y(1) = 1\}\} - \log\{\text{Pr}\{Y(0) = 1\} \}
$$


$$
\log[\frac{\text{Pr}\{Y(1) = 1\}}{1-\text{Pr}\{Y(1) = 1\}}] - \log[\frac{\text{Pr}\{Y(0) = 1\}}{1-\text{Pr}\{Y(0) = 1\}}]
$$

和上一章節一樣，我們可能實際上還會關心這些被估計量的調整後的條件平均因果效應 (conditinal ACE): 

$$
\text{Pr}\{Y(1) = 1 | \mathbf{V=v} \} - \text{Pr}\{Y(0) = 1 | \mathbf{V=v}\}\\ 
\log\{\text{Pr}\{Y(1) = 1| \mathbf{V=v}\}\} - \log\{\text{Pr}\{Y(0) = 1| \mathbf{V=v}\} \}\\
\log[\frac{\text{Pr}\{Y(1) = 1 | \mathbf{V=v}\}}{1-\text{Pr}\{Y(1) = 1 | \mathbf{V=v}\}}] - \log[\frac{\text{Pr}\{Y(0) = 1 | \mathbf{V=v}\}}{1-\text{Pr}\{Y(0) = 1 | \mathbf{V=v}\}}]
$$

### 比值比的不可壓縮性 non-collapsibility of the odds ratio




# Prospensity Score 傾向性評分  

# Inverse probability weighted estimation and doubly robust methods 

# Causal mediation analysis 


